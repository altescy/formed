
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://altescy.github.io/formed/reference/integrations/torch/">
      
      
        <link rel="prev" href="../sentence_transformers/">
      
      
        <link rel="next" href="../transformers/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Torch - Formed</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#torch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Formed" class="md-header__button md-logo" aria-label="Formed" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Formed
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Torch
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/altescy/formed" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    altescy/formed
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../quick_start/" class="md-tabs__link">
        
  
  
    
  
  Quick Start

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../tutorials/" class="md-tabs__link">
          
  
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../guides/" class="md-tabs__link">
          
  
  
  Guides

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  
  API Reference

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Formed" class="md-nav__button md-logo" aria-label="Formed" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Formed
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/altescy/formed" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    altescy/formed
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../quick_start/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Tutorials
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Tutorials
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/text_classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/causal_lm_finetuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Causal LM Finetuning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Integrations
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Integrations
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/integrations/ml/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/integrations/torch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Torch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" checked>
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Integrations
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Integrations
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../datasets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Datasets
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../flax/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Flax
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MLflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sentence_transformers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    SentenceTransformers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Torch
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Torch
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.context" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;context
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.context.use_device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;use_device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.context.get_device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_device
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;dataloader
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" dataloader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.ItemT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;ItemT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DataLoader
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DataLoader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.batch_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;batch_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;shuffle
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.collate_fn" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;collate_fn
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.num_workers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;num_workers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.drop_last" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;drop_last
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.pin_memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;pin_memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.kwargs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;kwargs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;distributors
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" distributors">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SingleDeviceDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" SingleDeviceDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DataParallelDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DataParallelDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DistributedDataParallelDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DistributedDataParallelDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.local_rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;local_rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;initializers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" initializers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.BaseTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.UniformTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;UniformTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.NormalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;NormalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.XavierUniformTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;XavierUniformTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.XavierNormalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;XavierNormalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.KaimingUniformTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;KaimingUniformTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.KaimingNormalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;KaimingNormalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.OrthogonalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;OrthogonalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.SparseTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SparseTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.ZerosTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ZerosTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.OnesTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;OnesTensorInitializer
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;model
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.model.BaseTorchModel" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseTorchModel
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseTorchModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.model.BaseTorchModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;schedulers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" schedulers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CosineLRScheduler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" CosineLRScheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.t_initial" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;t_initial
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.lr_min" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;lr_min
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_mul" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cycle_mul
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_decay" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cycle_decay
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_limit" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cycle_limit
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_t" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_t
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_lr_init" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_lr_init
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_prefix" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_prefix
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.t_in_epochs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;t_in_epochs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.base_lrs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;base_lrs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_steps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.get_lr" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_lr
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.get_cycle_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_cycle_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;state_dict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.load_state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load_state_dict
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;utils
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.PoolingMethod" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;PoolingMethod
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.set_random_seed" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;set_random_seed
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.ensure_torch_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ensure_torch_tensor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.move_to_device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;move_to_device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.determine_ndim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;determine_ndim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.masked_pool" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;masked_pool
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;embedders
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" embedders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.SurfaceBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;SurfaceBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PostagBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;PostagBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.CharacterBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;CharacterBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenVectorBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;TokenVectorBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;IVariableTensorBatch
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" IVariableTensorBatch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.tensor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;tensor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.mask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mask
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;IAnalyzedTextBatch
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" IAnalyzedTextBatch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.surfaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;surfaces
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.postags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;postags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.characters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;characters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.token_vectors" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;token_vectors
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.EmbedderOutput" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;EmbedderOutput
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" EmbedderOutput">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.EmbedderOutput.embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.EmbedderOutput.mask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mask
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.BaseEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.BaseEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.BaseEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;PassThroughEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" PassThroughEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;PretrainedTransformerEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" PretrainedTransformerEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_vocab_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_vocab_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.train" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;AnalyzedTextEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" AnalyzedTextEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;encoders
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LSTMSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" LSTMSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.lstm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;lstm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;GRUSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" GRUSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.gru" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;gru
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ResidualSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ResidualSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FeedForwardSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" FeedForwardSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;StackedSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" StackedSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BasePositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BasePositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SinusoidalPositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" SinusoidalPositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.pe" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;pe
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.dropout" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;dropout
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;RotaryPositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" RotaryPositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.inv_freq" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;inv_freq
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.cos_cached" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cos_cached
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.sin_cached" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sin_cached
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LearnablePositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" LearnablePositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.position_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;position_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.dropout" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;dropout
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TransformerEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TransformerEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.transformer_encoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;transformer_encoder
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;feedforward
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" feedforward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FeedForward
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" FeedForward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;losses
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" losses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseClassificationLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseClassificationLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseClassificationLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseClassificationLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.CrossEntropyLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossEntropyLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" CrossEntropyLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.CrossEntropyLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BCEWithLogitsLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BCEWithLogitsLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BCEWithLogitsLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BCEWithLogitsLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseRegressionLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseRegressionLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseRegressionLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseRegressionLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MeanSquaredErrorLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MeanSquaredErrorLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;masks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" masks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.BaseAttentionMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseAttentionMask
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.CausalMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CausalMask
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SlidingWindowAttentionMask
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" SlidingWindowAttentionMask">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask.window_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;window_size
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.CombinedMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CombinedMask
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" CombinedMask">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.CombinedMask.masks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;masks
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;samplers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" samplers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseLabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseLabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseLabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseLabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ArgmaxLabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ArgmaxLabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MultinomialLabelSamplerParams
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MultinomialLabelSamplerParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams.temperature" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;temperature
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MultinomialLabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MultinomialLabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ThresholdMultilabelSamplerParams
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ThresholdMultilabelSamplerParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams.threshold" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;threshold
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ThresholdMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ThresholdMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.threshold" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;threshold
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TopKMultilabelSamplerParams
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TopKMultilabelSamplerParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams.k" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;k
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TopKMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TopKMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.k" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;k
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BernoulliMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BernoulliMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;scalarmix
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" scalarmix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ScalarMix
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ScalarMix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.mixture_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mixture_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.do_layer_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;do_layer_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.scalar_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scalar_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.gamma" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;gamma
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;vectorizers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" vectorizers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseSequenceVectorizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseSequenceVectorizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BagOfEmbeddingsSequenceVectorizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BagOfEmbeddingsSequenceVectorizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;weighters
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" weighters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseLabelWeighter
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseLabelWeighter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.StaticLabelWeighter" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;StaticLabelWeighter
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" StaticLabelWeighter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.StaticLabelWeighter.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BalancedByDistributionLabelWeighter
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BalancedByDistributionLabelWeighter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;callbacks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" callbacks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchTrainingCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchTrainingCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;EvaluationCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" EvaluationCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;EarlyStoppingCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" EarlyStoppingCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MlflowCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MlflowCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;engine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" engine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchTrainingEngine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchTrainingEngine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.create_state" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;create_state
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.train_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train_step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.eval_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;eval_step
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DefaultTorchTrainingEngine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DefaultTorchTrainingEngine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.create_state" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;create_state
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.train_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train_step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.eval_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;eval_step
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.get_default_optimizer_factory" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_optimizer_factory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.get_default_lr_scheduler_factory" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_lr_scheduler_factory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.exceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;exceptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" exceptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.exceptions.StopEarly" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;StopEarly
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;state
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" state">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TrainState
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TrainState">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;optimizer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.lr_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;lr_scheduler
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.grad_scaler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;grad_scaler
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;state_dict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.load_state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load_state_dict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.get_learning_rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_learning_rate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.get_gradient_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_gradient_norm
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;trainer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.TorchTrainer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchTrainer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchTrainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.TorchTrainer.distributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;distributor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.TorchTrainer.train" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.get_default_max_epochs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_max_epochs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.get_default_distributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_distributor
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;workflow
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchModelFormat
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchModelFormat">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.identifier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;identifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.write" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;write
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.read" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;read
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.is_default_of" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;is_default_of
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.train_torch_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;train_torch_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.evaluate_torch_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;evaluate_torch_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.predict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;predict
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transformers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.context" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;context
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.context.use_device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;use_device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.context.get_device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_device
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;dataloader
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" dataloader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.ItemT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;ItemT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DataLoader
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DataLoader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.batch_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;batch_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;shuffle
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.collate_fn" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;collate_fn
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.num_workers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;num_workers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.drop_last" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;drop_last
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.pin_memory" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;pin_memory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.dataloader.DataLoader.kwargs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;kwargs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;distributors
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" distributors">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.BaseDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SingleDeviceDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" SingleDeviceDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DataParallelDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DataParallelDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DataParallelDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DistributedDataParallelDistributor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DistributedDataParallelDistributor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.is_main_process" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;is_main_process
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.local_rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;local_rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;world_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.wrap_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;wrap_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.prepare_data_loader" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;prepare_data_loader
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.reduce" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reduce
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.all_gather" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;all_gather
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;barrier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cleanup
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;initializers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" initializers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.BaseTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.UniformTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;UniformTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.NormalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;NormalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.XavierUniformTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;XavierUniformTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.XavierNormalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;XavierNormalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.KaimingUniformTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;KaimingUniformTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.KaimingNormalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;KaimingNormalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.OrthogonalTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;OrthogonalTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.SparseTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SparseTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.ZerosTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ZerosTensorInitializer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.initializers.OnesTensorInitializer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;OnesTensorInitializer
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;model
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.model.BaseTorchModel" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseTorchModel
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseTorchModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.model.BaseTorchModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;schedulers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" schedulers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CosineLRScheduler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" CosineLRScheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.t_initial" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;t_initial
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.lr_min" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;lr_min
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_mul" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cycle_mul
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_decay" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cycle_decay
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_limit" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cycle_limit
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_t" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_t
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_lr_init" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_lr_init
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_prefix" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_prefix
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.t_in_epochs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;t_in_epochs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.base_lrs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;base_lrs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_steps" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;warmup_steps
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.get_lr" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_lr
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.get_cycle_length" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_cycle_length
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;state_dict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.schedulers.CosineLRScheduler.load_state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load_state_dict
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;utils
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" utils">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.PoolingMethod" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;PoolingMethod
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.set_random_seed" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;set_random_seed
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.ensure_torch_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ensure_torch_tensor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.move_to_device" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;move_to_device
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.determine_ndim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;determine_ndim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.utils.masked_pool" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;masked_pool
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;embedders
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" embedders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.SurfaceBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;SurfaceBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PostagBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;PostagBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.CharacterBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;CharacterBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenVectorBatchT" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;TokenVectorBatchT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;IVariableTensorBatch
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" IVariableTensorBatch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.tensor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;tensor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.mask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mask
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;IAnalyzedTextBatch
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" IAnalyzedTextBatch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.surfaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;surfaces
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.postags" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;postags
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.characters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;characters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.token_vectors" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;token_vectors
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.EmbedderOutput" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;EmbedderOutput
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" EmbedderOutput">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.EmbedderOutput.embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.EmbedderOutput.mask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mask
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.BaseEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.BaseEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.BaseEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;PassThroughEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" PassThroughEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TokenEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TokenEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.TokenEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;PretrainedTransformerEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" PretrainedTransformerEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_vocab_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_vocab_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.train" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;AnalyzedTextEmbedder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" AnalyzedTextEmbedder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;encoders
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" encoders">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LSTMSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" LSTMSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.lstm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;lstm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;GRUSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" GRUSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.gru" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;gru
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ResidualSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ResidualSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FeedForwardSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" FeedForwardSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;StackedSequenceEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" StackedSequenceEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BasePositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BasePositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SinusoidalPositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" SinusoidalPositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.pe" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;pe
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.dropout" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;dropout
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;RotaryPositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" RotaryPositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.inv_freq" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;inv_freq
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.cos_cached" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;cos_cached
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.sin_cached" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;sin_cached
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LearnablePositionalEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" LearnablePositionalEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.position_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;position_embeddings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.dropout" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;dropout
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TransformerEncoder
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TransformerEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.transformer_encoder" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;transformer_encoder
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;feedforward
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" feedforward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FeedForward
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" FeedForward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.feedforward.FeedForward.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;losses
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" losses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseClassificationLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseClassificationLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseClassificationLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseClassificationLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.CrossEntropyLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CrossEntropyLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" CrossEntropyLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.CrossEntropyLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BCEWithLogitsLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BCEWithLogitsLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BCEWithLogitsLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BCEWithLogitsLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseRegressionLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseRegressionLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseRegressionLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.BaseRegressionLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MeanSquaredErrorLoss
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MeanSquaredErrorLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;masks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" masks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.BaseAttentionMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseAttentionMask
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.CausalMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CausalMask
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;SlidingWindowAttentionMask
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" SlidingWindowAttentionMask">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask.window_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;window_size
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.CombinedMask" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;CombinedMask
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" CombinedMask">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.masks.CombinedMask.masks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;masks
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;samplers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" samplers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseLabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseLabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseLabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseLabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ArgmaxLabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ArgmaxLabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MultinomialLabelSamplerParams
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MultinomialLabelSamplerParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams.temperature" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;temperature
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MultinomialLabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MultinomialLabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ThresholdMultilabelSamplerParams
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ThresholdMultilabelSamplerParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams.threshold" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;threshold
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ThresholdMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ThresholdMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.threshold" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;threshold
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TopKMultilabelSamplerParams
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TopKMultilabelSamplerParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams.k" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;k
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TopKMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TopKMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.k" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;k
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BernoulliMultilabelSampler
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BernoulliMultilabelSampler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;scalarmix
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" scalarmix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;ScalarMix
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" ScalarMix">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.mixture_size" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mixture_size
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.do_layer_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;do_layer_norm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.scalar_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scalar_parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.gamma" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;gamma
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;vectorizers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" vectorizers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseSequenceVectorizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseSequenceVectorizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BagOfEmbeddingsSequenceVectorizer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BagOfEmbeddingsSequenceVectorizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_input_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_input_dim
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_output_dim" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_output_dim
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;weighters
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" weighters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BaseLabelWeighter
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BaseLabelWeighter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.StaticLabelWeighter" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;StaticLabelWeighter
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" StaticLabelWeighter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.StaticLabelWeighter.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;BalancedByDistributionLabelWeighter
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" BalancedByDistributionLabelWeighter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter.forward" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;forward
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;callbacks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" callbacks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchTrainingCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchTrainingCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;EvaluationCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" EvaluationCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;EarlyStoppingCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" EarlyStoppingCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;MlflowCallback
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" MlflowCallback">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_log" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_log
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_training_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_epoch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_batch_end
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_start" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_start
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_end" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;on_eval_end
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;engine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" engine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchTrainingEngine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchTrainingEngine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.create_state" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;create_state
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.train_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train_step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.eval_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;eval_step
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DefaultTorchTrainingEngine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DefaultTorchTrainingEngine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.create_state" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;create_state
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.train_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train_step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.eval_step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;eval_step
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.get_default_optimizer_factory" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_optimizer_factory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.engine.get_default_lr_scheduler_factory" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_lr_scheduler_factory
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.exceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;exceptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" exceptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.exceptions.StopEarly" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;StopEarly
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;state
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" state">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TrainState
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TrainState">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;optimizer
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.lr_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;lr_scheduler
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.step" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.grad_scaler" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;grad_scaler
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;state_dict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.load_state_dict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load_state_dict
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.get_learning_rate" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_learning_rate
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.state.TrainState.get_gradient_norm" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;get_gradient_norm
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;trainer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.TorchTrainer" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchTrainer
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchTrainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.TorchTrainer.distributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;distributor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.TorchTrainer.train" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;train
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.get_default_max_epochs" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_max_epochs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.training.trainer.get_default_distributor" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_default_distributor
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;workflow
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;TorchModelFormat
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" TorchModelFormat">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.identifier" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;identifier
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.write" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;write
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.read" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;read
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.TorchModelFormat.is_default_of" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;is_default_of
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.train_torch_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;train_torch_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.evaluate_torch_model" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;evaluate_torch_model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formed.integrations.torch.workflow.predict" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;predict
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="torch">Torch<a class="headerlink" data-preview="" href="#torch" title="Permanent link">&para;</a></h1>
<ul>
<li><a data-preview="" href="#formed.integrations.torch.context">Context</a></li>
<li><a data-preview="" href="#formed.integrations.torch.dataloader">DataLoader</a></li>
<li><a data-preview="" href="#formed.integrations.torch.distributors">Distributors</a></li>
<li><a data-preview="" href="#formed.integrations.torch.initializers">Initializers</a></li>
<li><a data-preview="" href="#formed.integrations.torch.model">Model</a></li>
<li><a data-preview="" href="#formed.integrations.torch.schedulers">Schedulers</a></li>
<li><a data-preview="" href="#formed.integrations.torch.utils">Utils</a></li>
<li>Modules<ul>
<li><a data-preview="" href="#formed.integrations.torch.modules.embedders">Embedders</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.encoders">Encoders</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.feedforward">Feedforward</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.losses">Losses</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.masks">Masks</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.samplers">Samplers</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.scalarmix">ScalarMix</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.vectorizers">Vectorizers</a></li>
<li><a data-preview="" href="#formed.integrations.torch.modules.weighters">Weighters</a></li>
</ul>
</li>
<li>Training<ul>
<li><a data-preview="" href="#formed.integrations.torch.training.callbacks">Callbacks</a></li>
<li><a data-preview="" href="#formed.integrations.torch.training.engine">Engine</a></li>
<li><a data-preview="" href="#formed.integrations.torch.training.exceptions">Exceptions</a></li>
<li><a data-preview="" href="#formed.integrations.torch.training.state">State</a></li>
<li><a data-preview="" href="#formed.integrations.torch.training.trainer">Trainer</a></li>
</ul>
</li>
<li><a data-preview="" href="#formed.integrations.torch.workflow">Workflow</a></li>
</ul>


<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.context" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.context</span>


<a href="#formed.integrations.torch.context" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Context management for PyTorch operations.</p>










<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.context.use_device" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">use_device</span>


<a href="#formed.integrations.torch.context.use_device" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">use_device</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Context manager to set and restore the default PyTorch device.</p>
<p>This context manager allows temporarily setting the default device
used in PyTorch operations (e.g., in <code>ensure_torch_tensor</code>). It saves
the current device on entry and restores it on exit.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Device to use within the context. Can be a torch.device,
a string like <code>"cuda:0"</code> or <code>"cpu"</code>, or None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span> | <span title="torch.device">device</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">YIELDS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-yields-annotation">
                    <code><span title="torch.device">device</span></code>
                </span>
            </td>
            <td class="doc-yields-details">
              <div class="doc-md-description">
                <p>The current device within the context.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">use_device</span><span class="p">,</span> <span class="n">ensure_torch_tensor</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">use_device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">tensor</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-8"><span class="go">cuda:0  # or cpu if CUDA not available</span>
</span></code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/context.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-12"><span class="nd">@contextmanager</span>
</span><span id="__span-0-13"><span class="k">def</span><span class="w"> </span><span class="nf">use_device</span><span class="p">(</span><span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]:</span>
</span><span id="__span-0-14"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Context manager to set and restore the default PyTorch device.</span>
</span><span id="__span-0-15">
</span><span id="__span-0-16"><span class="sd">    This context manager allows temporarily setting the default device</span>
</span><span id="__span-0-17"><span class="sd">    used in PyTorch operations (e.g., in `ensure_torch_tensor`). It saves</span>
</span><span id="__span-0-18"><span class="sd">    the current device on entry and restores it on exit.</span>
</span><span id="__span-0-19">
</span><span id="__span-0-20"><span class="sd">    Args:</span>
</span><span id="__span-0-21"><span class="sd">        device: Device to use within the context. Can be a torch.device,</span>
</span><span id="__span-0-22"><span class="sd">            a string like `&quot;cuda:0&quot;` or `&quot;cpu&quot;`, or None.</span>
</span><span id="__span-0-23">
</span><span id="__span-0-24"><span class="sd">    Yields:</span>
</span><span id="__span-0-25"><span class="sd">        The current device within the context.</span>
</span><span id="__span-0-26">
</span><span id="__span-0-27"><span class="sd">    Examples:</span>
</span><span id="__span-0-28"><span class="sd">        &gt;&gt;&gt; import torch</span>
</span><span id="__span-0-29"><span class="sd">        &gt;&gt;&gt; from formed.integrations.torch import use_device, ensure_torch_tensor</span>
</span><span id="__span-0-30"><span class="sd">        &gt;&gt;&gt; import numpy as np</span>
</span><span id="__span-0-31"><span class="sd">        &gt;&gt;&gt; with use_device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;):</span>
</span><span id="__span-0-32"><span class="sd">        ...     arr = np.array([1.0, 2.0, 3.0])</span>
</span><span id="__span-0-33"><span class="sd">        ...     tensor = ensure_torch_tensor(arr)</span>
</span><span id="__span-0-34"><span class="sd">        ...     print(tensor.device)</span>
</span><span id="__span-0-35"><span class="sd">        cuda:0  # or cpu if CUDA not available</span>
</span><span id="__span-0-36"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-37">    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-38">        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="__span-0-39">            <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span>
</span><span id="__span-0-40">        <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="__span-0-41">            <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;mps&quot;</span>
</span><span id="__span-0-42">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-43">            <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="__span-0-44">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="__span-0-45">        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-46">    <span class="n">token</span> <span class="o">=</span> <span class="n">_TORCH_DEVICE</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</span><span id="__span-0-47">    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-48">        <span class="k">yield</span> <span class="n">device</span>
</span><span id="__span-0-49">    <span class="k">finally</span><span class="p">:</span>
</span><span id="__span-0-50">        <span class="n">_TORCH_DEVICE</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.context.get_device" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_device</span>


<a href="#formed.integrations.torch.context.get_device" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_device</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the current default PyTorch device from context.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.device">device</span> | None</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>The current device set in the context, or <code>None</code> if not set.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">use_device</span><span class="p">,</span> <span class="n">get_device</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">use_device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">):</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">get_device</span><span class="p">())</span>
</span><span id="__span-0-4"><span class="go">cuda:0</span>
</span></code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/context.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-53"><span class="k">def</span><span class="w"> </span><span class="nf">get_device</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-54"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the current default PyTorch device from context.</span>
</span><span id="__span-0-55">
</span><span id="__span-0-56"><span class="sd">    Returns:</span>
</span><span id="__span-0-57"><span class="sd">        The current device set in the context, or `None` if not set.</span>
</span><span id="__span-0-58">
</span><span id="__span-0-59"><span class="sd">    Examples:</span>
</span><span id="__span-0-60"><span class="sd">        &gt;&gt;&gt; from formed.integrations.torch import use_device, get_device</span>
</span><span id="__span-0-61"><span class="sd">        &gt;&gt;&gt; with use_device(&quot;cuda:0&quot;):</span>
</span><span id="__span-0-62"><span class="sd">        ...     print(get_device())</span>
</span><span id="__span-0-63"><span class="sd">        cuda:0</span>
</span><span id="__span-0-64"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-65">    <span class="k">return</span> <span class="n">_TORCH_DEVICE</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.dataloader" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.dataloader</span>


<a href="#formed.integrations.torch.dataloader" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>DataLoader utilities for PyTorch training.</p>
<p>This module provides convenient wrappers for creating PyTorch DataLoaders
that work seamlessly with the formed training framework.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a simple dataloader</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">collate_fn</span><span class="o">=</span><span class="n">my_collate_fn</span>
</span><span id="__span-0-8"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use with trainer</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
</span><span id="__span-0-13"><span class="gp">... </span>    <span class="o">...</span>
</span><span id="__span-0-14"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="formed.integrations.torch.dataloader.ItemT" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">ItemT</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.ItemT" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">ItemT</span> <span class="o">=</span> <span class="n"><span title="typing.TypeVar">TypeVar</span></span><span class="p">(</span><span class="s1">&#39;ItemT&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.dataloader.DataLoader" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">DataLoader</span>


<a href="#formed.integrations.torch.dataloader.DataLoader" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-9"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">



        <p>Simple DataLoader wrapper for PyTorch training.</p>
<p>This class wraps PyTorch's DataLoader with a simpler interface
that works with the formed training framework.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of samples per batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>shuffle</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to shuffle the data at every epoch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>collate_fn</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Function to collate samples into batches.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Callable">Callable</span>[[<span title="list">list</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;ItemT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.dataloader.ItemT&lt;/code&gt;)" href="#formed.integrations.torch.dataloader.ItemT">ItemT</a>]], <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>] | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of subprocesses for data loading.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drop_last</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to drop the last incomplete batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pin_memory</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If True, tensors are copied to CUDA pinned memory.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional arguments passed to torch.utils.data.DataLoader.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="c1"># Convert list of samples to batch tensors</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])}</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
</span><span id="__span-0-9"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/dataloader.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-62"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-63">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-64">    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-65">    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-66">    <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="n">ItemT</span><span class="p">]],</span> <span class="n">ModelInputT</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-67">    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-68">    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-69">    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-70">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-71"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-72">    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span><span id="__span-0-73">    <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
</span><span id="__span-0-74">    <span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span> <span class="o">=</span> <span class="n">collate_fn</span>
</span><span id="__span-0-75">    <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
</span><span id="__span-0-76">    <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span> <span class="o">=</span> <span class="n">drop_last</span>
</span><span id="__span-0-77">    <span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span> <span class="o">=</span> <span class="n">pin_memory</span>
</span><span id="__span-0-78">    <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.dataloader.DataLoader.batch_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">batch_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.DataLoader.batch_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">batch_size</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.dataloader.DataLoader(batch_size)">batch_size</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.dataloader.DataLoader.shuffle" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">shuffle</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.DataLoader.shuffle" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">shuffle</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.dataloader.DataLoader(shuffle)">shuffle</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.dataloader.DataLoader.collate_fn" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">collate_fn</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.DataLoader.collate_fn" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">collate_fn</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.dataloader.DataLoader(collate_fn)">collate_fn</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.dataloader.DataLoader.num_workers" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">num_workers</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.DataLoader.num_workers" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">num_workers</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.dataloader.DataLoader(num_workers)">num_workers</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.dataloader.DataLoader.drop_last" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">drop_last</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.DataLoader.drop_last" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">drop_last</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.dataloader.DataLoader(drop_last)">drop_last</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.dataloader.DataLoader.pin_memory" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">pin_memory</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.DataLoader.pin_memory" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">pin_memory</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.dataloader.DataLoader(pin_memory)">pin_memory</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.dataloader.DataLoader.kwargs" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">kwargs</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.dataloader.DataLoader.kwargs" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">kwargs</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.dataloader.DataLoader(kwargs)">kwargs</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.distributors" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.distributors</span>


<a href="#formed.integrations.torch.distributors" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Distributed computing abstractions for PyTorch models.</p>
<p>This module provides abstractions for distributed training across multiple devices,
supporting both single-device and data-parallel training strategies.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseDistributor</code>: Abstract interface for device distribution strategies</li>
<li><code>SingleDeviceDistributor</code>: No-op distributor for single-device training</li>
<li><code>DataParallelDistributor</code>: Data-parallel training using torch.nn.DataParallel</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Transparent device sharding and replication</li>
<li>Reduction operations (mean, sum) across devices</li>
<li>Compatible with TorchTrainer</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataParallelDistributor</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create data-parallel distributor for all available GPUs</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">distributor</span> <span class="o">=</span> <span class="n">DataParallelDistributor</span><span class="p">()</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Shard batch across devices</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">sharded_batch</span> <span class="o">=</span> <span class="n">distributor</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.distributors.BaseDistributor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseDistributor</span>


<a href="#formed.integrations.torch.distributors.BaseDistributor" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="abc.ABC">ABC</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]</code></p>



        <p>Abstract base class for device distribution strategies.</p>
<p>BaseDistributor defines the interface for distributing computations
across devices in a PyTorch training pipeline. It provides a unified
API for single-device, data-parallel, and distributed data-parallel training.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>ModelInputT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of model input data.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="key-methods" open>
  <summary>Key Methods</summary>
  <ul>
<li>device: Primary device for computation</li>
<li>is_main_process: Whether this is the main process (for logging, saving, etc.)</li>
<li>wrap_model: Wrap model for distributed training</li>
<li>prepare_data_loader: Prepare data loader with appropriate sampler</li>
<li>reduce: Reduce tensor across devices/processes</li>
<li>barrier: Synchronize all processes</li>
<li>all_gather: Gather tensors from all processes</li>
</ul>
</details>










<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.BaseDistributor.device" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">device</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.BaseDistributor.device" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">device</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Primary device for computation.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.BaseDistributor.is_main_process" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">is_main_process</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.BaseDistributor.is_main_process" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">is_main_process</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether this is the main process.</p>
<p>The main process is responsible for:
- Logging to console
- Saving models and checkpoints
- Writing metrics to file</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="bool">bool</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>True if this is the main process (rank 0), False otherwise.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.BaseDistributor.world_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">world_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.BaseDistributor.world_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">world_size</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Total number of processes/devices.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Number of processes in distributed training, or 1 for single device.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.BaseDistributor.rank" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">rank</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.BaseDistributor.rank" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">rank</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Global rank of this process.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Rank of this process (0 for main process).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.BaseDistributor.wrap_model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">wrap_model</span>


<a href="#formed.integrations.torch.distributors.BaseDistributor.wrap_model" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">wrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Wrap model for distributed training.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model to wrap.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.nn.Module">Module</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.nn.Module">Module</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Wrapped model (DataParallel, DDP, or unchanged).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-105"><span class="k">def</span><span class="w"> </span><span class="nf">wrap_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
</span><span id="__span-0-106"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap model for distributed training.</span>
</span><span id="__span-0-107">
</span><span id="__span-0-108"><span class="sd">    Args:</span>
</span><span id="__span-0-109"><span class="sd">        model: Model to wrap.</span>
</span><span id="__span-0-110">
</span><span id="__span-0-111"><span class="sd">    Returns:</span>
</span><span id="__span-0-112"><span class="sd">        Wrapped model (DataParallel, DDP, or unchanged).</span>
</span><span id="__span-0-113">
</span><span id="__span-0-114"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-115">    <span class="k">return</span> <span class="n">model</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.BaseDistributor.prepare_data_loader" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_data_loader</span>


<a href="#formed.integrations.torch.distributors.BaseDistributor.prepare_data_loader" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">dataset</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare data loader with appropriate sampler for this distributor.</p>
<p>For single device: uses default sampler
For DataParallel: uses default sampler (data split happens in forward)
For DDP: uses DistributedSampler to split data across processes</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dataset to load.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch size per device/process.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>shuffle</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to shuffle data.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of worker processes.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drop_last</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to drop last incomplete batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional arguments for DataLoader.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.utils.data.DataLoader">DataLoader</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Configured DataLoader.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-117"><span class="k">def</span><span class="w"> </span><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-118">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-119">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">,</span>
</span><span id="__span-0-120">    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-123">    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-124">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-125"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">:</span>
</span><span id="__span-0-126"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepare data loader with appropriate sampler for this distributor.</span>
</span><span id="__span-0-127">
</span><span id="__span-0-128"><span class="sd">    For single device: uses default sampler</span>
</span><span id="__span-0-129"><span class="sd">    For DataParallel: uses default sampler (data split happens in forward)</span>
</span><span id="__span-0-130"><span class="sd">    For DDP: uses DistributedSampler to split data across processes</span>
</span><span id="__span-0-131">
</span><span id="__span-0-132"><span class="sd">    Args:</span>
</span><span id="__span-0-133"><span class="sd">        dataset: Dataset to load.</span>
</span><span id="__span-0-134"><span class="sd">        batch_size: Batch size per device/process.</span>
</span><span id="__span-0-135"><span class="sd">        shuffle: Whether to shuffle data.</span>
</span><span id="__span-0-136"><span class="sd">        num_workers: Number of worker processes.</span>
</span><span id="__span-0-137"><span class="sd">        drop_last: Whether to drop last incomplete batch.</span>
</span><span id="__span-0-138"><span class="sd">        **kwargs: Additional arguments for DataLoader.</span>
</span><span id="__span-0-139">
</span><span id="__span-0-140"><span class="sd">    Returns:</span>
</span><span id="__span-0-141"><span class="sd">        Configured DataLoader.</span>
</span><span id="__span-0-142">
</span><span id="__span-0-143"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-144">    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
</span><span id="__span-0-145">
</span><span id="__span-0-146">    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-147">        <span class="n">dataset</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="__span-0-148">        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-149">        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="__span-0-150">        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
</span><span id="__span-0-151">        <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
</span><span id="__span-0-152">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-153">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.BaseDistributor.reduce" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">reduce</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.BaseDistributor.reduce" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Reduce a tensor across devices/processes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor to reduce.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>op</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Reduction operation (<code>"mean"</code> or <code>"sum"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._ReduceOp">_ReduceOp</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Reduced tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-155"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-156"><span class="k">def</span><span class="w"> </span><span class="nf">reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">_TensorT</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">_ReduceOp</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_TensorT</span><span class="p">:</span>
</span><span id="__span-0-157"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Reduce a tensor across devices/processes.</span>
</span><span id="__span-0-158">
</span><span id="__span-0-159"><span class="sd">    Args:</span>
</span><span id="__span-0-160"><span class="sd">        tensor: Tensor to reduce.</span>
</span><span id="__span-0-161"><span class="sd">        op: Reduction operation (`&quot;mean&quot;` or `&quot;sum&quot;`).</span>
</span><span id="__span-0-162">
</span><span id="__span-0-163"><span class="sd">    Returns:</span>
</span><span id="__span-0-164"><span class="sd">        Reduced tensor.</span>
</span><span id="__span-0-165">
</span><span id="__span-0-166"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-167">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.BaseDistributor.barrier" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">barrier</span>


<a href="#formed.integrations.torch.distributors.BaseDistributor.barrier" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">barrier</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Synchronize all processes.</p>
<p>This is a no-op for single device and DataParallel.
For DDP, it blocks until all processes reach this point.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-169"><span class="k">def</span><span class="w"> </span><span class="nf">barrier</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-170"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Synchronize all processes.</span>
</span><span id="__span-0-171">
</span><span id="__span-0-172"><span class="sd">    This is a no-op for single device and DataParallel.</span>
</span><span id="__span-0-173"><span class="sd">    For DDP, it blocks until all processes reach this point.</span>
</span><span id="__span-0-174">
</span><span id="__span-0-175"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-176">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.BaseDistributor.all_gather" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">all_gather</span>


<a href="#formed.integrations.torch.distributors.BaseDistributor.all_gather" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">all_gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Gather tensors from all processes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor to gather.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="torch.Tensor">Tensor</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>List of tensors from all processes.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="torch.Tensor">Tensor</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>For single device/DataParallel, returns [tensor].</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-178"><span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-179"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Gather tensors from all processes.</span>
</span><span id="__span-0-180">
</span><span id="__span-0-181"><span class="sd">    Args:</span>
</span><span id="__span-0-182"><span class="sd">        tensor: Tensor to gather.</span>
</span><span id="__span-0-183">
</span><span id="__span-0-184"><span class="sd">    Returns:</span>
</span><span id="__span-0-185"><span class="sd">        List of tensors from all processes.</span>
</span><span id="__span-0-186"><span class="sd">        For single device/DataParallel, returns [tensor].</span>
</span><span id="__span-0-187">
</span><span id="__span-0-188"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-189">    <span class="k">return</span> <span class="p">[</span><span class="n">tensor</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.BaseDistributor.cleanup" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">cleanup</span>


<a href="#formed.integrations.torch.distributors.BaseDistributor.cleanup" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">cleanup</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Cleanup resources (e.g., distributed process group).</p>
<p>This is a no-op for single device and DataParallel.
For DDP, destroys the process group.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-191"><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-192"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Cleanup resources (e.g., distributed process group).</span>
</span><span id="__span-0-193">
</span><span id="__span-0-194"><span class="sd">    This is a no-op for single device and DataParallel.</span>
</span><span id="__span-0-195"><span class="sd">    For DDP, destroys the process group.</span>
</span><span id="__span-0-196">
</span><span id="__span-0-197"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-198">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.distributors.SingleDeviceDistributor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SingleDeviceDistributor</span>


<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">SingleDeviceDistributor</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseDistributor&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.distributors.BaseDistributor&lt;/code&gt;)" href="#formed.integrations.torch.distributors.BaseDistributor">BaseDistributor</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]</code></p>



        <p>Distributor for single-device training.</p>
<p>This distributor operates on a single device without any distribution.
All shard, replicate, and unreplicate operations are no-ops.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Device to use (default: <code>"cuda"</code> if available, else <code>"cpu"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="torch.device">device</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">distributor</span> <span class="o">=</span> <span class="n">SingleDeviceDistributor</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">distributor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-217"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-218">    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-219">        <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="__span-0-220">    <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.device" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">device</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.device" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">device</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.is_main_process" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">is_main_process</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.is_main_process" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">is_main_process</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether this is the main process.</p>
<p>The main process is responsible for:
- Logging to console
- Saving models and checkpoints
- Writing metrics to file</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="bool">bool</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>True if this is the main process (rank 0), False otherwise.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.world_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">world_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.world_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">world_size</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Total number of processes/devices.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Number of processes in distributed training, or 1 for single device.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.rank" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">rank</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.rank" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">rank</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Global rank of this process.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Rank of this process (0 for main process).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.reduce" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">reduce</span>


<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.reduce" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return tensor unchanged (no reduction needed for single device).</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input tensor.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>op</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Reduction operation (ignored).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._ReduceOp">_ReduceOp</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Input tensor unchanged.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-226"><span class="k">def</span><span class="w"> </span><span class="nf">reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">_TensorT</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">_ReduceOp</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_TensorT</span><span class="p">:</span>
</span><span id="__span-0-227"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return tensor unchanged (no reduction needed for single device).</span>
</span><span id="__span-0-228">
</span><span id="__span-0-229"><span class="sd">    Args:</span>
</span><span id="__span-0-230"><span class="sd">        tensor: Input tensor.</span>
</span><span id="__span-0-231"><span class="sd">        op: Reduction operation (ignored).</span>
</span><span id="__span-0-232">
</span><span id="__span-0-233"><span class="sd">    Returns:</span>
</span><span id="__span-0-234"><span class="sd">        Input tensor unchanged.</span>
</span><span id="__span-0-235">
</span><span id="__span-0-236"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-237">    <span class="k">return</span> <span class="n">tensor</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.wrap_model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">wrap_model</span>


<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.wrap_model" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">wrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Wrap model for distributed training.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model to wrap.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.nn.Module">Module</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.nn.Module">Module</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Wrapped model (DataParallel, DDP, or unchanged).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-105"><span class="k">def</span><span class="w"> </span><span class="nf">wrap_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
</span><span id="__span-0-106"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap model for distributed training.</span>
</span><span id="__span-0-107">
</span><span id="__span-0-108"><span class="sd">    Args:</span>
</span><span id="__span-0-109"><span class="sd">        model: Model to wrap.</span>
</span><span id="__span-0-110">
</span><span id="__span-0-111"><span class="sd">    Returns:</span>
</span><span id="__span-0-112"><span class="sd">        Wrapped model (DataParallel, DDP, or unchanged).</span>
</span><span id="__span-0-113">
</span><span id="__span-0-114"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-115">    <span class="k">return</span> <span class="n">model</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.prepare_data_loader" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_data_loader</span>


<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.prepare_data_loader" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">dataset</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare data loader with appropriate sampler for this distributor.</p>
<p>For single device: uses default sampler
For DataParallel: uses default sampler (data split happens in forward)
For DDP: uses DistributedSampler to split data across processes</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dataset to load.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch size per device/process.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>shuffle</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to shuffle data.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of worker processes.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drop_last</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to drop last incomplete batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional arguments for DataLoader.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.utils.data.DataLoader">DataLoader</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Configured DataLoader.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-117"><span class="k">def</span><span class="w"> </span><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-118">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-119">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">,</span>
</span><span id="__span-0-120">    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-123">    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-124">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-125"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">:</span>
</span><span id="__span-0-126"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepare data loader with appropriate sampler for this distributor.</span>
</span><span id="__span-0-127">
</span><span id="__span-0-128"><span class="sd">    For single device: uses default sampler</span>
</span><span id="__span-0-129"><span class="sd">    For DataParallel: uses default sampler (data split happens in forward)</span>
</span><span id="__span-0-130"><span class="sd">    For DDP: uses DistributedSampler to split data across processes</span>
</span><span id="__span-0-131">
</span><span id="__span-0-132"><span class="sd">    Args:</span>
</span><span id="__span-0-133"><span class="sd">        dataset: Dataset to load.</span>
</span><span id="__span-0-134"><span class="sd">        batch_size: Batch size per device/process.</span>
</span><span id="__span-0-135"><span class="sd">        shuffle: Whether to shuffle data.</span>
</span><span id="__span-0-136"><span class="sd">        num_workers: Number of worker processes.</span>
</span><span id="__span-0-137"><span class="sd">        drop_last: Whether to drop last incomplete batch.</span>
</span><span id="__span-0-138"><span class="sd">        **kwargs: Additional arguments for DataLoader.</span>
</span><span id="__span-0-139">
</span><span id="__span-0-140"><span class="sd">    Returns:</span>
</span><span id="__span-0-141"><span class="sd">        Configured DataLoader.</span>
</span><span id="__span-0-142">
</span><span id="__span-0-143"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-144">    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
</span><span id="__span-0-145">
</span><span id="__span-0-146">    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-147">        <span class="n">dataset</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="__span-0-148">        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-149">        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="__span-0-150">        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
</span><span id="__span-0-151">        <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
</span><span id="__span-0-152">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-153">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.barrier" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">barrier</span>


<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.barrier" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">barrier</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Synchronize all processes.</p>
<p>This is a no-op for single device and DataParallel.
For DDP, it blocks until all processes reach this point.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-169"><span class="k">def</span><span class="w"> </span><span class="nf">barrier</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-170"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Synchronize all processes.</span>
</span><span id="__span-0-171">
</span><span id="__span-0-172"><span class="sd">    This is a no-op for single device and DataParallel.</span>
</span><span id="__span-0-173"><span class="sd">    For DDP, it blocks until all processes reach this point.</span>
</span><span id="__span-0-174">
</span><span id="__span-0-175"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-176">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.all_gather" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">all_gather</span>


<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.all_gather" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">all_gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Gather tensors from all processes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor to gather.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="torch.Tensor">Tensor</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>List of tensors from all processes.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="torch.Tensor">Tensor</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>For single device/DataParallel, returns [tensor].</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-178"><span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-179"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Gather tensors from all processes.</span>
</span><span id="__span-0-180">
</span><span id="__span-0-181"><span class="sd">    Args:</span>
</span><span id="__span-0-182"><span class="sd">        tensor: Tensor to gather.</span>
</span><span id="__span-0-183">
</span><span id="__span-0-184"><span class="sd">    Returns:</span>
</span><span id="__span-0-185"><span class="sd">        List of tensors from all processes.</span>
</span><span id="__span-0-186"><span class="sd">        For single device/DataParallel, returns [tensor].</span>
</span><span id="__span-0-187">
</span><span id="__span-0-188"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-189">    <span class="k">return</span> <span class="p">[</span><span class="n">tensor</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.SingleDeviceDistributor.cleanup" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">cleanup</span>


<a href="#formed.integrations.torch.distributors.SingleDeviceDistributor.cleanup" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">cleanup</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Cleanup resources (e.g., distributed process group).</p>
<p>This is a no-op for single device and DataParallel.
For DDP, destroys the process group.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-191"><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-192"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Cleanup resources (e.g., distributed process group).</span>
</span><span id="__span-0-193">
</span><span id="__span-0-194"><span class="sd">    This is a no-op for single device and DataParallel.</span>
</span><span id="__span-0-195"><span class="sd">    For DDP, destroys the process group.</span>
</span><span id="__span-0-196">
</span><span id="__span-0-197"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-198">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.distributors.DataParallelDistributor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">DataParallelDistributor</span>


<a href="#formed.integrations.torch.distributors.DataParallelDistributor" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">DataParallelDistributor</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">device_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_device</span><span class="o">=</span><span class="kc">None</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseDistributor&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.distributors.BaseDistributor&lt;/code&gt;)" href="#formed.integrations.torch.distributors.BaseDistributor">BaseDistributor</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]</code></p>



        <p>Distributor for data-parallel training across multiple GPUs.</p>
<p>This distributor uses <code>torch.nn.DataParallel</code> to execute the same computation
on different data shards across multiple GPUs. Data is automatically
sharded along the batch dimension.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of GPU device IDs to use. Defaults to all available GPUs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="list">list</span>[<span title="int">int</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_device</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Device for outputs. Defaults to device_ids[0].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Train on GPUs 0 and 1 with data parallelism</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">distributor</span> <span class="o">=</span> <span class="n">DataParallelDistributor</span><span class="p">(</span><span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Wrap model for data parallel training</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">distributor</span><span class="o">.</span><span class="n">wrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>Batch size must be divisible by the number of devices for proper sharding.</p>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-264"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-265">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-266">    <span class="n">device_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-267">    <span class="n">output_device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-268"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-269">    <span class="k">if</span> <span class="n">device_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-270">        <span class="n">device_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()))</span>
</span><span id="__span-0-271">    <span class="k">if</span> <span class="ow">not</span> <span class="n">device_ids</span><span class="p">:</span>
</span><span id="__span-0-272">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No GPU devices available for DataParallelDistributor&quot;</span><span class="p">)</span>
</span><span id="__span-0-273">
</span><span id="__span-0-274">    <span class="bp">self</span><span class="o">.</span><span class="n">_device_ids</span> <span class="o">=</span> <span class="n">device_ids</span>
</span><span id="__span-0-275">    <span class="bp">self</span><span class="o">.</span><span class="n">_output_device</span> <span class="o">=</span> <span class="n">output_device</span> <span class="k">if</span> <span class="n">output_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">device_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-276">    <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.device" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">device</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DataParallelDistributor.device" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">device</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.is_main_process" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">is_main_process</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DataParallelDistributor.is_main_process" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">is_main_process</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether this is the main process.</p>
<p>The main process is responsible for:
- Logging to console
- Saving models and checkpoints
- Writing metrics to file</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="bool">bool</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>True if this is the main process (rank 0), False otherwise.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.world_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">world_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DataParallelDistributor.world_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">world_size</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Total number of processes/devices.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Number of processes in distributed training, or 1 for single device.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.rank" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">rank</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DataParallelDistributor.rank" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">rank</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Global rank of this process.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Rank of this process (0 for main process).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.wrap_model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">wrap_model</span>


<a href="#formed.integrations.torch.distributors.DataParallelDistributor.wrap_model" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">wrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Wrap model with <code>DataParallel</code>.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model to wrap.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.nn.Module">Module</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.nn.Module">Module</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>DataParallel</code> wrapped model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-282"><span class="k">def</span><span class="w"> </span><span class="nf">wrap_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
</span><span id="__span-0-283"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap model with `DataParallel`.</span>
</span><span id="__span-0-284">
</span><span id="__span-0-285"><span class="sd">    Args:</span>
</span><span id="__span-0-286"><span class="sd">        model: Model to wrap.</span>
</span><span id="__span-0-287">
</span><span id="__span-0-288"><span class="sd">    Returns:</span>
</span><span id="__span-0-289"><span class="sd">        `DataParallel` wrapped model.</span>
</span><span id="__span-0-290">
</span><span id="__span-0-291"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-292">    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device_ids</span><span class="p">,</span> <span class="n">output_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_device</span><span class="p">))</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.reduce" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">reduce</span>


<a href="#formed.integrations.torch.distributors.DataParallelDistributor.reduce" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Reduce tensor across devices.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor to reduce across device dimension.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>op</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Reduction operation - <code>"sum"</code> or <code>"mean"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._ReduceOp">_ReduceOp</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Reduced tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code><span title="ValueError">ValueError</span></code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If unsupported reduction operation is specified.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-294"><span class="k">def</span><span class="w"> </span><span class="nf">reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">_TensorT</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">_ReduceOp</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_TensorT</span><span class="p">:</span>
</span><span id="__span-0-295"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Reduce tensor across devices.</span>
</span><span id="__span-0-296">
</span><span id="__span-0-297"><span class="sd">    Args:</span>
</span><span id="__span-0-298"><span class="sd">        tensor: Tensor to reduce across device dimension.</span>
</span><span id="__span-0-299"><span class="sd">        op: Reduction operation - `&quot;sum&quot;` or `&quot;mean&quot;`.</span>
</span><span id="__span-0-300">
</span><span id="__span-0-301"><span class="sd">    Returns:</span>
</span><span id="__span-0-302"><span class="sd">        Reduced tensor.</span>
</span><span id="__span-0-303">
</span><span id="__span-0-304"><span class="sd">    Raises:</span>
</span><span id="__span-0-305"><span class="sd">        ValueError: If unsupported reduction operation is specified.</span>
</span><span id="__span-0-306">
</span><span id="__span-0-307"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-308">    <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span id="__span-0-309">        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">_TensorT</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</span><span id="__span-0-310">    <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span id="__span-0-311">        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">_TensorT</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</span><span id="__span-0-312">    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported reduce operation: </span><span class="si">{</span><span class="n">op</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.prepare_data_loader" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_data_loader</span>


<a href="#formed.integrations.torch.distributors.DataParallelDistributor.prepare_data_loader" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">dataset</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare data loader with appropriate sampler for this distributor.</p>
<p>For single device: uses default sampler
For DataParallel: uses default sampler (data split happens in forward)
For DDP: uses DistributedSampler to split data across processes</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dataset to load.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch size per device/process.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>shuffle</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to shuffle data.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of worker processes.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drop_last</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to drop last incomplete batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional arguments for DataLoader.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.utils.data.DataLoader">DataLoader</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Configured DataLoader.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-117"><span class="k">def</span><span class="w"> </span><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-118">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-119">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">,</span>
</span><span id="__span-0-120">    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-123">    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-124">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-125"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">:</span>
</span><span id="__span-0-126"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepare data loader with appropriate sampler for this distributor.</span>
</span><span id="__span-0-127">
</span><span id="__span-0-128"><span class="sd">    For single device: uses default sampler</span>
</span><span id="__span-0-129"><span class="sd">    For DataParallel: uses default sampler (data split happens in forward)</span>
</span><span id="__span-0-130"><span class="sd">    For DDP: uses DistributedSampler to split data across processes</span>
</span><span id="__span-0-131">
</span><span id="__span-0-132"><span class="sd">    Args:</span>
</span><span id="__span-0-133"><span class="sd">        dataset: Dataset to load.</span>
</span><span id="__span-0-134"><span class="sd">        batch_size: Batch size per device/process.</span>
</span><span id="__span-0-135"><span class="sd">        shuffle: Whether to shuffle data.</span>
</span><span id="__span-0-136"><span class="sd">        num_workers: Number of worker processes.</span>
</span><span id="__span-0-137"><span class="sd">        drop_last: Whether to drop last incomplete batch.</span>
</span><span id="__span-0-138"><span class="sd">        **kwargs: Additional arguments for DataLoader.</span>
</span><span id="__span-0-139">
</span><span id="__span-0-140"><span class="sd">    Returns:</span>
</span><span id="__span-0-141"><span class="sd">        Configured DataLoader.</span>
</span><span id="__span-0-142">
</span><span id="__span-0-143"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-144">    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
</span><span id="__span-0-145">
</span><span id="__span-0-146">    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-147">        <span class="n">dataset</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="__span-0-148">        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-149">        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="__span-0-150">        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
</span><span id="__span-0-151">        <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
</span><span id="__span-0-152">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-153">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.barrier" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">barrier</span>


<a href="#formed.integrations.torch.distributors.DataParallelDistributor.barrier" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">barrier</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Synchronize all processes.</p>
<p>This is a no-op for single device and DataParallel.
For DDP, it blocks until all processes reach this point.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-169"><span class="k">def</span><span class="w"> </span><span class="nf">barrier</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-170"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Synchronize all processes.</span>
</span><span id="__span-0-171">
</span><span id="__span-0-172"><span class="sd">    This is a no-op for single device and DataParallel.</span>
</span><span id="__span-0-173"><span class="sd">    For DDP, it blocks until all processes reach this point.</span>
</span><span id="__span-0-174">
</span><span id="__span-0-175"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-176">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.all_gather" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">all_gather</span>


<a href="#formed.integrations.torch.distributors.DataParallelDistributor.all_gather" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">all_gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Gather tensors from all processes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor to gather.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="torch.Tensor">Tensor</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>List of tensors from all processes.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="torch.Tensor">Tensor</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>For single device/DataParallel, returns [tensor].</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-178"><span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-179"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Gather tensors from all processes.</span>
</span><span id="__span-0-180">
</span><span id="__span-0-181"><span class="sd">    Args:</span>
</span><span id="__span-0-182"><span class="sd">        tensor: Tensor to gather.</span>
</span><span id="__span-0-183">
</span><span id="__span-0-184"><span class="sd">    Returns:</span>
</span><span id="__span-0-185"><span class="sd">        List of tensors from all processes.</span>
</span><span id="__span-0-186"><span class="sd">        For single device/DataParallel, returns [tensor].</span>
</span><span id="__span-0-187">
</span><span id="__span-0-188"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-189">    <span class="k">return</span> <span class="p">[</span><span class="n">tensor</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DataParallelDistributor.cleanup" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">cleanup</span>


<a href="#formed.integrations.torch.distributors.DataParallelDistributor.cleanup" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">cleanup</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Cleanup resources (e.g., distributed process group).</p>
<p>This is a no-op for single device and DataParallel.
For DDP, destroys the process group.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-191"><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-192"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Cleanup resources (e.g., distributed process group).</span>
</span><span id="__span-0-193">
</span><span id="__span-0-194"><span class="sd">    This is a no-op for single device and DataParallel.</span>
</span><span id="__span-0-195"><span class="sd">    For DDP, destroys the process group.</span>
</span><span id="__span-0-196">
</span><span id="__span-0-197"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-198">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">DistributedDataParallelDistributor</span>


<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">DistributedDataParallelDistributor</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">backend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">init_method</span><span class="o">=</span><span class="s2">&quot;env://&quot;</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">world_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">local_rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">find_unused_parameters</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">broadcast_buffers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-9">    <span class="n">bucket_cap_mb</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseDistributor&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.distributors.BaseDistributor&lt;/code&gt;)" href="#formed.integrations.torch.distributors.BaseDistributor">BaseDistributor</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]</code></p>



        <p>Distributor for distributed data-parallel training using DDP.</p>
<p>This distributor uses torch.nn.parallel.DistributedDataParallel to execute
training across multiple processes and devices. This is more efficient than
DataParallel for multi-GPU training as it uses one process per GPU.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>backend</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Backend to use for distributed training (<code>"nccl"</code>, <code>"gloo"</code>, <code>"mpi"</code>).
Defaults to <code>"nccl"</code> for GPU and <code>"gloo"</code> for CPU.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="str">str</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>init_method</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>URL specifying how to initialize the process group.
Defaults to <code>"env://"</code> which uses environment variables.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;env://&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>world_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Total number of processes. If <code>None</code>, reads from environment.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rank</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Rank of this process. If None, reads from environment.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>local_rank</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Local rank on this machine. If <code>None</code>, uses rank.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>find_unused_parameters</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to find unused parameters. Default <code>False</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>broadcast_buffers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to broadcast buffers. Default <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bucket_cap_mb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Bucket size in MB for gradient allreduce. Default <code>25</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>25</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="environment-variables" open>
  <summary>Environment Variables</summary>
  <ul>
<li><code>RANK</code>: Global rank of the process</li>
<li><code>LOCAL_RANK</code>: Local rank on the machine</li>
<li><code>WORLD_SIZE</code>: Total number of processes</li>
<li><code>MASTER_ADDR</code>: Address of the master node</li>
<li><code>MASTER_PORT</code>: Port of the master node</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># On each process, initialize the distributor</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">distributor</span> <span class="o">=</span> <span class="n">DistributedDataParallelDistributor</span><span class="p">(</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">init_method</span><span class="o">=</span><span class="s2">&quot;env://&quot;</span>
</span><span id="__span-0-5"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Wrap model with DDP</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">distributor</span><span class="o">.</span><span class="n">wrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Train as usual - gradients are automatically synchronized</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <ul>
<li>Requires launching multiple processes (e.g., using <code>torch.distributed.launch</code>)</li>
<li>Each process should initialize its own distributor</li>
<li>Batch size should be per-process batch size</li>
</ul>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-361"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-362">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-363">    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-364">    <span class="n">init_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;env://&quot;</span><span class="p">,</span>
</span><span id="__span-0-365">    <span class="n">world_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-366">    <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-367">    <span class="n">local_rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-368">    <span class="n">find_unused_parameters</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-369">    <span class="n">broadcast_buffers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-370">    <span class="n">bucket_cap_mb</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
</span><span id="__span-0-371"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-372">    <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="__span-0-373">
</span><span id="__span-0-374">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
</span><span id="__span-0-375">
</span><span id="__span-0-376">    <span class="c1"># Determine backend</span>
</span><span id="__span-0-377">    <span class="k">if</span> <span class="n">backend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-378">        <span class="n">backend</span> <span class="o">=</span> <span class="s2">&quot;nccl&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;gloo&quot;</span>
</span><span id="__span-0-379">
</span><span id="__span-0-380">    <span class="c1"># Get rank and world_size from environment if not provided</span>
</span><span id="__span-0-381">    <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-382">        <span class="n">rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;RANK&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</span><span id="__span-0-383">    <span class="k">if</span> <span class="n">world_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-384">        <span class="n">world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-0-385">    <span class="k">if</span> <span class="n">local_rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-386">        <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="p">))</span>
</span><span id="__span-0-387">
</span><span id="__span-0-388">    <span class="bp">self</span><span class="o">.</span><span class="n">_backend</span> <span class="o">=</span> <span class="n">backend</span>
</span><span id="__span-0-389">    <span class="bp">self</span><span class="o">.</span><span class="n">_init_method</span> <span class="o">=</span> <span class="n">init_method</span>
</span><span id="__span-0-390">    <span class="bp">self</span><span class="o">.</span><span class="n">_world_size</span> <span class="o">=</span> <span class="n">world_size</span>
</span><span id="__span-0-391">    <span class="bp">self</span><span class="o">.</span><span class="n">_rank</span> <span class="o">=</span> <span class="n">rank</span>
</span><span id="__span-0-392">    <span class="bp">self</span><span class="o">.</span><span class="n">_local_rank</span> <span class="o">=</span> <span class="n">local_rank</span>
</span><span id="__span-0-393">    <span class="bp">self</span><span class="o">.</span><span class="n">_find_unused_parameters</span> <span class="o">=</span> <span class="n">find_unused_parameters</span>
</span><span id="__span-0-394">    <span class="bp">self</span><span class="o">.</span><span class="n">_broadcast_buffers</span> <span class="o">=</span> <span class="n">broadcast_buffers</span>
</span><span id="__span-0-395">    <span class="bp">self</span><span class="o">.</span><span class="n">_bucket_cap_mb</span> <span class="o">=</span> <span class="n">bucket_cap_mb</span>
</span><span id="__span-0-396">
</span><span id="__span-0-397">    <span class="c1"># Initialize process group if not already initialized</span>
</span><span id="__span-0-398">    <span class="k">if</span> <span class="ow">not</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="__span-0-399">        <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-400">            <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
</span><span id="__span-0-401">                <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span><span id="__span-0-402">                <span class="n">init_method</span><span class="o">=</span><span class="n">init_method</span><span class="p">,</span>
</span><span id="__span-0-403">                <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
</span><span id="__span-0-404">                <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
</span><span id="__span-0-405">            <span class="p">)</span>
</span><span id="__span-0-406">        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="__span-0-407">            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="__span-0-408">                <span class="sa">f</span><span class="s2">&quot;Failed to initialize distributed process group. &quot;</span>
</span><span id="__span-0-409">                <span class="sa">f</span><span class="s2">&quot;Backend: </span><span class="si">{</span><span class="n">backend</span><span class="si">}</span><span class="s2">, init_method: </span><span class="si">{</span><span class="n">init_method</span><span class="si">}</span><span class="s2">, &quot;</span>
</span><span id="__span-0-410">                <span class="sa">f</span><span class="s2">&quot;world_size: </span><span class="si">{</span><span class="n">world_size</span><span class="si">}</span><span class="s2">, rank: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">. &quot;</span>
</span><span id="__span-0-411">                <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. &quot;</span>
</span><span id="__span-0-412">                <span class="s2">&quot;Please ensure all processes are launched correctly using torchrun &quot;</span>
</span><span id="__span-0-413">                <span class="s2">&quot;and required environment variables (RANK, WORLD_SIZE, MASTER_ADDR, MASTER_PORT) are set.&quot;</span>
</span><span id="__span-0-414">            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="__span-0-415">
</span><span id="__span-0-416">    <span class="c1"># Set device based on local rank</span>
</span><span id="__span-0-417">    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="__span-0-418">        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-419">        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="__span-0-420">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-421">        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.device" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">device</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.device" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">device</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.is_main_process" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">is_main_process</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.is_main_process" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">is_main_process</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Whether this is the main process (rank 0).</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.rank" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">rank</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.rank" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">rank</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Global rank of this process.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.local_rank" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">local_rank</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.local_rank" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">local_rank</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Local rank on this machine.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.world_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">world_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.world_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">world_size</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Total number of processes.</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.wrap_model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">wrap_model</span>


<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.wrap_model" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">wrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Wrap model with DistributedDataParallel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model to wrap.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.nn.Module">Module</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.nn.Module">Module</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>DDP wrapped model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-447"><span class="k">def</span><span class="w"> </span><span class="nf">wrap_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
</span><span id="__span-0-448"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap model with DistributedDataParallel.</span>
</span><span id="__span-0-449">
</span><span id="__span-0-450"><span class="sd">    Args:</span>
</span><span id="__span-0-451"><span class="sd">        model: Model to wrap.</span>
</span><span id="__span-0-452">
</span><span id="__span-0-453"><span class="sd">    Returns:</span>
</span><span id="__span-0-454"><span class="sd">        DDP wrapped model.</span>
</span><span id="__span-0-455">
</span><span id="__span-0-456"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-457">    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span>
</span><span id="__span-0-458">        <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
</span><span id="__span-0-459">        <span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span>
</span><span id="__span-0-460">            <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-461">            <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_rank</span><span class="p">]</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-462">            <span class="n">output_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_rank</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-463">            <span class="n">find_unused_parameters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_find_unused_parameters</span><span class="p">,</span>
</span><span id="__span-0-464">            <span class="n">broadcast_buffers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_broadcast_buffers</span><span class="p">,</span>
</span><span id="__span-0-465">            <span class="n">bucket_cap_mb</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_bucket_cap_mb</span><span class="p">,</span>
</span><span id="__span-0-466">        <span class="p">),</span>
</span><span id="__span-0-467">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.prepare_data_loader" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">prepare_data_loader</span>


<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.prepare_data_loader" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">dataset</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Prepare data loader with DistributedSampler for DDP.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dataset to load.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch size per process.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>shuffle</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to shuffle data.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of worker processes.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>drop_last</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to drop last incomplete batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional arguments for DataLoader.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.utils.data.DataLoader">DataLoader</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>DataLoader with DistributedSampler.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-469"><span class="k">def</span><span class="w"> </span><span class="nf">prepare_data_loader</span><span class="p">(</span>
</span><span id="__span-0-470">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-471">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">,</span>
</span><span id="__span-0-472">    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-473">    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-474">    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-475">    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-476">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-477"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">:</span>
</span><span id="__span-0-478"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepare data loader with DistributedSampler for DDP.</span>
</span><span id="__span-0-479">
</span><span id="__span-0-480"><span class="sd">    Args:</span>
</span><span id="__span-0-481"><span class="sd">        dataset: Dataset to load.</span>
</span><span id="__span-0-482"><span class="sd">        batch_size: Batch size per process.</span>
</span><span id="__span-0-483"><span class="sd">        shuffle: Whether to shuffle data.</span>
</span><span id="__span-0-484"><span class="sd">        num_workers: Number of worker processes.</span>
</span><span id="__span-0-485"><span class="sd">        drop_last: Whether to drop last incomplete batch.</span>
</span><span id="__span-0-486"><span class="sd">        **kwargs: Additional arguments for DataLoader.</span>
</span><span id="__span-0-487">
</span><span id="__span-0-488"><span class="sd">    Returns:</span>
</span><span id="__span-0-489"><span class="sd">        DataLoader with DistributedSampler.</span>
</span><span id="__span-0-490">
</span><span id="__span-0-491"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-492">    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
</span><span id="__span-0-493">    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedSampler</span>
</span><span id="__span-0-494">
</span><span id="__span-0-495">    <span class="n">sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span>
</span><span id="__span-0-496">        <span class="n">dataset</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="__span-0-497">        <span class="n">num_replicas</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_world_size</span><span class="p">,</span>
</span><span id="__span-0-498">        <span class="n">rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_rank</span><span class="p">,</span>
</span><span id="__span-0-499">        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
</span><span id="__span-0-500">        <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
</span><span id="__span-0-501">    <span class="p">)</span>
</span><span id="__span-0-502">
</span><span id="__span-0-503">    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-504">        <span class="n">dataset</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="__span-0-505">        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-506">        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
</span><span id="__span-0-507">        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
</span><span id="__span-0-508">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-509">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.reduce" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">reduce</span>


<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.reduce" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Reduce tensor across all processes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor to reduce.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>op</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Reduction operation - <code>"sum"</code> or <code>"mean"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.distributors._ReduceOp">_ReduceOp</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="formed.integrations.torch.distributors._TensorT">_TensorT</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Reduced tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code><span title="ValueError">ValueError</span></code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If unsupported reduction operation is specified.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-511"><span class="k">def</span><span class="w"> </span><span class="nf">reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">_TensorT</span><span class="p">,</span> <span class="n">op</span><span class="p">:</span> <span class="n">_ReduceOp</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_TensorT</span><span class="p">:</span>
</span><span id="__span-0-512"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Reduce tensor across all processes.</span>
</span><span id="__span-0-513">
</span><span id="__span-0-514"><span class="sd">    Args:</span>
</span><span id="__span-0-515"><span class="sd">        tensor: Tensor to reduce.</span>
</span><span id="__span-0-516"><span class="sd">        op: Reduction operation - `&quot;sum&quot;` or `&quot;mean&quot;`.</span>
</span><span id="__span-0-517">
</span><span id="__span-0-518"><span class="sd">    Returns:</span>
</span><span id="__span-0-519"><span class="sd">        Reduced tensor.</span>
</span><span id="__span-0-520">
</span><span id="__span-0-521"><span class="sd">    Raises:</span>
</span><span id="__span-0-522"><span class="sd">        ValueError: If unsupported reduction operation is specified.</span>
</span><span id="__span-0-523">
</span><span id="__span-0-524"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-525">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
</span><span id="__span-0-526">
</span><span id="__span-0-527">    <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span id="__span-0-528">        <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
</span><span id="__span-0-529">        <span class="k">return</span> <span class="n">tensor</span>
</span><span id="__span-0-530">    <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span id="__span-0-531">        <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
</span><span id="__span-0-532">        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">_TensorT</span><span class="p">,</span> <span class="n">tensor</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_world_size</span><span class="p">)</span>
</span><span id="__span-0-533">    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported reduce operation: </span><span class="si">{</span><span class="n">op</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.all_gather" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">all_gather</span>


<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.all_gather" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">all_gather</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Gather tensors from all processes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor to gather.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="torch.Tensor">Tensor</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>List of tensors from all processes.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-535"><span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-0-536"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Gather tensors from all processes.</span>
</span><span id="__span-0-537">
</span><span id="__span-0-538"><span class="sd">    Args:</span>
</span><span id="__span-0-539"><span class="sd">        tensor: Tensor to gather.</span>
</span><span id="__span-0-540">
</span><span id="__span-0-541"><span class="sd">    Returns:</span>
</span><span id="__span-0-542"><span class="sd">        List of tensors from all processes.</span>
</span><span id="__span-0-543">
</span><span id="__span-0-544"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-545">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
</span><span id="__span-0-546">
</span><span id="__span-0-547">    <span class="n">gathered</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_world_size</span><span class="p">)]</span>
</span><span id="__span-0-548">    <span class="n">dist</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">gathered</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</span><span id="__span-0-549">    <span class="k">return</span> <span class="n">gathered</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.barrier" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">barrier</span>


<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.barrier" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">barrier</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Synchronize all processes.</p>
<p>This creates a barrier that blocks until all processes reach this point.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-551"><span class="k">def</span><span class="w"> </span><span class="nf">barrier</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-552"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Synchronize all processes.</span>
</span><span id="__span-0-553">
</span><span id="__span-0-554"><span class="sd">    This creates a barrier that blocks until all processes reach this point.</span>
</span><span id="__span-0-555">
</span><span id="__span-0-556"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-557">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
</span><span id="__span-0-558">
</span><span id="__span-0-559">    <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.distributors.DistributedDataParallelDistributor.cleanup" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">cleanup</span>


<a href="#formed.integrations.torch.distributors.DistributedDataParallelDistributor.cleanup" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">cleanup</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Cleanup distributed process group.</p>
<p>This should be called at the end of training.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/distributors.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-561"><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-562"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Cleanup distributed process group.</span>
</span><span id="__span-0-563">
</span><span id="__span-0-564"><span class="sd">    This should be called at the end of training.</span>
</span><span id="__span-0-565">
</span><span id="__span-0-566"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-567">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
</span><span id="__span-0-568">
</span><span id="__span-0-569">    <span class="k">if</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="__span-0-570">        <span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.initializers" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.initializers</span>


<a href="#formed.integrations.torch.initializers" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.BaseTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.BaseTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="colt.Registrable">Registrable</span></code></p>













<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.UniformTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">UniformTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.UniformTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">UniformTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-14"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">low</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
</span><span id="__span-0-15">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-16">    <span class="bp">self</span><span class="o">.</span><span class="n">_low</span> <span class="o">=</span> <span class="n">low</span>
</span><span id="__span-0-17">    <span class="bp">self</span><span class="o">.</span><span class="n">_high</span> <span class="o">=</span> <span class="n">high</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.NormalTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">NormalTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.NormalTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">NormalTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-25"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
</span><span id="__span-0-26">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-27">    <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">mean</span>
</span><span id="__span-0-28">    <span class="bp">self</span><span class="o">.</span><span class="n">_std</span> <span class="o">=</span> <span class="n">std</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.XavierUniformTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">XavierUniformTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.XavierUniformTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">XavierUniformTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-36"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">gain</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
</span><span id="__span-0-37">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-38">    <span class="bp">self</span><span class="o">.</span><span class="n">_gain</span> <span class="o">=</span> <span class="n">gain</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.XavierNormalTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">XavierNormalTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.XavierNormalTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">XavierNormalTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-48"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">gain</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
</span><span id="__span-0-49">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-50">    <span class="bp">self</span><span class="o">.</span><span class="n">_gain</span> <span class="o">=</span> <span class="n">gain</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.KaimingUniformTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">KaimingUniformTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.KaimingUniformTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">KaimingUniformTensorInitializer</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_in&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;leaky_relu&quot;</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-60"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-61">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-62">    <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
</span><span id="__span-0-63">    <span class="n">a</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-64">    <span class="n">mode</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_FanMode</span> <span class="o">=</span> <span class="s2">&quot;fan_in&quot;</span><span class="p">,</span>
</span><span id="__span-0-65">    <span class="n">nonlinearity</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_NonlinearityType</span> <span class="o">=</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
</span><span id="__span-0-66"><span class="p">):</span>
</span><span id="__span-0-67">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-68">    <span class="bp">self</span><span class="o">.</span><span class="n">_a</span> <span class="o">=</span> <span class="n">a</span>
</span><span id="__span-0-69">    <span class="bp">self</span><span class="o">.</span><span class="n">_mode</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_FanMode</span> <span class="o">=</span> <span class="n">mode</span>
</span><span id="__span-0-70">    <span class="bp">self</span><span class="o">.</span><span class="n">_nonlinearity</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_NonlinearityType</span> <span class="o">=</span> <span class="n">nonlinearity</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.KaimingNormalTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">KaimingNormalTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.KaimingNormalTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">KaimingNormalTensorInitializer</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">shape</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_in&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;leaky_relu&quot;</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-80"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-81">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-82">    <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
</span><span id="__span-0-83">    <span class="n">a</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-84">    <span class="n">mode</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_FanMode</span> <span class="o">=</span> <span class="s2">&quot;fan_in&quot;</span><span class="p">,</span>
</span><span id="__span-0-85">    <span class="n">nonlinearity</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_NonlinearityType</span> <span class="o">=</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
</span><span id="__span-0-86"><span class="p">):</span>
</span><span id="__span-0-87">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-88">    <span class="bp">self</span><span class="o">.</span><span class="n">_a</span> <span class="o">=</span> <span class="n">a</span>
</span><span id="__span-0-89">    <span class="bp">self</span><span class="o">.</span><span class="n">_mode</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_FanMode</span> <span class="o">=</span> <span class="n">mode</span>
</span><span id="__span-0-90">    <span class="bp">self</span><span class="o">.</span><span class="n">_nonlinearity</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_NonlinearityType</span> <span class="o">=</span> <span class="n">nonlinearity</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.OrthogonalTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">OrthogonalTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.OrthogonalTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">OrthogonalTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-100"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">gain</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
</span><span id="__span-0-101">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-102">    <span class="bp">self</span><span class="o">.</span><span class="n">_gain</span> <span class="o">=</span> <span class="n">gain</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.SparseTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SparseTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.SparseTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">SparseTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">sparsity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-112"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">sparsity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">):</span>
</span><span id="__span-0-113">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="__span-0-114">    <span class="bp">self</span><span class="o">.</span><span class="n">_sparsity</span> <span class="o">=</span> <span class="n">sparsity</span>
</span><span id="__span-0-115">    <span class="bp">self</span><span class="o">.</span><span class="n">_std</span> <span class="o">=</span> <span class="n">std</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.ZerosTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">ZerosTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.ZerosTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">ZerosTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-125"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
</span><span id="__span-0-126">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.initializers.OnesTensorInitializer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">OnesTensorInitializer</span>


<a href="#formed.integrations.torch.initializers.OnesTensorInitializer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">OnesTensorInitializer</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/initializers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-134"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
</span><span id="__span-0-135">    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">












  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.model</span>


<a href="#formed.integrations.torch.model" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Base model abstraction for PyTorch models.</p>
<p>This module provides the base class for all PyTorch models in the framework,
integrating torch.nn.Module with the registrable pattern for configuration-based
model instantiation.</p>


<details class="key-features" open>
  <summary>Key Features</summary>
  <ul>
<li>Integration with PyTorch Module system</li>
<li>Registrable pattern for configuration-based instantiation</li>
<li>Generic type support for inputs, outputs, and parameters</li>
<li>Compatible with TorchTrainer for end-to-end training</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseTorchModel</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="nd">@BaseTorchModel</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;my_model&quot;</span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">... </span><span class="k">class</span><span class="w"> </span><span class="nc">MyModel</span><span class="p">(</span><span class="n">BaseTorchModel</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="kc">None</span><span class="p">]):</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="__span-0-8"><span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-9"><span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
</span><span id="__span-0-10"><span class="gp">...</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-12"><span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.model.BaseTorchModel" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseTorchModel</span>


<a href="#formed.integrations.torch.model.BaseTorchModel" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code></p>



        <p>Base class for all PyTorch models in the framework.</p>
<p>This class combines PyTorch's nn.Module with the registrable pattern,
allowing models to be instantiated from configuration files and
seamlessly integrated with the training infrastructure.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>ModelInputT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of input data to the model.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ModelOutputT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of model output.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ModelParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional parameters (typically None or a dataclass).</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>Subclasses should implement <code>forward()</code> to define the forward pass.
Models are automatically compatible with <code>TorchTrainer</code> when registered.</p>
</details>










<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.model.BaseTorchModel.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.model.BaseTorchModel.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Forward pass of the model.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input data to the model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional additional parameters for the forward pass.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Model output.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code><span title="NotImplementedError">NotImplementedError</span></code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>This method must be implemented by subclasses.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-62"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">ModelInputT</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">ModelParamsT</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOutputT</span><span class="p">:</span>
</span><span id="__span-0-63"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Forward pass of the model.</span>
</span><span id="__span-0-64">
</span><span id="__span-0-65"><span class="sd">    Args:</span>
</span><span id="__span-0-66"><span class="sd">        inputs: Input data to the model.</span>
</span><span id="__span-0-67"><span class="sd">        params: Optional additional parameters for the forward pass.</span>
</span><span id="__span-0-68">
</span><span id="__span-0-69"><span class="sd">    Returns:</span>
</span><span id="__span-0-70"><span class="sd">        Model output.</span>
</span><span id="__span-0-71">
</span><span id="__span-0-72"><span class="sd">    Raises:</span>
</span><span id="__span-0-73"><span class="sd">        NotImplementedError: This method must be implemented by subclasses.</span>
</span><span id="__span-0-74">
</span><span id="__span-0-75"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-76">    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.schedulers" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.schedulers</span>


<a href="#formed.integrations.torch.schedulers" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Learning rate schedulers for PyTorch models.</p>
<p>This module provides custom learning rate schedulers that extend PyTorch's
standard scheduler functionality, including cosine annealing with warm restarts
and warmup phases.</p>


<details class="available-schedulers" open>
  <summary>Available Schedulers</summary>
  <ul>
<li><code>CosineLRScheduler</code>: Cosine annealing with optional restarts and warmup</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Cosine decay with configurable cycle length</li>
<li>Warm restarts with cycle multiplier</li>
<li>Learning rate warmup phase</li>
<li>Cycle-based decay multiplier</li>
<li>Compatible with Colt registration system</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.schedulers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineLRScheduler</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineLRScheduler</span><span class="p">(</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">optimizer</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">t_initial</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">lr_min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">warmup_t</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">warmup_lr_init</span><span class="o">=</span><span class="mf">1e-5</span>
</span><span id="__span-0-9"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.schedulers.CosineLRScheduler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CosineLRScheduler</span>


<a href="#formed.integrations.torch.schedulers.CosineLRScheduler" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">CosineLRScheduler</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">optimizer</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">t_initial</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">lr_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">cycle_mul</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">cycle_decay</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">cycle_limit</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">warmup_t</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-9">    <span class="n">warmup_lr_init</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-10">    <span class="n">warmup_prefix</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-11">    <span class="n">t_in_epochs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-12">    <span class="n">last_epoch</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-13"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.optim.lr_scheduler.LRScheduler">LRScheduler</span></code></p>



        <p>Cosine annealing learning rate scheduler with warm restarts.</p>
<p>Implements the SGDR (Stochastic Gradient Descent with Warm Restarts)
algorithm described in https://arxiv.org/abs/1608.03983.</p>
<p>This scheduler decreases the learning rate following a cosine curve,
optionally restarting the schedule multiple times during training.
It also supports a warmup phase at the beginning.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>optimizer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Wrapped optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.optim.Optimizer">Optimizer</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>t_initial</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of iterations/epochs for the first cycle.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lr_min</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Minimum learning rate. Default: <code>0</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cycle_mul</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Multiplier for cycle length after each restart. Default: <code>1.0</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cycle_decay</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Decay factor applied to learning rate at each restart. Default: <code>1.0</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cycle_limit</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum number of restart cycles (0 means no limit). Default: <code>1</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warmup_t</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of warmup iterations/epochs. Default: <code>0</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warmup_lr_init</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Initial learning rate during warmup. Default: <code>0</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warmup_prefix</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>True</code>, warmup iterations don't count toward t_initial. Default: <code>False</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>t_in_epochs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>True</code>, t values are in epochs; otherwise in iterations. Default: <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>last_epoch</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The index of last epoch. Default: <code>-1</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>-1</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create scheduler with 100 epoch cycles and 5 epoch warmup</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineLRScheduler</span><span class="p">(</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">optimizer</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">t_initial</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">lr_min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">cycle_mul</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>  <span class="c1"># Each cycle is 2x longer</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">warmup_t</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">warmup_lr_init</span><span class="o">=</span><span class="mf">1e-5</span>
</span><span id="__span-0-9"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Update learning rate each epoch</span>
</span><span id="__span-0-12"><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
</span><span id="__span-0-13"><span class="gp">... </span>    <span class="n">train_one_epoch</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span><span id="__span-0-14"><span class="gp">... </span>    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/schedulers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-80"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-81">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-82">    <span class="n">optimizer</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
</span><span id="__span-0-83">    <span class="n">t_initial</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-84">    <span class="n">lr_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-85">    <span class="n">cycle_mul</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-86">    <span class="n">cycle_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-87">    <span class="n">cycle_limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-88">    <span class="n">warmup_t</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-89">    <span class="n">warmup_lr_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-90">    <span class="n">warmup_prefix</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-91">    <span class="n">t_in_epochs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-92">    <span class="n">last_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-93"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-94">    <span class="k">assert</span> <span class="n">t_initial</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;t_initial must be positive&quot;</span>
</span><span id="__span-0-95">    <span class="k">assert</span> <span class="n">lr_min</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;lr_min must be non-negative&quot;</span>
</span><span id="__span-0-96">
</span><span id="__span-0-97">    <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span> <span class="o">=</span> <span class="n">t_initial</span>
</span><span id="__span-0-98">    <span class="bp">self</span><span class="o">.</span><span class="n">lr_min</span> <span class="o">=</span> <span class="n">lr_min</span>
</span><span id="__span-0-99">    <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span> <span class="o">=</span> <span class="n">cycle_mul</span>
</span><span id="__span-0-100">    <span class="bp">self</span><span class="o">.</span><span class="n">cycle_decay</span> <span class="o">=</span> <span class="n">cycle_decay</span>
</span><span id="__span-0-101">    <span class="bp">self</span><span class="o">.</span><span class="n">cycle_limit</span> <span class="o">=</span> <span class="n">cycle_limit</span>
</span><span id="__span-0-102">    <span class="bp">self</span><span class="o">.</span><span class="n">warmup_t</span> <span class="o">=</span> <span class="n">warmup_t</span>
</span><span id="__span-0-103">    <span class="bp">self</span><span class="o">.</span><span class="n">warmup_lr_init</span> <span class="o">=</span> <span class="n">warmup_lr_init</span>
</span><span id="__span-0-104">    <span class="bp">self</span><span class="o">.</span><span class="n">warmup_prefix</span> <span class="o">=</span> <span class="n">warmup_prefix</span>
</span><span id="__span-0-105">    <span class="bp">self</span><span class="o">.</span><span class="n">t_in_epochs</span> <span class="o">=</span> <span class="n">t_in_epochs</span>
</span><span id="__span-0-106">
</span><span id="__span-0-107">    <span class="c1"># Store base learning rates</span>
</span><span id="__span-0-108">    <span class="bp">self</span><span class="o">.</span><span class="n">base_lrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">]</span>
</span><span id="__span-0-109">
</span><span id="__span-0-110">    <span class="c1"># Initialize warmup steps</span>
</span><span id="__span-0-111">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_t</span><span class="p">:</span>
</span><span id="__span-0-112">        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="p">[(</span><span class="n">base_lr</span> <span class="o">-</span> <span class="n">warmup_lr_init</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_t</span> <span class="k">for</span> <span class="n">base_lr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_lrs</span><span class="p">]</span>
</span><span id="__span-0-113">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-114">        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_lrs</span><span class="p">]</span>
</span><span id="__span-0-115">
</span><span id="__span-0-116">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">last_epoch</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.t_initial" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">t_initial</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.t_initial" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">t_initial</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(t_initial)">t_initial</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.lr_min" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">lr_min</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.lr_min" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">lr_min</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(lr_min)">lr_min</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.cycle_mul" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">cycle_mul</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_mul" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">cycle_mul</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(cycle_mul)">cycle_mul</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.cycle_decay" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">cycle_decay</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_decay" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">cycle_decay</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(cycle_decay)">cycle_decay</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.cycle_limit" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">cycle_limit</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_limit" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">cycle_limit</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(cycle_limit)">cycle_limit</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.warmup_t" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">warmup_t</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_t" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">warmup_t</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(warmup_t)">warmup_t</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.warmup_lr_init" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">warmup_lr_init</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_lr_init" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">warmup_lr_init</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(warmup_lr_init)">warmup_lr_init</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.warmup_prefix" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">warmup_prefix</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_prefix" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">warmup_prefix</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(warmup_prefix)">warmup_prefix</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.t_in_epochs" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">t_in_epochs</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.t_in_epochs" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">t_in_epochs</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(t_in_epochs)">t_in_epochs</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.base_lrs" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">base_lrs</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.base_lrs" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">base_lrs</span> <span class="o">=</span> <span class="p">[(</span><span class="n"><span title="group">group</span></span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n"><span title="group">group</span></span> <span class="ow">in</span> <span class="p">(</span><span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(optimizer).param_groups">param_groups</span></span><span class="p">)]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.warmup_steps" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">warmup_steps</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_steps" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">warmup_steps</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-2">    <span class="p">((</span><span class="n"><span title="base_lr">base_lr</span></span> <span class="o">-</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(warmup_lr_init)">warmup_lr_init</span></span><span class="p">)</span> <span class="o">/</span> <span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(self).warmup_t">warmup_t</span></span><span class="p">)</span>
</span><span id="__span-0-3">    <span class="k">for</span> <span class="n"><span title="base_lr">base_lr</span></span> <span class="ow">in</span> <span class="p">(</span><span class="n"><span title="formed.integrations.torch.schedulers.CosineLRScheduler(self).base_lrs">base_lrs</span></span><span class="p">)</span>
</span><span id="__span-0-4"><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.get_lr" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_lr</span>


<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.get_lr" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_lr</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute learning rate at the current step.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="list">list</span>[<span title="float">float</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>List of learning rates for each parameter group.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/schedulers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-118"><span class="k">def</span><span class="w"> </span><span class="nf">get_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-119"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute learning rate at the current step.</span>
</span><span id="__span-0-120">
</span><span id="__span-0-121"><span class="sd">    Returns:</span>
</span><span id="__span-0-122"><span class="sd">        List of learning rates for each parameter group.</span>
</span><span id="__span-0-123">
</span><span id="__span-0-124"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-125">    <span class="c1"># Current timestep (starts from 0 after first step())</span>
</span><span id="__span-0-126">    <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span>
</span><span id="__span-0-127">
</span><span id="__span-0-128">    <span class="c1"># Warmup phase: linearly interpolate from warmup_lr_init to base_lr</span>
</span><span id="__span-0-129">    <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_t</span><span class="p">:</span>
</span><span id="__span-0-130">        <span class="n">lrs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">warmup_lr_init</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">step</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">]</span>
</span><span id="__span-0-131">        <span class="k">return</span> <span class="n">lrs</span>
</span><span id="__span-0-132">
</span><span id="__span-0-133">    <span class="c1"># Adjust t if warmup is a prefix</span>
</span><span id="__span-0-134">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_prefix</span><span class="p">:</span>
</span><span id="__span-0-135">        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_t</span>
</span><span id="__span-0-136">
</span><span id="__span-0-137">    <span class="c1"># Determine current cycle</span>
</span><span id="__span-0-138">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="__span-0-139">        <span class="c1"># Simple case: equal cycles</span>
</span><span id="__span-0-140">        <span class="n">cycle</span> <span class="o">=</span> <span class="n">t</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span>
</span><span id="__span-0-141">        <span class="n">t_curr</span> <span class="o">=</span> <span class="n">t</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span>
</span><span id="__span-0-142">        <span class="n">t_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span>
</span><span id="__span-0-143">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-144">        <span class="c1"># Geometric progression of cycle lengths</span>
</span><span id="__span-0-145">        <span class="c1"># Find which cycle we&#39;re in using logarithmic calculation</span>
</span><span id="__span-0-146">        <span class="n">cycle</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span><span class="p">))</span>
</span><span id="__span-0-147">        <span class="c1"># Compute cumulative time up to current cycle</span>
</span><span id="__span-0-148">        <span class="n">t_prev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span><span class="o">**</span><span class="n">cycle</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span><span class="p">)</span>
</span><span id="__span-0-149">        <span class="n">t_curr</span> <span class="o">=</span> <span class="n">t</span> <span class="o">-</span> <span class="n">t_prev</span>
</span><span id="__span-0-150">        <span class="n">t_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span><span class="o">**</span><span class="n">cycle</span><span class="p">)</span>
</span><span id="__span-0-151">
</span><span id="__span-0-152">    <span class="c1"># Apply cycle limit</span>
</span><span id="__span-0-153">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_limit</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">cycle</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_limit</span><span class="p">:</span>
</span><span id="__span-0-154">        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_min</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_lrs</span><span class="p">]</span>
</span><span id="__span-0-155">
</span><span id="__span-0-156">    <span class="c1"># Compute cycle decay</span>
</span><span id="__span-0-157">    <span class="n">cycle_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_decay</span><span class="o">**</span><span class="n">cycle</span>
</span><span id="__span-0-158">
</span><span id="__span-0-159">    <span class="c1"># Cosine annealing</span>
</span><span id="__span-0-160">    <span class="n">lrs</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-161">        <span class="bp">self</span><span class="o">.</span><span class="n">lr_min</span> <span class="o">+</span> <span class="p">(</span><span class="n">base_lr</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_min</span><span class="p">)</span> <span class="o">*</span> <span class="n">cycle_decay</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">t_curr</span> <span class="o">/</span> <span class="n">t_i</span><span class="p">))</span>
</span><span id="__span-0-162">        <span class="k">for</span> <span class="n">base_lr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_lrs</span>
</span><span id="__span-0-163">    <span class="p">]</span>
</span><span id="__span-0-164">
</span><span id="__span-0-165">    <span class="k">return</span> <span class="n">lrs</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.get_cycle_length" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_cycle_length</span>


<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.get_cycle_length" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_cycle_length</span><span class="p">(</span><span class="n">cycles</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Calculate total number of iterations for a given number of cycles.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>cycles</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of cycles (<code>0</code> means current cycle).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Total number of iterations.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/schedulers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-167"><span class="k">def</span><span class="w"> </span><span class="nf">get_cycle_length</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cycles</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-168"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate total number of iterations for a given number of cycles.</span>
</span><span id="__span-0-169">
</span><span id="__span-0-170"><span class="sd">    Args:</span>
</span><span id="__span-0-171"><span class="sd">        cycles: Number of cycles (`0` means current cycle).</span>
</span><span id="__span-0-172">
</span><span id="__span-0-173"><span class="sd">    Returns:</span>
</span><span id="__span-0-174"><span class="sd">        Total number of iterations.</span>
</span><span id="__span-0-175">
</span><span id="__span-0-176"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-177">    <span class="k">if</span> <span class="n">cycles</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-178">        <span class="n">cycles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_limit</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_limit</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
</span><span id="__span-0-179">
</span><span id="__span-0-180">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="__span-0-181">        <span class="n">length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span> <span class="o">*</span> <span class="n">cycles</span>
</span><span id="__span-0-182">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-183">        <span class="n">length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_initial</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span><span class="o">**</span><span class="n">cycles</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cycle_mul</span><span class="p">))</span>
</span><span id="__span-0-184">
</span><span id="__span-0-185">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_prefix</span><span class="p">:</span>
</span><span id="__span-0-186">        <span class="n">length</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_t</span>
</span><span id="__span-0-187">
</span><span id="__span-0-188">    <span class="k">return</span> <span class="n">length</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.state_dict" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">state_dict</span>


<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.state_dict" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">state_dict</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return the state of the scheduler as a dict.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Dictionary containing scheduler state.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/schedulers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-190"><span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span id="__span-0-191"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the state of the scheduler as a dict.</span>
</span><span id="__span-0-192">
</span><span id="__span-0-193"><span class="sd">    Returns:</span>
</span><span id="__span-0-194"><span class="sd">        Dictionary containing scheduler state.</span>
</span><span id="__span-0-195">
</span><span id="__span-0-196"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-197">    <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-198">        <span class="n">key</span><span class="p">:</span> <span class="n">value</span>
</span><span id="__span-0-199">        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
</span><span id="__span-0-200">        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;optimizer&quot;</span><span class="p">,</span> <span class="s2">&quot;_get_lr_called_within_step&quot;</span><span class="p">,</span> <span class="s2">&quot;_step_count&quot;</span><span class="p">)</span>
</span><span id="__span-0-201">    <span class="p">}</span>
</span><span id="__span-0-202">    <span class="k">return</span> <span class="n">state</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.schedulers.CosineLRScheduler.load_state_dict" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">load_state_dict</span>


<a href="#formed.integrations.torch.schedulers.CosineLRScheduler.load_state_dict" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Load the scheduler state.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>state_dict</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Scheduler state dict.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/schedulers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-204"><span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-205"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Load the scheduler state.</span>
</span><span id="__span-0-206">
</span><span id="__span-0-207"><span class="sd">    Args:</span>
</span><span id="__span-0-208"><span class="sd">        state_dict: Scheduler state dict.</span>
</span><span id="__span-0-209">
</span><span id="__span-0-210"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-211">    <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.utils" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.utils</span>


<a href="#formed.integrations.torch.utils" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Utility functions for PyTorch integration.</p>










<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="formed.integrations.torch.utils.PoolingMethod" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">PoolingMethod</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.utils.PoolingMethod" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">PoolingMethod</span> <span class="o">=</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span>
</span><span id="__span-0-2">    <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="s2">&quot;first&quot;</span><span class="p">,</span> <span class="s2">&quot;last&quot;</span><span class="p">,</span> <span class="s2">&quot;hier&quot;</span>
</span><span id="__span-0-3"><span class="p">]</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.utils.set_random_seed" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">set_random_seed</span>


<a href="#formed.integrations.torch.utils.set_random_seed" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Set random seed for reproducibility across torch, numpy, and random.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Random seed value.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-15"><span class="k">def</span><span class="w"> </span><span class="nf">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-16"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Set random seed for reproducibility across torch, numpy, and random.</span>
</span><span id="__span-0-17">
</span><span id="__span-0-18"><span class="sd">    Args:</span>
</span><span id="__span-0-19"><span class="sd">        seed: Random seed value.</span>
</span><span id="__span-0-20"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-21">    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="__span-0-22">    <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="__span-0-23">    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="__span-0-24">    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="__span-0-25">        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.utils.ensure_torch_tensor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">ensure_torch_tensor</span>


<a href="#formed.integrations.torch.utils.ensure_torch_tensor" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">ensure_torch_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Convert array-like objects to PyTorch tensors.</p>
<p>This function converts various array-like objects (numpy arrays, lists, etc.)
to PyTorch tensors. If the input is already a tensor, it returns it with the
appropriate dtype and device.</p>
<p>The device can be specified explicitly via the <code>device</code> parameter, or it will
be taken from the context set by <code>use_device()</code>. If neither is provided and
the input is not already a tensor, the tensor will be created on CPU.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input data (tensor, numpy array, list, etc.)</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional dtype for the output tensor.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.dtype">dtype</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional device for the output tensor. If None, uses the device
from context (set by <code>use_device()</code>). If the input is already a tensor,
its device is preserved unless explicitly specified.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="torch.device">device</span>, <span title="str">str</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>PyTorch tensor on the specified device with the specified dtype.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">ensure_torch_tensor</span><span class="p">,</span> <span class="n">use_device</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without context</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-8"><span class="go">device(type=&#39;cpu&#39;)</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With context</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">use_device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">):</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">tensor</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
</span><span id="__span-0-13"><span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-14"><span class="go">cuda:0</span>
</span></code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-28"><span class="k">def</span><span class="w"> </span><span class="nf">ensure_torch_tensor</span><span class="p">(</span>
</span><span id="__span-0-29">    <span class="n">x</span><span class="p">:</span> <span class="n">TensorCompatible</span><span class="p">,</span>
</span><span id="__span-0-30">    <span class="n">dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-31">    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-32"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-33"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert array-like objects to PyTorch tensors.</span>
</span><span id="__span-0-34">
</span><span id="__span-0-35"><span class="sd">    This function converts various array-like objects (numpy arrays, lists, etc.)</span>
</span><span id="__span-0-36"><span class="sd">    to PyTorch tensors. If the input is already a tensor, it returns it with the</span>
</span><span id="__span-0-37"><span class="sd">    appropriate dtype and device.</span>
</span><span id="__span-0-38">
</span><span id="__span-0-39"><span class="sd">    The device can be specified explicitly via the `device` parameter, or it will</span>
</span><span id="__span-0-40"><span class="sd">    be taken from the context set by `use_device()`. If neither is provided and</span>
</span><span id="__span-0-41"><span class="sd">    the input is not already a tensor, the tensor will be created on CPU.</span>
</span><span id="__span-0-42">
</span><span id="__span-0-43"><span class="sd">    Args:</span>
</span><span id="__span-0-44"><span class="sd">        x: Input data (tensor, numpy array, list, etc.)</span>
</span><span id="__span-0-45"><span class="sd">        dtype: Optional dtype for the output tensor.</span>
</span><span id="__span-0-46"><span class="sd">        device: Optional device for the output tensor. If None, uses the device</span>
</span><span id="__span-0-47"><span class="sd">            from context (set by `use_device()`). If the input is already a tensor,</span>
</span><span id="__span-0-48"><span class="sd">            its device is preserved unless explicitly specified.</span>
</span><span id="__span-0-49">
</span><span id="__span-0-50"><span class="sd">    Returns:</span>
</span><span id="__span-0-51"><span class="sd">        PyTorch tensor on the specified device with the specified dtype.</span>
</span><span id="__span-0-52">
</span><span id="__span-0-53"><span class="sd">    Examples:</span>
</span><span id="__span-0-54"><span class="sd">        &gt;&gt;&gt; import numpy as np</span>
</span><span id="__span-0-55"><span class="sd">        &gt;&gt;&gt; from formed.integrations.torch import ensure_torch_tensor, use_device</span>
</span><span id="__span-0-56"><span class="sd">        &gt;&gt;&gt; arr = np.array([1, 2, 3])</span>
</span><span id="__span-0-57"><span class="sd">        &gt;&gt;&gt;</span>
</span><span id="__span-0-58"><span class="sd">        &gt;&gt;&gt; # Without context</span>
</span><span id="__span-0-59"><span class="sd">        &gt;&gt;&gt; tensor = ensure_torch_tensor(arr)</span>
</span><span id="__span-0-60"><span class="sd">        &gt;&gt;&gt; tensor.device</span>
</span><span id="__span-0-61"><span class="sd">        device(type=&#39;cpu&#39;)</span>
</span><span id="__span-0-62"><span class="sd">        &gt;&gt;&gt;</span>
</span><span id="__span-0-63"><span class="sd">        &gt;&gt;&gt; # With context</span>
</span><span id="__span-0-64"><span class="sd">        &gt;&gt;&gt; with use_device(&quot;cuda:0&quot;):</span>
</span><span id="__span-0-65"><span class="sd">        ...     tensor = ensure_torch_tensor(arr)</span>
</span><span id="__span-0-66"><span class="sd">        ...     print(tensor.device)</span>
</span><span id="__span-0-67"><span class="sd">        cuda:0</span>
</span><span id="__span-0-68"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-69">    <span class="c1"># Determine target device</span>
</span><span id="__span-0-70">    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-71">        <span class="n">device</span> <span class="o">=</span> <span class="n">get_device</span><span class="p">()</span>
</span><span id="__span-0-72">
</span><span id="__span-0-73">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="__span-0-74">        <span class="c1"># If already a tensor, convert dtype/device as needed</span>
</span><span id="__span-0-75">        <span class="n">needs_dtype_conversion</span> <span class="o">=</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">dtype</span>
</span><span id="__span-0-76">        <span class="n">needs_device_conversion</span> <span class="o">=</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-77">
</span><span id="__span-0-78">        <span class="k">if</span> <span class="n">needs_dtype_conversion</span> <span class="ow">or</span> <span class="n">needs_device_conversion</span><span class="p">:</span>
</span><span id="__span-0-79">            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-0-80">            <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-81">                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtype</span>
</span><span id="__span-0-82">            <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-83">                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">device</span>
</span><span id="__span-0-84">            <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="__span-0-85">        <span class="k">return</span> <span class="n">x</span>
</span><span id="__span-0-86">
</span><span id="__span-0-87">    <span class="c1"># Convert numpy arrays, handling float64 -&gt; float32 conversion</span>
</span><span id="__span-0-88">    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-0-89">
</span><span id="__span-0-90">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
</span><span id="__span-0-91">        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="__span-0-92">            <span class="c1"># Default: convert float64 to float32 for PyTorch</span>
</span><span id="__span-0-93">            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
</span><span id="__span-0-94">        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-95">        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-96">            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-97">        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-98">            <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-99">        <span class="k">return</span> <span class="n">tensor</span>
</span><span id="__span-0-100">
</span><span id="__span-0-101">    <span class="c1"># Convert other array-like objects</span>
</span><span id="__span-0-102">    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-103">    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-104">        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="__span-0-105">    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-106">        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-107">    <span class="k">return</span> <span class="n">tensor</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.utils.move_to_device" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">move_to_device</span>


<a href="#formed.integrations.torch.utils.move_to_device" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">move_to_device</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Move tensor inputs to the appropriate device.</p>
<p>This function only moves existing torch.Tensor objects to the target device.
Other types (numpy arrays, primitives, etc.) are left unchanged.
Users should explicitly convert numpy arrays to tensors in their model's
forward method using <code>ensure_torch_tensor()</code>.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-110"><span class="k">def</span><span class="w"> </span><span class="nf">move_to_device</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">ModelInputT</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">ModelInputT</span><span class="p">:</span>
</span><span id="__span-0-111"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Move tensor inputs to the appropriate device.</span>
</span><span id="__span-0-112">
</span><span id="__span-0-113"><span class="sd">    This function only moves existing torch.Tensor objects to the target device.</span>
</span><span id="__span-0-114"><span class="sd">    Other types (numpy arrays, primitives, etc.) are left unchanged.</span>
</span><span id="__span-0-115"><span class="sd">    Users should explicitly convert numpy arrays to tensors in their model&#39;s</span>
</span><span id="__span-0-116"><span class="sd">    forward method using `ensure_torch_tensor()`.</span>
</span><span id="__span-0-117"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-118">    <span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>
</span><span id="__span-0-119">
</span><span id="__span-0-120">    <span class="n">visited</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span id="__span-0-121">
</span><span id="__span-0-122">    <span class="k">def</span><span class="w"> </span><span class="nf">_move</span><span class="p">(</span><span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="__span-0-123">        <span class="c1"># Handle tensors - move to device</span>
</span><span id="__span-0-124">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="__span-0-125">            <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-126">
</span><span id="__span-0-127">        <span class="c1"># Handle primitives and None - no conversion needed</span>
</span><span id="__span-0-128">        <span class="k">if</span> <span class="n">obj</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">type</span><span class="p">)):</span>
</span><span id="__span-0-129">            <span class="k">return</span> <span class="n">obj</span>
</span><span id="__span-0-130">
</span><span id="__span-0-131">        <span class="c1"># Check if already visited to avoid infinite recursion</span>
</span><span id="__span-0-132">        <span class="n">obj_id</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span><span id="__span-0-133">        <span class="k">if</span> <span class="n">obj_id</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
</span><span id="__span-0-134">            <span class="k">return</span> <span class="n">obj</span>
</span><span id="__span-0-135">        <span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">obj_id</span><span class="p">)</span>
</span><span id="__span-0-136">
</span><span id="__span-0-137">        <span class="c1"># Handle dict</span>
</span><span id="__span-0-138">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
</span><span id="__span-0-139">            <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">_move</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">obj</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="__span-0-140">
</span><span id="__span-0-141">        <span class="c1"># Handle list/tuple</span>
</span><span id="__span-0-142">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
</span><span id="__span-0-143">            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)(</span><span class="n">_move</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">)</span>
</span><span id="__span-0-144">
</span><span id="__span-0-145">        <span class="c1"># Handle objects with __dict__ (but not built-in types)</span>
</span><span id="__span-0-146">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;__dict__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
</span><span id="__span-0-147">            <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-148">                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
</span><span id="__span-0-149">                    <span class="c1"># Skip dunder attributes</span>
</span><span id="__span-0-150">                    <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">):</span>
</span><span id="__span-0-151">                        <span class="nb">setattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">_move</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
</span><span id="__span-0-152">            <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">):</span>
</span><span id="__span-0-153">                <span class="c1"># Skip objects that don&#39;t allow attribute modification</span>
</span><span id="__span-0-154">                <span class="k">pass</span>
</span><span id="__span-0-155">            <span class="k">return</span> <span class="n">obj</span>
</span><span id="__span-0-156">
</span><span id="__span-0-157">        <span class="k">return</span> <span class="n">obj</span>
</span><span id="__span-0-158">
</span><span id="__span-0-159">    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">_move</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.utils.determine_ndim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">determine_ndim</span>


<a href="#formed.integrations.torch.utils.determine_ndim" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">determine_ndim</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-162"><span class="k">def</span><span class="w"> </span><span class="nf">determine_ndim</span><span class="p">(</span>
</span><span id="__span-0-163">    <span class="n">first</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-164">    <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">]]],</span>
</span><span id="__span-0-165"><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-166">    <span class="n">output_dim</span> <span class="o">=</span> <span class="n">first</span>
</span><span id="__span-0-167">    <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
</span><span id="__span-0-168">        <span class="k">if</span> <span class="n">arg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-169">            <span class="k">continue</span>
</span><span id="__span-0-170">        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">arg</span><span class="p">):</span>
</span><span id="__span-0-171">            <span class="n">output_dim</span> <span class="o">=</span> <span class="n">arg</span><span class="p">(</span><span class="n">output_dim</span><span class="p">)</span>
</span><span id="__span-0-172">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-173">            <span class="n">output_dim</span> <span class="o">=</span> <span class="n">arg</span>
</span><span id="__span-0-174">    <span class="k">return</span> <span class="n">output_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.utils.masked_pool" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">masked_pool</span>


<a href="#formed.integrations.torch.utils.masked_pool" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">masked_pool</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">inputs</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">window_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Apply masked pooling over the sequence dimension.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input tensor of shape <code>(batch_size, seq_len, feature_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Mask tensor of shape <code>(batch_size, seq_len)</code>. <code>True</code>/<code>1</code> indicates valid positions.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pooling</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pooling method or sequence of methods.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;PoolingMethod&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.utils.PoolingMethod&lt;/code&gt;)" href="#formed.integrations.torch.utils.PoolingMethod">PoolingMethod</a>, <span title="collections.abc.Sequence">Sequence</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;PoolingMethod&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.utils.PoolingMethod&lt;/code&gt;)" href="#formed.integrations.torch.utils.PoolingMethod">PoolingMethod</a>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to L2-normalize before pooling.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>window_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Window size for hierarchical pooling (required if <code>pooling="hier"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Pooled tensor of shape <code>(batch_size, feature_dim * num_pooling_methods)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-180"><span class="k">def</span><span class="w"> </span><span class="nf">masked_pool</span><span class="p">(</span>
</span><span id="__span-0-181">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-182">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-183">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-184">    <span class="n">pooling</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">PoolingMethod</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">PoolingMethod</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
</span><span id="__span-0-185">    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-186">    <span class="n">window_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-187"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-188"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply masked pooling over the sequence dimension.</span>
</span><span id="__span-0-189">
</span><span id="__span-0-190"><span class="sd">    Args:</span>
</span><span id="__span-0-191"><span class="sd">        inputs: Input tensor of shape `(batch_size, seq_len, feature_dim)`.</span>
</span><span id="__span-0-192"><span class="sd">        mask: Mask tensor of shape `(batch_size, seq_len)`. `True`/`1` indicates valid positions.</span>
</span><span id="__span-0-193"><span class="sd">        pooling: Pooling method or sequence of methods.</span>
</span><span id="__span-0-194"><span class="sd">        normalize: Whether to L2-normalize before pooling.</span>
</span><span id="__span-0-195"><span class="sd">        window_size: Window size for hierarchical pooling (required if `pooling=&quot;hier&quot;`).</span>
</span><span id="__span-0-196">
</span><span id="__span-0-197"><span class="sd">    Returns:</span>
</span><span id="__span-0-198"><span class="sd">        Pooled tensor of shape `(batch_size, feature_dim * num_pooling_methods)`.</span>
</span><span id="__span-0-199">
</span><span id="__span-0-200"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-201">    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
</span><span id="__span-0-202">        <span class="n">inputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-203">
</span><span id="__span-0-204">    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-205">        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-206">
</span><span id="__span-0-207">    <span class="c1"># Convert mask to boolean if needed</span>
</span><span id="__span-0-208">    <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
</span><span id="__span-0-209">        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span id="__span-0-210">
</span><span id="__span-0-211">    <span class="n">pooling_methods</span> <span class="o">=</span> <span class="p">[</span><span class="n">pooling</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pooling</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">pooling</span><span class="p">)</span>
</span><span id="__span-0-212">    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-213">
</span><span id="__span-0-214">    <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">pooling_methods</span><span class="p">:</span>
</span><span id="__span-0-215">        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span id="__span-0-216">            <span class="c1"># Masked mean</span>
</span><span id="__span-0-217">            <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-218">            <span class="n">pooled</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-219">        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
</span><span id="__span-0-220">            <span class="c1"># Masked max</span>
</span><span id="__span-0-221">            <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
</span><span id="__span-0-222">            <span class="n">pooled</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-223">        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
</span><span id="__span-0-224">            <span class="c1"># Masked min</span>
</span><span id="__span-0-225">            <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span>
</span><span id="__span-0-226">            <span class="n">pooled</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-227">        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span id="__span-0-228">            <span class="c1"># Masked sum</span>
</span><span id="__span-0-229">            <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-230">            <span class="n">pooled</span> <span class="o">=</span> <span class="n">masked_inputs</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-231">        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;first&quot;</span><span class="p">:</span>
</span><span id="__span-0-232">            <span class="c1"># First token</span>
</span><span id="__span-0-233">            <span class="n">pooled</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="__span-0-234">        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span>
</span><span id="__span-0-235">            <span class="c1"># Last valid token</span>
</span><span id="__span-0-236">            <span class="c1"># Find the index of the last valid token for each sequence</span>
</span><span id="__span-0-237">            <span class="n">lengths</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># -1 because indices are 0-based</span>
</span><span id="__span-0-238">            <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-239">            <span class="n">pooled</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">,</span> <span class="n">lengths</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
</span><span id="__span-0-240">        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;hier&quot;</span><span class="p">:</span>
</span><span id="__span-0-241">            <span class="c1"># Hierarchical pooling with sliding window</span>
</span><span id="__span-0-242">            <span class="k">if</span> <span class="n">window_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-243">                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;window_size must be specified for hierarchical pooling&quot;</span><span class="p">)</span>
</span><span id="__span-0-244">
</span><span id="__span-0-245">            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-246">            <span class="n">feature_dim</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-247">            <span class="n">pooled_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-248">
</span><span id="__span-0-249">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
</span><span id="__span-0-250">                <span class="c1"># Get valid vectors for this sequence</span>
</span><span id="__span-0-251">                <span class="n">valid_vectors</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
</span><span id="__span-0-252">                <span class="n">seq_len</span> <span class="o">=</span> <span class="n">valid_vectors</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-253">
</span><span id="__span-0-254">                <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&lt;</span> <span class="n">window_size</span><span class="p">:</span>
</span><span id="__span-0-255">                    <span class="c1"># If sequence is shorter than window, just take mean</span>
</span><span id="__span-0-256">                    <span class="n">pooled_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_vectors</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="__span-0-257">                <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-258">                    <span class="c1"># Slide window and compute max of means</span>
</span><span id="__span-0-259">                    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">feature_dim</span><span class="p">,),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-260">                    <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">seq_len</span> <span class="o">-</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="__span-0-261">                        <span class="n">window</span> <span class="o">=</span> <span class="n">valid_vectors</span><span class="p">[</span><span class="n">offset</span> <span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">]</span>
</span><span id="__span-0-262">                        <span class="n">window_mean</span> <span class="o">=</span> <span class="n">window</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-263">                        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">window_mean</span><span class="p">)</span>
</span><span id="__span-0-264">                    <span class="n">pooled_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span><span id="__span-0-265">
</span><span id="__span-0-266">            <span class="n">pooled</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pooled_list</span><span class="p">)</span>
</span><span id="__span-0-267">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-268">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown pooling method: </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-269">
</span><span id="__span-0-270">        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
</span><span id="__span-0-271">
</span><span id="__span-0-272">    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.embedders" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.embedders</span>


<a href="#formed.integrations.torch.modules.embedders" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Text embedding modules for PyTorch models.</p>
<p>This module provides embedders that convert tokenized text into dense vector
representations. Embedders handle various text representations including
surface forms, part-of-speech tags, and character sequences.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseEmbedder</code>: Abstract base class for all embedders</li>
<li><code>TokenEmbedder</code>: Embeds token ID sequences into dense vectors</li>
<li><code>AnalyzedTextEmbedder</code>: Combines multiple embedding types (surface, POS, chars)</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Support for nested token sequences (e.g., word -&gt; character)</li>
<li>Automatic masking and padding handling</li>
<li>Configurable vectorization for character-level embeddings</li>
<li>Concatenation of multiple embedding types</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">TokenEmbedder</span><span class="p">,</span> <span class="n">AnalyzedTextEmbedder</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Simple token embedder</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">TokenEmbedder</span><span class="p">(</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span>
</span><span id="__span-0-8"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Multi-feature embedder</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">AnalyzedTextEmbedder</span><span class="p">(</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">surface</span><span class="o">=</span><span class="n">TokenEmbedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
</span><span id="__span-0-13"><span class="gp">... </span>    <span class="n">postag</span><span class="o">=</span><span class="n">TokenEmbedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</span><span id="__span-0-14"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="formed.integrations.torch.modules.embedders.SurfaceBatchT" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">SurfaceBatchT</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.SurfaceBatchT" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">SurfaceBatchT</span> <span class="o">=</span> <span class="n"><span title="typing_extensions.TypeVar">TypeVar</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="s2">&quot;SurfaceBatchT&quot;</span><span class="p">,</span> <span class="n"><span title="typing_extensions.TypeVar(bound)">bound</span></span><span class="o">=</span><span class="s2">&quot;IIDSequenceBatch&quot;</span><span class="p">,</span> <span class="n"><span title="typing_extensions.TypeVar(default)">default</span></span><span class="o">=</span><span class="n"><span title="typing.Any">Any</span></span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="formed.integrations.torch.modules.embedders.PostagBatchT" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">PostagBatchT</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.PostagBatchT" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">PostagBatchT</span> <span class="o">=</span> <span class="n"><span title="typing_extensions.TypeVar">TypeVar</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="s2">&quot;PostagBatchT&quot;</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n"><span title="typing_extensions.TypeVar(bound)">bound</span></span><span class="o">=</span><span class="n"><span title="typing.Union">Union</span></span><span class="p">[</span><span class="s2">&quot;IIDSequenceBatch&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
</span><span id="__span-0-4">    <span class="n"><span title="typing_extensions.TypeVar(default)">default</span></span><span class="o">=</span><span class="n"><span title="typing.Any">Any</span></span><span class="p">,</span>
</span><span id="__span-0-5"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="formed.integrations.torch.modules.embedders.CharacterBatchT" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">CharacterBatchT</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.CharacterBatchT" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">CharacterBatchT</span> <span class="o">=</span> <span class="n"><span title="typing_extensions.TypeVar">TypeVar</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="s2">&quot;CharacterBatchT&quot;</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n"><span title="typing_extensions.TypeVar(bound)">bound</span></span><span class="o">=</span><span class="n"><span title="typing.Union">Union</span></span><span class="p">[</span><span class="s2">&quot;IIDSequenceBatch&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
</span><span id="__span-0-4">    <span class="n"><span title="typing_extensions.TypeVar(default)">default</span></span><span class="o">=</span><span class="n"><span title="typing.Any">Any</span></span><span class="p">,</span>
</span><span id="__span-0-5"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="formed.integrations.torch.modules.embedders.TokenVectorBatchT" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">TokenVectorBatchT</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-module-attribute"><code>module-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.TokenVectorBatchT" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">TokenVectorBatchT</span> <span class="o">=</span> <span class="n"><span title="typing_extensions.TypeVar">TypeVar</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="s2">&quot;TokenVectorBatchT&quot;</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n"><span title="typing_extensions.TypeVar(bound)">bound</span></span><span class="o">=</span><span class="n"><span title="typing.Union">Union</span></span><span class="p">[</span><span class="s2">&quot;IVariableTensorBatch&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
</span><span id="__span-0-4">    <span class="n"><span title="typing_extensions.TypeVar(default)">default</span></span><span class="o">=</span><span class="n"><span title="typing.Any">Any</span></span><span class="p">,</span>
</span><span id="__span-0-5"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.IVariableTensorBatch" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">IVariableTensorBatch</span>


<a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.Protocol">Protocol</span>[<span title="formed.integrations.torch.types.TensorCompatibleT">TensorCompatibleT</span>]</code></p>



        <p>Protocol for variable-length tensor batches.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;tensor&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.IVariableTensorBatch.tensor&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.tensor">tensor</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Tensor of shape <code>(batch_size, seq_len, feature_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatibleT">TensorCompatibleT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;mask&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.IVariableTensorBatch.mask&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.mask">mask</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Attention mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatibleT">TensorCompatibleT</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.IVariableTensorBatch.tensor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">tensor</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.tensor" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">tensor</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.IVariableTensorBatch.mask" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">mask</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch.mask" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">mask</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.IAnalyzedTextBatch" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">IAnalyzedTextBatch</span>


<a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.Protocol">Protocol</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;SurfaceBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.SurfaceBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.SurfaceBatchT">SurfaceBatchT</a>, <a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;PostagBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.PostagBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.PostagBatchT">PostagBatchT</a>, <a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;CharacterBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.CharacterBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.CharacterBatchT">CharacterBatchT</a>, <a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;TokenVectorBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.TokenVectorBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.TokenVectorBatchT">TokenVectorBatchT</a>]</code></p>



        <p>Protocol for analyzed text batches with multiple linguistic features.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;surfaces&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.surfaces&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.surfaces">surfaces</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Surface form token IDs.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;SurfaceBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.SurfaceBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.SurfaceBatchT">SurfaceBatchT</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;postags&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.postags&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.postags">postags</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Part-of-speech tag IDs (optional).</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;PostagBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.PostagBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.PostagBatchT">PostagBatchT</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;characters&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.characters&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.characters">characters</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Character sequence IDs (optional).</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;CharacterBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.CharacterBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.CharacterBatchT">CharacterBatchT</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;token_vectors&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.token_vectors&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.token_vectors">token_vectors</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Token-level dense vectors (optional).</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;TokenVectorBatchT&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.TokenVectorBatchT&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.TokenVectorBatchT">TokenVectorBatchT</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.surfaces" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">surfaces</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.surfaces" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">surfaces</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.postags" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">postags</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.postags" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">postags</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.characters" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">characters</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.characters" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">characters</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.token_vectors" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">token_vectors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.token_vectors" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">token_vectors</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.EmbedderOutput" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">EmbedderOutput</span>


<a href="#formed.integrations.torch.modules.embedders.EmbedderOutput" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.NamedTuple">NamedTuple</span></code></p>



        <p>Output from an embedder.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;embeddings&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.EmbedderOutput.embeddings&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.EmbedderOutput.embeddings">embeddings</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Dense embeddings of shape <code>(batch_size, seq_len, embedding_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;mask&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.EmbedderOutput.mask&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.EmbedderOutput.mask">mask</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Attention mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.EmbedderOutput.embeddings" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">embeddings</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.EmbedderOutput.embeddings" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">embeddings</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.embedders.EmbedderOutput.mask" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">mask</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.EmbedderOutput.mask" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">mask</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.BaseEmbedder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseEmbedder</span>


<a href="#formed.integrations.torch.modules.embedders.BaseEmbedder" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.modules.embedders._TextBatchT">_TextBatchT</span>]</code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for text embedders.</p>
<p>Embedders convert tokenized text into dense vector representations.
They output both embeddings and attention masks.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>_TextBatchT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of input batch (e.g., <code>IIDSequenceBatch</code>, <code>IAnalyzedTextBatch</code>).</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.BaseEmbedder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.BaseEmbedder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Embed input tokens into dense vectors.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch of tokenized text.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.modules.embedders._TextBatchT">_TextBatchT</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;EmbedderOutput&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.EmbedderOutput&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.EmbedderOutput">EmbedderOutput</a></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>EmbedderOutput containing embeddings and mask.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-132"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-133"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">_TextBatchT</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedderOutput</span><span class="p">:</span>
</span><span id="__span-0-134"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Embed input tokens into dense vectors.</span>
</span><span id="__span-0-135">
</span><span id="__span-0-136"><span class="sd">    Args:</span>
</span><span id="__span-0-137"><span class="sd">        inputs: Batch of tokenized text.</span>
</span><span id="__span-0-138">
</span><span id="__span-0-139"><span class="sd">    Returns:</span>
</span><span id="__span-0-140"><span class="sd">        EmbedderOutput containing embeddings and mask.</span>
</span><span id="__span-0-141">
</span><span id="__span-0-142"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-143">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.BaseEmbedder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.embedders.BaseEmbedder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the output embedding dimension.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Embedding dimension.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-145"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-146"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-147"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the output embedding dimension.</span>
</span><span id="__span-0-148">
</span><span id="__span-0-149"><span class="sd">    Returns:</span>
</span><span id="__span-0-150"><span class="sd">        Embedding dimension.</span>
</span><span id="__span-0-151">
</span><span id="__span-0-152"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-153">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.PassThroughEmbedder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">PassThroughEmbedder</span>


<a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseEmbedder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.BaseEmbedder&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.BaseEmbedder">BaseEmbedder</a>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;IVariableTensorBatch&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.IVariableTensorBatch&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.IVariableTensorBatch">IVariableTensorBatch</a>[<span title="formed.integrations.torch.types.TensorCompatibleT">TensorCompatibleT</span>]]</code></p>



        <p>Embedder that passes through input tensors unchanged.</p>
<p>This embedder is useful when the input tensors are already in the desired
embedding format. It simply returns the input tensors and their masks.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">PassThroughEmbedder</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">PassThroughEmbedder</span><span class="p">()</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">embedder</span><span class="p">(</span><span class="n">variable_tensor_batch</span><span class="p">)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">variable_tensor_batch</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">variable_tensor_batch</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span>
</span></code></pre></div>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.PassThroughEmbedder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-176"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-177">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-178">    <span class="n">inputs</span><span class="p">:</span> <span class="n">IVariableTensorBatch</span><span class="p">[</span><span class="n">TensorCompatibleT</span><span class="p">],</span>
</span><span id="__span-0-179"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedderOutput</span><span class="p">:</span>
</span><span id="__span-0-180">    <span class="n">tensor</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
</span><span id="__span-0-181">    <span class="n">mask</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span id="__span-0-182">    <span class="k">return</span> <span class="n">EmbedderOutput</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.PassThroughEmbedder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.embedders.PassThroughEmbedder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">184</span>
<span class="normal">185</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-184"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-185">    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;PassThroughEmbedder does not have a fixed output dimension.&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.TokenEmbedder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TokenEmbedder</span>


<a href="#formed.integrations.torch.modules.embedders.TokenEmbedder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">TokenEmbedder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">initializer</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">freeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">vectorizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseEmbedder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.BaseEmbedder&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.BaseEmbedder">BaseEmbedder</a>[&#39;IIDSequenceBatch&#39;]</code></p>



        <p>Embedder for token ID sequences.</p>
<p>This embedder converts token IDs into dense embeddings using a learned
embedding matrix. It supports both 2D <code>(batch_size, seq_len)</code> and 3D
<code>(batch_size, seq_len, char_len)</code> token ID tensors.</p>
<p>For 3D inputs (e.g., character-level tokens within words), the embedder
can either average the embeddings or apply a custom vectorizer.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>initializer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor initializer or callable that returns the embedding tensor.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTensorInitializer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.initializers.BaseTensorInitializer&lt;/code&gt;)" href="#formed.integrations.torch.initializers.BaseTensorInitializer">BaseTensorInitializer</a> | <span title="collections.abc.Callable">Callable</span>[[], <span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>padding_idx</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Index of the padding token (default: <code>0</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vectorizer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional vectorizer for 3D inputs (character sequences).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceVectorizer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer&lt;/code&gt;)" href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer">BaseSequenceVectorizer</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Simple word embeddings</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">TokenEmbedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">embedder</span><span class="p">(</span><span class="n">word_ids_batch</span><span class="p">)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Character-level embeddings with pooling</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">TokenEmbedder</span><span class="p">(</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="gp">... </span>    <span class="n">vectorizer</span><span class="o">=</span><span class="n">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span><span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
</span><span id="__span-0-11"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-219"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-220">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-221">    <span class="n">initializer</span><span class="p">:</span> <span class="n">BaseTensorInitializer</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">TensorCompatible</span><span class="p">],</span>
</span><span id="__span-0-222">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-223">    <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-224">    <span class="n">freeze</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-225">    <span class="n">vectorizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseSequenceVectorizer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-226"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-227">    <span class="n">weight</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">initializer</span><span class="p">())</span>
</span><span id="__span-0-228">
</span><span id="__span-0-229">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-230">    <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span> <span class="n">freeze</span><span class="o">=</span><span class="n">freeze</span><span class="p">)</span>
</span><span id="__span-0-231">    <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.TokenEmbedder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.embedders.TokenEmbedder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-233"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="s2">&quot;IIDSequenceBatch&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedderOutput</span><span class="p">:</span>
</span><span id="__span-0-234">    <span class="n">token_ids</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
</span><span id="__span-0-235">    <span class="n">mask</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span id="__span-0-236">
</span><span id="__span-0-237">    <span class="n">nested</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-238">    <span class="k">if</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="__span-0-239">        <span class="k">if</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="__span-0-240">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Token ids must be of shape (batch_size, seq_len) or (batch_size, seq_len, char_len)&quot;</span><span class="p">)</span>
</span><span id="__span-0-241">        <span class="n">nested</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-0-242">
</span><span id="__span-0-243">    <span class="k">if</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="__span-0-244">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Token ids and mask must have the same shape, got </span><span class="si">{</span><span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-245">
</span><span id="__span-0-246">    <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
</span><span id="__span-0-247">
</span><span id="__span-0-248">    <span class="k">if</span> <span class="n">nested</span><span class="p">:</span>
</span><span id="__span-0-249">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-250">            <span class="c1"># Average pooling over character dimension</span>
</span><span id="__span-0-251">            <span class="n">embeddings</span> <span class="o">=</span> <span class="p">(</span><span class="n">embeddings</span> <span class="o">*</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-252">            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-253">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-254">            <span class="c1"># Flatten batch and sequence dimensions for vectorizer</span>
</span><span id="__span-0-255">            <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">char_len</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-0-256">            <span class="n">flat_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">char_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-257">            <span class="n">flat_mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">char_len</span><span class="p">)</span>
</span><span id="__span-0-258">
</span><span id="__span-0-259">            <span class="c1"># Apply vectorizer</span>
</span><span id="__span-0-260">            <span class="n">flat_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectorizer</span><span class="p">(</span><span class="n">flat_embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">flat_mask</span><span class="p">)</span>
</span><span id="__span-0-261">
</span><span id="__span-0-262">            <span class="c1"># Reshape back</span>
</span><span id="__span-0-263">            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">flat_embeddings</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-264">            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-265">
</span><span id="__span-0-266">    <span class="k">return</span> <span class="n">EmbedderOutput</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.TokenEmbedder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.embedders.TokenEmbedder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">268</span>
<span class="normal">269</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-268"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-269">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding</span><span class="o">.</span><span class="n">embedding_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">PretrainedTransformerEmbedder</span>


<a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">PretrainedTransformerEmbedder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">auto_class</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">subcmodule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">freeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">eval_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">layer_to_use</span><span class="o">=</span><span class="s2">&quot;last&quot;</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9">    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseEmbedder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.BaseEmbedder&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.BaseEmbedder">BaseEmbedder</a>[<span title="formed.integrations.torch.types.IIDSequenceBatch">IIDSequenceBatch</span>]</code></p>



        <p>Embedder using pretrained transformer models from Hugging Face.</p>
<p>This embedder wraps pretrained transformer models (BERT, RoBERTa, etc.)
to extract contextualized embeddings. It uses the last hidden state from
the transformer as the embedding representation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Either a model name/path string, <code>PathLike</code> object, or a <code>PreTrainedModel</code> instance.
If a string or <code>PathLike</code>, the model will be loaded using transformers auto classes.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="os.PathLike">PathLike</span>, <span title="transformers.PreTrainedModel">PreTrainedModel</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>auto_class</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The auto class to use for loading the model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span> | <span title="type">type</span>[<span title="transformers.models.auto.auto_factory._BaseAutoModelClass">_BaseAutoModelClass</span>] | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>subcmodule</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional submodule path to extract from the loaded model (e.g., <code>"encoder"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>freeze</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>True</code>, freezes all model parameters (no gradient computation).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional keyword arguments passed to the model loader.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Any">Any</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load a pretrained BERT model</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">PretrainedTransformerEmbedder</span><span class="p">(</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">freeze</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-5"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use a specific auto class</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">PretrainedTransformerEmbedder</span><span class="p">(</span>
</span><span id="__span-0-10"><span class="gp">... </span>    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;roberta-base&quot;</span><span class="p">,</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="n">auto_class</span><span class="o">=</span><span class="n">AutoModel</span><span class="p">,</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">freeze</span><span class="o">=</span><span class="kc">False</span>
</span><span id="__span-0-13"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-14"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-15"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use an already loaded model</span>
</span><span id="__span-0-16"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
</span><span id="__span-0-17"><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
</span><span id="__span-0-18"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">PretrainedTransformerEmbedder</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>Models are cached using LRU cache by the <code>load_pretrained_transformer</code> utility.
When <code>freeze=True</code>, all model parameters have <code>requires_grad=False</code>.</p>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-325"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-326">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-327">    <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">PathLike</span><span class="p">,</span> <span class="s2">&quot;PreTrainedModel&quot;</span><span class="p">],</span>
</span><span id="__span-0-328">    <span class="n">auto_class</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">type</span><span class="p">[</span><span class="s2">&quot;_BaseAutoModelClass&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-329">    <span class="n">subcmodule</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-330">    <span class="n">freeze</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-331">    <span class="n">eval_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-332">    <span class="n">layer_to_use</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;last&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;last&quot;</span><span class="p">,</span>
</span><span id="__span-0-333">    <span class="n">gradient_checkpointing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-334">    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span id="__span-0-335"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-336">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">PathLike</span><span class="p">)):</span>
</span><span id="__span-0-337">        <span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_pretrained_transformer</span>
</span><span id="__span-0-338">
</span><span id="__span-0-339">        <span class="n">model</span> <span class="o">=</span> <span class="n">load_pretrained_transformer</span><span class="o">.</span><span class="n">__wrapped__</span><span class="p">(</span>
</span><span id="__span-0-340">            <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-341">            <span class="n">auto_class</span><span class="o">=</span><span class="n">auto_class</span><span class="p">,</span>
</span><span id="__span-0-342">            <span class="n">submodule</span><span class="o">=</span><span class="n">subcmodule</span><span class="p">,</span>
</span><span id="__span-0-343">            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="__span-0-344">        <span class="p">)</span>
</span><span id="__span-0-345">
</span><span id="__span-0-346">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-347">
</span><span id="__span-0-348">    <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="__span-0-349">    <span class="bp">self</span><span class="o">.</span><span class="n">_scalar_mix</span><span class="p">:</span> <span class="n">ScalarMix</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-350">    <span class="bp">self</span><span class="o">.</span><span class="n">_eval_mode</span> <span class="o">=</span> <span class="n">eval_mode</span>
</span><span id="__span-0-351">    <span class="bp">self</span><span class="o">.</span><span class="n">_output_dim</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
</span><span id="__span-0-352">    <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span>
</span><span id="__span-0-353">
</span><span id="__span-0-354">    <span class="k">if</span> <span class="n">gradient_checkpointing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-355">        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;gradient_checkpointing&quot;</span><span class="p">:</span> <span class="n">gradient_checkpointing</span><span class="p">})</span>
</span><span id="__span-0-356">
</span><span id="__span-0-357">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_mode</span><span class="p">:</span>
</span><span id="__span-0-358">        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="__span-0-359">
</span><span id="__span-0-360">    <span class="k">if</span> <span class="n">freeze</span><span class="p">:</span>
</span><span id="__span-0-361">        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span><span id="__span-0-362">            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-363">
</span><span id="__span-0-364">    <span class="k">if</span> <span class="n">layer_to_use</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
</span><span id="__span-0-365">        <span class="bp">self</span><span class="o">.</span><span class="n">_scalar_mix</span> <span class="o">=</span> <span class="n">ScalarMix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)</span>
</span><span id="__span-0-366">        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-0-367">    <span class="k">elif</span> <span class="n">layer_to_use</span> <span class="o">==</span> <span class="s2">&quot;embeddings&quot;</span><span class="p">:</span>
</span><span id="__span-0-368">        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">PretrainedTransformerEmbedder</span><span class="o">.</span><span class="n">_Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-370"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">IIDSequenceBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedderOutput</span><span class="p">:</span>
</span><span id="__span-0-371">    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
</span><span id="__span-0-372">    <span class="n">mask</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-373">
</span><span id="__span-0-374">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span> <span class="n">PretrainedTransformerEmbedder</span><span class="o">.</span><span class="n">_Embedding</span><span class="p">):</span>
</span><span id="__span-0-375">        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="__span-0-376">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-377">        <span class="n">transformer_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-378">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalar_mix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-379">            <span class="c1"># The hidden states will also include the embedding layer, which we don&#39;t</span>
</span><span id="__span-0-380">            <span class="c1"># include in the scalar mix. Hence the `[1:]` slicing.</span>
</span><span id="__span-0-381">            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">transformer_outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="__span-0-382">            <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scalar_mix</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
</span><span id="__span-0-383">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-384">            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">transformer_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
</span><span id="__span-0-385">    <span class="k">return</span> <span class="n">EmbedderOutput</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">387</span>
<span class="normal">388</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-387"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-388">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_vocab_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_vocab_size</span>


<a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_vocab_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_vocab_size</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">390</span>
<span class="normal">391</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-390"><span class="k">def</span><span class="w"> </span><span class="nf">get_vocab_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-391">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_size</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.train" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">train</span>


<a href="#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.train" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">train</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-393"><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
</span><span id="__span-0-394">    <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">mode</span>
</span><span id="__span-0-395">    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
</span><span id="__span-0-396">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_mode</span> <span class="ow">and</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;_model&quot;</span><span class="p">:</span>
</span><span id="__span-0-397">            <span class="n">module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="__span-0-398">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-399">            <span class="n">module</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
</span><span id="__span-0-400">    <span class="k">return</span> <span class="bp">self</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">AnalyzedTextEmbedder</span>


<a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">AnalyzedTextEmbedder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">surface</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">postag</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">character</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">token_vector</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseEmbedder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.BaseEmbedder&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.BaseEmbedder">BaseEmbedder</a>[&#39;IAnalyzedTextBatch&#39;]</code></p>



        <p>Embedder for analyzed text with multiple linguistic features.</p>
<p>This embedder combines embeddings from multiple linguistic representations
(surface forms, part-of-speech tags, character sequences) by concatenating
them along the feature dimension.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>surface</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional embedder for surface form tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseEmbedder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.BaseEmbedder&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.BaseEmbedder">BaseEmbedder</a>[<span title="formed.integrations.torch.types.IIDSequenceBatch">IIDSequenceBatch</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>postag</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional embedder for part-of-speech tags.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseEmbedder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.BaseEmbedder&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.BaseEmbedder">BaseEmbedder</a>[<span title="formed.integrations.torch.types.IIDSequenceBatch">IIDSequenceBatch</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>character</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional embedder for character sequences.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseEmbedder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.embedders.BaseEmbedder&lt;/code&gt;)" href="#formed.integrations.torch.modules.embedders.BaseEmbedder">BaseEmbedder</a>[<span title="formed.integrations.torch.types.IIDSequenceBatch">IIDSequenceBatch</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code><span title="ValueError">ValueError</span></code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If all embedders are None (at least one is required).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">AnalyzedTextEmbedder</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">TokenEmbedder</span>
</span><span id="__span-0-4"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="n">embedder</span> <span class="o">=</span> <span class="n">AnalyzedTextEmbedder</span><span class="p">(</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">surface</span><span class="o">=</span><span class="n">TokenEmbedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">postag</span><span class="o">=</span><span class="n">TokenEmbedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">character</span><span class="o">=</span><span class="n">TokenEmbedder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</span><span id="__span-0-10"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-12"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Output dimension is sum of all embedding dimensions (128 + 32 + 32 = 192)</span>
</span><span id="__span-0-13"><span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">embedder</span><span class="o">.</span><span class="n">get_output_dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">192</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>All provided embedders share the same mask, which is taken from
the last non-None embedder processed.</p>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-440"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-441">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-442">    <span class="n">surface</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;BaseEmbedder[IIDSequenceBatch]&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-443">    <span class="n">postag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;BaseEmbedder[IIDSequenceBatch]&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-444">    <span class="n">character</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;BaseEmbedder[IIDSequenceBatch]&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-445">    <span class="n">token_vector</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;BaseEmbedder[IVariableTensorBatch]&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-446"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-447">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-448">    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">embedder</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">embedder</span> <span class="ow">in</span> <span class="p">(</span><span class="n">surface</span><span class="p">,</span> <span class="n">postag</span><span class="p">,</span> <span class="n">character</span><span class="p">)):</span>
</span><span id="__span-0-449">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one embedder must be provided for AnalyzedTextEmbedder.&quot;</span><span class="p">)</span>
</span><span id="__span-0-450">
</span><span id="__span-0-451">    <span class="bp">self</span><span class="o">.</span><span class="n">_surface</span> <span class="o">=</span> <span class="n">surface</span>
</span><span id="__span-0-452">    <span class="bp">self</span><span class="o">.</span><span class="n">_postag</span> <span class="o">=</span> <span class="n">postag</span>
</span><span id="__span-0-453">    <span class="bp">self</span><span class="o">.</span><span class="n">_character</span> <span class="o">=</span> <span class="n">character</span>
</span><span id="__span-0-454">    <span class="bp">self</span><span class="o">.</span><span class="n">_token_vector</span> <span class="o">=</span> <span class="n">token_vector</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-456"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="s2">&quot;IAnalyzedTextBatch&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmbedderOutput</span><span class="p">:</span>
</span><span id="__span-0-457">    <span class="n">embeddings</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-458">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-459">
</span><span id="__span-0-460">    <span class="k">for</span> <span class="n">embedder</span><span class="p">,</span> <span class="n">ids</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="__span-0-461">        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surface</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">surfaces</span><span class="p">),</span>
</span><span id="__span-0-462">        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_postag</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">postags</span><span class="p">),</span>
</span><span id="__span-0-463">        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_character</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">characters</span><span class="p">),</span>
</span><span id="__span-0-464">    <span class="p">):</span>
</span><span id="__span-0-465">        <span class="k">if</span> <span class="n">embedder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-466">            <span class="n">output</span> <span class="o">=</span> <span class="n">embedder</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
</span><span id="__span-0-467">            <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">embeddings</span><span class="p">)</span>
</span><span id="__span-0-468">            <span class="n">mask</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">mask</span>
</span><span id="__span-0-469">
</span><span id="__span-0-470">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">inputs</span><span class="o">.</span><span class="n">token_vectors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-471">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_vector</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">token_vectors</span><span class="p">)</span>
</span><span id="__span-0-472">        <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">embeddings</span><span class="p">)</span>
</span><span id="__span-0-473">
</span><span id="__span-0-474">    <span class="k">if</span> <span class="ow">not</span> <span class="n">embeddings</span><span class="p">:</span>
</span><span id="__span-0-475">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No embeddings were computed in AnalyzedTextEmbedder.&quot;</span><span class="p">)</span>
</span><span id="__span-0-476">    <span class="k">assert</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-477">
</span><span id="__span-0-478">    <span class="k">return</span> <span class="n">EmbedderOutput</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/embedders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-480"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-481">    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
</span><span id="__span-0-482">        <span class="n">embedder</span><span class="o">.</span><span class="n">get_output_dim</span><span class="p">()</span>
</span><span id="__span-0-483">        <span class="k">for</span> <span class="n">embedder</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_surface</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_postag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_character</span><span class="p">)</span>
</span><span id="__span-0-484">        <span class="k">if</span> <span class="n">embedder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-485">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.encoders" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.encoders</span>


<a href="#formed.integrations.torch.modules.encoders" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Sequence encoding modules for PyTorch models.</p>
<p>This module provides encoders that process sequential data, including
RNN-based encoders, positional encoders, and Transformer encoders.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseSequenceEncoder</code>: Abstract base for sequence encoders</li>
<li><code>LSTMSequenceEncoder</code>: LSTM-specific encoder</li>
<li><code>GRUSequenceEncoder</code>: GRU-specific encoder</li>
<li><code>BasePositionalEncoder</code>: Abstract base for positional encoders</li>
<li><code>SinusoidalPositionalEncoder</code>: Sinusoidal positional encoding</li>
<li><code>RotaryPositionalEncoder</code>: Rotary positional encoding (RoPE)</li>
<li><code>LearnablePositionalEncoder</code>: Learnable positional embeddings</li>
<li><code>TransformerEncoder</code>: Transformer-based encoder with configurable masking</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Bidirectional RNN support</li>
<li>Stacked layers with dropout</li>
<li>Masked sequence processing</li>
<li>Various positional encoding strategies</li>
<li>Flexible attention masking</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">LSTMSequenceEncoder</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Bidirectional LSTM encoder</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">LSTMSequenceEncoder</span><span class="p">(</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
</span><span id="__span-0-10"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.BaseSequenceEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseSequenceEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for sequence encoders.</p>
<p>Sequence encoders process sequential data and output encoded representations.</p>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.BaseSequenceEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode input sequence.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-55"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-56"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-57">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-58">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-59">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-60"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-61"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode input sequence.</span>
</span><span id="__span-0-62">
</span><span id="__span-0-63"><span class="sd">    Args:</span>
</span><span id="__span-0-64"><span class="sd">        inputs: Input sequence of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-65"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-66">
</span><span id="__span-0-67"><span class="sd">    Returns:</span>
</span><span id="__span-0-68"><span class="sd">        Encoded sequence of shape `(batch_size, seq_len, output_dim)`.</span>
</span><span id="__span-0-69">
</span><span id="__span-0-70"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-71">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the expected input dimension.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-73"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-74"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-75"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the expected input dimension.&quot;&quot;&quot;</span>
</span><span id="__span-0-76">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the output dimension.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-78"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-79"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-80"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the output dimension.&quot;&quot;&quot;</span>
</span><span id="__span-0-81">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">LSTMSequenceEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">LSTMSequenceEncoder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">input_dim</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">hidden_dim</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BaseSequenceEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder">BaseSequenceEncoder</a></code></p>



        <p>LSTM-based sequence encoder.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input dimension.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Hidden state dimension.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of LSTM layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bidirectional</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use bidirectional LSTM.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dropout rate between layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_first</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether input is batch-first (default: <code>True</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">LSTMSequenceEncoder</span><span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-6"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-113"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-114">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-115">    <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-116">    <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-117">    <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-118">    <span class="n">bidirectional</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-119">    <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-120">    <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-121"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-122">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-123">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
</span><span id="__span-0-124">    <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
</span><span id="__span-0-125">    <span class="bp">self</span><span class="o">.</span><span class="n">_num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
</span><span id="__span-0-126">    <span class="bp">self</span><span class="o">.</span><span class="n">_bidirectional</span> <span class="o">=</span> <span class="n">bidirectional</span>
</span><span id="__span-0-127">
</span><span id="__span-0-128">    <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
</span><span id="__span-0-129">        <span class="n">input_size</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
</span><span id="__span-0-130">        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
</span><span id="__span-0-131">        <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
</span><span id="__span-0-132">        <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">,</span>
</span><span id="__span-0-133">        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span> <span class="k">if</span> <span class="n">num_layers</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-134">        <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
</span><span id="__span-0-135">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.lstm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">lstm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.lstm" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">lstm</span> <span class="o">=</span> <span class="n"><span title="torch.nn.LSTM">LSTM</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n"><span title="torch.nn.LSTM(input_size)">input_size</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder(input_dim)">input_dim</span></span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n"><span title="torch.nn.LSTM(hidden_size)">hidden_size</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder(hidden_dim)">hidden_dim</span></span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n"><span title="torch.nn.LSTM(num_layers)">num_layers</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder(num_layers)">num_layers</span></span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n"><span title="torch.nn.LSTM(bidirectional)">bidirectional</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder(bidirectional)">bidirectional</span></span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n"><span title="torch.nn.LSTM(dropout)">dropout</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder(dropout)">dropout</span></span> <span class="k">if</span> <span class="n"><span title="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder(num_layers)">num_layers</span></span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n"><span title="torch.nn.LSTM(batch_first)">batch_first</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder(batch_first)">batch_first</span></span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode input sequence.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-137"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-138">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-139">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-140">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-141"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-142"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode input sequence.</span>
</span><span id="__span-0-143">
</span><span id="__span-0-144"><span class="sd">    Args:</span>
</span><span id="__span-0-145"><span class="sd">        inputs: Input of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-146"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-147">
</span><span id="__span-0-148"><span class="sd">    Returns:</span>
</span><span id="__span-0-149"><span class="sd">        Encoded sequence of shape `(batch_size, seq_len, output_dim)`.</span>
</span><span id="__span-0-150">
</span><span id="__span-0-151"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-152">    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-153">        <span class="c1"># Pack padded sequence for efficiency</span>
</span><span id="__span-0-154">        <span class="n">lengths</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span><span id="__span-0-155">        <span class="n">packed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-0-156">        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">packed</span><span class="p">)</span>
</span><span id="__span-0-157">        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-158">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-159">        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-0-160">
</span><span id="__span-0-161">    <span class="k">return</span> <span class="n">output</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-163"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-164">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-166"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-167">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_dim</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bidirectional</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.GRUSequenceEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">GRUSequenceEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">GRUSequenceEncoder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">input_dim</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">hidden_dim</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BaseSequenceEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder">BaseSequenceEncoder</a></code></p>



        <p>GRU-based sequence encoder.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input dimension.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Hidden state dimension.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of GRU layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bidirectional</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use bidirectional GRU.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dropout rate between layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_first</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether input is batch-first (default: <code>True</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">GRUSequenceEncoder</span><span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-6"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-192"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-193">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-194">    <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-195">    <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-196">    <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-197">    <span class="n">bidirectional</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-198">    <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-199">    <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-200"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-201">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-202">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
</span><span id="__span-0-203">    <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
</span><span id="__span-0-204">    <span class="bp">self</span><span class="o">.</span><span class="n">_num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
</span><span id="__span-0-205">    <span class="bp">self</span><span class="o">.</span><span class="n">_bidirectional</span> <span class="o">=</span> <span class="n">bidirectional</span>
</span><span id="__span-0-206">
</span><span id="__span-0-207">    <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
</span><span id="__span-0-208">        <span class="n">input_size</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
</span><span id="__span-0-209">        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
</span><span id="__span-0-210">        <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
</span><span id="__span-0-211">        <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">,</span>
</span><span id="__span-0-212">        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span> <span class="k">if</span> <span class="n">num_layers</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-213">        <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
</span><span id="__span-0-214">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.GRUSequenceEncoder.gru" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">gru</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.gru" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">gru</span> <span class="o">=</span> <span class="n"><span title="torch.nn.GRU">GRU</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n"><span title="torch.nn.GRU(input_size)">input_size</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.GRUSequenceEncoder(input_dim)">input_dim</span></span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n"><span title="torch.nn.GRU(hidden_size)">hidden_size</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.GRUSequenceEncoder(hidden_dim)">hidden_dim</span></span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n"><span title="torch.nn.GRU(num_layers)">num_layers</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.GRUSequenceEncoder(num_layers)">num_layers</span></span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n"><span title="torch.nn.GRU(bidirectional)">bidirectional</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.GRUSequenceEncoder(bidirectional)">bidirectional</span></span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n"><span title="torch.nn.GRU(dropout)">dropout</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.GRUSequenceEncoder(dropout)">dropout</span></span> <span class="k">if</span> <span class="n"><span title="formed.integrations.torch.modules.encoders.GRUSequenceEncoder(num_layers)">num_layers</span></span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n"><span title="torch.nn.GRU(batch_first)">batch_first</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.GRUSequenceEncoder(batch_first)">batch_first</span></span><span class="p">,</span>
</span><span id="__span-0-8"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.GRUSequenceEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode input sequence.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-216"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-217">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-218">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-219">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-220"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-221"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode input sequence.</span>
</span><span id="__span-0-222">
</span><span id="__span-0-223"><span class="sd">    Args:</span>
</span><span id="__span-0-224"><span class="sd">        inputs: Input of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-225"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-226">
</span><span id="__span-0-227"><span class="sd">    Returns:</span>
</span><span id="__span-0-228"><span class="sd">        Encoded sequence of shape `(batch_size, seq_len, output_dim)`.</span>
</span><span id="__span-0-229">
</span><span id="__span-0-230"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-231">    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-232">        <span class="c1"># Pack padded sequence for efficiency</span>
</span><span id="__span-0-233">        <span class="n">lengths</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span><span id="__span-0-234">        <span class="n">packed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-0-235">        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">packed</span><span class="p">)</span>
</span><span id="__span-0-236">        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-237">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-238">        <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-0-239">
</span><span id="__span-0-240">    <span class="k">return</span> <span class="n">output</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">242</span>
<span class="normal">243</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-242"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-243">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-245"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-246">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_dim</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bidirectional</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.ResidualSequenceEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">ResidualSequenceEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">ResidualSequenceEncoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BaseSequenceEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder">BaseSequenceEncoder</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-251"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">:</span> <span class="n">BaseSequenceEncoder</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-252">    <span class="k">assert</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_input_dim</span><span class="p">()</span> <span class="o">==</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_output_dim</span><span class="p">()</span>
</span><span id="__span-0-253">
</span><span id="__span-0-254">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-255">    <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span> <span class="o">=</span> <span class="n">encoder</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-257"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-258">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-259">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-260">    <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-261"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-262">    <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-263">    <span class="k">return</span> <span class="n">inputs</span> <span class="o">+</span> <span class="n">encoded</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">265</span>
<span class="normal">266</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-265"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-266">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="o">.</span><span class="n">get_input_dim</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">268</span>
<span class="normal">269</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-268"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-269">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span><span class="o">.</span><span class="n">get_output_dim</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">FeedForwardSequenceEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">FeedForwardSequenceEncoder</span><span class="p">(</span><span class="n">feedforward</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BaseSequenceEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder">BaseSequenceEncoder</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-274"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feedforward</span><span class="p">:</span> <span class="n">FeedForward</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-275">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-276">    <span class="bp">self</span><span class="o">.</span><span class="n">_feedforward</span> <span class="o">=</span> <span class="n">feedforward</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-278"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-279">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-280">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-281">    <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-282"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-283">    <span class="k">del</span> <span class="n">mask</span>
</span><span id="__span-0-284">
</span><span id="__span-0-285">    <span class="n">original_shape</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-0-286">    <span class="n">flattened_inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="__span-0-287">    <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feedforward</span><span class="p">(</span><span class="n">flattened_inputs</span><span class="p">)</span>
</span><span id="__span-0-288">    <span class="k">return</span> <span class="n">encoded</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">original_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">290</span>
<span class="normal">291</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-290"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-291">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feedforward</span><span class="o">.</span><span class="n">get_input_dim</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">293</span>
<span class="normal">294</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-293"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-294">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feedforward</span><span class="o">.</span><span class="n">get_output_dim</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.StackedSequenceEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">StackedSequenceEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">StackedSequenceEncoder</span><span class="p">(</span><span class="n">encoders</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BaseSequenceEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder">BaseSequenceEncoder</a></code></p>










                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-299"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoders</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">BaseSequenceEncoder</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-300">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-301">    <span class="bp">self</span><span class="o">.</span><span class="n">_encoders</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">encoders</span><span class="p">)</span>
</span><span id="__span-0-302">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">encoders</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_input_dim</span><span class="p">()</span>
</span><span id="__span-0-303">    <span class="bp">self</span><span class="o">.</span><span class="n">_output_dim</span> <span class="o">=</span> <span class="n">encoders</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_output_dim</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.StackedSequenceEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-305"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-306">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-307">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-308">    <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-309"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-310">    <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
</span><span id="__span-0-311">    <span class="k">for</span> <span class="n">encoder</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encoders</span><span class="p">:</span>
</span><span id="__span-0-312">        <span class="n">x</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-313">    <span class="k">return</span> <span class="n">x</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">315</span>
<span class="normal">316</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-315"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-316">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">318</span>
<span class="normal">319</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-318"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-319">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.BasePositionalEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BasePositionalEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for positional encoders.</p>
<p>Positional encoders add positional information to sequential data.</p>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.BasePositionalEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Add positional encoding to input sequence.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Position-encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-329"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-330"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-331">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-332">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-333">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-334"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-335"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Add positional encoding to input sequence.</span>
</span><span id="__span-0-336">
</span><span id="__span-0-337"><span class="sd">    Args:</span>
</span><span id="__span-0-338"><span class="sd">        inputs: Input sequence of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-339"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-340">
</span><span id="__span-0-341"><span class="sd">    Returns:</span>
</span><span id="__span-0-342"><span class="sd">        Position-encoded sequence of shape `(batch_size, seq_len, output_dim)`.</span>
</span><span id="__span-0-343">
</span><span id="__span-0-344"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-345">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the expected input dimension.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-347"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-348"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-349"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the expected input dimension.&quot;&quot;&quot;</span>
</span><span id="__span-0-350">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the output dimension.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-352"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-353"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-354"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the output dimension.&quot;&quot;&quot;</span>
</span><span id="__span-0-355">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SinusoidalPositionalEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">SinusoidalPositionalEncoder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">input_dim</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BasePositionalEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BasePositionalEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder">BasePositionalEncoder</a></code></p>



        <p>Sinusoidal positional encoding.</p>
<p>Uses sine and cosine functions of different frequencies to encode
position information, as introduced in "Attention Is All You Need".</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimension of the embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_len</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum sequence length to pre-compute.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>5000</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dropout rate to apply after adding positional encoding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">SinusoidalPositionalEncoder</span><span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
</span><span id="__span-0-5"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-388"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-389">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-390">    <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-391">    <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span>
</span><span id="__span-0-392">    <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-393"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-394">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-395">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
</span><span id="__span-0-396">    <span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span> <span class="o">=</span> <span class="n">max_len</span>
</span><span id="__span-0-397">
</span><span id="__span-0-398">    <span class="c1"># Create positional encoding matrix</span>
</span><span id="__span-0-399">    <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-400">    <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">))</span> <span class="o">/</span> <span class="n">input_dim</span><span class="p">))</span>
</span><span id="__span-0-401">
</span><span id="__span-0-402">    <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
</span><span id="__span-0-403">    <span class="n">pe</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
</span><span id="__span-0-404">    <span class="n">pe</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
</span><span id="__span-0-405">
</span><span id="__span-0-406">    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;pe&quot;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>
</span><span id="__span-0-407">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.pe" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">pe</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.pe" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">pe</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.dropout" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">dropout</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.dropout" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">dropout</span> <span class="o">=</span> <span class="n"><span title="torch.nn.Dropout">Dropout</span></span><span class="p">(</span><span class="n"><span title="torch.nn.Dropout(p)">p</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder(dropout)">dropout</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Add sinusoidal positional encoding to inputs.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Position-encoded sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-409"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-410">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-411">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-412">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-413"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-414"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Add sinusoidal positional encoding to inputs.</span>
</span><span id="__span-0-415">
</span><span id="__span-0-416"><span class="sd">    Args:</span>
</span><span id="__span-0-417"><span class="sd">        inputs: Input of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-418"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-419">
</span><span id="__span-0-420"><span class="sd">    Returns:</span>
</span><span id="__span-0-421"><span class="sd">        Position-encoded sequence of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-422">
</span><span id="__span-0-423"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-424">    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-425">    <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span><span class="p">:</span>
</span><span id="__span-0-426">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sequence length </span><span class="si">{</span><span class="n">seq_len</span><span class="si">}</span><span class="s2"> exceeds maximum length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-427">
</span><span id="__span-0-428">    <span class="n">output</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="__span-0-429">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">431</span>
<span class="normal">432</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-431"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-432">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">434</span>
<span class="normal">435</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-434"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-435">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.RotaryPositionalEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">RotaryPositionalEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">RotaryPositionalEncoder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">input_dim</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mf">10000.0</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BasePositionalEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BasePositionalEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder">BasePositionalEncoder</a></code></p>



        <p>Rotary positional encoding (RoPE).</p>
<p>Applies rotary position embeddings by rotating pairs of dimensions
in the feature space, as introduced in "RoFormer: Enhanced Transformer with Rotary Position Embedding".</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimension of the embeddings (must be even).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_len</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum sequence length to pre-compute.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2048</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>base</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Base for the geometric progression (default: <code>10000</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>10000.0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">RotaryPositionalEncoder</span><span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">max_len</span><span class="o">=</span><span class="mi">2048</span>
</span><span id="__span-0-4"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-462"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-463">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-464">    <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-465">    <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
</span><span id="__span-0-466">    <span class="n">base</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10000.0</span><span class="p">,</span>
</span><span id="__span-0-467"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-468">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-469">    <span class="k">if</span> <span class="n">input_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-470">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input_dim must be even, got </span><span class="si">{</span><span class="n">input_dim</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-471">
</span><span id="__span-0-472">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
</span><span id="__span-0-473">    <span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span> <span class="o">=</span> <span class="n">max_len</span>
</span><span id="__span-0-474">
</span><span id="__span-0-475">    <span class="c1"># Compute inverse frequencies</span>
</span><span id="__span-0-476">    <span class="n">inv_freq</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">base</span> <span class="o">**</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">input_dim</span><span class="p">))</span>
</span><span id="__span-0-477">    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;inv_freq&quot;</span><span class="p">,</span> <span class="n">inv_freq</span><span class="p">)</span>
</span><span id="__span-0-478">
</span><span id="__span-0-479">    <span class="c1"># Pre-compute cos and sin for max_len positions</span>
</span><span id="__span-0-480">    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="__span-0-481">    <span class="n">freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">inv_freq</span><span class="p">)</span>
</span><span id="__span-0-482">    <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">freqs</span><span class="p">,</span> <span class="n">freqs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-483">
</span><span id="__span-0-484">    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;cos_cached&quot;</span><span class="p">,</span> <span class="n">emb</span><span class="o">.</span><span class="n">cos</span><span class="p">()[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span>
</span><span id="__span-0-485">    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;sin_cached&quot;</span><span class="p">,</span> <span class="n">emb</span><span class="o">.</span><span class="n">sin</span><span class="p">()[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.inv_freq" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">inv_freq</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.inv_freq" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">inv_freq</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.cos_cached" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">cos_cached</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.cos_cached" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">cos_cached</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.sin_cached" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">sin_cached</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.sin_cached" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">sin_cached</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Apply rotary positional encoding to inputs.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Position-encoded sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-492"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-493">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-494">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-495">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-496"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-497"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply rotary positional encoding to inputs.</span>
</span><span id="__span-0-498">
</span><span id="__span-0-499"><span class="sd">    Args:</span>
</span><span id="__span-0-500"><span class="sd">        inputs: Input of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-501"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-502">
</span><span id="__span-0-503"><span class="sd">    Returns:</span>
</span><span id="__span-0-504"><span class="sd">        Position-encoded sequence of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-505">
</span><span id="__span-0-506"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-507">    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-508">    <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span><span class="p">:</span>
</span><span id="__span-0-509">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sequence length </span><span class="si">{</span><span class="n">seq_len</span><span class="si">}</span><span class="s2"> exceeds maximum length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-510">
</span><span id="__span-0-511">    <span class="n">cos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos_cached</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="__span-0-512">    <span class="n">sin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sin_cached</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="__span-0-513">
</span><span id="__span-0-514">    <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">*</span> <span class="n">cos</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_rotate_half</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">*</span> <span class="n">sin</span><span class="p">)</span>
</span><span id="__span-0-515">    <span class="k">return</span> <span class="n">output</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">517</span>
<span class="normal">518</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-517"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-518">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">520</span>
<span class="normal">521</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-520"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-521">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">LearnablePositionalEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">LearnablePositionalEncoder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">input_dim</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BasePositionalEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BasePositionalEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder">BasePositionalEncoder</a></code></p>



        <p>Learnable positional embeddings.</p>
<p>Uses a learnable embedding table to encode position information,
similar to token embeddings.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimension of the embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_len</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum sequence length (vocabulary size for positions).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dropout rate to apply after adding positional encoding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">LearnablePositionalEncoder</span><span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">max_len</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
</span><span id="__span-0-5"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-545"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-546">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-547">    <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-548">    <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
</span><span id="__span-0-549">    <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-550"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-551">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-552">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
</span><span id="__span-0-553">    <span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span> <span class="o">=</span> <span class="n">max_len</span>
</span><span id="__span-0-554">
</span><span id="__span-0-555">    <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
</span><span id="__span-0-556">    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.position_embeddings" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">position_embeddings</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.position_embeddings" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">position_embeddings</span> <span class="o">=</span> <span class="n"><span title="torch.nn.Embedding">Embedding</span></span><span class="p">(</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder(max_len)">max_len</span></span><span class="p">,</span> <span class="n"><span title="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder(input_dim)">input_dim</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.dropout" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">dropout</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.dropout" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">dropout</span> <span class="o">=</span> <span class="n"><span title="torch.nn.Dropout">Dropout</span></span><span class="p">(</span><span class="n"><span title="torch.nn.Dropout(p)">p</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder(dropout)">dropout</span></span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Add learnable positional encoding to inputs.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Position-encoded sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-558"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-559">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-560">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-561">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-562"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-563"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Add learnable positional encoding to inputs.</span>
</span><span id="__span-0-564">
</span><span id="__span-0-565"><span class="sd">    Args:</span>
</span><span id="__span-0-566"><span class="sd">        inputs: Input of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-567"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-568">
</span><span id="__span-0-569"><span class="sd">    Returns:</span>
</span><span id="__span-0-570"><span class="sd">        Position-encoded sequence of shape `(batch_size, seq_len, input_dim)`.</span>
</span><span id="__span-0-571">
</span><span id="__span-0-572"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-573">    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-574">    <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span><span class="p">:</span>
</span><span id="__span-0-575">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sequence length </span><span class="si">{</span><span class="n">seq_len</span><span class="si">}</span><span class="s2"> exceeds maximum length </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_len</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-576">
</span><span id="__span-0-577">    <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-578">    <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-579">
</span><span id="__span-0-580">    <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>
</span><span id="__span-0-581">    <span class="n">output</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">+</span> <span class="n">position_embeddings</span>
</span><span id="__span-0-582">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">584</span>
<span class="normal">585</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-584"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-585">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">587</span>
<span class="normal">588</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-587"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-588">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.encoders.TransformerEncoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TransformerEncoder</span>


<a href="#formed.integrations.torch.modules.encoders.TransformerEncoder" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">TransformerEncoder</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">input_dim</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">num_heads</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">num_layers</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">feedforward_dim</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">positional_encoder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9">    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="__span-0-10">    <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
</span><span id="__span-0-11">    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-12"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BaseSequenceEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BaseSequenceEncoder">BaseSequenceEncoder</a></code></p>



        <p>Transformer-based sequence encoder.</p>
<p>Uses stacked TransformerEncoderLayers with positional encoding and
configurable attention masking via dependency injection.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimension of the embeddings (<code>d_model</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of attention heads.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of transformer layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feedforward_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimension of feedforward network.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dropout rate.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>positional_encoder</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional positional encoder to add position information.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BasePositionalEncoder&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.encoders.BasePositionalEncoder&lt;/code&gt;)" href="#formed.integrations.torch.modules.encoders.BasePositionalEncoder">BasePositionalEncoder</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask generator for self-attention.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseAttentionMask&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.masks.BaseAttentionMask&lt;/code&gt;)" href="#formed.integrations.torch.modules.masks.BaseAttentionMask">BaseAttentionMask</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Activation function (default: <code>"relu"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;relu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Epsilon for layer normalization.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_first</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether input is batch-first (default: <code>True</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules.encoders</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">TransformerEncoder</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">SinusoidalPositionalEncoder</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">CausalMask</span>
</span><span id="__span-0-5"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Standard transformer encoder</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="gp">... </span>    <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">feedforward_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
</span><span id="__span-0-13"><span class="gp">... </span>    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-0-14"><span class="gp">... </span>    <span class="n">positional_encoder</span><span class="o">=</span><span class="n">SinusoidalPositionalEncoder</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
</span><span id="__span-0-15"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-16"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-17"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Transformer with causal masking (for autoregressive tasks)</span>
</span><span id="__span-0-18"><span class="gp">&gt;&gt;&gt; </span><span class="n">causal_encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span>
</span><span id="__span-0-19"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-0-20"><span class="gp">... </span>    <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="__span-0-21"><span class="gp">... </span>    <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
</span><span id="__span-0-22"><span class="gp">... </span>    <span class="n">feedforward_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
</span><span id="__span-0-23"><span class="gp">... </span>    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-0-24"><span class="gp">... </span>    <span class="n">positional_encoder</span><span class="o">=</span><span class="n">SinusoidalPositionalEncoder</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">),</span>
</span><span id="__span-0-25"><span class="gp">... </span>    <span class="n">attention_mask</span><span class="o">=</span><span class="n">CausalMask</span><span class="p">()</span>
</span><span id="__span-0-26"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-640"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-641">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-642">    <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-643">    <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-644">    <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-645">    <span class="n">feedforward_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-646">    <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-0-647">    <span class="n">positional_encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BasePositionalEncoder</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-648">    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseAttentionMask</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-649">    <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="__span-0-650">    <span class="n">layer_norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
</span><span id="__span-0-651">    <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-652"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-653">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-654">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
</span><span id="__span-0-655">    <span class="bp">self</span><span class="o">.</span><span class="n">_positional_encoder</span> <span class="o">=</span> <span class="n">positional_encoder</span>
</span><span id="__span-0-656">    <span class="bp">self</span><span class="o">.</span><span class="n">_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span>
</span><span id="__span-0-657">    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_first</span> <span class="o">=</span> <span class="n">batch_first</span>
</span><span id="__span-0-658">
</span><span id="__span-0-659">    <span class="c1"># Create transformer encoder layers</span>
</span><span id="__span-0-660">    <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span>
</span><span id="__span-0-661">        <span class="n">d_model</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
</span><span id="__span-0-662">        <span class="n">nhead</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
</span><span id="__span-0-663">        <span class="n">dim_feedforward</span><span class="o">=</span><span class="n">feedforward_dim</span><span class="p">,</span>
</span><span id="__span-0-664">        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="__span-0-665">        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
</span><span id="__span-0-666">        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">,</span>
</span><span id="__span-0-667">        <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
</span><span id="__span-0-668">        <span class="n">norm_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-669">    <span class="p">)</span>
</span><span id="__span-0-670">
</span><span id="__span-0-671">    <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span>
</span><span id="__span-0-672">        <span class="n">encoder_layer</span><span class="o">=</span><span class="n">encoder_layer</span><span class="p">,</span>
</span><span id="__span-0-673">        <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
</span><span id="__span-0-674">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.encoders.TransformerEncoder.transformer_encoder" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">transformer_encoder</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.transformer_encoder" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n"><span title="torch.nn.TransformerEncoder">TransformerEncoder</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n"><span title="torch.nn.TransformerEncoder(encoder_layer)">encoder_layer</span></span><span class="o">=</span><span class="n"><span title="encoder_layer">encoder_layer</span></span><span class="p">,</span> <span class="n"><span title="torch.nn.TransformerEncoder(num_layers)">num_layers</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.encoders.TransformerEncoder(num_layers)">num_layers</span></span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.TransformerEncoder.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Encode input sequence using transformer.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input of shape <code>(batch_size, seq_len, input_dim)</code> if <code>batch_first=True</code>,
   or <code>(seq_len, batch_size, input_dim)</code> if <code>batch_first=False</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional mask of shape <code>(batch_size, seq_len)</code> where 1=valid, 0=padding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Encoded sequence of same shape as input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-676"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-677">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-678">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-679">    <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-680"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-681"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Encode input sequence using transformer.</span>
</span><span id="__span-0-682">
</span><span id="__span-0-683"><span class="sd">    Args:</span>
</span><span id="__span-0-684"><span class="sd">        inputs: Input of shape `(batch_size, seq_len, input_dim)` if `batch_first=True`,</span>
</span><span id="__span-0-685"><span class="sd">               or `(seq_len, batch_size, input_dim)` if `batch_first=False`.</span>
</span><span id="__span-0-686"><span class="sd">        mask: Optional mask of shape `(batch_size, seq_len)` where 1=valid, 0=padding.</span>
</span><span id="__span-0-687">
</span><span id="__span-0-688"><span class="sd">    Returns:</span>
</span><span id="__span-0-689"><span class="sd">        Encoded sequence of same shape as input.</span>
</span><span id="__span-0-690">
</span><span id="__span-0-691"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-692">    <span class="c1"># Apply positional encoding if provided</span>
</span><span id="__span-0-693">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_positional_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-694">        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_positional_encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-695">
</span><span id="__span-0-696">    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_first</span> <span class="k">else</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-697">    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_first</span> <span class="k">else</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-698">
</span><span id="__span-0-699">    <span class="c1"># Generate attention mask if generator is provided</span>
</span><span id="__span-0-700">    <span class="c1"># All attention masks return (seq_len, seq_len) or (batch_size, seq_len, seq_len)</span>
</span><span id="__span-0-701">    <span class="n">src_mask</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-702">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-703">        <span class="n">src_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_mask</span><span class="p">(</span>
</span><span id="__span-0-704">            <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
</span><span id="__span-0-705">            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span><span id="__span-0-706">            <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="__span-0-707">            <span class="n">padding_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span id="__span-0-708">        <span class="p">)</span>
</span><span id="__span-0-709">        <span class="k">if</span> <span class="n">src_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-710">            <span class="n">src_mask</span> <span class="o">=</span> <span class="n">src_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-711">
</span><span id="__span-0-712">    <span class="c1"># Generate key padding mask for transformer</span>
</span><span id="__span-0-713">    <span class="c1"># This is separate from attention_mask and handles padding from input mask</span>
</span><span id="__span-0-714">    <span class="c1"># TransformerEncoder expects True for positions to be masked</span>
</span><span id="__span-0-715">    <span class="n">src_key_padding_mask</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-716">    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-717">        <span class="c1"># Convert mask: 1=valid -&gt; False (not masked), 0=padding -&gt; True (masked)</span>
</span><span id="__span-0-718">        <span class="n">src_key_padding_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span id="__span-0-719">
</span><span id="__span-0-720">    <span class="c1"># Apply transformer encoder</span>
</span><span id="__span-0-721">    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_encoder</span><span class="p">(</span>
</span><span id="__span-0-722">        <span class="n">inputs</span><span class="p">,</span>
</span><span id="__span-0-723">        <span class="n">mask</span><span class="o">=</span><span class="n">src_mask</span><span class="p">,</span>
</span><span id="__span-0-724">        <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding_mask</span><span class="p">,</span>
</span><span id="__span-0-725">    <span class="p">)</span>
</span><span id="__span-0-726">
</span><span id="__span-0-727">    <span class="k">return</span> <span class="n">output</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.TransformerEncoder.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">729</span>
<span class="normal">730</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-729"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-730">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.encoders.TransformerEncoder.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.encoders.TransformerEncoder.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/encoders.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">732</span>
<span class="normal">733</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-732"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-733">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.feedforward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.feedforward</span>


<a href="#formed.integrations.torch.modules.feedforward" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Feed-forward neural network modules for PyTorch models.</p>
<p>This module provides feed-forward network layers with support for
multiple layers, dropout, layer normalization, and residual connections.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li>FeedForward: Multi-layer feed-forward network</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Configurable activation functions</li>
<li>Layer normalization</li>
<li>Dropout for regularization</li>
<li>Residual connections</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">FeedForward</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Simple 3-layer feed-forward network</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">input_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
</span><span id="__span-0-10"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.feedforward.FeedForward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">FeedForward</span>


<a href="#formed.integrations.torch.modules.feedforward.FeedForward" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">FeedForward</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n"><span title="torch.nn.ReLU">ReLU</span></span><span class="p">()</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>A simple feed forward neural network.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dimension of the input.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_dims</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A sequence of integers specifying the dimensions of each layer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span>[<span title="int">int</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dropout probability. Defaults to <code>0.0</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The activation function. Defaults to <code>torch.nn.ReLU()</code></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.nn.Module">Module</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="torch.nn.ReLU">ReLU</span>()</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-46"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-47">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-48">    <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-49">    <span class="n">hidden_dims</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
</span><span id="__span-0-50">    <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-51">    <span class="n">activation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="__span-0-52"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-53">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-54">    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
</span><span id="__span-0-55">    <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_dims</span> <span class="o">=</span> <span class="n">hidden_dims</span>
</span><span id="__span-0-56">    <span class="bp">self</span><span class="o">.</span><span class="n">_dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</span><span id="__span-0-57">    <span class="bp">self</span><span class="o">.</span><span class="n">_activation</span> <span class="o">=</span> <span class="n">activation</span>
</span><span id="__span-0-58">
</span><span id="__span-0-59">    <span class="n">layer_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_dim</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">)</span>
</span><span id="__span-0-60">    <span class="bp">self</span><span class="o">.</span><span class="n">_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
</span><span id="__span-0-61">        <span class="p">[</span>
</span><span id="__span-0-62">            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="__span-0-63">                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_dims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">layer_dims</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]),</span>
</span><span id="__span-0-64">                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
</span><span id="__span-0-65">                <span class="n">activation</span><span class="p">,</span>
</span><span id="__span-0-66">            <span class="p">)</span>
</span><span id="__span-0-67">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_dims</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-68">        <span class="p">]</span>
</span><span id="__span-0-69">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.feedforward.FeedForward.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.feedforward.FeedForward.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">



<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A tensor of shape <code>(batch_size, ..., input_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.FloatTensor">FloatTensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.FloatTensor">FloatTensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>A tensor of shape <code>(batch_size, ..., hidden_dims[-1])</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-71"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">:</span>
</span><span id="__span-0-72"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-73"><span class="sd">    Args:</span>
</span><span id="__span-0-74"><span class="sd">        inputs: A tensor of shape `(batch_size, ..., input_dim)`.</span>
</span><span id="__span-0-75">
</span><span id="__span-0-76"><span class="sd">    Returns:</span>
</span><span id="__span-0-77"><span class="sd">        A tensor of shape `(batch_size, ..., hidden_dims[-1])`.</span>
</span><span id="__span-0-78"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-79">    <span class="n">output</span> <span class="o">=</span> <span class="n">inputs</span>
</span><span id="__span-0-80">    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layers</span><span class="p">:</span>
</span><span id="__span-0-81">        <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span><span id="__span-0-82">    <span class="k">return</span> <span class="n">output</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.feedforward.FeedForward.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.feedforward.FeedForward.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-84"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-85">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dim</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.feedforward.FeedForward.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.feedforward.FeedForward.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">87</span>
<span class="normal">88</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-87"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-88">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hidden_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.losses" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.losses</span>


<a href="#formed.integrations.torch.modules.losses" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Loss functions for classification tasks.</p>
<p>This module provides loss functions for classification with support for
label weighting and different reduction strategies.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseClassificationLoss</code>: Abstract base class for classification losses</li>
<li><code>CrossEntropyLoss</code>: Standard cross-entropy loss with optional weighting</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">CrossEntropyLoss</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Simple cross-entropy</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># (batch_size, num_classes)</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span>  <span class="c1"># (batch_size,)</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With label weighting</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">StaticLabelWeighter</span>
</span><span id="__span-0-12"><span class="gp">&gt;&gt;&gt; </span><span class="n">weighter</span> <span class="o">=</span> <span class="n">StaticLabelWeighter</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</span><span id="__span-0-13"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weighter</span><span class="o">=</span><span class="n">weighter</span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.losses.BaseClassificationLoss" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseClassificationLoss</span>


<a href="#formed.integrations.torch.modules.losses.BaseClassificationLoss" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for classification loss functions.</p>
<p>A ClassificationLoss defines a strategy for computing loss based on model logits and true labels.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>_ParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional parameters used during loss computation.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.losses.BaseClassificationLoss.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.losses.BaseClassificationLoss.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the classification loss.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model output logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>True target labels of shape <code>(...)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional additional parameters for loss computation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Computed loss as a scalar tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-52"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-53"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-54"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the classification loss.</span>
</span><span id="__span-0-55">
</span><span id="__span-0-56"><span class="sd">    Args:</span>
</span><span id="__span-0-57"><span class="sd">        logits: Model output logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-58"><span class="sd">        labels: True target labels of shape `(...)`.</span>
</span><span id="__span-0-59"><span class="sd">        params: Optional additional parameters for loss computation.</span>
</span><span id="__span-0-60">
</span><span id="__span-0-61"><span class="sd">    Returns:</span>
</span><span id="__span-0-62"><span class="sd">        Computed loss as a scalar tensor.</span>
</span><span id="__span-0-63">
</span><span id="__span-0-64"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-65">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.losses.CrossEntropyLoss" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CrossEntropyLoss</span>


<a href="#formed.integrations.torch.modules.losses.CrossEntropyLoss" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">CrossEntropyLoss</span><span class="p">(</span><span class="n">weighter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseClassificationLoss&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.losses.BaseClassificationLoss&lt;/code&gt;)" href="#formed.integrations.torch.modules.losses.BaseClassificationLoss">BaseClassificationLoss</a>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code></p>



        <p>Cross-entropy loss for classification tasks.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weighter</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An optional label weighter to assign weights to each class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseLabelWeighter&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.weighters.BaseLabelWeighter&lt;/code&gt;)" href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter">BaseLabelWeighter</a>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reduce</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Reduction method - <code>"mean"</code> or <code>"sum"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Literal">Literal</span>[&#39;mean&#39;, &#39;sum&#39;]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-89"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-90">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-91">    <span class="n">weighter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseLabelWeighter</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-92">    <span class="n">reduce</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
</span><span id="__span-0-93"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-94">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-95">    <span class="bp">self</span><span class="o">.</span><span class="n">_weighter</span> <span class="o">=</span> <span class="n">weighter</span>
</span><span id="__span-0-96">    <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">reduce</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.losses.CrossEntropyLoss.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.losses.CrossEntropyLoss.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute cross-entropy loss.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Labels of shape <code>(...)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional parameters for the weighter.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Loss scalar.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-98"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-99">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-100">    <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-101">    <span class="n">labels</span><span class="p">:</span> <span class="n">TensorCompatible</span><span class="p">,</span>
</span><span id="__span-0-102">    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-103"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-104"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute cross-entropy loss.</span>
</span><span id="__span-0-105">
</span><span id="__span-0-106"><span class="sd">    Args:</span>
</span><span id="__span-0-107"><span class="sd">        logits: Logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-108"><span class="sd">        labels: Labels of shape `(...)`.</span>
</span><span id="__span-0-109"><span class="sd">        params: Optional parameters for the weighter.</span>
</span><span id="__span-0-110">
</span><span id="__span-0-111"><span class="sd">    Returns:</span>
</span><span id="__span-0-112"><span class="sd">        Loss scalar.</span>
</span><span id="__span-0-113">
</span><span id="__span-0-114"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-115">    <span class="n">labels</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span id="__span-0-116">
</span><span id="__span-0-117">    <span class="n">num_classes</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-118">    <span class="n">one_hot_labels</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="__span-0-119">    <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-120">
</span><span id="__span-0-121">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weighter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-122">        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weighter</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</span><span id="__span-0-123">        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">one_hot_labels</span> <span class="o">*</span> <span class="n">log_probs</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-124">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-125">        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">one_hot_labels</span> <span class="o">*</span> <span class="n">log_probs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-126">
</span><span id="__span-0-127">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span id="__span-0-128">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="__span-0-129">    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span id="__span-0-130">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="__span-0-131">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-132">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown reduce operation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.losses.BCEWithLogitsLoss" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BCEWithLogitsLoss</span>


<a href="#formed.integrations.torch.modules.losses.BCEWithLogitsLoss" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">BCEWithLogitsLoss</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">weighter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">pos_weight</span><span class="o">=</span><span class="kc">None</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseClassificationLoss&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.losses.BaseClassificationLoss&lt;/code&gt;)" href="#formed.integrations.torch.modules.losses.BaseClassificationLoss">BaseClassificationLoss</a>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code></p>



        <p>Binary cross-entropy loss with logits for multilabel classification tasks.</p>
<p>This loss combines a Sigmoid layer and the BCELoss in one single class.
This version is more numerically stable than using a plain Sigmoid followed by BCELoss.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weighter</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An optional label weighter to assign weights to each class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseLabelWeighter&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.weighters.BaseLabelWeighter&lt;/code&gt;)" href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter">BaseLabelWeighter</a>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reduce</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Reduction method - <code>"mean"</code> or <code>"sum"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Literal">Literal</span>[&#39;mean&#39;, &#39;sum&#39;]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pos_weight</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional weight for positive examples per class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># (batch_size, num_classes)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>  <span class="c1"># (batch_size, num_classes)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-155"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-156">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-157">    <span class="n">weighter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseLabelWeighter</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-158">    <span class="n">reduce</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
</span><span id="__span-0-159">    <span class="n">pos_weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorCompatible</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-160"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-161">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-162">    <span class="bp">self</span><span class="o">.</span><span class="n">_weighter</span> <span class="o">=</span> <span class="n">weighter</span>
</span><span id="__span-0-163">    <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">reduce</span>
</span><span id="__span-0-164">    <span class="bp">self</span><span class="o">.</span><span class="n">_pos_weight</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">pos_weight</span><span class="p">)</span> <span class="k">if</span> <span class="n">pos_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.losses.BCEWithLogitsLoss.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.losses.BCEWithLogitsLoss.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute BCE with logits loss.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Binary labels of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional parameters for the weighter.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Loss scalar.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-166"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-167">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-168">    <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-169">    <span class="n">labels</span><span class="p">:</span> <span class="n">TensorCompatible</span><span class="p">,</span>
</span><span id="__span-0-170">    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-171"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-172"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute BCE with logits loss.</span>
</span><span id="__span-0-173">
</span><span id="__span-0-174"><span class="sd">    Args:</span>
</span><span id="__span-0-175"><span class="sd">        logits: Logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-176"><span class="sd">        labels: Binary labels of shape `(..., num_classes)`.</span>
</span><span id="__span-0-177"><span class="sd">        params: Optional parameters for the weighter.</span>
</span><span id="__span-0-178">
</span><span id="__span-0-179"><span class="sd">    Returns:</span>
</span><span id="__span-0-180"><span class="sd">        Loss scalar.</span>
</span><span id="__span-0-181">
</span><span id="__span-0-182"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-183">    <span class="n">labels</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="__span-0-184">
</span><span id="__span-0-185">    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">pos_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos_weight</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
</span><span id="__span-0-186">
</span><span id="__span-0-187">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weighter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-188">        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weighter</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</span><span id="__span-0-189">        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">weights</span>
</span><span id="__span-0-190">
</span><span id="__span-0-191">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span id="__span-0-192">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="__span-0-193">    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span id="__span-0-194">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="__span-0-195">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-196">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown reduce operation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.losses.BaseRegressionLoss" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseRegressionLoss</span>


<a href="#formed.integrations.torch.modules.losses.BaseRegressionLoss" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for regression loss functions.</p>
<p>A RegressionLoss defines a strategy for computing loss based on model predictions and true labels.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>_ParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional parameters used during loss computation.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.losses.BaseRegressionLoss.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.losses.BaseRegressionLoss.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the regression loss.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>predictions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model output predictions of shape <code>(...)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>True target labels of shape <code>(...)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional additional parameters for loss computation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Computed loss as a scalar tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-209"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-210"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-211">    <span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-212"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-213"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the regression loss.</span>
</span><span id="__span-0-214">
</span><span id="__span-0-215"><span class="sd">    Args:</span>
</span><span id="__span-0-216"><span class="sd">        predictions: Model output predictions of shape `(...)`.</span>
</span><span id="__span-0-217"><span class="sd">        labels: True target labels of shape `(...)`.</span>
</span><span id="__span-0-218"><span class="sd">        params: Optional additional parameters for loss computation.</span>
</span><span id="__span-0-219">
</span><span id="__span-0-220"><span class="sd">    Returns:</span>
</span><span id="__span-0-221"><span class="sd">        Computed loss as a scalar tensor.</span>
</span><span id="__span-0-222">
</span><span id="__span-0-223"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-224">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.losses.MeanSquaredErrorLoss" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">MeanSquaredErrorLoss</span>


<a href="#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">MeanSquaredErrorLoss</span><span class="p">(</span><span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseRegressionLoss&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.losses.BaseRegressionLoss&lt;/code&gt;)" href="#formed.integrations.torch.modules.losses.BaseRegressionLoss">BaseRegressionLoss</a>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code></p>



        <p>Mean Squared Error (MSE) loss for regression tasks.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>reduce</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Reduction method - <code>"mean"</code> or <code>"sum"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Literal">Literal</span>[&#39;mean&#39;, &#39;sum&#39;]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">MeanSquaredErrorLoss</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-247"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-248">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-249">    <span class="n">reduce</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
</span><span id="__span-0-250"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-251">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-252">    <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">=</span> <span class="n">reduce</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.losses.MeanSquaredErrorLoss.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute MSE loss.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>predictions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Predictions of shape <code>(...)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Labels of shape <code>(...)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.losses._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Loss scalar.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/losses.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-254"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-255">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-256">    <span class="n">predictions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-257">    <span class="n">labels</span><span class="p">:</span> <span class="n">TensorCompatible</span><span class="p">,</span>
</span><span id="__span-0-258">    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-259"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-260"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute MSE loss.</span>
</span><span id="__span-0-261">
</span><span id="__span-0-262"><span class="sd">    Args:</span>
</span><span id="__span-0-263"><span class="sd">        predictions: Predictions of shape `(...)`.</span>
</span><span id="__span-0-264"><span class="sd">        labels: Labels of shape `(...)`.</span>
</span><span id="__span-0-265"><span class="sd">        params: Ignored.</span>
</span><span id="__span-0-266">
</span><span id="__span-0-267"><span class="sd">    Returns:</span>
</span><span id="__span-0-268"><span class="sd">        Loss scalar.</span>
</span><span id="__span-0-269">
</span><span id="__span-0-270"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-271">    <span class="n">labels</span> <span class="o">=</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span id="__span-0-272">
</span><span id="__span-0-273">    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-274">
</span><span id="__span-0-275">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span id="__span-0-276">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="__span-0-277">    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span id="__span-0-278">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="__span-0-279">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-280">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown reduce operation: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_reduce</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.masks" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.masks</span>


<a href="#formed.integrations.torch.modules.masks" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Attention mask generation for transformer models.
This module provides reusable attention mask generators for transformer-based
models in PyTorch. Attention masks control which positions in a sequence
can attend to which other positions, enabling various attention patterns
such as causal masking for autoregressive models or sliding window attention
for long sequences.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseAttentionMask</code>: Abstract base class for attention mask generators</li>
<li><code>CausalMask</code>: Generates causal (autoregressive) attention masks</li>
<li><code>SlidingWindowAttentionMask</code>: Generates sliding window attention masks</li>
<li><code>CombinedMask</code>: Combines multiple attention masks into a single mask</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Standardized attention mask format compatible with PyTorch Transformer modules</li>
<li>Support for batch-wise and sequence-wise masks</li>
<li>Easily extensible via registration system for custom masks</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">CausalMask</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a causal mask generator</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">mask_generator</span> <span class="o">=</span> <span class="n">CausalMask</span><span class="p">()</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate a causal mask for sequence length 5 and batch size 2</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">mask_generator</span><span class="p">(</span><span class="n">seq_len</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># mask shape will be (5, 5) with float values: 0.0 for attendable positions,</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># float(&#39;-inf&#39;) for masked positions</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.masks.BaseAttentionMask" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseAttentionMask</span>


<a href="#formed.integrations.torch.modules.masks.BaseAttentionMask" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Base class for attention mask generation.</p>
<p>Attention masks control which positions can attend to which other positions
in transformer models.</p>
<p>All attention masks must return a mask of shape <code>(seq_len, seq_len)</code> or
<code>(batch_size, seq_len, seq_len)</code> using float values where:</p>
<ul>
<li><code>0.0</code> indicates positions that CAN be attended to</li>
<li><code>float('-inf')</code> indicates positions that should NOT be attended to</li>
</ul>
<p>This standardized format ensures compatibility with PyTorch's
<code>TransformerEncoder.mask</code> parameter.</p>











<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.masks.CausalMask" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CausalMask</span>


<a href="#formed.integrations.torch.modules.masks.CausalMask" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseAttentionMask&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.masks.BaseAttentionMask&lt;/code&gt;)" href="#formed.integrations.torch.modules.masks.BaseAttentionMask">BaseAttentionMask</a></code></p>



        <p>Generates causal (autoregressive) attention masks.</p>
<p>Causal masks ensure that each position can only attend to itself
and previous positions, enabling autoregressive generation.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">masks</span> <span class="o">=</span> <span class="n">CausalMask</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">masks</span><span class="p">(</span><span class="n">seq_len</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># mask[i, j] = 0.0 if j &lt;= i else float(&#39;-inf&#39;)</span>
</span></code></pre></div>











<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.masks.SlidingWindowAttentionMask" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SlidingWindowAttentionMask</span>


<a href="#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">SlidingWindowAttentionMask</span><span class="p">(</span><span class="n">window_size</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseAttentionMask&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.masks.BaseAttentionMask&lt;/code&gt;)" href="#formed.integrations.torch.modules.masks.BaseAttentionMask">BaseAttentionMask</a></code></p>



        <p>Sliding window attention mask.</p>
<p>Restricts attention to a local window around each position, enabling
efficient processing of long sequences. Commonly used in models like
Longformer and Mistral.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>window_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the attention window on each side.
         Total window is <code>(2 * window_size + 1)</code> centered on each position.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Window size of 1 means each position can attend to itself and</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># one position on each side</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">mask_gen</span> <span class="o">=</span> <span class="n">SlidingWindowAttentionMask</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">mask_gen</span><span class="p">(</span><span class="n">seq_len</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Position 0: can attend to [0, 1]</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Position 1: can attend to [0, 1, 2]</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Position 2: can attend to [1, 2, 3]</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Position 3: can attend to [2, 3]</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/masks.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-148"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-149">    <span class="k">if</span> <span class="n">window_size</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-150">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;window_size must be non-negative, got </span><span class="si">{</span><span class="n">window_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-151">    <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.masks.SlidingWindowAttentionMask.window_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">window_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask.window_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">window_size</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.modules.masks.SlidingWindowAttentionMask(window_size)">window_size</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.masks.CombinedMask" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">CombinedMask</span>


<a href="#formed.integrations.torch.modules.masks.CombinedMask" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">CombinedMask</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseAttentionMask&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.masks.BaseAttentionMask&lt;/code&gt;)" href="#formed.integrations.torch.modules.masks.BaseAttentionMask">BaseAttentionMask</a></code></p>



        <p>Combines multiple attention masks.</p>
<p>Applies multiple masks in sequence and combines their results.
A position is masked if ANY mask blocks it (logical OR for <code>-inf</code> values).</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>masks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of attention masks to combine.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseAttentionMask&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.masks.BaseAttentionMask&lt;/code&gt;)" href="#formed.integrations.torch.modules.masks.BaseAttentionMask">BaseAttentionMask</a>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Combine multiple structural masks</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">mask1</span> <span class="o">=</span> <span class="n">CausalMask</span><span class="p">()</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">mask2</span> <span class="o">=</span> <span class="n">SomeOtherMask</span><span class="p">()</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">combined</span> <span class="o">=</span> <span class="n">CombinedMask</span><span class="p">(</span><span class="n">masks</span><span class="o">=</span><span class="p">[</span><span class="n">mask1</span><span class="p">,</span> <span class="n">mask2</span><span class="p">])</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/masks.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">202</span>
<span class="normal">203</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-202"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">masks</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">BaseAttentionMask</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-203">    <span class="bp">self</span><span class="o">.</span><span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.masks.CombinedMask.masks" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">masks</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.masks.CombinedMask.masks" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">masks</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.modules.masks.CombinedMask(masks)">masks</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.samplers" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.samplers</span>


<a href="#formed.integrations.torch.modules.samplers" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Label samplers for classification tasks.</p>
<p>This module provides samplers that convert model logits into discrete labels.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseLabelSampler</code>: Abstract base class for label samplers</li>
<li><code>ArgmaxLabelSampler</code>: Selects the label with highest logit</li>
<li><code>MultinomialLabelSampler</code>: Samples from categorical distribution</li>
<li><code>BaseMultilabelSampler</code>: Abstract base class for multilabel samplers</li>
<li><code>ThresholdMultilabelSampler</code>: Selects labels above a threshold</li>
<li><code>TopKMultilabelSampler</code>: Selects top-k labels</li>
<li><code>BernoulliMultilabelSampler</code>: Samples labels from independent Bernoulli distributions</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">ArgmaxLabelSampler</span><span class="p">,</span> <span class="n">MultinomialLabelSampler</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># (batch_size, num_classes)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Argmax sampling (deterministic)</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="n">argmax_sampler</span> <span class="o">=</span> <span class="n">ArgmaxLabelSampler</span><span class="p">()</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">argmax_sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Multinomial sampling (stochastic)</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="n">multi_sampler</span> <span class="o">=</span> <span class="n">MultinomialLabelSampler</span><span class="p">()</span>
</span><span id="__span-0-12"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">multi_sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.BaseLabelSampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseLabelSampler</span>


<a href="#formed.integrations.torch.modules.samplers.BaseLabelSampler" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.modules.samplers._ParamsT">_ParamsT</span>]</code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for label samplers.</p>
<p>A LabelSampler defines a strategy for sampling labels based on model logits.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>_ParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional parameters used during sampling.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.samplers.BaseLabelSampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.samplers.BaseLabelSampler.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample labels from logits.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model output logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional parameters for sampling.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.samplers._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Sampled labels of shape <code>(...)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-52"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-53"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-54"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample labels from logits.</span>
</span><span id="__span-0-55">
</span><span id="__span-0-56"><span class="sd">    Args:</span>
</span><span id="__span-0-57"><span class="sd">        logits: Model output logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-58"><span class="sd">        params: Additional parameters for sampling.</span>
</span><span id="__span-0-59">
</span><span id="__span-0-60"><span class="sd">    Returns:</span>
</span><span id="__span-0-61"><span class="sd">        Sampled labels of shape `(...)`.</span>
</span><span id="__span-0-62">
</span><span id="__span-0-63"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-64">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.ArgmaxLabelSampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">ArgmaxLabelSampler</span>


<a href="#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseLabelSampler&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.BaseLabelSampler&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.BaseLabelSampler">BaseLabelSampler</a>[None]</code></p>



        <p>Label sampler that selects the label with the highest logit.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">ArgmaxLabelSampler</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>  <span class="c1"># Shape: (4,)</span>
</span></code></pre></div>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.samplers.ArgmaxLabelSampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Select the argmax label.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Labels of shape <code>(...)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-81"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-82"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Select the argmax label.</span>
</span><span id="__span-0-83">
</span><span id="__span-0-84"><span class="sd">    Args:</span>
</span><span id="__span-0-85"><span class="sd">        logits: Logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-86"><span class="sd">        params: Ignored.</span>
</span><span id="__span-0-87">
</span><span id="__span-0-88"><span class="sd">    Returns:</span>
</span><span id="__span-0-89"><span class="sd">        Labels of shape `(...)`.</span>
</span><span id="__span-0-90">
</span><span id="__span-0-91"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-92">    <span class="k">return</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">MultinomialLabelSamplerParams</span>


<a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.TypedDict">TypedDict</span></code></p>



        <p>Parameters for MultinomialLabelSampler.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;temperature&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams.temperature&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams.temperature">temperature</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Sampling temperature to control randomness.
Higher temperature = more random, lower = more deterministic.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams.temperature" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">temperature</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams.temperature" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">temperature</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.MultinomialLabelSampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">MultinomialLabelSampler</span>


<a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSampler" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseLabelSampler&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.BaseLabelSampler&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.BaseLabelSampler">BaseLabelSampler</a>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;MultinomialLabelSamplerParams&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams">MultinomialLabelSamplerParams</a>]</code></p>



        <p>Label sampler that samples labels from a multinomial distribution.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">MultinomialLabelSampler</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Sample with default temperature</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Sample with temperature scaling</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></code></pre></div>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.samplers.MultinomialLabelSampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.samplers.MultinomialLabelSampler.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample labels from categorical distribution.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional parameters containing temperature for sampling.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;MultinomialLabelSamplerParams&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams">MultinomialLabelSamplerParams</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Sampled labels of shape <code>(...)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-123"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultinomialLabelSamplerParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-124"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample labels from categorical distribution.</span>
</span><span id="__span-0-125">
</span><span id="__span-0-126"><span class="sd">    Args:</span>
</span><span id="__span-0-127"><span class="sd">        logits: Logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-128"><span class="sd">        params: Optional parameters containing temperature for sampling.</span>
</span><span id="__span-0-129">
</span><span id="__span-0-130"><span class="sd">    Returns:</span>
</span><span id="__span-0-131"><span class="sd">        Sampled labels of shape `(...)`.</span>
</span><span id="__span-0-132">
</span><span id="__span-0-133"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-134">    <span class="n">temperature</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span>
</span><span id="__span-0-135">    <span class="k">if</span> <span class="n">temperature</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="__span-0-136">        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span> <span class="o">/</span> <span class="n">temperature</span>
</span><span id="__span-0-137">
</span><span id="__span-0-138">    <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-139">    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.BaseMultilabelSampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseMultilabelSampler</span>


<a href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.modules.samplers._ParamsT">_ParamsT</span>]</code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for multilabel samplers.</p>
<p>A MultilabelSampler defines a strategy for sampling multiple labels
based on model logits.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>_ParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional parameters used during sampling.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.samplers.BaseMultilabelSampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample multiple labels from logits.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model output logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional parameters for sampling.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.samplers._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Sampled labels of shape <code>(..., num_labels)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-153"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-154"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-155"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample multiple labels from logits.</span>
</span><span id="__span-0-156">
</span><span id="__span-0-157"><span class="sd">    Args:</span>
</span><span id="__span-0-158"><span class="sd">        logits: Model output logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-159"><span class="sd">        params: Additional parameters for sampling.</span>
</span><span id="__span-0-160">
</span><span id="__span-0-161"><span class="sd">    Returns:</span>
</span><span id="__span-0-162"><span class="sd">        Sampled labels of shape `(..., num_labels)`.</span>
</span><span id="__span-0-163">
</span><span id="__span-0-164"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-165">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">ThresholdMultilabelSamplerParams</span>


<a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.TypedDict">TypedDict</span></code></p>



        <p>Parameters for ThresholdMultilabelSampler.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;threshold&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams.threshold&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams.threshold">threshold</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Probability threshold for selecting labels.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams.threshold" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">threshold</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams.threshold" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">threshold</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">ThresholdMultilabelSampler</span>


<a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">ThresholdMultilabelSampler</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseMultilabelSampler&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.BaseMultilabelSampler&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler">BaseMultilabelSampler</a>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;ThresholdMultilabelSamplerParams&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams">ThresholdMultilabelSamplerParams</a>]</code></p>



        <p>Multilabel sampler that selects labels above a certain threshold.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">ThresholdMultilabelSampler</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>  <span class="c1"># Shape: (4, num_labels)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-193"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-194">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-195">    <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.threshold" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">threshold</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.threshold" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">threshold</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler(threshold)">threshold</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Select labels above the threshold.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional parameters containing threshold.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;ThresholdMultilabelSamplerParams&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams">ThresholdMultilabelSamplerParams</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Labels of shape <code>(..., num_labels)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-197"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-198">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-199">    <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-200">    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ThresholdMultilabelSamplerParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-201"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-202"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Select labels above the threshold.</span>
</span><span id="__span-0-203">
</span><span id="__span-0-204"><span class="sd">    Args:</span>
</span><span id="__span-0-205"><span class="sd">        logits: Logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-206"><span class="sd">        params: Optional parameters containing threshold.</span>
</span><span id="__span-0-207">
</span><span id="__span-0-208"><span class="sd">    Returns:</span>
</span><span id="__span-0-209"><span class="sd">        Labels of shape `(..., num_labels)`.</span>
</span><span id="__span-0-210">
</span><span id="__span-0-211"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-212">    <span class="n">threshold</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;threshold&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span>
</span><span id="__span-0-213">    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="__span-0-214">    <span class="k">return</span> <span class="p">(</span><span class="n">probs</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TopKMultilabelSamplerParams</span>


<a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.TypedDict">TypedDict</span></code></p>



        <p>Parameters for TopKMultilabelSampler.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;k&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams.k&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams.k">k</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Number of top labels to select.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams.k" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">k</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams.k" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">k</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.TopKMultilabelSampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TopKMultilabelSampler</span>


<a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">TopKMultilabelSampler</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseMultilabelSampler&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.BaseMultilabelSampler&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler">BaseMultilabelSampler</a>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TopKMultilabelSamplerParams&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams">TopKMultilabelSamplerParams</a>]</code></p>



        <p>Multilabel sampler that selects the top-k labels.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">TopKMultilabelSampler</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>  <span class="c1"># Shape: (4, num_labels)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-239"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-240">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-241">    <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.samplers.TopKMultilabelSampler.k" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">k</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.k" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">k</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.modules.samplers.TopKMultilabelSampler(k)">k</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.samplers.TopKMultilabelSampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Select the top-k labels.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional parameters containing k for top-k selection.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TopKMultilabelSamplerParams&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams">TopKMultilabelSamplerParams</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Labels of shape <code>(..., num_labels)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-243"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-244">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-245">    <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-246">    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TopKMultilabelSamplerParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-247"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-248"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Select the top-k labels.</span>
</span><span id="__span-0-249">
</span><span id="__span-0-250"><span class="sd">    Args:</span>
</span><span id="__span-0-251"><span class="sd">        logits: Logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-252"><span class="sd">        params: Optional parameters containing k for top-k selection.</span>
</span><span id="__span-0-253">
</span><span id="__span-0-254"><span class="sd">    Returns:</span>
</span><span id="__span-0-255"><span class="sd">        Labels of shape `(..., num_labels)`.</span>
</span><span id="__span-0-256">
</span><span id="__span-0-257"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-258">    <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span> <span class="ow">or</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="__span-0-259">    <span class="n">topk_indices</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span>
</span><span id="__span-0-260">    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">topk_indices</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
</span><span id="__span-0-261">    <span class="k">return</span> <span class="n">labels</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BernoulliMultilabelSampler</span>


<a href="#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseMultilabelSampler&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.samplers.BaseMultilabelSampler&lt;/code&gt;)" href="#formed.integrations.torch.modules.samplers.BaseMultilabelSampler">BaseMultilabelSampler</a>[None]</code></p>



        <p>Multilabel sampler that samples labels from independent Bernoulli distributions.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">BernoulliMultilabelSampler</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>  <span class="c1"># Shape: (4, num_labels)</span>
</span></code></pre></div>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample labels from Bernoulli distributions.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Sampled labels of shape <code>(..., num_labels)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/samplers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-275"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-276"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample labels from Bernoulli distributions.</span>
</span><span id="__span-0-277">
</span><span id="__span-0-278"><span class="sd">    Args:</span>
</span><span id="__span-0-279"><span class="sd">        logits: Logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-280"><span class="sd">        params: Ignored.</span>
</span><span id="__span-0-281">
</span><span id="__span-0-282"><span class="sd">    Returns:</span>
</span><span id="__span-0-283"><span class="sd">        Sampled labels of shape `(..., num_labels)`.</span>
</span><span id="__span-0-284">
</span><span id="__span-0-285"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-286">    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="__span-0-287">    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.scalarmix" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.scalarmix</span>


<a href="#formed.integrations.torch.modules.scalarmix" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.scalarmix.ScalarMix" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">ScalarMix</span>


<a href="#formed.integrations.torch.modules.scalarmix.ScalarMix" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">ScalarMix</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">mixture_size</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">do_layer_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">initial_scalar_parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>



        <p>Computes a parameterised scalar mixture of N tensors, <code>mixture = gamma * sum(s_k * tensor_k)</code>
where <code>s = softmax(w)</code>, with <code>w</code> and <code>gamma</code> scalar parameters.
In addition, if <code>do_layer_norm=True</code> then apply layer normalization to each tensor
before weighting.</p>


<details class="note" open>
  <summary>Note</summary>
  <p>This script is based on the AllenNLP implementation of ScalarMix:
https://github.com/allenai/allennlp/blob/v2.10.0/allennlp/modules/scalar_mix.py</p>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/scalarmix.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-18"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-19">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-20">    <span class="n">mixture_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-21">    <span class="n">do_layer_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-22">    <span class="n">initial_scalar_parameters</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-23">    <span class="n">trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-24"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-25">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-26">    <span class="bp">self</span><span class="o">.</span><span class="n">mixture_size</span> <span class="o">=</span> <span class="n">mixture_size</span>
</span><span id="__span-0-27">    <span class="bp">self</span><span class="o">.</span><span class="n">do_layer_norm</span> <span class="o">=</span> <span class="n">do_layer_norm</span>
</span><span id="__span-0-28">
</span><span id="__span-0-29">    <span class="k">if</span> <span class="n">initial_scalar_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-30">        <span class="n">initial_scalar_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">mixture_size</span>
</span><span id="__span-0-31">    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">initial_scalar_parameters</span><span class="p">)</span> <span class="o">!=</span> <span class="n">mixture_size</span><span class="p">:</span>
</span><span id="__span-0-32">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-33">            <span class="s2">&quot;Length of initial_scalar_parameters </span><span class="si">{}</span><span class="s2"> differs from mixture_size </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="__span-0-34">                <span class="n">initial_scalar_parameters</span><span class="p">,</span> <span class="n">mixture_size</span>
</span><span id="__span-0-35">            <span class="p">)</span>
</span><span id="__span-0-36">        <span class="p">)</span>
</span><span id="__span-0-37">
</span><span id="__span-0-38">    <span class="bp">self</span><span class="o">.</span><span class="n">scalar_parameters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">(</span>
</span><span id="__span-0-39">        <span class="p">[</span>
</span><span id="__span-0-40">            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="n">initial_scalar_parameters</span><span class="p">[</span><span class="n">i</span><span class="p">]]),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">trainable</span><span class="p">)</span>
</span><span id="__span-0-41">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mixture_size</span><span class="p">)</span>
</span><span id="__span-0-42">        <span class="p">]</span>
</span><span id="__span-0-43">    <span class="p">)</span>
</span><span id="__span-0-44">    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">trainable</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.scalarmix.ScalarMix.mixture_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">mixture_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.mixture_size" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">mixture_size</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.modules.scalarmix.ScalarMix(mixture_size)">mixture_size</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.scalarmix.ScalarMix.do_layer_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">do_layer_norm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.do_layer_norm" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">do_layer_norm</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.modules.scalarmix.ScalarMix(do_layer_norm)">do_layer_norm</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.scalarmix.ScalarMix.scalar_parameters" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">scalar_parameters</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.scalar_parameters" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">scalar_parameters</span> <span class="o">=</span> <span class="n"><span title="torch.nn.ParameterList">ParameterList</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="p">[</span>
</span><span id="__span-0-3">        <span class="p">(</span>
</span><span id="__span-0-4">            <span class="n"><span title="torch.nn.Parameter">Parameter</span></span><span class="p">(</span>
</span><span id="__span-0-5">                <span class="n"><span title="torch.FloatTensor">FloatTensor</span></span><span class="p">(</span>
</span><span id="__span-0-6">                    <span class="p">[</span><span class="n"><span title="formed.integrations.torch.modules.scalarmix.ScalarMix(initial_scalar_parameters)">initial_scalar_parameters</span></span><span class="p">[</span><span class="n"><span title="i">i</span></span><span class="p">]]</span>
</span><span id="__span-0-7">                <span class="p">),</span>
</span><span id="__span-0-8">                <span class="n"><span title="torch.nn.Parameter(requires_grad)">requires_grad</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.scalarmix.ScalarMix(trainable)">trainable</span></span><span class="p">,</span>
</span><span id="__span-0-9">            <span class="p">)</span>
</span><span id="__span-0-10">        <span class="p">)</span>
</span><span id="__span-0-11">        <span class="k">for</span> <span class="n"><span title="i">i</span></span> <span class="ow">in</span> <span class="p">(</span><span class="n"><span title="range">range</span></span><span class="p">(</span><span class="n"><span title="formed.integrations.torch.modules.scalarmix.ScalarMix(mixture_size)">mixture_size</span></span><span class="p">))</span>
</span><span id="__span-0-12">    <span class="p">]</span>
</span><span id="__span-0-13"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.modules.scalarmix.ScalarMix.gamma" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">gamma</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.gamma" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">gamma</span> <span class="o">=</span> <span class="n"><span title="torch.nn.Parameter">Parameter</span></span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n"><span title="torch.FloatTensor">FloatTensor</span></span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n"><span title="torch.nn.Parameter(requires_grad)">requires_grad</span></span><span class="o">=</span><span class="n"><span title="formed.integrations.torch.modules.scalarmix.ScalarMix(trainable)">trainable</span></span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.scalarmix.ScalarMix.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.scalarmix.ScalarMix.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute a weighted average of the <code>tensors</code>.  The input tensors an be any shape
with at least two dimensions, but must all be the same shape.
When <code>do_layer_norm=True</code>, the <code>mask</code> is required input.  If the <code>tensors</code> are
dimensioned  <code>(dim_0, ..., dim_{n-1}, dim_n)</code>, then the <code>mask</code> is dimensioned
<code>(dim_0, ..., dim_{n-1})</code>, as in the typical case with <code>tensors</code> of shape
<code>(batch_size, timesteps, dim)</code> and <code>mask</code> of shape <code>(batch_size, timesteps)</code>.
When <code>do_layer_norm=False</code> the <code>mask</code> is ignored.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/scalarmix.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-46"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-47"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-48"><span class="sd">    Compute a weighted average of the `tensors`.  The input tensors an be any shape</span>
</span><span id="__span-0-49"><span class="sd">    with at least two dimensions, but must all be the same shape.</span>
</span><span id="__span-0-50"><span class="sd">    When `do_layer_norm=True`, the `mask` is required input.  If the `tensors` are</span>
</span><span id="__span-0-51"><span class="sd">    dimensioned  `(dim_0, ..., dim_{n-1}, dim_n)`, then the `mask` is dimensioned</span>
</span><span id="__span-0-52"><span class="sd">    `(dim_0, ..., dim_{n-1})`, as in the typical case with `tensors` of shape</span>
</span><span id="__span-0-53"><span class="sd">    `(batch_size, timesteps, dim)` and `mask` of shape `(batch_size, timesteps)`.</span>
</span><span id="__span-0-54"><span class="sd">    When `do_layer_norm=False` the `mask` is ignored.</span>
</span><span id="__span-0-55"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-56">    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixture_size</span><span class="p">:</span>
</span><span id="__span-0-57">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-58">            <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> tensors were passed, but the module was initialized to mix </span><span class="si">{}</span><span class="s2"> tensors.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="__span-0-59">                <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixture_size</span>
</span><span id="__span-0-60">            <span class="p">)</span>
</span><span id="__span-0-61">        <span class="p">)</span>
</span><span id="__span-0-62">
</span><span id="__span-0-63">    <span class="k">def</span><span class="w"> </span><span class="nf">_do_layer_norm</span><span class="p">(</span>
</span><span id="__span-0-64">        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-65">        <span class="n">broadcast_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-66">        <span class="n">num_elements_not_masked</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-67">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-68">        <span class="n">tensor_masked</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">*</span> <span class="n">broadcast_mask</span>
</span><span id="__span-0-69">        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tensor_masked</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_elements_not_masked</span>
</span><span id="__span-0-70">        <span class="n">variance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">tensor_masked</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="n">broadcast_mask</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_elements_not_masked</span>
</span><span id="__span-0-71">        <span class="k">return</span> <span class="p">(</span><span class="n">tensor</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="mf">1e-13</span><span class="p">)</span>
</span><span id="__span-0-72">
</span><span id="__span-0-73">    <span class="n">normed_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
</span><span id="__span-0-74">        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">parameter</span> <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scalar_parameters</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
</span><span id="__span-0-75">        <span class="n">split_size_or_sections</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-76">    <span class="p">)</span>
</span><span id="__span-0-77">
</span><span id="__span-0-78">    <span class="n">pieces</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
</span><span id="__span-0-79">    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_layer_norm</span><span class="p">:</span>
</span><span id="__span-0-80">        <span class="n">pieces</span> <span class="o">=</span> <span class="p">[</span><span class="n">weight</span> <span class="o">*</span> <span class="n">tensor</span> <span class="k">for</span> <span class="n">weight</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">normed_weights</span><span class="p">,</span> <span class="n">tensors</span><span class="p">)]</span>
</span><span id="__span-0-81">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">pieces</span><span class="p">)</span>
</span><span id="__span-0-82">
</span><span id="__span-0-83">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-84">        <span class="k">assert</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="__span-0-85">        <span class="n">broadcast_mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-86">        <span class="n">input_dim</span> <span class="o">=</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-87">        <span class="n">num_elements_not_masked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">*</span> <span class="n">input_dim</span>
</span><span id="__span-0-88">
</span><span id="__span-0-89">        <span class="n">pieces</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-90">            <span class="n">weight</span> <span class="o">*</span> <span class="n">_do_layer_norm</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">broadcast_mask</span><span class="p">,</span> <span class="n">num_elements_not_masked</span><span class="p">)</span>
</span><span id="__span-0-91">            <span class="k">for</span> <span class="n">weight</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">normed_weights</span><span class="p">,</span> <span class="n">tensors</span><span class="p">)</span>
</span><span id="__span-0-92">        <span class="p">]</span>
</span><span id="__span-0-93">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">pieces</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.vectorizers" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.vectorizers</span>


<a href="#formed.integrations.torch.modules.vectorizers" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Sequence vectorization modules for PyTorch models.</p>
<p>This module provides vectorizers that convert variable-length sequences
into fixed-size vectors. Vectorizers apply pooling operations over the
sequence dimension to produce single vectors per sequence.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseSequenceVectorizer</code>: Abstract base class for vectorizers</li>
<li><code>BagOfEmbeddingsSequenceVectorizer</code>: Pools sequence embeddings</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Multiple pooling strategies (mean, max, min, sum, first, last, hier)</li>
<li>Masked pooling to ignore padding tokens</li>
<li>Optional normalization before pooling</li>
<li>Hierarchical pooling with sliding windows</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Mean pooling over sequence</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span><span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">vector</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Max pooling with normalization</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="gp">... </span>    <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-11"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseSequenceVectorizer</span>


<a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for sequence vectorizers.</p>
<p>Vectorizers convert variable-length sequences into fixed-size vectors
by applying pooling operations over the sequence dimension.</p>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Vectorize a sequence into a fixed-size vector.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input embeddings of shape <code>(batch_size, seq_len, embedding_dim)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional attention mask of shape <code>(batch_size, seq_len)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Vectorized output of shape <code>(batch_size, output_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-49"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-50"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-51">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-52">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-53">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-54">    <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-55"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-56"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Vectorize a sequence into a fixed-size vector.</span>
</span><span id="__span-0-57">
</span><span id="__span-0-58"><span class="sd">    Args:</span>
</span><span id="__span-0-59"><span class="sd">        inputs: Input embeddings of shape `(batch_size, seq_len, embedding_dim)`.</span>
</span><span id="__span-0-60"><span class="sd">        mask: Optional attention mask of shape `(batch_size, seq_len)`.</span>
</span><span id="__span-0-61">
</span><span id="__span-0-62"><span class="sd">    Returns:</span>
</span><span id="__span-0-63"><span class="sd">        Vectorized output of shape `(batch_size, output_dim)`.</span>
</span><span id="__span-0-64">
</span><span id="__span-0-65"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-66">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the expected input dimension.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span> | None</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Input dimension or None if dimension-agnostic.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-68"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-69"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-70"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the expected input dimension.</span>
</span><span id="__span-0-71">
</span><span id="__span-0-72"><span class="sd">    Returns:</span>
</span><span id="__span-0-73"><span class="sd">        Input dimension or None if dimension-agnostic.</span>
</span><span id="__span-0-74">
</span><span id="__span-0-75"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-76">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the output dimension.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="int">int</span> | <span title="collections.abc.Callable">Callable</span>[[<span title="int">int</span>], <span title="int">int</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Output feature dimension or a function mapping input dim to output dim.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-78"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-79"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
</span><span id="__span-0-80"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the output dimension.</span>
</span><span id="__span-0-81">
</span><span id="__span-0-82"><span class="sd">    Returns:</span>
</span><span id="__span-0-83"><span class="sd">        Output feature dimension or a function mapping input dim to output dim.</span>
</span><span id="__span-0-84">
</span><span id="__span-0-85"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-86">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BagOfEmbeddingsSequenceVectorizer</span>


<a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="kc">None</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseSequenceVectorizer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer&lt;/code&gt;)" href="#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer">BaseSequenceVectorizer</a></code></p>



        <p>Bag-of-embeddings vectorizer using pooling operations.</p>
<p>This vectorizer applies pooling over the sequence dimension to create
fixed-size vectors. Multiple pooling strategies are supported, and
padding tokens are properly masked during pooling.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pooling</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pooling strategy to use:
- <code>"mean"</code>: Average pooling (default)
- <code>"max"</code>: Max pooling
- <code>"min"</code>: Min pooling
- <code>"sum"</code>: Sum pooling
- <code>"first"</code>: Take first token
- <code>"last"</code>: Take last non-padding token
- <code>"hier"</code>: Hierarchical pooling with sliding window</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;PoolingMethod&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.utils.PoolingMethod&lt;/code&gt;)" href="#formed.integrations.torch.utils.PoolingMethod">PoolingMethod</a> | <span title="collections.abc.Sequence">Sequence</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;PoolingMethod&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.utils.PoolingMethod&lt;/code&gt;)" href="#formed.integrations.torch.utils.PoolingMethod">PoolingMethod</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;mean&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to L2-normalize embeddings before pooling.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>window_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Window size for hierarchical pooling (required if <code>pooling="hier"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Mean pooling</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span><span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">vector</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Max pooling with normalization</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-9"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Multiple pooling methods combined</span>
</span><span id="__span-0-12"><span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span>
</span><span id="__span-0-13"><span class="gp">... </span>    <span class="n">pooling</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">]</span>
</span><span id="__span-0-14"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-15"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-16"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Hierarchical pooling</span>
</span><span id="__span-0-17"><span class="gp">&gt;&gt;&gt; </span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">BagOfEmbeddingsSequenceVectorizer</span><span class="p">(</span>
</span><span id="__span-0-18"><span class="gp">... </span>    <span class="n">pooling</span><span class="o">=</span><span class="s2">&quot;hier&quot;</span><span class="p">,</span>
</span><span id="__span-0-19"><span class="gp">... </span>    <span class="n">window_size</span><span class="o">=</span><span class="mi">3</span>
</span><span id="__span-0-20"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>This vectorizer is dimension-agnostic - it preserves the embedding
dimension from input to output (multiplied by number of pooling methods).</p>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-138"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-139">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-140">    <span class="n">pooling</span><span class="p">:</span> <span class="n">PoolingMethod</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">PoolingMethod</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
</span><span id="__span-0-141">    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-142">    <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-143"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-144">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-145">    <span class="bp">self</span><span class="o">.</span><span class="n">_pooling</span><span class="p">:</span> <span class="n">PoolingMethod</span> <span class="o">|</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">PoolingMethod</span><span class="p">]</span> <span class="o">=</span> <span class="n">pooling</span>
</span><span id="__span-0-146">    <span class="bp">self</span><span class="o">.</span><span class="n">_normalize</span> <span class="o">=</span> <span class="n">normalize</span>
</span><span id="__span-0-147">    <span class="bp">self</span><span class="o">.</span><span class="n">_window_size</span> <span class="o">=</span> <span class="n">window_size</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-149"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-150">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-151">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-152">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-153">    <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-154"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-155">    <span class="k">return</span> <span class="n">masked_pool</span><span class="p">(</span>
</span><span id="__span-0-156">        <span class="n">inputs</span><span class="p">,</span>
</span><span id="__span-0-157">        <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span id="__span-0-158">        <span class="n">pooling</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_pooling</span><span class="p">,</span>
</span><span id="__span-0-159">        <span class="n">normalize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_normalize</span><span class="p">,</span>
</span><span id="__span-0-160">        <span class="n">window_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_window_size</span><span class="p">,</span>
</span><span id="__span-0-161">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_input_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_input_dim</span>


<a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_input_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_input_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-163"><span class="k">def</span><span class="w"> </span><span class="nf">get_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-164">    <span class="k">return</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_output_dim" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_output_dim</span>


<a href="#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_output_dim" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_output_dim</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-166"><span class="k">def</span><span class="w"> </span><span class="nf">get_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
</span><span id="__span-0-167">    <span class="n">num_pooling</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pooling</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pooling</span><span class="p">)</span>
</span><span id="__span-0-168">    <span class="k">return</span> <span class="k">lambda</span> <span class="n">input_dim</span><span class="p">:</span> <span class="n">input_dim</span> <span class="o">*</span> <span class="n">num_pooling</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.modules.weighters" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.modules.weighters</span>


<a href="#formed.integrations.torch.modules.weighters" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Label weighters for classification tasks.</p>
<p>This module provides weighters that assign weights to class labels,
useful for handling imbalanced datasets.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>BaseLabelWeighter</code>: Abstract base class for label weighters</li>
<li><code>StaticLabelWeighter</code>: Uses fixed weights per class</li>
<li><code>BalancedByDistributionLabelWeighter</code>: Balances based on class distribution</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch.modules</span><span class="w"> </span><span class="kn">import</span> <span class="n">StaticLabelWeighter</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Static weights for 3 classes</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>  <span class="c1"># Weight rare classes more</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="n">weighter</span> <span class="o">=</span> <span class="n">StaticLabelWeighter</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="n">class_weights</span> <span class="o">=</span> <span class="n">weighter</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># Shape: (1, 3)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.weighters.BaseLabelWeighter" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseLabelWeighter</span>


<a href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.modules.weighters._ParamsT">_ParamsT</span>]</code>, <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for label weighters.</p>
<p>A LabelWeighter defines a strategy for assigning weights to each label
based on model logits and true targets.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>_ParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional parameters used during weighting.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.weighters.BaseLabelWeighter.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute weights for each target label.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model output logits of shape <code>(..., num_classes)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>targets</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>True target labels of shape <code>(...)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional additional parameters for weighting.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.modules.weighters._ParamsT">_ParamsT</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Weights for each logit of shape <code>(1, num_classes)</code> or broadcastable to logits shape.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/weighters.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-49"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-50"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-51">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-52">    <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-53">    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-54">    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ParamsT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-55"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-56"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute weights for each target label.</span>
</span><span id="__span-0-57">
</span><span id="__span-0-58"><span class="sd">    Args:</span>
</span><span id="__span-0-59"><span class="sd">        logits: Model output logits of shape `(..., num_classes)`.</span>
</span><span id="__span-0-60"><span class="sd">        targets: True target labels of shape `(...)`.</span>
</span><span id="__span-0-61"><span class="sd">        params: Optional additional parameters for weighting.</span>
</span><span id="__span-0-62">
</span><span id="__span-0-63"><span class="sd">    Returns:</span>
</span><span id="__span-0-64"><span class="sd">        Weights for each logit of shape `(1, num_classes)` or broadcastable to logits shape.</span>
</span><span id="__span-0-65">
</span><span id="__span-0-66"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-67">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.weighters.StaticLabelWeighter" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">StaticLabelWeighter</span>


<a href="#formed.integrations.torch.modules.weighters.StaticLabelWeighter" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">StaticLabelWeighter</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseLabelWeighter&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.weighters.BaseLabelWeighter&lt;/code&gt;)" href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter">BaseLabelWeighter</a>[None]</code></p>



        <p>Label weighter that assigns static weights to each class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>weights</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A tensor of shape <code>(num_classes,)</code> containing the weight for each class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Weight class 1 twice as much as class 0</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">weighter</span> <span class="o">=</span> <span class="n">StaticLabelWeighter</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="n">class_weights</span> <span class="o">=</span> <span class="n">weighter</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/weighters.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-87"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">TensorCompatible</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-88">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-89">    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_weights&quot;</span><span class="p">,</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">))</span>
</span><span id="__span-0-90">    <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.weighters.StaticLabelWeighter.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.weighters.StaticLabelWeighter.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Return static weights.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>targets</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Weights of shape <code>(1, num_classes)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/weighters.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-92"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-93">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-94">    <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-95">    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-96">    <span class="n">params</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-97"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-98"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return static weights.</span>
</span><span id="__span-0-99">
</span><span id="__span-0-100"><span class="sd">    Args:</span>
</span><span id="__span-0-101"><span class="sd">        logits: Ignored.</span>
</span><span id="__span-0-102"><span class="sd">        targets: Ignored.</span>
</span><span id="__span-0-103"><span class="sd">        params: Ignored.</span>
</span><span id="__span-0-104">
</span><span id="__span-0-105"><span class="sd">    Returns:</span>
</span><span id="__span-0-106"><span class="sd">        Weights of shape `(1, num_classes)`.</span>
</span><span id="__span-0-107">
</span><span id="__span-0-108"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-109">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BalancedByDistributionLabelWeighter</span>


<a href="#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">BalancedByDistributionLabelWeighter</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">distribution</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span>
</span><span id="__span-0-3"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseLabelWeighter&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.modules.weighters.BaseLabelWeighter&lt;/code&gt;)" href="#formed.integrations.torch.modules.weighters.BaseLabelWeighter">BaseLabelWeighter</a>[None]</code></p>



        <p>Label weighter that balances classes based on their distribution.</p>
<p>The weight for each class is computed as: <code>1 / (distribution * num_classes + eps)</code></p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>distribution</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A tensor of shape <code>(num_classes,)</code> representing the class distribution
(should sum to <code>1.0</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.TensorCompatible">TensorCompatible</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A small epsilon value to avoid division by zero.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="float">float</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-08</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Class distribution: 50%, 30%, 20%</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">weighter</span> <span class="o">=</span> <span class="n">BalancedByDistributionLabelWeighter</span><span class="p">(</span><span class="n">distribution</span><span class="o">=</span><span class="n">distribution</span><span class="p">)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="n">class_weights</span> <span class="o">=</span> <span class="n">weighter</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Rare classes get higher weights</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/modules/weighters.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-134"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distribution</span><span class="p">:</span> <span class="n">TensorCompatible</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-135">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-136">    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_distribution&quot;</span><span class="p">,</span> <span class="n">ensure_torch_tensor</span><span class="p">(</span><span class="n">distribution</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">))</span>
</span><span id="__span-0-137">    <span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</span><span id="__span-0-138">    <span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">=</span> <span class="n">eps</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter.forward" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">forward</span>


<a href="#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter.forward" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">forward</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute balanced weights.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>logits</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>targets</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="torch.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignored.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="torch.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Weights of shape <code>(1, num_classes)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/modules/weighters.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-140"><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span id="__span-0-141">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-142">    <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-143">    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-144">    <span class="n">params</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-145"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-146"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute balanced weights.</span>
</span><span id="__span-0-147">
</span><span id="__span-0-148"><span class="sd">    Args:</span>
</span><span id="__span-0-149"><span class="sd">        logits: Ignored.</span>
</span><span id="__span-0-150"><span class="sd">        targets: Ignored.</span>
</span><span id="__span-0-151"><span class="sd">        params: Ignored.</span>
</span><span id="__span-0-152">
</span><span id="__span-0-153"><span class="sd">    Returns:</span>
</span><span id="__span-0-154"><span class="sd">        Weights of shape `(1, num_classes)`.</span>
</span><span id="__span-0-155">
</span><span id="__span-0-156"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-157">    <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="p">)</span>
</span><span id="__span-0-158">    <span class="n">weights</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span> <span class="o">*</span> <span class="n">num_classes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eps</span><span class="p">)</span>
</span><span id="__span-0-159">    <span class="k">return</span> <span class="n">weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.training.callbacks" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.training.callbacks</span>


<a href="#formed.integrations.torch.training.callbacks" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Training callbacks for monitoring and controlling PyTorch model training.</p>
<p>This module provides a callback system for PyTorch training, allowing custom
logic to be executed at various points in the training loop. Callbacks can
monitor metrics, save checkpoints, implement early stopping, and integrate
with experiment tracking systems.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>TorchTrainingCallback</code>: Base class for all callbacks</li>
<li><code>EvaluationCallback</code>: Computes metrics using custom evaluators</li>
<li><code>EarlyStoppingCallback</code>: Stops training based on metric improvements</li>
<li><code>MlflowCallback</code>: Logs metrics to MLflow</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Hook points at training/epoch/batch start and end</li>
<li>Metric computation and logging</li>
<li>Model checkpointing</li>
<li>Early stopping with patience</li>
<li>MLflow integration</li>
<li>Extensible for custom callbacks</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">TorchTrainer</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">EarlyStoppingCallback</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">EvaluationCallback</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">MlflowCallback</span>
</span><span id="__span-0-6"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="gp">... </span>    <span class="n">val_dataloader</span><span class="o">=</span><span class="n">val_loader</span><span class="p">,</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-0-12"><span class="gp">... </span>        <span class="n">EvaluationCallback</span><span class="p">(</span><span class="n">my_evaluator</span><span class="p">),</span>
</span><span id="__span-0-13"><span class="gp">... </span>        <span class="n">EarlyStoppingCallback</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;-loss&quot;</span><span class="p">),</span>
</span><span id="__span-0-14"><span class="gp">... </span>        <span class="n">MlflowCallback</span><span class="p">()</span>
</span><span id="__span-0-15"><span class="gp">... </span>    <span class="p">]</span>
</span><span id="__span-0-16"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TorchTrainingCallback</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="colt.Registrable">Registrable</span></code></p>



        <p>Base class for training callbacks.</p>
<p>Callbacks provide hooks to execute custom logic at various points
during training. Subclasses can override any hook method to implement
custom behavior such as logging, checkpointing, or early stopping.</p>


<details class="hook-execution-order" open>
  <summary>Hook execution order</summary>
  <ol>
<li><code>on_training_start</code> - once at the beginning</li>
<li><code>on_epoch_start</code> - at the start of each epoch</li>
<li><code>on_batch_start</code> - before each training batch</li>
<li><code>on_batch_end</code> - after each training batch</li>
<li><code>on_eval_start</code> - before evaluation (returns evaluator)</li>
<li><code>on_eval_end</code> - after evaluation with computed metrics</li>
<li><code>on_log</code> - when metrics are logged</li>
<li><code>on_epoch_end</code> - at the end of each epoch</li>
<li><code>on_training_end</code> - once at the end (can modify final state)</li>
</ol>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="nd">@TorchTrainingCallback</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;my_callback&quot;</span><span class="p">)</span>
</span><span id="__span-0-2"><span class="gp">... </span><span class="k">class</span><span class="w"> </span><span class="nc">MyCallback</span><span class="p">(</span><span class="n">TorchTrainingCallback</span><span class="p">):</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
</span><span id="__span-0-4"><span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Completed epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> at step </span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_start</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-85"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_start</span><span class="p">(</span>
</span><span id="__span-0-86">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-87">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-88">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-89">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-90"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-91">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_end</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span>
<span class="normal">99</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-93"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_end</span><span class="p">(</span>
</span><span id="__span-0-94">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-95">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-96">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-97">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-98"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainState</span><span class="p">:</span>
</span><span id="__span-0-99">    <span class="k">return</span> <span class="n">state</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_start</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-101"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_start</span><span class="p">(</span>
</span><span id="__span-0-102">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-103">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-104">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-105">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-106">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-107"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-108">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_end</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-110"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span>
</span><span id="__span-0-111">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-112">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-113">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-114">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-115">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-116"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-117">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_start</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-119"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_start</span><span class="p">(</span>
</span><span id="__span-0-120">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-123">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-124">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-125"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-126">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_end</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-128"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_end</span><span class="p">(</span>
</span><span id="__span-0-129">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-130">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-131">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-132">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-133">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-134">    <span class="n">output</span><span class="p">:</span> <span class="n">ModelOutputT</span><span class="p">,</span>
</span><span id="__span-0-135"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-136">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_start</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-138"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_start</span><span class="p">(</span>
</span><span id="__span-0-139">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-140">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-141">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-142">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-143"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">IEvaluator</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">]:</span>
</span><span id="__span-0-144">    <span class="k">class</span><span class="w"> </span><span class="nc">DummyMetric</span><span class="p">(</span><span class="n">IEvaluator</span><span class="p">):</span>
</span><span id="__span-0-145">        <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="o">/</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-146">            <span class="k">pass</span>
</span><span id="__span-0-147">
</span><span id="__span-0-148">        <span class="k">def</span><span class="w"> </span><span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-149">            <span class="k">return</span> <span class="p">{}</span>
</span><span id="__span-0-150">
</span><span id="__span-0-151">        <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-152">            <span class="k">pass</span>
</span><span id="__span-0-153">
</span><span id="__span-0-154">    <span class="k">return</span> <span class="n">DummyMetric</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_end</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-156"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_end</span><span class="p">(</span>
</span><span id="__span-0-157">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-158">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-159">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-160">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-161">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-162">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-163"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-164">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_log" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_log</span>


<a href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_log" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_log</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-166"><span class="k">def</span><span class="w"> </span><span class="nf">on_log</span><span class="p">(</span>
</span><span id="__span-0-167">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-168">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-169">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-170">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-171">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-172">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-173"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-174">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.callbacks.EvaluationCallback" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">EvaluationCallback</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">EvaluationCallback</span><span class="p">(</span><span class="n">evaluator</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainingCallback&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.callbacks.TorchTrainingCallback&lt;/code&gt;)" href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback">TorchTrainingCallback</a></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>]</code></p>



        <p>Callback for computing metrics using a custom evaluator.</p>
<p>This callback integrates a custom evaluator into the training loop,
resetting it before each evaluation phase and returning it for
metric accumulation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>evaluator</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Evaluator implementing the <code>IEvaluator</code> protocol.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.IEvaluator">IEvaluator</span>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.ml.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">MulticlassAccuracy</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">MulticlassAccuracy</span><span class="p">()</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">callback</span> <span class="o">=</span> <span class="n">EvaluationCallback</span><span class="p">(</span><span class="n">evaluator</span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-196"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evaluator</span><span class="p">:</span> <span class="n">IEvaluator</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-197">    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span> <span class="o">=</span> <span class="n">evaluator</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_start</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-199"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_start</span><span class="p">(</span>  <span class="c1"># pyright: ignore[reportIncompatibleMethodOverride]</span>
</span><span id="__span-0-200">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-201">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-202">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-203">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-204"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">IEvaluator</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">]:</span>
</span><span id="__span-0-205">    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="__span-0-206">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_start</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-85"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_start</span><span class="p">(</span>
</span><span id="__span-0-86">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-87">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-88">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-89">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-90"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-91">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_end</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span>
<span class="normal">99</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-93"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_end</span><span class="p">(</span>
</span><span id="__span-0-94">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-95">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-96">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-97">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-98"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainState</span><span class="p">:</span>
</span><span id="__span-0-99">    <span class="k">return</span> <span class="n">state</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_start</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-101"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_start</span><span class="p">(</span>
</span><span id="__span-0-102">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-103">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-104">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-105">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-106">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-107"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-108">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_end</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-110"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span>
</span><span id="__span-0-111">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-112">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-113">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-114">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-115">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-116"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-117">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_start</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-119"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_start</span><span class="p">(</span>
</span><span id="__span-0-120">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-123">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-124">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-125"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-126">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_end</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-128"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_end</span><span class="p">(</span>
</span><span id="__span-0-129">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-130">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-131">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-132">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-133">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-134">    <span class="n">output</span><span class="p">:</span> <span class="n">ModelOutputT</span><span class="p">,</span>
</span><span id="__span-0-135"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-136">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_end</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-156"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_end</span><span class="p">(</span>
</span><span id="__span-0-157">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-158">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-159">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-160">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-161">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-162">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-163"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-164">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EvaluationCallback.on_log" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_log</span>


<a href="#formed.integrations.torch.training.callbacks.EvaluationCallback.on_log" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_log</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-166"><span class="k">def</span><span class="w"> </span><span class="nf">on_log</span><span class="p">(</span>
</span><span id="__span-0-167">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-168">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-169">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-170">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-171">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-172">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-173"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-174">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">EarlyStoppingCallback</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">EarlyStoppingCallback</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;-train/loss&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainingCallback&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.callbacks.TorchTrainingCallback&lt;/code&gt;)" href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback">TorchTrainingCallback</a></code></p>



        <p>Callback for early stopping based on metric improvements.</p>
<p>This callback monitors a specified metric and stops training if it
doesn't improve for a given number of evaluations (patience). The
best model is automatically saved and restored at the end of training.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>patience</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of evaluations without improvement before stopping.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>5</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Metric to monitor. Prefix with <code>-</code> to maximize (e.g., <code>"-loss"</code>),
or <code>+</code> to minimize (e.g., <code>"+error"</code>). Default is <code>"-loss"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;-train/loss&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Stop if validation loss doesn&#39;t improve for 5 evaluations</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">callback</span> <span class="o">=</span> <span class="n">EarlyStoppingCallback</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;-val/loss&quot;</span><span class="p">)</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Stop if accuracy doesn&#39;t improve for 3 evaluations</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">callback</span> <span class="o">=</span> <span class="n">EarlyStoppingCallback</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;+accuracy&quot;</span><span class="p">)</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>The best model is saved to the step working directory and
automatically restored when training ends early or completes.</p>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-235"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-236">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-237">    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
</span><span id="__span-0-238">    <span class="n">metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;-train/loss&quot;</span><span class="p">,</span>
</span><span id="__span-0-239"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-240">    <span class="bp">self</span><span class="o">.</span><span class="n">_patience</span> <span class="o">=</span> <span class="n">patience</span>
</span><span id="__span-0-241">    <span class="bp">self</span><span class="o">.</span><span class="n">_metric</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s2">&quot;-+&quot;</span><span class="p">)</span>
</span><span id="__span-0-242">    <span class="bp">self</span><span class="o">.</span><span class="n">_direction</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">metric</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
</span><span id="__span-0-243">    <span class="bp">self</span><span class="o">.</span><span class="n">_best_metric</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
</span><span id="__span-0-244">    <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span> <span class="o">=</span> <span class="mi">0</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_start</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-254"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_start</span><span class="p">(</span>
</span><span id="__span-0-255">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-256">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-257">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-258">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-259"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-260">    <span class="bp">self</span><span class="o">.</span><span class="n">_best_metric</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
</span><span id="__span-0-261">    <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span> <span class="o">=</span> <span class="mi">0</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_end</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-263"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_end</span><span class="p">(</span>
</span><span id="__span-0-264">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-265">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-266">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-267">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-268">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-269">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-270"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-271">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-272">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
</span><span id="__span-0-273">
</span><span id="__span-0-274">    <span class="n">logger</span> <span class="o">=</span> <span class="n">use_step_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="__span-0-275">
</span><span id="__span-0-276">    <span class="c1"># For DDP: only rank 0 makes the early stopping decision</span>
</span><span id="__span-0-277">    <span class="n">should_stop</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-278">
</span><span id="__span-0-279">    <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
</span><span id="__span-0-280">        <span class="k">if</span> <span class="n">prefix</span><span class="p">:</span>
</span><span id="__span-0-281">            <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="__span-0-282">        <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-283">            <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_direction</span> <span class="o">*</span> <span class="n">metrics</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_metric</span><span class="p">]</span>
</span><span id="__span-0-284">        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
</span><span id="__span-0-285">            <span class="k">return</span>
</span><span id="__span-0-286">        <span class="k">if</span> <span class="n">metric</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_best_metric</span><span class="p">:</span>
</span><span id="__span-0-287">            <span class="bp">self</span><span class="o">.</span><span class="n">_best_metric</span> <span class="o">=</span> <span class="n">metric</span>
</span><span id="__span-0-288">            <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-289">            <span class="c1"># Save state_dict for serialization efficiency</span>
</span><span id="__span-0-290">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_checkpoint_path</span><span class="p">())</span>
</span><span id="__span-0-291">            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New best model saved with </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_metric</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_best_metric</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-292">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-293">            <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="__span-0-294">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_patience</span><span class="p">:</span>
</span><span id="__span-0-295">                <span class="n">should_stop</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-0-296">
</span><span id="__span-0-297">    <span class="c1"># For DDP: broadcast the early stopping decision from rank 0 to all processes</span>
</span><span id="__span-0-298">    <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="__span-0-299">        <span class="c1"># Create a tensor for broadcasting</span>
</span><span id="__span-0-300">        <span class="c1"># Get device from model&#39;s first parameter</span>
</span><span id="__span-0-301">        <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="__span-0-302">        <span class="n">should_stop_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">should_stop</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-303">        <span class="n">dist</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">should_stop_tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-304">        <span class="n">should_stop</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">should_stop_tensor</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span id="__span-0-305">
</span><span id="__span-0-306">    <span class="c1"># Synchronize all processes before potentially raising StopEarly</span>
</span><span id="__span-0-307">    <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
</span><span id="__span-0-308">
</span><span id="__span-0-309">    <span class="k">if</span> <span class="n">should_stop</span><span class="p">:</span>
</span><span id="__span-0-310">        <span class="k">raise</span> <span class="n">StopEarly</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_end</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-312"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_end</span><span class="p">(</span>
</span><span id="__span-0-313">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-314">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-315">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-316">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-317"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainState</span><span class="p">:</span>
</span><span id="__span-0-318">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-0-319">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
</span><span id="__span-0-320">
</span><span id="__span-0-321">    <span class="n">logger</span> <span class="o">=</span> <span class="n">use_step_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="__span-0-322">
</span><span id="__span-0-323">    <span class="c1"># Synchronize before loading best model</span>
</span><span id="__span-0-324">    <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
</span><span id="__span-0-325">
</span><span id="__span-0-326">    <span class="c1"># Load best model if it exists</span>
</span><span id="__span-0-327">    <span class="k">if</span> <span class="p">(</span><span class="n">checkpoint_path</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_checkpoint_path</span><span class="p">())</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="__span-0-328">        <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
</span><span id="__span-0-329">            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading best state from early stopping checkpoint.&quot;</span><span class="p">)</span>
</span><span id="__span-0-330">            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="__span-0-331">            <span class="n">state</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span><span id="__span-0-332">
</span><span id="__span-0-333">        <span class="c1"># For DDP: broadcast the model state from rank 0 to all other processes</span>
</span><span id="__span-0-334">        <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span><span id="__span-0-335">            <span class="c1"># Broadcast model parameters</span>
</span><span id="__span-0-336">            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span><span id="__span-0-337">                <span class="n">dist</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-338">            <span class="c1"># Broadcast optimizer state</span>
</span><span id="__span-0-339">            <span class="c1"># Note: optimizer state broadcasting is complex, so we skip it for now</span>
</span><span id="__span-0-340">            <span class="c1"># Users can re-initialize optimizer if needed after loading best model</span>
</span><span id="__span-0-341">            <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
</span><span id="__span-0-342">                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Broadcasted best model to all processes.&quot;</span><span class="p">)</span>
</span><span id="__span-0-343">
</span><span id="__span-0-344">    <span class="c1"># Synchronize after loading so all processes have the best model</span>
</span><span id="__span-0-345">    <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
</span><span id="__span-0-346">    <span class="k">return</span> <span class="n">state</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_start</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-101"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_start</span><span class="p">(</span>
</span><span id="__span-0-102">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-103">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-104">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-105">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-106">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-107"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-108">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_end</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-110"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span>
</span><span id="__span-0-111">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-112">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-113">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-114">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-115">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-116"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-117">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_start</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-119"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_start</span><span class="p">(</span>
</span><span id="__span-0-120">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-123">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-124">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-125"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-126">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_end</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-128"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_end</span><span class="p">(</span>
</span><span id="__span-0-129">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-130">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-131">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-132">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-133">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-134">    <span class="n">output</span><span class="p">:</span> <span class="n">ModelOutputT</span><span class="p">,</span>
</span><span id="__span-0-135"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-136">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_start</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-138"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_start</span><span class="p">(</span>
</span><span id="__span-0-139">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-140">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-141">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-142">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-143"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">IEvaluator</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">]:</span>
</span><span id="__span-0-144">    <span class="k">class</span><span class="w"> </span><span class="nc">DummyMetric</span><span class="p">(</span><span class="n">IEvaluator</span><span class="p">):</span>
</span><span id="__span-0-145">        <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="o">/</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-146">            <span class="k">pass</span>
</span><span id="__span-0-147">
</span><span id="__span-0-148">        <span class="k">def</span><span class="w"> </span><span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-149">            <span class="k">return</span> <span class="p">{}</span>
</span><span id="__span-0-150">
</span><span id="__span-0-151">        <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-152">            <span class="k">pass</span>
</span><span id="__span-0-153">
</span><span id="__span-0-154">    <span class="k">return</span> <span class="n">DummyMetric</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_log" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_log</span>


<a href="#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_log" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_log</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-166"><span class="k">def</span><span class="w"> </span><span class="nf">on_log</span><span class="p">(</span>
</span><span id="__span-0-167">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-168">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-169">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-170">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-171">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-172">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-173"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-174">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.callbacks.MlflowCallback" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">MlflowCallback</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">MlflowCallback</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainingCallback&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.callbacks.TorchTrainingCallback&lt;/code&gt;)" href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback">TorchTrainingCallback</a></code></p>



        <p>Callback for logging metrics to MLflow.</p>
<p>This callback automatically logs training and validation metrics to
MLflow when used within a workflow step that has MLflow tracking enabled.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchTrainer</span><span class="p">,</span> <span class="n">MlflowCallback</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">val_dataloader</span><span class="o">=</span><span class="n">val_loader</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">MlflowCallback</span><span class="p">()]</span>
</span><span id="__span-0-7"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>Requires the formed mlflow integration and must be used within
a workflow step with MLflow tracking configured.</p>
</details>







                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-371"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-372">    <span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.mlflow.workflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">MlflowLogger</span>
</span><span id="__span-0-373">
</span><span id="__span-0-374">    <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MlflowLogger</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_training_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_start</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-376"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_start</span><span class="p">(</span>
</span><span id="__span-0-377">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-378">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-379">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-380">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-381"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-382">    <span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.mlflow.workflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">use_mlflow_logger</span>
</span><span id="__span-0-383">    <span class="kn">from</span><span class="w"> </span><span class="nn">formed.workflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">use_step_logger</span>
</span><span id="__span-0-384">
</span><span id="__span-0-385">    <span class="c1"># Only main process logs to MLflow</span>
</span><span id="__span-0-386">    <span class="k">if</span> <span class="ow">not</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
</span><span id="__span-0-387">        <span class="k">return</span>
</span><span id="__span-0-388">
</span><span id="__span-0-389">    <span class="n">logger</span> <span class="o">=</span> <span class="n">use_step_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="__span-0-390">
</span><span id="__span-0-391">    <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span> <span class="o">=</span> <span class="n">use_mlflow_logger</span><span class="p">()</span>
</span><span id="__span-0-392">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-393">        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;MlflowLogger not found. Skipping logging.&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_log" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_log</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_log" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_log</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-395"><span class="k">def</span><span class="w"> </span><span class="nf">on_log</span><span class="p">(</span>
</span><span id="__span-0-396">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-397">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-398">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-399">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-400">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-401">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-402"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-403">    <span class="c1"># Only main process logs to MLflow</span>
</span><span id="__span-0-404">    <span class="k">if</span> <span class="ow">not</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
</span><span id="__span-0-405">        <span class="k">return</span>
</span><span id="__span-0-406">
</span><span id="__span-0-407">    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="__span-0-408">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-409">        <span class="c1"># Log all metrics</span>
</span><span id="__span-0-410">        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="__span-0-411">            <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">))</span>
</span><span id="__span-0-412">
</span><span id="__span-0-413">        <span class="c1"># Log learning rate</span>
</span><span id="__span-0-414">        <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get_learning_rate</span><span class="p">()</span>
</span><span id="__span-0-415">        <span class="k">if</span> <span class="n">learning_rate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-416">            <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">))</span>
</span><span id="__span-0-417">
</span><span id="__span-0-418">        <span class="c1"># Log gradient norm</span>
</span><span id="__span-0-419">        <span class="n">gradient_norm</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get_gradient_norm</span><span class="p">()</span>
</span><span id="__span-0-420">        <span class="k">if</span> <span class="n">gradient_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-421">            <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;gradient_norm&quot;</span><span class="p">,</span> <span class="n">gradient_norm</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">))</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_end</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-423"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_end</span><span class="p">(</span>
</span><span id="__span-0-424">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-425">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-426">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-427">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-428">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-429"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-430">    <span class="c1"># Only main process logs to MLflow</span>
</span><span id="__span-0-431">    <span class="k">if</span> <span class="ow">not</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distributor</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
</span><span id="__span-0-432">        <span class="k">return</span>
</span><span id="__span-0-433">
</span><span id="__span-0-434">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-435">        <span class="bp">self</span><span class="o">.</span><span class="n">_mlflow_logger</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">step</span><span class="p">))</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_training_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_training_end</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_training_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span>
<span class="normal">99</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-93"><span class="k">def</span><span class="w"> </span><span class="nf">on_training_end</span><span class="p">(</span>
</span><span id="__span-0-94">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-95">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-96">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-97">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-98"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainState</span><span class="p">:</span>
</span><span id="__span-0-99">    <span class="k">return</span> <span class="n">state</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_epoch_start</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_epoch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-101"><span class="k">def</span><span class="w"> </span><span class="nf">on_epoch_start</span><span class="p">(</span>
</span><span id="__span-0-102">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-103">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-104">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-105">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-106">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-107"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-108">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_start</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-119"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_start</span><span class="p">(</span>
</span><span id="__span-0-120">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-123">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-124">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-125"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-126">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_batch_end</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_batch_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-128"><span class="k">def</span><span class="w"> </span><span class="nf">on_batch_end</span><span class="p">(</span>
</span><span id="__span-0-129">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-130">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-131">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-132">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-133">    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-0-134">    <span class="n">output</span><span class="p">:</span> <span class="n">ModelOutputT</span><span class="p">,</span>
</span><span id="__span-0-135"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-136">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_start" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_start</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_start" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_start</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-138"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_start</span><span class="p">(</span>
</span><span id="__span-0-139">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-140">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-141">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-142">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-143"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">IEvaluator</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">]:</span>
</span><span id="__span-0-144">    <span class="k">class</span><span class="w"> </span><span class="nc">DummyMetric</span><span class="p">(</span><span class="n">IEvaluator</span><span class="p">):</span>
</span><span id="__span-0-145">        <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="o">/</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-146">            <span class="k">pass</span>
</span><span id="__span-0-147">
</span><span id="__span-0-148">        <span class="k">def</span><span class="w"> </span><span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-149">            <span class="k">return</span> <span class="p">{}</span>
</span><span id="__span-0-150">
</span><span id="__span-0-151">        <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-152">            <span class="k">pass</span>
</span><span id="__span-0-153">
</span><span id="__span-0-154">    <span class="k">return</span> <span class="n">DummyMetric</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_end" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">on_eval_end</span>


<a href="#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_end" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">on_eval_end</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-156"><span class="k">def</span><span class="w"> </span><span class="nf">on_eval_end</span><span class="p">(</span>
</span><span id="__span-0-157">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-158">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-159">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-160">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-161">    <span class="n">metrics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
</span><span id="__span-0-162">    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span id="__span-0-163"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-164">    <span class="k">pass</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.training.engine" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.training.engine</span>


<a href="#formed.integrations.torch.training.engine" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Training engine abstractions for PyTorch models.</p>
<p>This module provides the training engine abstraction that defines how
models are trained and evaluated. Engines handle loss computation,
gradient calculation, and parameter updates.</p>


<details class="key-components" open>
  <summary>Key Components</summary>
  <ul>
<li><code>TorchTrainingEngine</code>: Abstract base class for training engines</li>
<li><code>DefaultTorchTrainingEngine</code>: Default implementation with automatic differentiation</li>
</ul>
</details>

<details class="features" open>
  <summary>Features</summary>
  <ul>
<li>Customizable loss functions</li>
<li>Automatic gradient computation using PyTorch autograd</li>
<li>State creation and management</li>
<li>Separate train and eval steps</li>
<li>Compatible with TorchTrainer and distributors</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">DefaultTorchTrainingEngine</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create engine with custom loss accessor</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="n">engine</span> <span class="o">=</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;total_loss&quot;</span><span class="p">)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Or with custom loss function</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">custom_loss</span><span class="p">(</span><span class="n">output</span><span class="p">):</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">loss</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">output</span><span class="o">.</span><span class="n">regularization</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt; </span><span class="n">engine</span> <span class="o">=</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">custom_loss</span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.engine.TorchTrainingEngine" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TorchTrainingEngine</span>


<a href="#formed.integrations.torch.training.engine.TorchTrainingEngine" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code>, <code><span title="colt.Registrable">Registrable</span></code>, <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code></p>



        <p>Abstract base class for PyTorch training engines.</p>
<p>A training engine defines how models are trained by implementing
state creation, training steps, and evaluation steps. This allows
for custom training loops and loss computations.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>ModelInputT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of model input.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ModelOutputT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of model output.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ModelParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional parameters.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>











<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.engine.TorchTrainingEngine.create_state" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">create_state</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.create_state" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">create_state</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Create initial training state from model and trainer.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>trainer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Trainer instance.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.trainer.TorchTrainer&lt;/code&gt;)" href="#formed.integrations.torch.training.trainer.TorchTrainer">TorchTrainer</a>[<span title="typing.Any">Any</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model to train.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTorchModel&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.model.BaseTorchModel&lt;/code&gt;)" href="#formed.integrations.torch.model.BaseTorchModel">BaseTorchModel</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TrainState&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState">TrainState</a></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Initial training state.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-75"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-76"><span class="k">def</span><span class="w"> </span><span class="nf">create_state</span><span class="p">(</span>
</span><span id="__span-0-77">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-78">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-79">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-80"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainState</span><span class="p">:</span>
</span><span id="__span-0-81"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Create initial training state from model and trainer.</span>
</span><span id="__span-0-82">
</span><span id="__span-0-83"><span class="sd">    Args:</span>
</span><span id="__span-0-84"><span class="sd">        trainer: Trainer instance.</span>
</span><span id="__span-0-85"><span class="sd">        model: Model to train.</span>
</span><span id="__span-0-86">
</span><span id="__span-0-87"><span class="sd">    Returns:</span>
</span><span id="__span-0-88"><span class="sd">        Initial training state.</span>
</span><span id="__span-0-89">
</span><span id="__span-0-90"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-91">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.engine.TorchTrainingEngine.train_step" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">train_step</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.train_step" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Execute a single training step.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch of training inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>state</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Current training state (model and optimizer are updated in-place).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TrainState&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState">TrainState</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trainer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Trainer instance.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.trainer.TorchTrainer&lt;/code&gt;)" href="#formed.integrations.torch.training.trainer.TorchTrainer">TorchTrainer</a>[<span title="typing.Any">Any</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Model output.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>This method updates the state in-place for efficiency.
The step counter is incremented automatically.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-93"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-94"><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span>
</span><span id="__span-0-95">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-96">    <span class="n">inputs</span><span class="p">:</span> <span class="n">ModelInputT</span><span class="p">,</span>
</span><span id="__span-0-97">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-98">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-99"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOutputT</span><span class="p">:</span>
</span><span id="__span-0-100"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute a single training step.</span>
</span><span id="__span-0-101">
</span><span id="__span-0-102"><span class="sd">    Args:</span>
</span><span id="__span-0-103"><span class="sd">        inputs: Batch of training inputs.</span>
</span><span id="__span-0-104"><span class="sd">        state: Current training state (model and optimizer are updated in-place).</span>
</span><span id="__span-0-105"><span class="sd">        trainer: Trainer instance.</span>
</span><span id="__span-0-106">
</span><span id="__span-0-107"><span class="sd">    Returns:</span>
</span><span id="__span-0-108"><span class="sd">        Model output.</span>
</span><span id="__span-0-109">
</span><span id="__span-0-110"><span class="sd">    Note:</span>
</span><span id="__span-0-111"><span class="sd">        This method updates the state in-place for efficiency.</span>
</span><span id="__span-0-112"><span class="sd">        The step counter is incremented automatically.</span>
</span><span id="__span-0-113">
</span><span id="__span-0-114"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-115">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.engine.TorchTrainingEngine.eval_step" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">eval_step</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#formed.integrations.torch.training.engine.TorchTrainingEngine.eval_step" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">eval_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Execute a single evaluation step.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch of evaluation inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>state</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Current training state.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TrainState&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState">TrainState</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trainer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Trainer instance.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.trainer.TorchTrainer&lt;/code&gt;)" href="#formed.integrations.torch.training.trainer.TorchTrainer">TorchTrainer</a>[<span title="typing.Any">Any</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Model output.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-117"><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="__span-0-118"><span class="k">def</span><span class="w"> </span><span class="nf">eval_step</span><span class="p">(</span>
</span><span id="__span-0-119">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-120">    <span class="n">inputs</span><span class="p">:</span> <span class="n">ModelInputT</span><span class="p">,</span>
</span><span id="__span-0-121">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-122">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-123"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOutputT</span><span class="p">:</span>
</span><span id="__span-0-124"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Execute a single evaluation step.</span>
</span><span id="__span-0-125">
</span><span id="__span-0-126"><span class="sd">    Args:</span>
</span><span id="__span-0-127"><span class="sd">        inputs: Batch of evaluation inputs.</span>
</span><span id="__span-0-128"><span class="sd">        state: Current training state.</span>
</span><span id="__span-0-129"><span class="sd">        trainer: Trainer instance.</span>
</span><span id="__span-0-130">
</span><span id="__span-0-131"><span class="sd">    Returns:</span>
</span><span id="__span-0-132"><span class="sd">        Model output.</span>
</span><span id="__span-0-133">
</span><span id="__span-0-134"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-135">    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.engine.DefaultTorchTrainingEngine" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">DefaultTorchTrainingEngine</span>


<a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">DefaultTorchTrainingEngine</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">max_grad_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9">    <span class="n">grad_scaler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainingEngine&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.engine.TorchTrainingEngine&lt;/code&gt;)" href="#formed.integrations.torch.training.engine.TorchTrainingEngine">TorchTrainingEngine</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code></p>



        <p>Default training engine using automatic differentiation.</p>
<p>This engine computes gradients using PyTorch's autograd
and updates parameters using the provided optimizer. Loss is extracted
from model output either by attribute name or custom function.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>optimizer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optimizer factory or instance. Can be a Lazy object, callable
that takes model parameters, or an optimizer instance.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.types.OptimizerFactory">OptimizerFactory</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lr_scheduler</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional learning rate scheduler factory or instance.
Can be a Lazy object, callable that takes optimizer, a sequence of
schedulers (will be chained), or a scheduler instance.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[<span title="formed.integrations.torch.types.LRSchedulerFactory">LRSchedulerFactory</span>, <span title="collections.abc.Sequence">Sequence</span>[<span title="formed.integrations.torch.types.LRSchedulerFactory">LRSchedulerFactory</span>], None]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>loss</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Loss accessor - either attribute name (e.g., <code>"loss"</code>) or
callable that extracts loss from model output.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="collections.abc.Callable">Callable</span>[[<span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>], <span title="torch.Tensor">Tensor</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;loss&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gradient_accumulation_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of steps to accumulate gradients
before performing an optimizer step.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_grad_norm</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum gradient norm for clipping. If <code>None</code>, no clipping is applied.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional additional parameters to pass to the model during training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Data type for mixed precision training (<code>"float32"</code>, <code>"float16"</code>, <code>"bfloat16"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Literal">Literal</span>[&#39;float32&#39;, &#39;float16&#39;, &#39;bfloat16&#39;] | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>grad_scaler</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Gradient scaler for mixed precision training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="colt.Lazy">Lazy</span>[<span title="torch.amp.grad_scaler.GradScaler">GradScaler</span> | <span title="formed.integrations.torch.types.IGradScaler">IGradScaler</span>] | <span title="formed.integrations.torch.types.IGradScaler">IGradScaler</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Basic usage with optimizer</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">engine</span> <span class="o">=</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">(</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span>
</span><span id="__span-0-5"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With learning rate scheduler and gradient clipping</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="n">engine</span> <span class="o">=</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">(</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">optimizer</span><span class="o">=</span><span class="n">Lazy</span><span class="p">(</span><span class="bp">cls</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">}),</span>
</span><span id="__span-0-10"><span class="gp">... </span>    <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">Lazy</span><span class="p">(</span><span class="bp">cls</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;T_max&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">}),</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">loss</span><span class="o">=</span><span class="k">lambda</span> <span class="n">output</span><span class="p">:</span> <span class="n">output</span><span class="o">.</span><span class="n">loss</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">output</span><span class="o">.</span><span class="n">regularization</span>
</span><span id="__span-0-13"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-14"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-15"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With mixed precision training</span>
</span><span id="__span-0-16"><span class="gp">&gt;&gt;&gt; </span><span class="n">engine</span> <span class="o">=</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">(</span>
</span><span id="__span-0-17"><span class="gp">... </span>    <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">,</span>
</span><span id="__span-0-18"><span class="gp">... </span>    <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;bfloat16&quot;</span><span class="p">,</span>
</span><span id="__span-0-19"><span class="gp">... </span>    <span class="n">grad_scaler</span><span class="o">=</span><span class="n">Lazy</span><span class="p">(</span><span class="bp">cls</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">),</span>
</span><span id="__span-0-20"><span class="gp">... </span>    <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">1.0</span>
</span><span id="__span-0-21"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-196"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-197">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-198">    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">OptimizerFactory</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-199">    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">LRSchedulerFactory</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">LRSchedulerFactory</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-200">    <span class="n">loss</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">ModelOutputT</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;loss&quot;</span><span class="p">,</span>
</span><span id="__span-0-201">    <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-202">    <span class="n">max_grad_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-203">    <span class="n">params</span><span class="p">:</span> <span class="n">ModelParamsT</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-204">    <span class="n">dtype</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="s2">&quot;float16&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-205">    <span class="n">grad_scaler</span><span class="p">:</span> <span class="n">Lazy</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">grad_scaler</span><span class="o">.</span><span class="n">GradScaler</span> <span class="o">|</span> <span class="n">IGradScaler</span><span class="p">]</span> <span class="o">|</span> <span class="n">IGradScaler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-206"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-207">    <span class="k">assert</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="s2">&quot;float16&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">),</span> <span class="p">(</span>
</span><span id="__span-0-208">        <span class="s2">&quot;dtype must be one of None, &#39;float32&#39;, &#39;float16&#39;, or &#39;bfloat16&#39;&quot;</span>
</span><span id="__span-0-209">    <span class="p">)</span>
</span><span id="__span-0-210">
</span><span id="__span-0-211">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-0-212">    <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_factory</span> <span class="o">=</span> <span class="n">optimizer</span> <span class="ow">or</span> <span class="n">get_default_optimizer_factory</span><span class="p">()</span>
</span><span id="__span-0-213">    <span class="bp">self</span><span class="o">.</span><span class="n">_lr_scheduler_factory</span> <span class="o">=</span> <span class="n">lr_scheduler</span> <span class="ow">or</span> <span class="n">get_default_lr_scheduler_factory</span><span class="p">()</span>
</span><span id="__span-0-214">    <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">xgetattr</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">loss</span>
</span><span id="__span-0-215">    <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_accumulation_steps</span> <span class="o">=</span> <span class="n">gradient_accumulation_steps</span>
</span><span id="__span-0-216">    <span class="bp">self</span><span class="o">.</span><span class="n">_max_grad_norm</span> <span class="o">=</span> <span class="n">max_grad_norm</span>
</span><span id="__span-0-217">    <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">params</span>
</span><span id="__span-0-218">    <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span> <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="__span-0-219">    <span class="bp">self</span><span class="o">.</span><span class="n">_grad_scaler</span> <span class="o">=</span> <span class="n">grad_scaler</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.create_state" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">create_state</span>


<a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.create_state" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">create_state</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-221"><span class="k">def</span><span class="w"> </span><span class="nf">create_state</span><span class="p">(</span>
</span><span id="__span-0-222">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-223">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-224">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-225"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainState</span><span class="p">:</span>
</span><span id="__span-0-226">    <span class="c1"># Construct optimizer</span>
</span><span id="__span-0-227">    <span class="n">optimizer</span><span class="p">:</span> <span class="n">IOptimizer</span>
</span><span id="__span-0-228">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_factory</span><span class="p">,</span> <span class="n">Lazy</span><span class="p">):</span>
</span><span id="__span-0-229">        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_factory</span><span class="o">.</span><span class="n">construct</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</span><span id="__span-0-230">    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_factory</span><span class="p">):</span>
</span><span id="__span-0-231">        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_factory</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</span><span id="__span-0-232">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-233">        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_factory</span>
</span><span id="__span-0-234">
</span><span id="__span-0-235">    <span class="c1"># Construct lr_scheduler</span>
</span><span id="__span-0-236">    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">ILRScheduler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-237">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lr_scheduler_factory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-238">
</span><span id="__span-0-239">        <span class="k">def</span><span class="w"> </span><span class="nf">_construct_lr_scheduler</span><span class="p">(</span><span class="n">factory</span><span class="p">:</span> <span class="n">LRSchedulerFactory</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ILRScheduler</span><span class="p">:</span>
</span><span id="__span-0-240">            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">factory</span><span class="p">,</span> <span class="n">Lazy</span><span class="p">):</span>
</span><span id="__span-0-241">                <span class="k">return</span> <span class="n">factory</span><span class="o">.</span><span class="n">construct</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
</span><span id="__span-0-242">            <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">factory</span><span class="p">):</span>
</span><span id="__span-0-243">                <span class="k">return</span> <span class="n">factory</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
</span><span id="__span-0-244">            <span class="k">return</span> <span class="n">factory</span>
</span><span id="__span-0-245">
</span><span id="__span-0-246">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lr_scheduler_factory</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
</span><span id="__span-0-247">            <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ChainedScheduler</span><span class="p">(</span>
</span><span id="__span-0-248">                <span class="p">[</span>
</span><span id="__span-0-249">                    <span class="n">cast</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LRScheduler</span><span class="p">,</span> <span class="n">_construct_lr_scheduler</span><span class="p">(</span><span class="n">scheduler</span><span class="p">))</span>
</span><span id="__span-0-250">                    <span class="k">for</span> <span class="n">scheduler</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lr_scheduler_factory</span>
</span><span id="__span-0-251">                <span class="p">],</span>
</span><span id="__span-0-252">                <span class="n">optimizer</span><span class="o">=</span><span class="n">cast</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">),</span>
</span><span id="__span-0-253">            <span class="p">)</span>
</span><span id="__span-0-254">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-255">            <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">_construct_lr_scheduler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lr_scheduler_factory</span><span class="p">)</span>
</span><span id="__span-0-256">
</span><span id="__span-0-257">    <span class="c1"># Initialize grad_scaler only if requested and on appropriate device</span>
</span><span id="__span-0-258">    <span class="n">grad_scaler</span><span class="p">:</span> <span class="n">IGradScaler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-0-259">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_grad_scaler</span><span class="p">,</span> <span class="n">IGradScaler</span><span class="p">):</span>
</span><span id="__span-0-260">        <span class="n">grad_scaler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_grad_scaler</span>
</span><span id="__span-0-261">    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_grad_scaler</span><span class="p">,</span> <span class="n">Lazy</span><span class="p">):</span>
</span><span id="__span-0-262">        <span class="k">if</span> <span class="n">device</span> <span class="o">:=</span> <span class="n">get_device</span><span class="p">():</span>
</span><span id="__span-0-263">            <span class="n">grad_scaler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_grad_scaler</span><span class="o">.</span><span class="n">construct</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
</span><span id="__span-0-264">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-265">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;GradScaler requested but device is not set. GradScaler will not be used.&quot;</span><span class="p">)</span>
</span><span id="__span-0-266">
</span><span id="__span-0-267">    <span class="k">return</span> <span class="n">TrainState</span><span class="p">(</span>
</span><span id="__span-0-268">        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-269">        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
</span><span id="__span-0-270">        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
</span><span id="__span-0-271">        <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-272">        <span class="n">grad_scaler</span><span class="o">=</span><span class="n">grad_scaler</span><span class="p">,</span>
</span><span id="__span-0-273">    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.train_step" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">train_step</span>


<a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.train_step" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-275"><span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span>
</span><span id="__span-0-276">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-277">    <span class="n">inputs</span><span class="p">:</span> <span class="n">ModelInputT</span><span class="p">,</span>
</span><span id="__span-0-278">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-279">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-280"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOutputT</span><span class="p">:</span>
</span><span id="__span-0-281">    <span class="k">del</span> <span class="n">trainer</span>
</span><span id="__span-0-282">
</span><span id="__span-0-283">    <span class="c1"># Set model to training mode</span>
</span><span id="__span-0-284">    <span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span><span id="__span-0-285">
</span><span id="__span-0-286">    <span class="c1"># Zero gradients at the start of accumulation cycle</span>
</span><span id="__span-0-287">    <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-288">        <span class="n">state</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="__span-0-289">
</span><span id="__span-0-290">    <span class="k">with</span> <span class="n">ExitStack</span><span class="p">()</span> <span class="k">as</span> <span class="n">stack</span><span class="p">:</span>
</span><span id="__span-0-291">        <span class="k">if</span> <span class="p">(</span><span class="n">device</span> <span class="o">:=</span> <span class="n">get_device</span><span class="p">())</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-292">            <span class="n">stack</span><span class="o">.</span><span class="n">enter_context</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">))</span>
</span><span id="__span-0-293">
</span><span id="__span-0-294">        <span class="n">output</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">)</span>
</span><span id="__span-0-295">
</span><span id="__span-0-296">        <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-297">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span><span id="__span-0-298">        <span class="k">except</span> <span class="p">(</span><span class="ne">KeyError</span><span class="p">,</span> <span class="ne">AttributeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="__span-0-299">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-300">                <span class="sa">f</span><span class="s2">&quot;Failed to extract loss from model output. &quot;</span>
</span><span id="__span-0-301">                <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. &quot;</span>
</span><span id="__span-0-302">                <span class="sa">f</span><span class="s2">&quot;Output type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. &quot;</span>
</span><span id="__span-0-303">                <span class="s2">&quot;Please ensure your model&#39;s forward() method returns output with a &#39;loss&#39; attribute or key.&quot;</span>
</span><span id="__span-0-304">            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="__span-0-305">
</span><span id="__span-0-306">    <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-307">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-308">            <span class="s2">&quot;Model output loss is None. &quot;</span>
</span><span id="__span-0-309">            <span class="s2">&quot;This typically happens when labels are not provided during training. &quot;</span>
</span><span id="__span-0-310">            <span class="s2">&quot;Please ensure your training data includes labels.&quot;</span>
</span><span id="__span-0-311">        <span class="p">)</span>
</span><span id="__span-0-312">
</span><span id="__span-0-313">    <span class="c1"># Scale loss for gradient accumulation</span>
</span><span id="__span-0-314">    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_accumulation_steps</span>
</span><span id="__span-0-315">
</span><span id="__span-0-316">    <span class="c1"># Backward pass with or without gradient scaling</span>
</span><span id="__span-0-317">    <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">grad_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-318">        <span class="n">state</span><span class="o">.</span><span class="n">grad_scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="__span-0-319">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-320">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="__span-0-321">
</span><span id="__span-0-322">    <span class="c1"># Update optimizer and scheduler when accumulation is complete</span>
</span><span id="__span-0-323">    <span class="k">if</span> <span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-324">        <span class="c1"># Clip gradients if max_grad_norm is specified</span>
</span><span id="__span-0-325">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_grad_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-326">            <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">grad_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-327">                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
</span><span id="__span-0-328">                    <span class="c1"># Unscale gradients before clipping when using grad_scaler</span>
</span><span id="__span-0-329">                    <span class="n">state</span><span class="o">.</span><span class="n">grad_scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
</span><span id="__span-0-330">                <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-331">                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span id="__span-0-332">                        <span class="s2">&quot;Cannot unscale gradients for gradient clipping because &quot;</span>
</span><span id="__span-0-333">                        <span class="s2">&quot;the optimizer is not a torch.optim.Optimizer instance.&quot;</span>
</span><span id="__span-0-334">                    <span class="p">)</span>
</span><span id="__span-0-335">            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_grad_norm</span><span class="p">)</span>
</span><span id="__span-0-336">
</span><span id="__span-0-337">        <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">grad_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-338">            <span class="c1"># GradScaler.step expects torch.optim.Optimizer</span>
</span><span id="__span-0-339">            <span class="n">state</span><span class="o">.</span><span class="n">grad_scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">cast</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">optimizer</span><span class="p">))</span>
</span><span id="__span-0-340">            <span class="n">state</span><span class="o">.</span><span class="n">grad_scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</span><span id="__span-0-341">        <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-342">            <span class="n">state</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="__span-0-343">        <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-344">            <span class="n">state</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="__span-0-345">
</span><span id="__span-0-346">    <span class="c1"># Increment step counter (counts micro-batches)</span>
</span><span id="__span-0-347">    <span class="n">state</span><span class="o">.</span><span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="__span-0-348">
</span><span id="__span-0-349">    <span class="k">return</span> <span class="n">output</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.eval_step" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">eval_step</span>


<a href="#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.eval_step" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">eval_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-351"><span class="k">def</span><span class="w"> </span><span class="nf">eval_step</span><span class="p">(</span>
</span><span id="__span-0-352">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-353">    <span class="n">inputs</span><span class="p">:</span> <span class="n">ModelInputT</span><span class="p">,</span>
</span><span id="__span-0-354">    <span class="n">state</span><span class="p">:</span> <span class="n">TrainState</span><span class="p">,</span>
</span><span id="__span-0-355">    <span class="n">trainer</span><span class="p">:</span> <span class="s2">&quot;TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]&quot;</span><span class="p">,</span>
</span><span id="__span-0-356"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOutputT</span><span class="p">:</span>
</span><span id="__span-0-357">    <span class="k">del</span> <span class="n">trainer</span>
</span><span id="__span-0-358">
</span><span id="__span-0-359">    <span class="c1"># Set model to eval mode</span>
</span><span id="__span-0-360">    <span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="__span-0-361">
</span><span id="__span-0-362">    <span class="c1"># Standard PyTorch evaluation step</span>
</span><span id="__span-0-363">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-0-364">        <span class="n">output</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-0-365">
</span><span id="__span-0-366">    <span class="k">return</span> <span class="n">output</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.training.engine.get_default_optimizer_factory" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_default_optimizer_factory</span>


<a href="#formed.integrations.torch.training.engine.get_default_optimizer_factory" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_default_optimizer_factory</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get a default optimizer factory (Adam with lr=1e-3).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-138"><span class="k">def</span><span class="w"> </span><span class="nf">get_default_optimizer_factory</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">OptimizerFactory</span><span class="p">:</span>
</span><span id="__span-0-139"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a default optimizer factory (Adam with lr=1e-3).&quot;&quot;&quot;</span>
</span><span id="__span-0-140">    <span class="k">return</span> <span class="n">Lazy</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">},</span> <span class="bp">cls</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.training.engine.get_default_lr_scheduler_factory" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_default_lr_scheduler_factory</span>


<a href="#formed.integrations.torch.training.engine.get_default_lr_scheduler_factory" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_default_lr_scheduler_factory</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get a default learning rate scheduler factory (None).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/engine.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-143"><span class="k">def</span><span class="w"> </span><span class="nf">get_default_lr_scheduler_factory</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LRSchedulerFactory</span><span class="p">]:</span>
</span><span id="__span-0-144"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a default learning rate scheduler factory (None).&quot;&quot;&quot;</span>
</span><span id="__span-0-145">    <span class="k">return</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.training.exceptions" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.training.exceptions</span>


<a href="#formed.integrations.torch.training.exceptions" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.exceptions.StopEarly" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">StopEarly</span>


<a href="#formed.integrations.torch.training.exceptions.StopEarly" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="Exception">Exception</span></code></p>



        <p>Raised to stop training early.</p>









    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.training.state" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.training.state</span>


<a href="#formed.integrations.torch.training.state" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Training state management for PyTorch models.</p>
<p>This module provides a training state class that encapsulates model parameters,
optimizer state, and training progress for PyTorch models.</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.state.TrainState" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TrainState</span>


<a href="#formed.integrations.torch.training.state.TrainState" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">TrainState</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">optimizer</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">grad_scaler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">



        <p>Training state for PyTorch models.</p>
<p>This class encapsulates the training state including model,
optimizer, learning rate scheduler, and training progress counters.
Unlike the Flax version, this directly holds references to the model
and optimizer for efficiency.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;model&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState.model&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState.model">model</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The PyTorch model being trained.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;optimizer&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState.optimizer&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState.optimizer">optimizer</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The optimizer for training.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;lr_scheduler&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState.lr_scheduler&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState.lr_scheduler">lr_scheduler</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Optional learning rate scheduler.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;step&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState.step&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState.step">step</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Training step counter.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-attribute&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-attribute-name&quot;&gt;grad_scaler&lt;/span&gt;


  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-instance-attribute&quot;&gt;&lt;code&gt;instance-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState.grad_scaler&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState.grad_scaler">grad_scaler</a></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Optional gradient scaler for mixed precision training.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create state from model and optimizer</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">state</span> <span class="o">=</span> <span class="n">TrainState</span><span class="p">(</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">step</span><span class="o">=</span><span class="mi">0</span>
</span><span id="__span-0-6"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Access model and optimizer directly</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt; </span><span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="n">state</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/training/state.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-45"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-46">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-47">    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
</span><span id="__span-0-48">    <span class="n">optimizer</span><span class="p">:</span> <span class="s2">&quot;IOptimizer&quot;</span><span class="p">,</span>
</span><span id="__span-0-49">    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-50">    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;ILRScheduler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-51">    <span class="n">grad_scaler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;IGradScaler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-52"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-53">    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="__span-0-54">    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
</span><span id="__span-0-55">    <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span>
</span><span id="__span-0-56">    <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">step</span>
</span><span id="__span-0-57">    <span class="bp">self</span><span class="o">.</span><span class="n">grad_scaler</span> <span class="o">=</span> <span class="n">grad_scaler</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.training.state.TrainState.model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.training.state.TrainState.model" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">model</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.training.state.TrainState(model)">model</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.training.state.TrainState.optimizer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">optimizer</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.training.state.TrainState.optimizer" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">optimizer</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.training.state.TrainState(optimizer)">optimizer</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.training.state.TrainState.lr_scheduler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">lr_scheduler</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.training.state.TrainState.lr_scheduler" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.training.state.TrainState(lr_scheduler)">lr_scheduler</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.training.state.TrainState.step" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">step</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.training.state.TrainState.step" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">step</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.training.state.TrainState(step)">step</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.training.state.TrainState.grad_scaler" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">grad_scaler</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#formed.integrations.torch.training.state.TrainState.grad_scaler" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">grad_scaler</span> <span class="o">=</span> <span class="n"><span title="formed.integrations.torch.training.state.TrainState(grad_scaler)">grad_scaler</span></span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.state.TrainState.state_dict" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">state_dict</span>


<a href="#formed.integrations.torch.training.state.TrainState.state_dict" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">state_dict</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get state dictionary for serialization.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Dictionary containing model state, <code>optimizer</code> state, <code>lr_scheduler</code> state (if present), <code>grad_scaler</code> state (if present), and <code>step</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/state.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-59"><span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span id="__span-0-60"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get state dictionary for serialization.</span>
</span><span id="__span-0-61">
</span><span id="__span-0-62"><span class="sd">    Returns:</span>
</span><span id="__span-0-63"><span class="sd">        Dictionary containing model state, `optimizer` state, `lr_scheduler` state (if present), `grad_scaler` state (if present), and `step`.</span>
</span><span id="__span-0-64">
</span><span id="__span-0-65"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-66">    <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-67">        <span class="s2">&quot;model_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
</span><span id="__span-0-68">        <span class="s2">&quot;optimizer_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
</span><span id="__span-0-69">        <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
</span><span id="__span-0-70">    <span class="p">}</span>
</span><span id="__span-0-71">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-72">        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;lr_scheduler_state&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</span><span id="__span-0-73">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-74">        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;grad_scaler_state&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_scaler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</span><span id="__span-0-75">    <span class="k">return</span> <span class="n">state</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.state.TrainState.load_state_dict" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">load_state_dict</span>


<a href="#formed.integrations.torch.training.state.TrainState.load_state_dict" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Load state from dictionary.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>state_dict</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary containing model state, optimizer state, lr_scheduler state (optional), grad_scaler state (optional), and step.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/state.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-77"><span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-78"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Load state from dictionary.</span>
</span><span id="__span-0-79">
</span><span id="__span-0-80"><span class="sd">    Args:</span>
</span><span id="__span-0-81"><span class="sd">        state_dict: Dictionary containing model state, optimizer state, lr_scheduler state (optional), grad_scaler state (optional), and step.</span>
</span><span id="__span-0-82">
</span><span id="__span-0-83"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-84">    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;model_state&quot;</span><span class="p">])</span>
</span><span id="__span-0-85">    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;optimizer_state&quot;</span><span class="p">])</span>
</span><span id="__span-0-86">    <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span>
</span><span id="__span-0-87">    <span class="k">if</span> <span class="s2">&quot;lr_scheduler_state&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-88">        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;lr_scheduler_state&quot;</span><span class="p">])</span>
</span><span id="__span-0-89">    <span class="k">if</span> <span class="s2">&quot;grad_scaler_state&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-90">        <span class="bp">self</span><span class="o">.</span><span class="n">grad_scaler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;grad_scaler_state&quot;</span><span class="p">])</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.state.TrainState.get_learning_rate" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_learning_rate</span>


<a href="#formed.integrations.torch.training.state.TrainState.get_learning_rate" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_learning_rate</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get current learning rate from optimizer.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Current learning rate from the first parameter group, or <code>None</code> if unavailable.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get_learning_rate</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current learning rate: </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/state.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-92"><span class="k">def</span><span class="w"> </span><span class="nf">get_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-93"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get current learning rate from optimizer.</span>
</span><span id="__span-0-94">
</span><span id="__span-0-95"><span class="sd">    Returns:</span>
</span><span id="__span-0-96"><span class="sd">        Current learning rate from the first parameter group, or `None` if unavailable.</span>
</span><span id="__span-0-97">
</span><span id="__span-0-98"><span class="sd">    Examples:</span>
</span><span id="__span-0-99"><span class="sd">        &gt;&gt;&gt; lr = state.get_learning_rate()</span>
</span><span id="__span-0-100"><span class="sd">        &gt;&gt;&gt; if lr is not None:</span>
</span><span id="__span-0-101"><span class="sd">        ...     print(f&quot;Current learning rate: {lr}&quot;)</span>
</span><span id="__span-0-102">
</span><span id="__span-0-103"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-104">    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span>
</span><span id="__span-0-105">
</span><span id="__span-0-106">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
</span><span id="__span-0-107">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
</span><span id="__span-0-108">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
</span><span id="__span-0-109">    <span class="k">return</span> <span class="kc">None</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.state.TrainState.get_gradient_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">get_gradient_norm</span>


<a href="#formed.integrations.torch.training.state.TrainState.get_gradient_norm" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_gradient_norm</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute L2 norm of all gradients.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>L2 norm of all parameter gradients, or <code>None</code> if no gradients are available.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">grad_norm</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get_gradient_norm</span><span class="p">()</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">grad_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient norm: </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div>


<details class="note" open>
  <summary>Note</summary>
  <p>This method computes the gradient norm on-demand. It should be called
after <code>backward()</code> but before optimizer.step() or <code>zero_grad()</code> to get
meaningful results.</p>
</details>

            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/state.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-111"><span class="k">def</span><span class="w"> </span><span class="nf">get_gradient_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-112"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute L2 norm of all gradients.</span>
</span><span id="__span-0-113">
</span><span id="__span-0-114"><span class="sd">    Returns:</span>
</span><span id="__span-0-115"><span class="sd">        L2 norm of all parameter gradients, or `None` if no gradients are available.</span>
</span><span id="__span-0-116">
</span><span id="__span-0-117"><span class="sd">    Examples:</span>
</span><span id="__span-0-118"><span class="sd">        &gt;&gt;&gt; grad_norm = state.get_gradient_norm()</span>
</span><span id="__span-0-119"><span class="sd">        &gt;&gt;&gt; if grad_norm is not None:</span>
</span><span id="__span-0-120"><span class="sd">        ...     print(f&quot;Gradient norm: {grad_norm:.4f}&quot;)</span>
</span><span id="__span-0-121">
</span><span id="__span-0-122"><span class="sd">    Note:</span>
</span><span id="__span-0-123"><span class="sd">        This method computes the gradient norm on-demand. It should be called</span>
</span><span id="__span-0-124"><span class="sd">        after `backward()` but before optimizer.step() or `zero_grad()` to get</span>
</span><span id="__span-0-125"><span class="sd">        meaningful results.</span>
</span><span id="__span-0-126">
</span><span id="__span-0-127"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-128">    <span class="n">total_norm</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span id="__span-0-129">    <span class="n">has_gradients</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-130">
</span><span id="__span-0-131">    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span><span id="__span-0-132">        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-133">            <span class="n">has_gradients</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-0-134">            <span class="n">param_norm</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-135">            <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
</span><span id="__span-0-136">
</span><span id="__span-0-137">    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_gradients</span><span class="p">:</span>
</span><span id="__span-0-138">        <span class="k">return</span> <span class="kc">None</span>
</span><span id="__span-0-139">
</span><span id="__span-0-140">    <span class="k">return</span> <span class="n">total_norm</span><span class="o">**</span><span class="mf">0.5</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.training.trainer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.training.trainer</span>


<a href="#formed.integrations.torch.training.trainer" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>High-level trainer for PyTorch models.</p>
<p>This module provides the TorchTrainer class, which orchestrates the complete
training process for PyTorch models including data loading, optimization,
evaluation, callbacks, and distributed training.</p>


<details class="key-features" open>
  <summary>Key Features</summary>
  <ul>
<li>Flexible training loop with epoch and step-based logging/evaluation</li>
<li>Support for callbacks at various training stages</li>
<li>Distributed training via data parallelism</li>
<li>Integration with PyTorch optimizers</li>
<li>Rich progress bars with training metrics</li>
<li>Early stopping and checkpointing</li>
<li>MLflow integration</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">TorchTrainer</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">EvaluationCallback</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">EarlyStoppingCallback</span>
</span><span id="__span-0-5"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.ml</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">BasicBatchSampler</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Setup data loaders and engine</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="n">sampler</span><span class="o">=</span><span class="n">BasicBatchSampler</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">collator</span><span class="o">=</span><span class="n">datamodule</span><span class="o">.</span><span class="n">batch</span>
</span><span id="__span-0-13"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-14"><span class="gp">&gt;&gt;&gt; </span><span class="n">engine</span> <span class="o">=</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">(</span>
</span><span id="__span-0-15"><span class="gp">... </span>    <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
</span><span id="__span-0-16"><span class="gp">... </span>    <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span>
</span><span id="__span-0-17"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-18"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-19"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create trainer</span>
</span><span id="__span-0-20"><span class="gp">&gt;&gt;&gt; </span><span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
</span><span id="__span-0-21"><span class="gp">... </span>    <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span>
</span><span id="__span-0-22"><span class="gp">... </span>    <span class="n">val_dataloader</span><span class="o">=</span><span class="n">val_dataloader</span><span class="p">,</span>
</span><span id="__span-0-23"><span class="gp">... </span>    <span class="n">engine</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span>
</span><span id="__span-0-24"><span class="gp">... </span>    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span><span id="__span-0-25"><span class="gp">... </span>    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
</span><span id="__span-0-26"><span class="gp">... </span>        <span class="n">EvaluationCallback</span><span class="p">(</span><span class="n">my_evaluator</span><span class="p">),</span>
</span><span id="__span-0-27"><span class="gp">... </span>        <span class="n">EarlyStoppingCallback</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="__span-0-28"><span class="gp">... </span>    <span class="p">]</span>
</span><span id="__span-0-29"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-30"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-31"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Train model</span>
</span><span id="__span-0-32"><span class="gp">&gt;&gt;&gt; </span><span class="n">state</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">)</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.training.trainer.TorchTrainer" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TorchTrainer</span>


<a href="#formed.integrations.torch.training.trainer.TorchTrainer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">TorchTrainer</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">train_dataloader</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">val_dataloader</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">engine</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">callbacks</span><span class="o">=</span><span class="p">(),</span>
</span><span id="__span-0-7">    <span class="n">distributor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">max_epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9">    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
</span><span id="__span-0-10">    <span class="n">eval_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-11">    <span class="n">logging_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
</span><span id="__span-0-12">    <span class="n">logging_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-13">    <span class="n">logging_first_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-14">    <span class="n">train_prefix</span><span class="o">=</span><span class="s2">&quot;train/&quot;</span><span class="p">,</span>
</span><span id="__span-0-15">    <span class="n">val_prefix</span><span class="o">=</span><span class="s2">&quot;val/&quot;</span><span class="p">,</span>
</span><span id="__span-0-16"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="typing.Generic">Generic</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code></p>



        <p>High-level trainer for PyTorch models.</p>
<p>TorchTrainer provides a complete training loop with support for
distributed training, callbacks, evaluation, and metric logging.
It handles the coordination of data loading, model training,
evaluation, and callback execution.</p>


<table>
      <thead>
        <tr>
          <th>
            <span class="doc-section-title">
              CLASS TYPE PARAMETER
            </span>
          </th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>ItemT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of raw dataset items.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ModelInputT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of batched model inputs.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ModelOutputT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of model outputs.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ModelParamsT</code>
            </td>
            <td class="doc-type_param-details">
              <div class="doc-md-description">
                <p>Type of additional model parameters.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>train_dataloader</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Data loader for training dataset.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.IDataLoader">IDataLoader</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_dataloader</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional data loader for validation dataset.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="formed.integrations.torch.types.IDataLoader">IDataLoader</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>engine</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Training engine (defaults to <code>DefaultTorchTrainingEngine</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainingEngine&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.engine.TorchTrainingEngine&lt;/code&gt;)" href="#formed.integrations.torch.training.engine.TorchTrainingEngine">TorchTrainingEngine</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>callbacks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Sequence of training callbacks.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainingCallback&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.callbacks.TorchTrainingCallback&lt;/code&gt;)" href="#formed.integrations.torch.training.callbacks.TorchTrainingCallback">TorchTrainingCallback</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>()</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>distributor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Device distributor (defaults to <code>SingleDeviceDistributor</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseDistributor&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.distributors.BaseDistributor&lt;/code&gt;)" href="#formed.integrations.torch.distributors.BaseDistributor">BaseDistributor</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_epochs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum number of training epochs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When to evaluate - <code>"epoch"</code> or <code>"step"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Literal">Literal</span>[&#39;epoch&#39;, &#39;step&#39;]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;epoch&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_interval</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Evaluation interval (epochs or steps).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When to log - <code>"epoch"</code> or <code>"step"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Literal">Literal</span>[&#39;epoch&#39;, &#39;step&#39;]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;epoch&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_interval</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logging interval (epochs or steps).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_first_step</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to log after the first training step.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="bool">bool</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_prefix</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Prefix for training metrics logging. Default is <code>"train/"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;train/&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_prefix</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Prefix for validation metrics logging. Default is <code>"val/"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;val/&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">engine</span> <span class="o">=</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span>
</span><span id="__span-0-4"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">trainer</span> <span class="o">=</span> <span class="n">TorchTrainer</span><span class="p">(</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">val_dataloader</span><span class="o">=</span><span class="n">val_loader</span><span class="p">,</span>
</span><span id="__span-0-8"><span class="gp">... </span>    <span class="n">engine</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span>
</span><span id="__span-0-9"><span class="gp">... </span>    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span><span id="__span-0-10"><span class="gp">... </span>    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
</span><span id="__span-0-11"><span class="gp">... </span>    <span class="n">logging_strategy</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">,</span>
</span><span id="__span-0-12"><span class="gp">... </span>    <span class="n">logging_interval</span><span class="o">=</span><span class="mi">100</span>
</span><span id="__span-0-13"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>








                  <details class="mkdocstrings-source">
                    <summary>Source code in <code>src/formed/integrations/torch/training/trainer.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-144"><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-145">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-146">    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-147">    <span class="n">train_dataloader</span><span class="p">:</span> <span class="n">IDataLoader</span><span class="p">[</span><span class="n">ItemT</span><span class="p">,</span> <span class="n">ModelInputT</span><span class="p">],</span>
</span><span id="__span-0-148">    <span class="n">val_dataloader</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">IDataLoader</span><span class="p">[</span><span class="n">ItemT</span><span class="p">,</span> <span class="n">ModelInputT</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-149">    <span class="n">engine</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TorchTrainingEngine</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-150">    <span class="n">callbacks</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">TorchTrainingCallback</span><span class="p">]</span> <span class="o">=</span> <span class="p">(),</span>
</span><span id="__span-0-151">    <span class="n">distributor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BaseDistributor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-152">    <span class="n">max_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-153">    <span class="n">eval_strategy</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
</span><span id="__span-0-154">    <span class="n">eval_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-155">    <span class="n">logging_strategy</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
</span><span id="__span-0-156">    <span class="n">logging_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-0-157">    <span class="n">logging_first_step</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-158">    <span class="n">train_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;train/&quot;</span><span class="p">,</span>
</span><span id="__span-0-159">    <span class="n">val_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;val/&quot;</span><span class="p">,</span>
</span><span id="__span-0-160"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-161">    <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataloader</span> <span class="o">=</span> <span class="n">train_dataloader</span>
</span><span id="__span-0-162">    <span class="bp">self</span><span class="o">.</span><span class="n">_val_dataloader</span> <span class="o">=</span> <span class="n">val_dataloader</span>
</span><span id="__span-0-163">    <span class="bp">self</span><span class="o">.</span><span class="n">_engine</span> <span class="o">=</span> <span class="n">engine</span> <span class="ow">or</span> <span class="n">DefaultTorchTrainingEngine</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">]()</span>
</span><span id="__span-0-164">    <span class="bp">self</span><span class="o">.</span><span class="n">_distributor</span> <span class="o">=</span> <span class="n">distributor</span> <span class="ow">or</span> <span class="n">get_default_distributor</span><span class="p">()</span>
</span><span id="__span-0-165">    <span class="bp">self</span><span class="o">.</span><span class="n">_max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span> <span class="ow">or</span> <span class="n">get_default_max_epochs</span><span class="p">()</span>
</span><span id="__span-0-166">    <span class="bp">self</span><span class="o">.</span><span class="n">_eval_strategy</span> <span class="o">=</span> <span class="n">eval_strategy</span>
</span><span id="__span-0-167">    <span class="bp">self</span><span class="o">.</span><span class="n">_eval_interval</span> <span class="o">=</span> <span class="n">eval_interval</span>
</span><span id="__span-0-168">    <span class="bp">self</span><span class="o">.</span><span class="n">_logging_strategy</span> <span class="o">=</span> <span class="n">logging_strategy</span>
</span><span id="__span-0-169">    <span class="bp">self</span><span class="o">.</span><span class="n">_logging_interval</span> <span class="o">=</span> <span class="n">logging_interval</span>
</span><span id="__span-0-170">    <span class="bp">self</span><span class="o">.</span><span class="n">_logging_first_step</span> <span class="o">=</span> <span class="n">logging_first_step</span>
</span><span id="__span-0-171">    <span class="bp">self</span><span class="o">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>
</span><span id="__span-0-172">    <span class="bp">self</span><span class="o">.</span><span class="n">_train_prefix</span> <span class="o">=</span> <span class="n">train_prefix</span>
</span><span id="__span-0-173">    <span class="bp">self</span><span class="o">.</span><span class="n">_val_prefix</span> <span class="o">=</span> <span class="n">val_prefix</span>
</span></code></pre></div></td></tr></table></div>
                  </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.training.trainer.TorchTrainer.distributor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">distributor</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.training.trainer.TorchTrainer.distributor" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">distributor</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.training.trainer.TorchTrainer.train" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">train</span>


<a href="#formed.integrations.torch.training.trainer.TorchTrainer.train" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Train a model on the provided datasets.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Model to train.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTorchModel&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.model.BaseTorchModel&lt;/code&gt;)" href="#formed.integrations.torch.model.BaseTorchModel">BaseTorchModel</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Sequence of training items.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional sequence of validation items.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="collections.abc.Sequence">Sequence</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>state</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional pre-initialized training state (for resuming).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TrainState&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState">TrainState</a>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TrainState&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.state.TrainState&lt;/code&gt;)" href="#formed.integrations.torch.training.state.TrainState">TrainState</a></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Final training state with trained parameters.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code><span title="ValueError">ValueError</span></code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If <code>val_dataset</code> is provided but <code>val_dataloader</code> is not.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">state</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
</span><span id="__span-0-2"><span class="gp">... </span>    <span class="n">model</span><span class="p">,</span> <span class="n">train_items</span><span class="p">,</span> <span class="n">val_items</span>
</span><span id="__span-0-3"><span class="gp">... </span><span class="p">)</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load trained parameters</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">model_state</span><span class="p">)</span>
</span></code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-179"><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span>
</span><span id="__span-0-180">    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-181">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-182">    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ItemT</span><span class="p">],</span>
</span><span id="__span-0-183">    <span class="n">val_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">ItemT</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-184">    <span class="n">state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TrainState</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-185"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainState</span><span class="p">:</span>
</span><span id="__span-0-186"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Train a model on the provided datasets.</span>
</span><span id="__span-0-187">
</span><span id="__span-0-188"><span class="sd">    Args:</span>
</span><span id="__span-0-189"><span class="sd">        model: Model to train.</span>
</span><span id="__span-0-190"><span class="sd">        train_dataset: Sequence of training items.</span>
</span><span id="__span-0-191"><span class="sd">        val_dataset: Optional sequence of validation items.</span>
</span><span id="__span-0-192"><span class="sd">        state: Optional pre-initialized training state (for resuming).</span>
</span><span id="__span-0-193">
</span><span id="__span-0-194"><span class="sd">    Returns:</span>
</span><span id="__span-0-195"><span class="sd">        Final training state with trained parameters.</span>
</span><span id="__span-0-196">
</span><span id="__span-0-197"><span class="sd">    Raises:</span>
</span><span id="__span-0-198"><span class="sd">        ValueError: If `val_dataset` is provided but `val_dataloader` is not.</span>
</span><span id="__span-0-199">
</span><span id="__span-0-200"><span class="sd">    Examples:</span>
</span><span id="__span-0-201"><span class="sd">        &gt;&gt;&gt; state = trainer.train(</span>
</span><span id="__span-0-202"><span class="sd">        ...     model, train_items, val_items</span>
</span><span id="__span-0-203"><span class="sd">        ... )</span>
</span><span id="__span-0-204"><span class="sd">        &gt;&gt;&gt; # Load trained parameters</span>
</span><span id="__span-0-205"><span class="sd">        &gt;&gt;&gt; model.load_state_dict(state.model_state)</span>
</span><span id="__span-0-206">
</span><span id="__span-0-207"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-208">    <span class="k">if</span> <span class="n">val_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_dataloader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-209">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Validation dataloader is not provided.&quot;</span><span class="p">)</span>
</span><span id="__span-0-210">
</span><span id="__span-0-211">    <span class="n">logger</span> <span class="o">=</span> <span class="n">use_step_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="__span-0-212">
</span><span id="__span-0-213">    <span class="c1"># Set device context for ensure_torch_tensor</span>
</span><span id="__span-0-214">    <span class="k">with</span> <span class="n">use_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distributor</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
</span><span id="__span-0-215">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_impl</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">logger</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.training.trainer.get_default_max_epochs" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_default_max_epochs</span>


<a href="#formed.integrations.torch.training.trainer.get_default_max_epochs" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_default_max_epochs</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get a default maximum number of training epochs.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-81"><span class="k">def</span><span class="w"> </span><span class="nf">get_default_max_epochs</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="__span-0-82"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a default maximum number of training epochs.&quot;&quot;&quot;</span>
</span><span id="__span-0-83">    <span class="k">return</span> <span class="mi">10</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.training.trainer.get_default_distributor" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_default_distributor</span>


<a href="#formed.integrations.torch.training.trainer.get_default_distributor" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">get_default_distributor</span><span class="p">()</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get a default single-device distributor.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/training/trainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-86"><span class="k">def</span><span class="w"> </span><span class="nf">get_default_distributor</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">BaseDistributor</span><span class="p">:</span>
</span><span id="__span-0-87"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a default single-device distributor.&quot;&quot;&quot;</span>
</span><span id="__span-0-88">    <span class="k">return</span> <span class="n">SingleDeviceDistributor</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="formed.integrations.torch.workflow" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">formed.integrations.torch.workflow</span>


<a href="#formed.integrations.torch.workflow" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Workflow integration for PyTorch model training.</p>
<p>This module provides workflow steps for training PyTorch models, allowing
them to be integrated into the formed workflow system with automatic
caching and dependency tracking.</p>


<details class="available-steps" open>
  <summary>Available Steps</summary>
  <ul>
<li><code>torch::train</code>: Train a PyTorch model using the provided trainer.</li>
<li><code>torch::evaluate</code>: Evaluate a PyTorch model on a dataset.</li>
<li><code>torch::predict</code>: Generate predictions on a dataset using a PyTorch model.</li>
<li><code>torch::predict_without_caching</code>: Generate predictions without caching (same as <code>torch::predict</code> but uncached).</li>
</ul>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">formed.integrations.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_torch_model</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt;</span>
</span><span id="__span-0-3"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># In workflow configuration (jsonnet):</span>
</span><span id="__span-0-4"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># {</span>
</span><span id="__span-0-5"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#   steps: {</span>
</span><span id="__span-0-6"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#     train: {</span>
</span><span id="__span-0-7"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#       type: &quot;torch::train&quot;,</span>
</span><span id="__span-0-8"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#       model: { type: &quot;my_model&quot;, ... },</span>
</span><span id="__span-0-9"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#       trainer: { type: &quot;torch_trainer&quot;, ... },</span>
</span><span id="__span-0-10"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#       train_dataset: { type: &quot;ref&quot;, ref: &quot;preprocess&quot; },</span>
</span><span id="__span-0-11"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#       random_seed: 42</span>
</span><span id="__span-0-12"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#     }</span>
</span><span id="__span-0-13"><span class="gp">&gt;&gt;&gt; </span><span class="c1">#   }</span>
</span><span id="__span-0-14"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># }</span>
</span></code></pre></div>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="formed.integrations.torch.workflow.TorchModelFormat" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">TorchModelFormat</span>


<a href="#formed.integrations.torch.workflow.TorchModelFormat" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;Format&lt;/span&gt; (&lt;code&gt;formed.workflow.Format&lt;/code&gt;)" href="../../workflow/#formed.workflow.format.Format">Format</a>[<span title="formed.integrations.torch.workflow._ModelT">_ModelT</span>]</code></p>













<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="formed.integrations.torch.workflow.TorchModelFormat.identifier" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">identifier</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#formed.integrations.torch.workflow.TorchModelFormat.identifier" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="n">identifier</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Get the unique identifier for this format.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="str">str</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Format identifier string.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.workflow.TorchModelFormat.write" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">write</span>


<a href="#formed.integrations.torch.workflow.TorchModelFormat.write" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">write</span><span class="p">(</span><span class="n">artifact</span><span class="p">,</span> <span class="n">directory</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/workflow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-68"><span class="k">def</span><span class="w"> </span><span class="nf">write</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">artifact</span><span class="p">:</span> <span class="n">_ModelT</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-69">    <span class="k">if</span> <span class="n">artifact</span><span class="o">.</span><span class="n">__model_config__</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-70">        <span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">artifact</span><span class="o">.</span><span class="n">__model_config__</span><span class="p">)</span>
</span><span id="__span-0-71">        <span class="n">config</span><span class="p">[</span><span class="n">COLT_TYPEKEY</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">artifact</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__module__</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">artifact</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="__span-0-72">        <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_path</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span>
</span><span id="__span-0-73">            <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
</span><span id="__span-0-74">                <span class="n">artifact</span><span class="o">.</span><span class="n">__model_config__</span><span class="p">,</span>
</span><span id="__span-0-75">                <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="__span-0-76">                <span class="bp">cls</span><span class="o">=</span><span class="n">WorkflowJSONEncoder</span><span class="p">,</span>
</span><span id="__span-0-77">            <span class="p">)</span>
</span><span id="__span-0-78">        <span class="p">)</span>
</span><span id="__span-0-79">        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
</span><span id="__span-0-80">            <span class="n">artifact</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
</span><span id="__span-0-81">            <span class="bp">self</span><span class="o">.</span><span class="n">_get_state_path</span><span class="p">(</span><span class="n">directory</span><span class="p">),</span>
</span><span id="__span-0-82">        <span class="p">)</span>
</span><span id="__span-0-83">    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-84">        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pickle_path</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="__span-0-85">            <span class="n">cloudpickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">artifact</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.workflow.TorchModelFormat.read" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">read</span>


<a href="#formed.integrations.torch.workflow.TorchModelFormat.read" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">read</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/workflow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-87"><span class="k">def</span><span class="w"> </span><span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">directory</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_ModelT</span><span class="p">:</span>
</span><span id="__span-0-88">    <span class="k">if</span> <span class="p">(</span><span class="n">pickle_path</span> <span class="o">:=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pickle_path</span><span class="p">(</span><span class="n">directory</span><span class="p">))</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="__span-0-89">        <span class="k">with</span> <span class="n">pickle_path</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="__span-0-90">            <span class="n">model</span> <span class="o">=</span> <span class="n">cloudpickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span><span id="__span-0-91">        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">_ModelT</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</span><span id="__span-0-92">
</span><span id="__span-0-93">    <span class="n">config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span>
</span><span id="__span-0-94">        <span class="bp">self</span><span class="o">.</span><span class="n">_get_config_path</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span><span class="o">.</span><span class="n">read_text</span><span class="p">(),</span>
</span><span id="__span-0-95">        <span class="bp">cls</span><span class="o">=</span><span class="n">WorkflowJSONDecoder</span><span class="p">,</span>
</span><span id="__span-0-96">    <span class="p">)</span>
</span><span id="__span-0-97">    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_state_path</span><span class="p">(</span><span class="n">directory</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="__span-0-98">    <span class="n">model</span> <span class="o">=</span> <span class="n">COLT_BUILDER</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">BaseTorchModel</span><span class="p">)</span>
</span><span id="__span-0-99">    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span><span id="__span-0-100">    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">_ModelT</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="formed.integrations.torch.workflow.TorchModelFormat.is_default_of" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">is_default_of</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#formed.integrations.torch.workflow.TorchModelFormat.is_default_of" class="headerlink" title="Permanent link">&para;</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">is_default_of</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Check if this format is the default for the given object type.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>obj</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Object to check.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Any">Any</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="bool">bool</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>True if this format should be used by default for this type.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/workflow/format.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-101"><span class="nd">@classmethod</span>
</span><span id="__span-0-102"><span class="k">def</span><span class="w"> </span><span class="nf">is_default_of</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="__span-0-103"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if this format is the default for the given object type.</span>
</span><span id="__span-0-104">
</span><span id="__span-0-105"><span class="sd">    Args:</span>
</span><span id="__span-0-106"><span class="sd">        obj: Object to check.</span>
</span><span id="__span-0-107">
</span><span id="__span-0-108"><span class="sd">    Returns:</span>
</span><span id="__span-0-109"><span class="sd">        True if this format should be used by default for this type.</span>
</span><span id="__span-0-110">
</span><span id="__span-0-111"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-112">    <span class="k">return</span> <span class="kc">False</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.workflow.train_torch_model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">train_torch_model</span>


<a href="#formed.integrations.torch.workflow.train_torch_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">train_torch_model</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">trainer</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">train_dataset</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">val_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Train a PyTorch model using the provided trainer.</p>
<p>This workflow step trains a PyTorch model on the provided datasets,
returning the trained model. The training process is cached based on
the model architecture, trainer configuration, and dataset fingerprints.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>PyTorch model to train.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="colt.Lazy">Lazy</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTorchModel&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.model.BaseTorchModel&lt;/code&gt;)" href="#formed.integrations.torch.model.BaseTorchModel">BaseTorchModel</a>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trainer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Trainer configuration with dataloaders and callbacks.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;TorchTrainer&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.training.TorchTrainer&lt;/code&gt;)" href="#formed.integrations.torch.training.trainer.TorchTrainer">TorchTrainer</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Training dataset items.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional validation dataset items.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Sequence">Sequence</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>] | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>random_seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Random seed for reproducibility.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTorchModel&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.model.BaseTorchModel&lt;/code&gt;)" href="#formed.integrations.torch.model.BaseTorchModel">BaseTorchModel</a></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Trained PyTorch model with updated parameters.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use in Python code</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">trained_model</span> <span class="o">=</span> <span class="n">train_torch_model</span><span class="p">(</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">model</span><span class="o">=</span><span class="n">my_model</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">val_dataset</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
</span><span id="__span-0-7"><span class="gp">... </span>    <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span>
</span><span id="__span-0-8"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/workflow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-103"><span class="nd">@step</span><span class="p">(</span><span class="s2">&quot;torch::train&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">TorchModelFormat</span><span class="p">())</span>
</span><span id="__span-0-104"><span class="k">def</span><span class="w"> </span><span class="nf">train_torch_model</span><span class="p">(</span>
</span><span id="__span-0-105">    <span class="n">model</span><span class="p">:</span> <span class="n">Lazy</span><span class="p">[</span><span class="n">BaseTorchModel</span><span class="p">],</span>
</span><span id="__span-0-106">    <span class="n">trainer</span><span class="p">:</span> <span class="n">TorchTrainer</span><span class="p">,</span>
</span><span id="__span-0-107">    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ItemT</span><span class="p">],</span>
</span><span id="__span-0-108">    <span class="n">val_dataset</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ItemT</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-109">    <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-0-110"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BaseTorchModel</span><span class="p">:</span>
</span><span id="__span-0-111"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Train a PyTorch model using the provided trainer.</span>
</span><span id="__span-0-112">
</span><span id="__span-0-113"><span class="sd">    This workflow step trains a PyTorch model on the provided datasets,</span>
</span><span id="__span-0-114"><span class="sd">    returning the trained model. The training process is cached based on</span>
</span><span id="__span-0-115"><span class="sd">    the model architecture, trainer configuration, and dataset fingerprints.</span>
</span><span id="__span-0-116">
</span><span id="__span-0-117"><span class="sd">    Args:</span>
</span><span id="__span-0-118"><span class="sd">        model: PyTorch model to train.</span>
</span><span id="__span-0-119"><span class="sd">        trainer: Trainer configuration with dataloaders and callbacks.</span>
</span><span id="__span-0-120"><span class="sd">        train_dataset: Training dataset items.</span>
</span><span id="__span-0-121"><span class="sd">        val_dataset: Optional validation dataset items.</span>
</span><span id="__span-0-122"><span class="sd">        random_seed: Random seed for reproducibility.</span>
</span><span id="__span-0-123">
</span><span id="__span-0-124"><span class="sd">    Returns:</span>
</span><span id="__span-0-125"><span class="sd">        Trained PyTorch model with updated parameters.</span>
</span><span id="__span-0-126">
</span><span id="__span-0-127"><span class="sd">    Examples:</span>
</span><span id="__span-0-128"><span class="sd">        &gt;&gt;&gt; # Use in Python code</span>
</span><span id="__span-0-129"><span class="sd">        &gt;&gt;&gt; trained_model = train_torch_model(</span>
</span><span id="__span-0-130"><span class="sd">        ...     model=my_model,</span>
</span><span id="__span-0-131"><span class="sd">        ...     trainer=trainer,</span>
</span><span id="__span-0-132"><span class="sd">        ...     train_dataset=train_data,</span>
</span><span id="__span-0-133"><span class="sd">        ...     val_dataset=val_data,</span>
</span><span id="__span-0-134"><span class="sd">        ...     random_seed=42</span>
</span><span id="__span-0-135"><span class="sd">        ... )</span>
</span><span id="__span-0-136">
</span><span id="__span-0-137"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-138">    <span class="c1"># Set random seeds for reproducibility</span>
</span><span id="__span-0-139">    <span class="n">set_random_seed</span><span class="p">(</span><span class="n">random_seed</span><span class="p">)</span>
</span><span id="__span-0-140">
</span><span id="__span-0-141">    <span class="c1"># Build model from Lazy</span>
</span><span id="__span-0-142">    <span class="n">model_instance</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">construct</span><span class="p">()</span>
</span><span id="__span-0-143">
</span><span id="__span-0-144">    <span class="c1"># Set config for selialization</span>
</span><span id="__span-0-145">    <span class="n">model_instance</span><span class="o">.</span><span class="n">__model_config__</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</span><span id="__span-0-146">
</span><span id="__span-0-147">    <span class="c1"># Train the model</span>
</span><span id="__span-0-148">    <span class="n">state</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model_instance</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">)</span>
</span><span id="__span-0-149">
</span><span id="__span-0-150">    <span class="c1"># Return the trained model</span>
</span><span id="__span-0-151">    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">BaseTorchModel</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.workflow.evaluate_torch_model" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">evaluate_torch_model</span>


<a href="#formed.integrations.torch.workflow.evaluate_torch_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">evaluate_torch_model</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">evaluator</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">dataset</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">dataloader</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">random_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Evaluate a PyTorch model on a dataset using the provided evaluator.</p>
<p>This workflow step evaluates a PyTorch model on the provided dataset,
computing metrics using the evaluator. Evaluation is performed in
evaluation mode (no gradient computation).</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>PyTorch model to evaluate.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTorchModel&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.model.BaseTorchModel&lt;/code&gt;)" href="#formed.integrations.torch.model.BaseTorchModel">BaseTorchModel</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>evaluator</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Evaluator to compute metrics.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.IEvaluator">IEvaluator</span>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dataset items for evaluation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Iterable">Iterable</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataloader</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>DataLoader to convert items to model inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.IStreamingDataLoader">IStreamingDataLoader</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional model parameters to use for evaluation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>random_seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional random seed for reproducibility.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional device (e.g., <code>"cpu"</code>, <code>"cuda"</code>) to run evaluation on.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span> | <span title="torch.device">device</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="float">float</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Dictionary of computed evaluation metrics.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span id="__span-0-1"><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use in Python code</span>
</span><span id="__span-0-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span> <span class="o">=</span> <span class="n">evaluate_torch_model</span><span class="p">(</span>
</span><span id="__span-0-3"><span class="gp">... </span>    <span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span>
</span><span id="__span-0-4"><span class="gp">... </span>    <span class="n">evaluator</span><span class="o">=</span><span class="n">my_evaluator</span><span class="p">,</span>
</span><span id="__span-0-5"><span class="gp">... </span>    <span class="n">dataset</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
</span><span id="__span-0-6"><span class="gp">... </span>    <span class="n">dataloader</span><span class="o">=</span><span class="n">test_loader</span>
</span><span id="__span-0-7"><span class="gp">... </span><span class="p">)</span>
</span></code></pre></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/workflow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-154"><span class="nd">@step</span><span class="p">(</span><span class="s2">&quot;torch::evaluate&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;json&quot;</span><span class="p">)</span>
</span><span id="__span-0-155"><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_torch_model</span><span class="p">(</span>
</span><span id="__span-0-156">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-157">    <span class="n">evaluator</span><span class="p">:</span> <span class="n">IEvaluator</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">],</span>
</span><span id="__span-0-158">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">ItemT</span><span class="p">],</span>
</span><span id="__span-0-159">    <span class="n">dataloader</span><span class="p">:</span> <span class="n">IStreamingDataLoader</span><span class="p">[</span><span class="n">ItemT</span><span class="p">,</span> <span class="n">ModelInputT</span><span class="p">],</span>
</span><span id="__span-0-160">    <span class="n">params</span><span class="p">:</span> <span class="n">ModelParamsT</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-161">    <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-162">    <span class="n">device</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">WorkflowStepArgFlag</span><span class="o">.</span><span class="n">IGNORE</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-163"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">WorkflowStepResultFlag</span><span class="o">.</span><span class="n">METRICS</span><span class="p">]:</span>
</span><span id="__span-0-164"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate a PyTorch model on a dataset using the provided evaluator.</span>
</span><span id="__span-0-165">
</span><span id="__span-0-166"><span class="sd">    This workflow step evaluates a PyTorch model on the provided dataset,</span>
</span><span id="__span-0-167"><span class="sd">    computing metrics using the evaluator. Evaluation is performed in</span>
</span><span id="__span-0-168"><span class="sd">    evaluation mode (no gradient computation).</span>
</span><span id="__span-0-169">
</span><span id="__span-0-170"><span class="sd">    Args:</span>
</span><span id="__span-0-171"><span class="sd">        model: PyTorch model to evaluate.</span>
</span><span id="__span-0-172"><span class="sd">        evaluator: Evaluator to compute metrics.</span>
</span><span id="__span-0-173"><span class="sd">        dataset: Dataset items for evaluation.</span>
</span><span id="__span-0-174"><span class="sd">        dataloader: DataLoader to convert items to model inputs.</span>
</span><span id="__span-0-175"><span class="sd">        params: Optional model parameters to use for evaluation.</span>
</span><span id="__span-0-176"><span class="sd">        random_seed: Optional random seed for reproducibility.</span>
</span><span id="__span-0-177"><span class="sd">        device: Optional device (e.g., `&quot;cpu&quot;`, `&quot;cuda&quot;`) to run evaluation on.</span>
</span><span id="__span-0-178">
</span><span id="__span-0-179"><span class="sd">    Returns:</span>
</span><span id="__span-0-180"><span class="sd">        Dictionary of computed evaluation metrics.</span>
</span><span id="__span-0-181">
</span><span id="__span-0-182"><span class="sd">    Examples:</span>
</span><span id="__span-0-183"><span class="sd">        &gt;&gt;&gt; # Use in Python code</span>
</span><span id="__span-0-184"><span class="sd">        &gt;&gt;&gt; metrics = evaluate_torch_model(</span>
</span><span id="__span-0-185"><span class="sd">        ...     model=trained_model,</span>
</span><span id="__span-0-186"><span class="sd">        ...     evaluator=my_evaluator,</span>
</span><span id="__span-0-187"><span class="sd">        ...     dataset=test_data,</span>
</span><span id="__span-0-188"><span class="sd">        ...     dataloader=test_loader</span>
</span><span id="__span-0-189"><span class="sd">        ... )</span>
</span><span id="__span-0-190">
</span><span id="__span-0-191"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-192">    <span class="n">logger</span> <span class="o">=</span> <span class="n">use_step_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="__span-0-193">
</span><span id="__span-0-194">    <span class="c1"># Set random seed if provided</span>
</span><span id="__span-0-195">    <span class="k">if</span> <span class="n">random_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-196">        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">random_seed</span><span class="p">)</span>
</span><span id="__span-0-197">        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="__span-0-198">            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">random_seed</span><span class="p">)</span>
</span><span id="__span-0-199">
</span><span id="__span-0-200">    <span class="c1"># Evaluate model</span>
</span><span id="__span-0-201">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">(),</span> <span class="n">use_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">as</span> <span class="n">device</span><span class="p">:</span>
</span><span id="__span-0-202">        <span class="c1"># Move model to device if specified</span>
</span><span id="__span-0-203">        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-204">
</span><span id="__span-0-205">        <span class="c1"># Set model to evaluation mode</span>
</span><span id="__span-0-206">        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="__span-0-207">
</span><span id="__span-0-208">        <span class="c1"># Reset evaluator state</span>
</span><span id="__span-0-209">        <span class="n">evaluator</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="__span-0-210">
</span><span id="__span-0-211">        <span class="k">with</span> <span class="p">(</span>
</span><span id="__span-0-212">            <span class="n">closing</span><span class="p">(</span><span class="n">dataloader</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span> <span class="k">as</span> <span class="n">loader</span><span class="p">,</span>
</span><span id="__span-0-213">            <span class="n">progress</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Evaluating model&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">iterator</span><span class="p">,</span>
</span><span id="__span-0-214">        <span class="p">):</span>
</span><span id="__span-0-215">            <span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
</span><span id="__span-0-216">                <span class="n">inputs</span> <span class="o">=</span> <span class="n">move_to_device</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-217">                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</span><span id="__span-0-218">                <span class="n">evaluator</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</span><span id="__span-0-219">
</span><span id="__span-0-220">    <span class="n">metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</span><span id="__span-0-221">    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Evaluation metrics: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</span><span id="__span-0-222">
</span><span id="__span-0-223">    <span class="k">return</span> <span class="n">metrics</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="formed.integrations.torch.workflow.predict" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">predict</span>


<a href="#formed.integrations.torch.workflow.predict" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span id="__span-0-1"><span class="nf">predict</span><span class="p">(</span>
</span><span id="__span-0-2">    <span class="n">dataset</span><span class="p">,</span>
</span><span id="__span-0-3">    <span class="n">dataloader</span><span class="p">,</span>
</span><span id="__span-0-4">    <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-5">    <span class="n">postprocessor</span><span class="p">,</span>
</span><span id="__span-0-6">    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-7">    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-8">    <span class="n">random_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-9"><span class="p">)</span>
</span></code></pre></div>

    <div class="doc doc-contents ">

        <p>Generate predictions on a dataset using a PyTorch model.</p>
<p>This step applies a model to a dataset and postprocesses the outputs
to generate final predictions.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dataset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dataset items for prediction.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Iterable">Iterable</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataloader</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>DataLoader to convert items to model inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.IStreamingDataLoader">IStreamingDataLoader</span>[<span title="formed.integrations.torch.types.ItemT">ItemT</span>, <span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>PyTorch model to use for prediction.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;doc-symbol doc-symbol-heading doc-symbol-class&quot;&gt;&lt;/code&gt;            &lt;span class=&quot;doc doc-object-name doc-class-name&quot;&gt;BaseTorchModel&lt;/span&gt; (&lt;code&gt;formed.integrations.torch.model.BaseTorchModel&lt;/code&gt;)" href="#formed.integrations.torch.model.BaseTorchModel">BaseTorchModel</a>[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>, <span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>postprocessor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Function to convert model outputs to final results.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="collections.abc.Callable">Callable</span>[[<span title="formed.integrations.torch.types.ModelInputT">ModelInputT</span>, <span title="formed.integrations.torch.types.ModelOutputT">ModelOutputT</span>], <span title="collections.abc.Iterable">Iterable</span>[<span title="formed.integrations.torch.workflow._ResultT">_ResultT</span>]]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>params</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional model parameters to use for prediction.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="formed.integrations.torch.types.ModelParamsT">ModelParamsT</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional device (e.g., <code>"cpu"</code>, <code>"cuda"</code>) to run prediction on.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="str">str</span> | <span title="torch.device">device</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>random_seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional random seed for reproducibility.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="int">int</span> | None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="collections.abc.Iterator">Iterator</span>[<span title="formed.integrations.torch.workflow._ResultT">_ResultT</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Iterator of prediction results.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/formed/integrations/torch/workflow.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-226"><span class="nd">@step</span><span class="p">(</span><span class="s2">&quot;torch::predict&quot;</span><span class="p">)</span>
</span><span id="__span-0-227"><span class="nd">@step</span><span class="p">(</span><span class="s2">&quot;torch::predict_without_caching&quot;</span><span class="p">,</span> <span class="n">cacheable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-0-228"><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
</span><span id="__span-0-229">    <span class="n">dataset</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">ItemT</span><span class="p">],</span>
</span><span id="__span-0-230">    <span class="n">dataloader</span><span class="p">:</span> <span class="n">IStreamingDataLoader</span><span class="p">[</span><span class="n">ItemT</span><span class="p">,</span> <span class="n">ModelInputT</span><span class="p">],</span>
</span><span id="__span-0-231">    <span class="n">model</span><span class="p">:</span> <span class="n">BaseTorchModel</span><span class="p">[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">,</span> <span class="n">ModelParamsT</span><span class="p">],</span>
</span><span id="__span-0-232">    <span class="n">postprocessor</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">ModelInputT</span><span class="p">,</span> <span class="n">ModelOutputT</span><span class="p">],</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">_ResultT</span><span class="p">]],</span>
</span><span id="__span-0-233">    <span class="n">params</span><span class="p">:</span> <span class="n">ModelParamsT</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-234">    <span class="n">device</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">WorkflowStepArgFlag</span><span class="o">.</span><span class="n">IGNORE</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-235">    <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-236"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">_ResultT</span><span class="p">]:</span>
</span><span id="__span-0-237"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate predictions on a dataset using a PyTorch model.</span>
</span><span id="__span-0-238">
</span><span id="__span-0-239"><span class="sd">    This step applies a model to a dataset and postprocesses the outputs</span>
</span><span id="__span-0-240"><span class="sd">    to generate final predictions.</span>
</span><span id="__span-0-241">
</span><span id="__span-0-242"><span class="sd">    Args:</span>
</span><span id="__span-0-243"><span class="sd">        dataset: Dataset items for prediction.</span>
</span><span id="__span-0-244"><span class="sd">        dataloader: DataLoader to convert items to model inputs.</span>
</span><span id="__span-0-245"><span class="sd">        model: PyTorch model to use for prediction.</span>
</span><span id="__span-0-246"><span class="sd">        postprocessor: Function to convert model outputs to final results.</span>
</span><span id="__span-0-247"><span class="sd">        params: Optional model parameters to use for prediction.</span>
</span><span id="__span-0-248"><span class="sd">        device: Optional device (e.g., `&quot;cpu&quot;`, `&quot;cuda&quot;`) to run prediction on.</span>
</span><span id="__span-0-249"><span class="sd">        random_seed: Optional random seed for reproducibility.</span>
</span><span id="__span-0-250">
</span><span id="__span-0-251"><span class="sd">    Returns:</span>
</span><span id="__span-0-252"><span class="sd">        Iterator of prediction results.</span>
</span><span id="__span-0-253"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-254">    <span class="c1"># Set random seed if provided</span>
</span><span id="__span-0-255">    <span class="k">if</span> <span class="n">random_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-256">        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">random_seed</span><span class="p">)</span>
</span><span id="__span-0-257">        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="__span-0-258">            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">random_seed</span><span class="p">)</span>
</span><span id="__span-0-259">
</span><span id="__span-0-260">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">(),</span> <span class="n">use_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">as</span> <span class="n">device</span><span class="p">:</span>
</span><span id="__span-0-261">        <span class="c1"># Move model to device if specified</span>
</span><span id="__span-0-262">        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-263">
</span><span id="__span-0-264">        <span class="c1"># Set model to evaluation mode</span>
</span><span id="__span-0-265">        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="__span-0-266">
</span><span id="__span-0-267">        <span class="k">with</span> <span class="p">(</span>
</span><span id="__span-0-268">            <span class="n">closing</span><span class="p">(</span><span class="n">dataloader</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span> <span class="k">as</span> <span class="n">loader</span><span class="p">,</span>
</span><span id="__span-0-269">            <span class="n">progress</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Predicting&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">iterator</span><span class="p">,</span>
</span><span id="__span-0-270">        <span class="p">):</span>
</span><span id="__span-0-271">            <span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
</span><span id="__span-0-272">                <span class="n">inputs</span> <span class="o">=</span> <span class="n">move_to_device</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-273">                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</span><span id="__span-0-274">                <span class="k">yield from</span> <span class="n">postprocessor</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["content.code.copy", "content.tabs.link", "content.tooltips", "navigation.tabs", "navigation.tabs.sticky", "search.highlight", "toc.follow"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>