{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83e\uddec Formed","text":"<p>Formed is a framework for managing data/experiments/workflows in both research and production environments. It is designed to be flexible and extensible, and to provide a simple and consistent interface for managing data and workflows.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>DAG-based workflow system: Define complex workflows as directed acyclic   graphs (DAGs) to manage dependencies and execution order.</li> <li>Experiment tracking: Keep track of experiments, parameters, and results   in a structured manner.</li> <li>Built-in integration with popular data science libraries: Seamlessly work   with libraries like PyTorch, \ud83e\udd17 Transformers, MLflow, and more.</li> <li>Extensible architecture: Easily extend the framework with custom components   and plugins.</li> </ul>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>Define steps in a workflow using the <code>@workflow.step</code> decorator with type hints:</p> <pre><code># mysteps.py\n\nfrom collections.abc import Iterator\nfrom formed import workflow\n\n@workflow.step\ndef load_dataset(size: int) -&gt; Iterator[int]:\n    for i in range(size):\n        yield i\n\n@workflow.step\ndef square(dataset: Iterator[int]) -&gt; Iterator[int]:\n    for i in dataset:\n        yield i * i\n</code></pre> <p>Create a workflow definition using Jsonnet:</p> <pre><code># workflow.jsonnet\n\n{\n  steps: {\n    dataset: {\n      type: 'load_dataset',\n      size: 10\n    },\n    results: {\n      type: 'square',\n      dataset: { type: 'ref', ref: 'dataset' } // reference to dataset\n    }\n  }\n}\n</code></pre> <p>Setup the project configuration in <code>formed.yml</code>:</p> <pre><code># formed.yml\n\nworkflow:\n  organizer:\n    type: filesystem  # store execution results in the filesystem\n\nrequired_modules:\n  - mysteps           # include the custom steps module\n</code></pre> <p>Run the workflow via the command line interface:</p> <pre><code>formed run workflow.jsonnet --execution-id my-experiment\n</code></pre>"},{"location":"#documentation-guide","title":"Documentation Guide","text":"<ul> <li>Quick Start</li> <li>API Reference</li> </ul>"},{"location":"quick_start/","title":"Quick Start","text":""},{"location":"quick_start/#installation","title":"Installation","text":"<pre><code>pip install formed\n</code></pre> <p>If you want to use integrations, install the corresponding extra packages:</p> <pre><code>pip install formed[mlflow]\npip install formed[torch]\npip install formed[flax]\npip install formed[transformers]\npip install formed[sentence-transformers]\npip install formed[all]  # install all integrations\n</code></pre>"},{"location":"quick_start/#basic-usage","title":"Basic Usage","text":"<p>This section walks you through building a simple workflow to explore properties of the Collatz sequence. You'll learn the fundamental workflow of formed:</p> <ol> <li>Define steps as reusable computation units</li> <li>Define a workflow configuration that connects steps</li> <li>Configure formed settings</li> <li>Run the workflow via CLI</li> <li>Inspect the results programmatically</li> </ol>"},{"location":"quick_start/#1-define-steps","title":"1. Define Steps","text":"<p>Steps are the building blocks of workflows. Each step is a Python function decorated with <code>@workflow.step</code>:</p> <pre><code># collatz.py\n\nfrom collections.abc import Iterator\nfrom formed import workflow\n\n\n@workflow.step\ndef generate_collatz(init: int) -&gt; Iterator[int]:\n    n = init\n    while n != 1:\n        yield n\n        if n % 2 == 0:\n            n //= 2\n        else:\n            n = 3 * n + 1\n    yield 1\n\n\n@workflow.step\ndef count_steps(sequence: Iterator[int]) -&gt; int:\n    return sum(1 for _ in sequence) - 1\n\n\n@workflow.step\ndef max_value(sequence: Iterator[int]) -&gt; int:\n    return max(sequence)\n\n\n@workflow.step\ndef summarize(**kwargs: int) -&gt; dict[str, int]:\n    logger = workflow.use_step_logger(__name__)\n    logger.info(f\"Summary: {kwargs}\")\n    return kwargs\n</code></pre> <p>Each step is automatically cached based on its inputs and source code, so re-running the workflow will skip unchanged steps.</p>"},{"location":"quick_start/#2-define-workflow","title":"2. Define Workflow","text":"<p>Workflows are defined using Jsonnet (or JSON) configuration files. The configuration specifies which steps to run and how to connect their inputs and outputs:</p> <pre><code>// config.jsonnet\n\n{\n    steps: {\n        collatz_sequence: {\n            type: \"generate_collatz\",\n            init: 7,\n        },\n        step_count: {\n            type: \"count_steps\",\n            sequence: {type: \"ref\", ref: \"collatz_sequence\"},\n        },\n        summary: {\n            type: \"summarize\",\n            step_count: {type: \"ref\", ref: \"step_count\"},\n        },\n    }\n}\n</code></pre> <p>The <code>type</code> field specifies which step function to use, and other fields are passed as arguments. Use <code>{type: \"ref\", ref: \"step_name\"}</code> to reference outputs from other steps.</p>"},{"location":"quick_start/#3-configure-formed","title":"3. Configure Formed","text":"<pre><code># formed.yml\n\nworkflow:\n  organizer:\n    type: filesystem\n\nrequired_modules:\n  - collatz\n</code></pre> <p>The <code>formed.yml</code> file configures how formed manages workflows:</p> <ul> <li><code>workflow.organizer</code>: Specifies how to store and manage workflow execution results. The <code>filesystem</code> organizer saves results to local files in the <code>.formed</code> directory.</li> <li><code>required_modules</code>: Lists Python modules containing step definitions. Formed automatically loads these modules and all their submodules, making steps available for use in workflows.</li> </ul>"},{"location":"quick_start/#4-run-workflow","title":"4. Run Workflow","text":"<p>Execute the workflow from the command line in the same directory as <code>formed.yml</code>:</p> <pre><code>formed workflow run config.jsonnet --execution-id ex1\n</code></pre> <p>The <code>--execution-id</code> flag assigns a unique identifier to this execution, allowing you to retrieve results later. Formed will execute the workflow DAG, caching each step's results.</p>"},{"location":"quick_start/#5-check-results","title":"5. Check Results","text":"<p>After execution completes, you can programmatically access the results:</p> <pre><code>from formed import workflow\nfrom formed.settings import load_formed_settings\n\nsettings = load_formed_settings(\"formed.yml\")\norganizer = settings.organizer\n\ncontext = organizer.get(workflow.WorkflowExecutionID(\"ex1\"))\nassert context is not None\n\nsummary = context.cache[context.info.graph[\"summary\"]]\n</code></pre> <p>The <code>organizer.get()</code> method retrieves the execution context by ID, and <code>context.cache</code> provides access to cached step results. You can use step names (like <code>\"summary\"</code>) to look up results in the workflow graph.</p> <p>For more details on workflow concepts and advanced features, see the Workflow Guide.</p>"},{"location":"quick_start/#python-api","title":"Python API","text":"<p>You can also define and run workflows entirely in Python without configuration files:</p> <pre><code>import logging\nfrom formed import workflow\n\nlogging.basicConfig(level=logging.INFO)\norganizer = workflow.MemoryWorkflowOrganizer()\nexecutor = workflow.DefaultWorkflowExecutor()\ngraph = workflow.WorkflowGraph.from_config(\n    {\n        \"steps\": {\n            \"collatz_sequence\": {\n                \"type\": \"generate_collatz\",\n                \"init\": 7,\n            },\n            \"step_count\": {\n                \"type\": \"count_steps\",\n                \"sequence\": {\"type\": \"ref\", \"ref\": \"collatz_sequence\"},\n            },\n            \"summary\": {\n                \"type\": \"summarize\",\n                \"step_count\": {\"type\": \"ref\", \"ref\": \"step_count\"},\n            },\n        }\n    }\n)\ncontext = organizer.run(executor, graph)\nprint(f\"{context.cache[context.info.graph['summary']]=}\")\n</code></pre> <p>This approach uses <code>MemoryWorkflowOrganizer</code> to store results in memory instead of on disk, which is useful for quick experiments and testing.</p>"},{"location":"quick_start/#working-with-integrations","title":"Working with Integrations","text":"<p>Formed integrates with popular tools like MLflow, PyTorch, and \ud83e\udd17 Transformers. This example demonstrates using MLflow to track experiments.</p> <p>First, install the MLflow integration:</p> <pre><code>pip install formed[mlflow]\n</code></pre> <p>Then update your <code>formed.yml</code> to use the MLflow organizer:</p> <pre><code># formed.yml\n\nworkflow:\n  organizer:\n-   type: filesystem\n+   type: mlflow\n+   experiment_name: collatz\n\nrequired_modules:\n  - collatz\n+ - formed.integrations.mlflow\n</code></pre> <p>The MLflow organizer automatically logs workflow executions as MLflow runs, including parameters, metrics, and artifacts.</p> <p>Run the workflow as before:</p> <pre><code>formed workflow run config.jsonnet --execution-id ex1\n</code></pre> <p>View the results in the MLflow UI:</p> <pre><code>mlflow ui\n</code></pre> <p>This integration allows you to track experiments, compare results, and manage model versions using MLflow's interface. For more integration examples, see the Tutorials.</p>"},{"location":"quick_start/#further-reading","title":"Further Reading","text":"<ul> <li>Tutorials: Practical examples including text classification and language model fine-tuning</li> <li>Guides: In-depth explanations of workflow concepts, caching, and advanced features</li> <li>API Reference: Complete API documentation for all modules and integrations</li> </ul>"},{"location":"guides/","title":"Guides","text":"<ul> <li>Workflow</li> <li>Integrations<ul> <li>ML</li> <li>Torch</li> </ul> </li> </ul>"},{"location":"guides/workflow/","title":"Workflow Guide","text":""},{"location":"guides/workflow/#overview","title":"Overview","text":"<p>Formed's workflow system provides a flexible framework for organizing computational pipelines with automatic caching, dependency tracking, and reproducible execution. This guide explains the core concepts and how to work with workflows using Python and Jsonnet/JSON configuration files.</p>"},{"location":"guides/workflow/#core-concepts","title":"Core Concepts","text":""},{"location":"guides/workflow/#architecture-components","title":"Architecture Components","text":"<p>Formed's workflow system is built around the following core components:</p> <ul> <li><code>WorkflowStep</code></li> <li>The fundamental unit of computation, defined using the <code>@workflow.step</code> decorator</li> <li>Each step represents a reusable, cacheable processing unit</li> <li><code>WorkflowGraph</code></li> <li>A Directed Acyclic Graph (DAG) that defines dependencies between steps</li> <li>Built from Jsonnet/JSON configuration files</li> <li><code>WorkflowExecutor</code></li> <li>Executes the DAG based on dependency relationships</li> <li>Provides sequential execution with automatic dependency resolution</li> <li><code>WorkflowCallback</code></li> <li>Provides hooks for additional processing at step start/end and execution start/end</li> <li>Useful for experiment tracking, monitoring execution results, and integration with experiment management tools</li> <li><code>WorkflowCache</code></li> <li>Loads and restores step execution results based on content-based hashes</li> <li>Enables automatic memoization and reproducible experiments</li> <li><code>Format</code></li> <li>Handles serialization and deserialization of execution results</li> <li>Can be configured per-step (e.g., <code>pickle</code>, <code>json</code>, custom formats)</li> <li><code>WorkflowOrganizer</code></li> <li>Manages workflow execution and results</li> <li>Multiple organizer types available: <code>memory</code>, <code>filesystem</code>, <code>mlflow</code></li> <li>Configured via <code>formed.yml</code></li> </ul>"},{"location":"guides/workflow/#how-workflows-execute","title":"How Workflows Execute","text":"<p>Workflows are executed as Directed Acyclic Graphs (DAGs) where:</p> <ul> <li>Dependency resolution: The executor determines execution order based on step dependencies</li> <li>Content-based caching: Each step has a fingerprint computed from its source code and parameters</li> <li>Steps are only re-executed when their fingerprint changes</li> <li>Code changes are detected via AST structure, so comments and whitespace changes are ignored</li> <li>Automatic memoization: Results are cached and restored based on fingerprints</li> <li>Enables reproducible experiments and efficient re-execution</li> </ul>"},{"location":"guides/workflow/#working-with-steps","title":"Working with Steps","text":""},{"location":"guides/workflow/#defining-steps","title":"Defining Steps","text":"<p>The most basic way to define a step is to decorate a function with <code>@workflow.step</code>:</p> <pre><code>from formed import workflow\n\n@workflow.step\ndef your_awesome_step(x: int, y: int) -&gt; int:\n    return x + y\n</code></pre> <p>Default behavior:</p> <ul> <li>Caching: Results are automatically cached based on content-addressed fingerprints</li> <li>Format auto-selection: Storage format is automatically chosen based on data type</li> <li>JSON-compatible values and dataclass objects are saved as JSON</li> <li>Other objects are serialized using cloudpickle</li> <li>Change detection: Steps are re-executed when argument values or function code changes</li> <li>Code changes are detected via AST structure, so comments and whitespace changes are ignored</li> <li>Jsonnet reference: Steps are referenced in Jsonnet using <code>type: '&lt;function_name&gt;'</code></li> <li>Example: <code>{ steps: { result: { type: 'your_awesome_step', x: 123, y: 456 } } }</code></li> </ul>"},{"location":"guides/workflow/#step-behavior-and-customization","title":"Step Behavior and Customization","text":"<p>You can customize step behavior using decorator parameters and type annotations:</p> <pre><code>from typing import Annotated\nfrom formed.workflow import WorkflowStepArgFlag\n\n@workflow.step(\n    name=\"my::awesome_step\",   # Custom name for the step\n    version=\"001\",             # Manual version control\n    deterministic=True,        # Declare step determinism\n    cacheable=True,            # Enable/disable caching\n    format=\"json\",             # Specify cache format\n)\ndef your_awesome_step(\n    x: int,\n    y: Annotated[int, WorkflowStepArgFlag.IGNORE],  # Exclude from fingerprint\n) -&gt; int:\n    return x + y\n</code></pre> <p>Decorator parameters:</p> <ul> <li><code>name</code>: Assign a custom name instead of using the function name</li> <li>Useful for namespacing or when refactoring function names</li> <li><code>version</code>: Manual version string for the step</li> <li>When specified, AST-based change detection is disabled</li> <li>Increment this when you want to force cache invalidation</li> <li><code>deterministic</code>: Flag indicating whether the step is deterministic</li> <li>Set to <code>False</code> to prevent caching (e.g., for steps with random behavior or side effects)</li> <li><code>cacheable</code>: Explicitly enable/disable caching (default: <code>True</code>)</li> <li>Use <code>False</code> for steps that should always re-execute</li> <li><code>format</code>: Specify the serialization format for results</li> <li>Can be a string (e.g., <code>\"json\"</code>, <code>\"pickle\"</code>) or a <code>Format</code> class instance</li> </ul> <p>Argument annotations:</p> <ul> <li><code>WorkflowStepArgFlag.IGNORE</code>: Exclude specific arguments from the step's fingerprint</li> <li>Changes to these arguments won't trigger re-execution</li> <li>Useful for runtime configuration that doesn't affect results (e.g., device selection, logging verbosity)</li> </ul>"},{"location":"guides/workflow/#step-runtime-context","title":"Step Runtime Context","text":"<p>Steps can access runtime context and utilities during execution:</p> <pre><code>from formed.workflow import use_step_context, use_step_logger, use_step_workdir\n\n@workflow.step\ndef my_step(x: int) -&gt; int:\n    # Access step context (info, state, fingerprint, etc.)\n    context = use_step_context()\n\n    # Access step-specific logger\n    logger = use_step_logger()\n    logger.info(f\"Processing {x}\")\n\n    # Access step-specific working directory\n    workdir = use_step_workdir()\n    # Save temporary files to workdir\n\n    return x * 2\n</code></pre> <p>These context managers provide: - <code>use_step_context()</code>: Access to step metadata and execution state - <code>use_step_logger()</code>: Step-specific logger instance - <code>use_step_workdir()</code>: Dedicated working directory for the step</p>"},{"location":"guides/workflow/#working-with-configurations","title":"Working with Configurations","text":""},{"location":"guides/workflow/#configuration-structure","title":"Configuration Structure","text":"<p>Workflows are defined using Jsonnet or JSON configuration files with the following structure:</p> <pre><code>{\n  steps: {                                      // Required root key\n    dataset: {                                  // Arbitrary name for the step result\n      type: 'generate_dataset',                 // Name of the step defined in Python\n      size: 100                                 // Step arguments\n    },\n    model: {\n      type: 'train_model',\n      dataset: { type: 'ref', ref: 'dataset' }  // Reference another step's result\n    }\n  }\n}\n</code></pre> <p>Key concepts:</p> <ul> <li><code>steps</code>: Required root object containing all workflow steps</li> <li>Step names: Arbitrary identifiers for step results (e.g., <code>dataset</code>, <code>model</code>)</li> <li><code>type</code>: The registered name of the step (function or class)</li> <li>Step references: Use <code>{ type: 'ref', ref: 'step_name' }</code> to pass one step's output as another step's input</li> <li>Arguments: All other keys in the step object are passed as arguments to the step</li> </ul>"},{"location":"guides/workflow/#basic-workflow-example","title":"Basic Workflow Example","text":"<p>1. Define steps in Python:</p> <pre><code># my_project.py\nfrom formed import workflow\n\n@workflow.step\ndef add_two_integers(a: int, b: int) -&gt; int:\n    return a + b\n</code></pre> <p>2. Write Jsonnet configuration:</p> <p>Specify the step using <code>type</code> and provide corresponding arguments:</p> <pre><code>// config.jsonnet\n{\n  steps: {\n    result: {\n      type: 'add_two_integers',\n      a: 1,\n      b: 2\n    }\n  }\n}\n</code></pre> <p>3. Configure required modules:</p> <p>In <code>formed.yml</code>, specify the Python modules containing your steps in <code>required_modules</code>. All submodules under the specified modules will also be loaded:</p> <pre><code># formed.yml\nrequired_modules:\n  - my_project\n</code></pre> <p>4. Execute from command line:</p> <pre><code>$ ls\nconfig.jsonnet  formed.yml  my_project.py\n\n$ formed workflow run config.jsonnet\n</code></pre>"},{"location":"guides/workflow/#advanced-configuration-patterns","title":"Advanced Configuration Patterns","text":""},{"location":"guides/workflow/#object-construction","title":"Object Construction","text":"<p>altescy/colt automatically maps configuration to Python objects based on type hints and function signatures:</p> <pre><code>class AwesomeProcessor:\n    def __init__(self, name: str):\n        ...\n\n@workflow.step\ndef do_experiment(processor: AwesomeProcessor):\n    ...\n</code></pre> <p>The following configuration automatically constructs an <code>AwesomeProcessor</code> instance and passes it to <code>do_experiment</code>:</p> <pre><code>{\n  steps: {\n    experiment: {\n      type: 'do_experiment',\n      processor: {\n        name: \"Alice\"  // Maps to AwesomeProcessor.__init__ parameters\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/workflow/#using-registrable","title":"Using Registrable","text":"<p>Use <code>colt.Registrable</code> to register classes with a common interface, making it easy to inject and swap logic:</p> <pre><code>import colt\n\nclass BaseCallback(colt.Registrable):\n    ...\n\n@BaseCallback.register(\"log\")\nclass LoggingCallback(BaseCallback):\n    ...\n\n@BaseCallback.register(\"notify\")\nclass NotificationCallback(BaseCallback):\n    ...\n\n@workflow.step\ndef train_model(..., callbacks: list[BaseCallback]):\n    ...\n</code></pre> <p>In the configuration, registered types can be referenced by their registration names:</p> <pre><code>{\n  steps: {\n    model: {\n      type: 'train_model',\n      ...,\n      callbacks: [\n        { type: 'log', ... },      // LoggingCallback\n        { type: 'notify', ... }    // NotificationCallback\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"guides/workflow/#direct-module-references","title":"Direct Module References","text":"<p>Use the <code>type: 'path.to:ClassName'</code> notation to reference any class or function from any module:</p> <pre><code>@workflow.step\ndef train_sklearn(model, X, y):\n    ...\n</code></pre> <pre><code>{\n  steps: {\n    model: {\n      type: 'train_sklearn',\n      model: {\n        type: 'sklearn.ensemble:RandomForestClassifier',\n        n_estimators: 100,\n      },\n      ...\n    }\n  }\n}\n</code></pre> <p>Syntax: <code>'module.path:ClassName'</code> or <code>'module.path:function_name'</code></p> <p>This allows you to use any Python object without pre-registration.</p>"},{"location":"guides/workflow/#json-schema-support","title":"JSON Schema Support","text":"<p>The <code>formed workflow schema</code> command generates a JSON Schema for your workflow configuration:</p> <pre><code>formed workflow schema --output schema.json\n</code></pre> <p>Use this schema with JSON Schema-compatible LSP (Language Server Protocol) implementations for: - Auto-completion - Type validation - Documentation on hover</p> <p>Reference the schema in your configuration file:</p> <pre><code>{\n  \"$schema\": \"./schema.json\",\n  \"steps\": {\n    ...\n  }\n}\n</code></pre> <p>This enables IDE support for efficient configuration writing with validation and auto-completion.</p>"},{"location":"guides/integrations/ml/","title":"ML Integration Guide","text":""},{"location":"guides/integrations/ml/#overview","title":"Overview","text":"<p>The <code>formed.integrations.ml</code> module provides framework-agnostic machine learning utilities organized into three main components:</p> <ul> <li>Data Transformation: Type-safe, composable transformations with automatic batching using <code>BaseTransform</code> and <code>DataModule</code></li> <li>Metrics: Various metrics for classification, regression, and ranking tasks with a consistent interface</li> <li>DataLoader: Utilities for efficient data loading and batching in training pipelines</li> </ul>"},{"location":"guides/integrations/ml/#data-transformation","title":"Data Transformation","text":""},{"location":"guides/integrations/ml/#overview_1","title":"Overview","text":"<p>The data transformation system provides a structured way to convert raw data into model-ready batches:</p> <ul> <li>BaseTransform: Base class for field-level transformations (e.g., tokenization, label indexing)</li> <li>DataModule: Container for composing multiple transforms with nested structure preservation</li> <li>Transformation pipeline: Raw data \u2192 <code>instance()</code> \u2192 batchable instances \u2192 <code>batch()</code> \u2192 batches</li> </ul>"},{"location":"guides/integrations/ml/#basic-example","title":"Basic Example","text":"<pre><code>from typing import Any, Generic\n\nfrom formed.common.iterutils import batched\nfrom formed.integrations import ml\n\n# Define field-level transformations using DataModule\n# Fields with BaseTransform types are automatically batched\nclass TextClassificationDataModule(ml.DataModule):\n    id: ml.MetadataTransform\n    text: ml.Tokenizer\n    label: ml.Extra[ml.LabelIndexer] = ml.Extra.default()  # Use Extra for optional fields (e.g., absent during inference)\n\n\ntrain_dataset = [\n    {\"id\": \"1\", \"text\": \"I love programming.\", \"label\": \"positive\"},\n    {\"id\": \"2\", \"text\": \"I hate bugs.\", \"label\": \"negative\"},\n]\ntest_dataset = [\n    {\"id\": \"3\", \"text\": \"Debugging is fun.\", \"label\": \"positive\"},\n    {\"id\": \"4\", \"text\": \"I dislike errors.\", \"label\": \"negative\"},\n]\n\ndatamodule = TextClassificationDataModule(\n    id=ml.MetadataTransform(),\n    text=ml.Tokenizer(),\n    label=ml.LabelIndexer(),\n)\n\n# Build vocabularies and label sets\nwith datamodule.train():\n    # Convert raw data to batchable instances using datamodule.instance()\n    train_instances = [datamodule.instance(example) for example in train_dataset]\n\ntest_instances = [datamodule.instance(example) for example in test_dataset]\n\n# Create batches using datamodule.batch()\n# The DataModule structure is preserved in batched form\nfor batch in map(datamodule.batch, batched(train_instances, batch_size=2)):\n    print(\"Train Batch:\", batch)\n    # Train Batch: TextClassificationDataModule(\n    #   id=['1', '2'],\n    #   text=Tokenizer(\n    #     surfaces=IDSequenceBatch(\n    #       ids=array([[1, 4, 5], [1, 3, 2]]),\n    #       mask=array([[ True,  True,  True], [ True,  True,  True]])\n    #     ),\n    #   ),\n    #   label=array([0, 1]),\n    # )\n</code></pre>"},{"location":"guides/integrations/ml/#basetransform","title":"BaseTransform","text":"<p><code>BaseTransform</code> is the base class for all transformations, providing two key methods:</p> <ul> <li><code>instance(...)</code>: Converts raw input data into a batchable instance</li> <li><code>batch(...)</code>: Converts a sequence of instances into a batch</li> </ul> <p>Preprocessing with accessors:</p> <p>Use the <code>accessor</code> parameter to specify which field to process or apply preprocessing:</p> <ul> <li><code>SomeTransform(..., accessor=\"path.to.field\")</code> extracts data from nested structures using dot notation</li> <li><code>SomeTransform(..., accessor=lambda raw: ...)</code> applies custom extraction logic with a function</li> </ul> <p>This allows transforms to work with complex nested data structures without modifying the transform implementation.</p>"},{"location":"guides/integrations/ml/#datamodule","title":"DataModule","text":"<p><code>DataModule</code> is a transformation module for handling nested data structures:</p> <ul> <li>Inherit from <code>DataModule</code> and assign <code>BaseTransform</code> or nested <code>DataModule</code> instances to fields</li> <li>Each field defines how that data element should be transformed</li> <li>The structure is preserved through the transformation pipeline (raw \u2192 instance \u2192 batch)</li> </ul> <p>Key features:</p> <ul> <li>Composability: Nest DataModules to handle complex hierarchical data</li> <li>Type preservation: Field structure is maintained across transformations</li> <li>Training mode: Use <code>with datamodule.train():</code> context to build vocabularies and other statistics</li> </ul>"},{"location":"guides/integrations/ml/#type-system","title":"Type System","text":"<p>DataModule has three modes that control field types and behavior:</p> <ul> <li><code>AsConverter</code>: Data transformation mode providing <code>instance()</code> and <code>batch()</code> methods</li> <li>This is the default mode when you create a DataModule instance</li> <li>Provides methods for transforming data</li> <li><code>AsInstance</code>: Data container mode for pre-batch data</li> <li><code>instance()</code> returns <code>DataModule[AsInstance]</code></li> <li>Represents individual examples ready for batching</li> <li><code>AsBatch</code>: Data container mode for batched data</li> <li><code>batch()</code> returns <code>DataModule[AsBatch]</code></li> <li>Represents batched data ready for model input</li> </ul> <p>Proper type annotations allow type checkers to track types across transformation stages:</p> <pre><code>from typing import TypeVar\nfrom formed.integrations.ml import types as mlt\n\nT = TypeVar(\"T\")\n\nclass TextClassificationDataModule(\n    ml.DataModule[\n        mlt.DataModuleModeT,                                # DataModule mode\n        T,                                                  # Type accepted by instance()\n        \"TextClassificationDataModule[mlt.AsInstance]\",     # Type returned by instance() / accepted by batch()\n        \"TextClassificationDataModule[mlt.AsBatch]\",        # Type returned by batch()\n    ]\n):\n    id: ml.MetadataTransform\n    text: ml.Tokenizer\n    label: ml.Extra[ml.LabelIndexer] = ml.Extra.default()\n\n...\n\ndatamodule = TextClassificationDataModule(...)\ndatamodule.text.surfaces      # Type checker recognizes this as TokenSequenceIndexer\ndatamodule.text.surfaces.ids  # Type error!\n\nbatch = datamodule.batch(instances)\nbatch.text.surfaces     # Now recognized as IDSequenceBatch\nbatch.text.surfaces.ids # OK: numpy.ndarray\n</code></pre>"},{"location":"guides/integrations/ml/#special-field-types","title":"Special Field Types","text":"<p>The ML integration provides special field descriptors for common patterns:</p> <ul> <li><code>Extra</code>: Marks fields that may be absent in some contexts (e.g., labels during inference)</li> <li>Use <code>Extra[SomeTransform]</code> to declare optional fields</li> <li>Fields marked with <code>Extra</code> can be omitted from input data without errors</li> <li> <p>Example: <code>label: ml.Extra[ml.LabelIndexer] = ml.Extra.default()</code></p> </li> <li> <p><code>Param</code>: Marks fields that should not be transformed (passed through as-is)</p> </li> <li>Use <code>Param</code> for metadata or configuration that doesn't need transformation</li> <li>These fields bypass the transformation pipeline</li> </ul>"},{"location":"guides/integrations/ml/#metrics","title":"Metrics","text":""},{"location":"guides/integrations/ml/#overview_2","title":"Overview","text":"<p>The <code>ml.metrics</code> module implements various metrics for machine learning tasks with a consistent interface:</p> <p>Metric lifecycle: - <code>update(...)</code>: Update internal state with predictions and targets - <code>compute()</code>: Calculate final metrics and return as a dictionary - <code>reset()</code>: Reset internal state for the next evaluation round</p> <p>This pattern supports incremental metric computation across multiple batches.</p>"},{"location":"guides/integrations/ml/#basic-usage","title":"Basic Usage","text":"<pre><code>from formed.integrations import ml\n\nmetric = ml.MulticlassAccuracy(average=\"macro\")\nmetric.update(\n    ml.MulticlassAccuracy.Input(\n        predictions=[0, 2, 1, 3],\n        targets=[0, 1, 2, 3],\n    ),\n)\nmetrics = metric.compute()  # =&gt; {\"accuracy\": 0.5}\nmetric.reset()\n</code></pre> <p>Available metrics include:</p> <ul> <li>Classification: Accuracy, Precision, Recall, F-beta, etc.</li> <li>Regression: MAE, MSE, RMSE, R\u00b2, etc.</li> <li>Ranking: MRR, NDCG, etc.</li> <li>Utilities: Average (for tracking losses and other scalars)</li> </ul>"},{"location":"guides/integrations/ml/#building-evaluators","title":"Building Evaluators","text":"<p>Use base metric classes (e.g., <code>MulticlassClassificationMetric</code>) to build reusable, configurable evaluators:</p> <pre><code>from typing import NamedTuple, Sequence\nimport numpy\n\nclass ClassificationBatch(NamedTuple):\n    data: ...\n    label: numpy.ndarray | None\n\n\nclass ClassifierOutput(NamedTuple):\n    label: numpy.ndarray\n    loss: float | None\n\n\nclass ClassificationEvaluator:\n    def __init__(self, metrics: Sequence[ml.MulticlassClassificationMetric]) -&gt; None:\n        self._loss = ml.Average(\"loss\")\n        self._metrics = metrics\n\n    def update(\n        self,\n        inputs: ClassificationBatch,\n        output: ClassifierOutput,\n    ) -&gt; None:\n        if output.loss is not None:\n            self._loss.update([output.loss])\n        if inputs.label is not None:\n            predictions = output.label.tolist()\n            targets = inputs.label.tolist()\n            for metric in self._metrics:\n                metric.update(metric.Input(predictions=predictions, targets=targets))\n\n    def compute(self) -&gt; dict[str, float]:\n        metrics = self._loss.compute()\n        for metric in self._metrics:\n            metrics.update(metric.compute())\n        return metrics\n\n    def reset(self) -&gt; None:\n        self._loss.reset()\n        for metric in self._metrics:\n            metric.reset()\n\n\nevaluator = ClassificationEvaluator(\n    metrics=[\n        ml.MulticlassAccuracy(average=\"macro\"),\n        ml.MulticlassFBeta(average=\"macro\"),\n    ]\n)\n</code></pre> <p>This pattern provides:</p> <ul> <li>Common interface: Unified API across different metric types</li> <li>Configurable composition: Mix and match metrics for different tasks</li> <li>Task-specific logic: Encapsulate evaluation logic per task</li> </ul>"},{"location":"guides/integrations/ml/#dataloader","title":"DataLoader","text":""},{"location":"guides/integrations/ml/#overview_3","title":"Overview","text":"<p>The <code>ml.DataLoader</code> class provides efficient data loading utilities for training pipelines. It combines three key components:</p> <ul> <li>BatchSampler: Generates batch indices (which items to include in each batch)</li> <li>Collator: Transforms a sequence of items into a batch</li> <li>DataLoader: Orchestrates sampling and collation with optional prefetching</li> </ul> <p>This separation of concerns allows flexible configuration of batching strategies independent of data transformation logic.</p>"},{"location":"guides/integrations/ml/#core-components","title":"Core Components","text":""},{"location":"guides/integrations/ml/#batchsampler","title":"BatchSampler","text":"<p><code>BaseBatchSampler</code> generates sequences of indices for batching:</p> <p>BasicBatchSampler - Standard batching with shuffle support:</p> <pre><code>from formed.integrations import ml\n\nsampler = ml.BasicBatchSampler(\n    batch_size=32,\n    shuffle=True,      # Shuffle data before batching\n    drop_last=False,   # Keep incomplete final batch\n    seed=0,            # Random seed for reproducibility\n)\n</code></pre> <p>SizeOrderedBucketBatchSampler - Batch by item size for efficiency:</p> <pre><code>sampler = ml.SizeOrderedBucketBatchSampler(\n    attribute=\"text\",  # Attribute to determine size (or callable)\n    batch_size=32,\n    shuffle=True,      # Shuffle batches (not items within batches)\n    drop_last=False,\n)\n</code></pre> <p>This sampler:</p> <ol> <li>Sorts items by size (e.g., sequence length)</li> <li>Groups consecutive items into batches</li> <li>Optionally shuffles the batches</li> </ol> <p>Benefits:</p> <ul> <li>Reduces padding in batches (items have similar sizes)</li> <li>Improves training efficiency and memory usage</li> <li>Particularly useful for variable-length sequences</li> </ul>"},{"location":"guides/integrations/ml/#collator","title":"Collator","text":"<p>The collator is a function that transforms a sequence of items into a batch. Common patterns:</p> <p>Using DataModule's batch method:</p> <pre><code># DataModule.batch is a perfect collator\ncollator = datamodule.batch\n</code></pre> <p>Custom collator function:</p> <pre><code>import numpy as np\n\ndef custom_collator(items):\n    # Stack features and labels\n    features = np.stack([item.features for item in items])\n    labels = np.array([item.label for item in items])\n    return {\"features\": features, \"labels\": labels}\n</code></pre>"},{"location":"guides/integrations/ml/#dataloader_1","title":"DataLoader","text":"<p><code>DataLoader</code> combines sampler and collator to create batched iterators:</p> <pre><code>from formed.integrations import ml\n\nloader = ml.DataLoader(\n    sampler=ml.BasicBatchSampler(batch_size=32, shuffle=True),\n    collator=datamodule.batch,\n    buffer_size=0,  # Optional prefetch buffer (see below)\n)\n\n# Create batched iterator from dataset\nfor batch in loader(instances):\n    # Process batch\n    ...\n</code></pre>"},{"location":"guides/integrations/ml/#basic-usage_1","title":"Basic Usage","text":"<p>Complete example with DataModule integration:</p> <pre><code>from formed.integrations import ml\nfrom formed.common.iterutils import batched\n\n# 1. Define DataModule\nclass MyDataModule(ml.DataModule):\n    features: ml.TensorTransform\n    label: ml.LabelIndexer\n\ndatamodule = MyDataModule(\n    features=ml.TensorTransform(),\n    label=ml.LabelIndexer(),\n)\n\n# 2. Create instances\nwith datamodule.train():\n    train_instances = [datamodule.instance(ex) for ex in train_data]\ntest_instances = [datamodule.instance(ex) for ex in test_data]\n\n# 3. Create DataLoader\ntrain_loader = ml.DataLoader(\n    sampler=ml.BasicBatchSampler(batch_size=32, shuffle=True),\n    collator=datamodule.batch,\n)\n\n# 4. Iterate over batches\nfor batch in train_loader(train_instances):\n    # batch is MyDataModule[AsBatch] with properly batched fields\n    ...\n</code></pre>"},{"location":"guides/integrations/ml/#advanced-features","title":"Advanced Features","text":""},{"location":"guides/integrations/ml/#prefetch-buffering","title":"Prefetch Buffering","text":"<p>When collation is expensive, use buffering to prefetch batches in a background process:</p> <pre><code>from formed.common.ctxutils import closing\n\nloader = ml.DataLoader(\n    sampler=ml.BasicBatchSampler(batch_size=32, shuffle=True),\n    collator=datamodule.batch,\n    buffer_size=10,  # Prefetch up to 10 batches in background\n)\n\n# Use with context manager for proper cleanup\nwith closing(loader(instances)) as batches:\n    for batch in batches:\n        # Process batch while next batches are prepared\n        ...\n</code></pre> <p>Important notes:</p> <ul> <li>Collator and referenced objects must be picklable (for multiprocessing)</li> <li>Always use context manager (<code>closing</code>) to ensure background process cleanup</li> <li>Adjust <code>buffer_size</code> based on collation cost and memory constraints</li> </ul>"},{"location":"guides/integrations/ml/#size-ordered-batching-for-sequences","title":"Size-Ordered Batching for Sequences","text":"<p>For variable-length sequences, size-ordered batching reduces padding:</p> <pre><code># Instances have varying text lengths\nsampler = ml.SizeOrderedBucketBatchSampler(\n    attribute=\"text.surfaces\",  # Path to sequence field\n    batch_size=32,\n    shuffle=True,\n)\n\nloader = ml.DataLoader(sampler=sampler, collator=datamodule.batch)\n\nfor batch in loader(instances):\n    # Batch contains items with similar lengths\n    # Less padding \u2192 more efficient training\n    ...\n</code></pre> <p>Alternative: use callable for custom size extraction:</p> <pre><code>sampler = ml.SizeOrderedBucketBatchSampler(\n    attribute=lambda item: len(item.text.surfaces.ids),\n    batch_size=32,\n)\n</code></pre>"},{"location":"guides/integrations/ml/#workflow-integration","title":"Workflow Integration","text":""},{"location":"guides/integrations/ml/#datamodule-in-workflows","title":"DataModule in Workflows","text":"<p>DataModules can be constructed and used in Jsonnet workflow configurations:</p> <pre><code>{\n  steps: {\n    # 1. Load IMDB dataset from Huggingface Datasets\n    dataset: {\n      type: 'datasets::load_dataset',\n      path: 'stanfordnlp/imdb',\n      split: 'train[:100]',\n    },\n\n    # 2. Build DataModule and create instances\n    datamodule_and_instances: {\n      type: 'ml::train_datamodule_with_instances',\n      dataset: { type: 'ref', ref: 'dataset' },\n      datamodule: {\n        type: 'classification:TextClassificationDataModule',\n        id: { accessor: { type: 'classification:ExampleID' } },\n        text: {\n          type: 'formed.integrations.ml:Tokenizer',\n          surfaces: { unk_token: '&lt;UNK&gt;', min_df: 3, max_vocab_size: 10000 },\n          characters: { unk_token: '&lt;UNK&gt;', min_characters: 5 },\n        },\n        label: {},\n      },\n    },\n\n    # 3. Use the constructed DataModule and instances\n    model: {\n      type: 'your_training_step',\n      # Reference instances from previous step\n      train_dataset: { type: 'ref', ref: 'datamodule_and_instances.instances' },\n      train_dataloader: {\n        type: 'formed.integrations.ml:DataLoader',\n        # Reference batch function from DataModule\n        collator: { type: 'ref', ref: 'datamodule_and_instances.datamodule.batch' },\n      },\n      ...\n    },\n  },\n}\n</code></pre>"},{"location":"guides/integrations/ml/#workflow-patterns","title":"Workflow Patterns","text":"<p>Using <code>ml::train_datamodule_with_instances</code>:</p> <p>This built-in step builds DataModule vocabularies and creates instances in one operation:</p> <ul> <li>Takes a dataset and a DataModule configuration</li> <li>Returns both the fitted DataModule and processed instances</li> <li>Ensures vocabularies are built correctly in training mode</li> </ul> <p>Field references:</p> <p>Access specific fields from previous steps using dot notation:</p> <ul> <li><code>{ type: 'ref', ref: 'step_name.field_name' }</code> accesses nested fields</li> <li>Example: <code>'datamodule_and_instances.instances'</code> gets the instances field</li> </ul> <p>Method references:</p> <p>Reference DataModule methods directly in configurations:</p> <ul> <li><code>{ type: 'ref', ref: 'step_name.datamodule.batch' }</code> references the batch method</li> <li>Allows passing transformation functions as parameters</li> <li>Enables configuration-driven pipeline construction</li> </ul>"},{"location":"guides/integrations/torch/","title":"PyTorch Integration Guide","text":""},{"location":"guides/integrations/torch/#overview","title":"Overview","text":"<p>The <code>formed.integrations.torch</code> module provides comprehensive PyTorch integration for training deep learning models within the formed workflow system. It combines model definition, training infrastructure, and workflow integration with automatic caching and reproducibility.</p> <p>Design philosophy:</p> <p>This integration emphasizes declarative model composition through reusable, configurable modules. Rather than implementing models from scratch, you compose them from pre-built components (embedders, encoders, vectorizers, etc.) that can be fully specified in configuration files. This approach separates model architecture from implementation details and enables rapid experimentation.</p> <p>Key capabilities:</p> <ul> <li>Declarative Model Composition: Build models from reusable modules (<code>formed.integrations.torch.modules</code>)</li> <li>Configuration-Driven: Define complete models and training pipelines in Jsonnet/JSON</li> <li>Training Infrastructure: Complete training pipeline with callbacks, evaluation, and distributed training</li> <li>Workflow Integration: Built-in workflow steps for seamless integration with formed's caching system</li> <li>Distributed Training: Support for data parallelism across multiple devices</li> </ul>"},{"location":"guides/integrations/torch/#core-concepts","title":"Core Concepts","text":""},{"location":"guides/integrations/torch/#architecture-overview","title":"Architecture Overview","text":"<p>The PyTorch integration is organized around several key components that work together:</p> <pre><code>BaseTorchModel              # Model definition with forward pass\n     \u2193\nTorchTrainingEngine         # Loss computation and optimization logic\n     \u2193\nTorchTrainer                # Training loop coordination\n\u2502    \u2193 (uses)\n\u251c\u2500 DataLoader               # Batch iteration\n\u251c\u2500 BaseDistributor          # Device management and parallelism\n\u251c\u2500 TorchTrainingCallback    # Hooks for monitoring and control\n\u2514\u2500 Evaluator                # Metric computation\n     \u2193\ntrain_torch_model           # Workflow step for training\n</code></pre> <p>Component relationships:</p> <ol> <li>BaseTorchModel defines model architecture and forward pass</li> <li>TorchTrainingEngine implements training logic (loss, gradients, optimization)</li> <li>TorchTrainer orchestrates the training loop, calling the engine for each batch</li> <li>BaseDistributor manages device placement and distributed training</li> <li>TorchTrainingCallback provides hooks for custom behavior at various training stages</li> <li>train_torch_model wraps everything as a workflow step with caching</li> </ol>"},{"location":"guides/integrations/torch/#training-flow","title":"Training Flow","text":"<p>The typical training flow:</p> <ol> <li>Initialization: TorchTrainer creates TrainState from model and engine</li> <li>Epoch Loop: For each epoch:</li> <li>Load batches from train DataLoader</li> <li>Execute train_step via engine (forward + backward + optimize)</li> <li>Optionally evaluate on validation data</li> <li>Execute callbacks at appropriate points</li> <li>Log metrics according to logging strategy</li> <li>Completion: Return final model and training state</li> </ol>"},{"location":"guides/integrations/torch/#model-definition","title":"Model Definition","text":""},{"location":"guides/integrations/torch/#basetorchmodel","title":"BaseTorchModel","text":"<p><code>BaseTorchModel</code> is the base class for all PyTorch models in the framework. It combines <code>torch.nn.Module</code> with the registrable pattern for configuration-based instantiation.</p> <p>Type parameters:</p> <pre><code>BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT]\n</code></pre> <ul> <li>ModelInputT: Type of batched input (typically from DataModule)</li> <li>ModelOutputT: Type of model output (dict, NamedTuple, or custom dataclass)</li> <li>ModelParamsT: Type of additional parameters (usually <code>None</code> or a dataclass)</li> </ul> <p>Key features:</p> <ul> <li>Automatically compatible with TorchTrainer</li> <li>Can be registered and instantiated from configuration</li> <li>Supports automatic model serialization with <code>TorchModelFormat</code></li> </ul>"},{"location":"guides/integrations/torch/#declarative-model-composition","title":"Declarative Model Composition","text":"<p>The <code>formed.integrations.torch.modules</code> package provides reusable neural network modules that can be composed declaratively:</p> <p>Example - Text Classification Model:</p> <pre><code>from formed.integrations.torch import BaseTorchModel\nfrom formed.integrations.torch import modules as ftm\nfrom formed.integrations.ml import types as mlt\nimport dataclasses\nimport torch\n\n@dataclasses.dataclass\nclass ClassifierOutput:\n    probs: torch.Tensor\n    label: torch.Tensor\n    loss: torch.Tensor | None = None\n\n@BaseTorchModel.register(\"text_classifier\")\nclass TextClassifier(BaseTorchModel):\n    def __init__(\n        self,\n        num_classes: int,\n        embedder: ftm.BaseEmbedder,\n        encoder: ftm.BaseSequenceEncoder | None = None,\n        vectorizer: ftm.BaseSequenceVectorizer | None = None,\n        feedforward: ftm.FeedForward | None = None,\n        sampler: ftm.BaseLabelSampler | None = None,\n        loss: ftm.BaseClassificationLoss | None = None,\n        dropout: float = 0.1,\n    ):\n        super().__init__()\n\n        # Use defaults if not provided\n        vectorizer = vectorizer or ftm.BagOfEmbeddingsSequenceVectorizer()\n        sampler = sampler or ftm.ArgmaxLabelSampler()\n        loss = loss or ftm.CrossEntropyLoss()\n\n        # Determine output dimension through the pipeline\n        feature_dim = self._determine_feature_dim(\n            embedder, encoder, vectorizer, feedforward\n        )\n\n        self._embedder = embedder\n        self._encoder = encoder\n        self._vectorizer = vectorizer\n        self._feedforward = feedforward\n        self._dropout = torch.nn.Dropout(dropout)\n        self._classifier = torch.nn.Linear(feature_dim, num_classes)\n        self._sampler = sampler\n        self._loss = loss\n\n    def forward(self, inputs, params=None):\n        # inputs: batch from DataModule (e.g., TextClassificationDataModule[AsBatch])\n        embeddings, mask = self._embedder(inputs.text)\n\n        if self._encoder is not None:\n            embeddings = self._encoder(embeddings, mask=mask)\n\n        vector = self._vectorizer(embeddings, mask=mask)\n\n        if self._feedforward is not None:\n            vector = self._feedforward(vector)\n\n        vector = self._dropout(vector)\n        logits = self._classifier(vector)\n        probs = torch.nn.functional.softmax(logits, dim=-1)\n        label = self._sampler(logits)\n\n        loss = None\n        if inputs.label is not None:\n            loss = self._loss(logits, inputs.label)\n\n        return ClassifierOutput(probs=probs, label=label, loss=loss)\n</code></pre>"},{"location":"guides/integrations/torch/#available-modules","title":"Available Modules","text":"<p>The <code>formed.integrations.torch.modules</code> package provides building blocks for composing models. These modules form a typical NLP pipeline:</p> <ol> <li>Embedders - Convert tokens to embeddings (e.g., <code>TokenEmbedder</code>, <code>AnalyzedTextEmbedder</code>)</li> <li>Encoders - Process sequences with context (e.g., <code>LSTMSequenceEncoder</code>, <code>TransformerEncoder</code>)</li> <li>Vectorizers - Aggregate sequences to fixed-size vectors (e.g., <code>BagOfEmbeddingsSequenceVectorizer</code>)</li> <li>FeedForward - Additional transformation layers with configurable depth and activations</li> <li>Losses - Task-specific loss functions (e.g., <code>CrossEntropyLoss</code>, <code>BCEWithLogitsLoss</code>)</li> <li>Samplers - Convert logits to labels (e.g., <code>ArgmaxLabelSampler</code>, <code>MultinomialLabelSampler</code>)</li> </ol> <p>Additional modules include positional encoders, attention masks, and label weighters. See the API reference for complete details.</p>"},{"location":"guides/integrations/torch/#configuration-based-model-definition","title":"Configuration-Based Model Definition","text":"<p>Models composed from these modules can be fully specified in configuration:</p> <pre><code>{\n  model: {\n    type: 'text_classifier',\n    num_classes: 2,\n    embedder: {\n      type: 'token',\n      embedding_dim: 128,\n      vocab_size: 10000,\n    },\n    encoder: {\n      type: 'lstm',\n      hidden_size: 256,\n      num_layers: 2,\n      bidirectional: true,\n    },\n    vectorizer: {\n      type: 'bag_of_embeddings',\n    },\n    feedforward: {\n      input_dim: 512,  # 256 * 2 (bidirectional)\n      hidden_dims: [256, 128],\n      activations: 'relu',\n    },\n    dropout: 0.2,\n  },\n}\n</code></pre> <p>This declarative approach:</p> <ul> <li>Separates model architecture from implementation</li> <li>Enables easy experimentation with different configurations</li> <li>Maintains type safety through the pipeline</li> <li>Reduces boilerplate code</li> </ul>"},{"location":"guides/integrations/torch/#training-infrastructure","title":"Training Infrastructure","text":""},{"location":"guides/integrations/torch/#torchtrainingengine","title":"TorchTrainingEngine","text":"<p><code>TorchTrainingEngine</code> defines how models are trained by implementing state creation, training steps, and evaluation steps.</p> <p>DefaultTorchTrainingEngine - Standard training with automatic differentiation:</p> <pre><code>from formed.integrations.torch import DefaultTorchTrainingEngine\nimport torch.optim as optim\n\nengine = DefaultTorchTrainingEngine(\n    optimizer=optim.Adam,           # Optimizer class or factory\n    optimizer_params={\"lr\": 1e-3},  # Optimizer parameters\n    lr_scheduler=optim.lr_scheduler.StepLR,  # Optional scheduler\n    lr_scheduler_params={\"step_size\": 10, \"gamma\": 0.1},\n    loss=\"loss\",                    # Accessor for loss in model output\n    max_grad_norm=1.0,             # Optional gradient clipping\n    accumulation_steps=1,          # Gradient accumulation steps\n)\n</code></pre> <p>Loss specification:</p> <p>The <code>loss</code> parameter can be:</p> <ul> <li>A string accessor: <code>\"loss\"</code> extracts <code>output[\"loss\"]</code> or <code>output.loss</code></li> <li>A callable: <code>lambda output: output.loss + 0.1 * output.regularization</code></li> </ul> <p>Custom engines:</p> <p>Implement <code>TorchTrainingEngine</code> for custom training logic:</p> <pre><code>class CustomTrainingEngine(TorchTrainingEngine):\n    def create_state(self, trainer, model):\n        # Initialize optimizer, scheduler, etc.\n        optimizer = torch.optim.Adam(model.parameters())\n        return TrainState(model=model, optimizer=optimizer)\n\n    def train_step(self, inputs, state, trainer):\n        state.model.train()\n        state.optimizer.zero_grad()\n\n        output = state.model(inputs)\n        loss = output[\"loss\"]\n        loss.backward()\n\n        state.optimizer.step()\n        return output\n\n    def eval_step(self, inputs, state, trainer):\n        state.model.eval()\n        with torch.no_grad():\n            output = state.model(inputs)\n        return output\n</code></pre>"},{"location":"guides/integrations/torch/#torchtrainer","title":"TorchTrainer","text":"<p><code>TorchTrainer</code> orchestrates the complete training process, coordinating data loading, training steps, evaluation, callbacks, and logging.</p> <p>Basic usage:</p> <pre><code>from formed.integrations.torch import TorchTrainer, DefaultTorchTrainingEngine\nfrom formed.integrations.ml import DataLoader, BasicBatchSampler\nimport torch.optim as optim\n\n# Setup data loaders\ntrain_loader = DataLoader(\n    sampler=BasicBatchSampler(batch_size=32, shuffle=True),\n    collator=datamodule.batch,\n)\n\nval_loader = DataLoader(\n    sampler=BasicBatchSampler(batch_size=64),\n    collator=datamodule.batch,\n)\n\n# Create engine\nengine = DefaultTorchTrainingEngine(\n    optimizer=optim.Adam,\n    optimizer_params={\"lr\": 1e-3},\n)\n\n# Create trainer\ntrainer = TorchTrainer(\n    train_dataloader=train_loader,\n    val_dataloader=val_loader,\n    engine=engine,\n    max_epochs=10,\n    eval_strategy=\"epoch\",      # Evaluate every N epochs\n    eval_interval=1,\n    logging_strategy=\"step\",    # Log every N steps\n    logging_interval=100,\n)\n\n# Train model\nstate = trainer.train(model, train_instances, val_instances)\n</code></pre> <p>Configuration options:</p> <ul> <li>max_epochs: Maximum number of training epochs</li> <li>eval_strategy: When to evaluate - <code>\"epoch\"</code> or <code>\"step\"</code></li> <li>eval_interval: Evaluation frequency (number of epochs or steps)</li> <li>logging_strategy: When to log metrics - <code>\"epoch\"</code> or <code>\"step\"</code></li> <li>logging_interval: Logging frequency (number of epochs or steps)</li> <li>logging_first_step: Whether to log after the first training step</li> <li>train_prefix: Prefix for training metrics (default: <code>\"train/\"</code>)</li> <li>val_prefix: Prefix for validation metrics (default: <code>\"val/\"</code>)</li> </ul>"},{"location":"guides/integrations/torch/#trainstate","title":"TrainState","text":"<p><code>TrainState</code> encapsulates the training state, including model, optimizer, and counters:</p> <pre><code>@dataclasses.dataclass\nclass TrainState:\n    model: BaseTorchModel           # The model being trained\n    optimizer: IOptimizer           # Optimizer instance\n    lr_scheduler: ILRScheduler | None  # Optional LR scheduler\n    step: int = 0                   # Global step counter\n    epoch: int = 0                  # Current epoch\n    best_metric: float | None = None   # Best validation metric\n    metadata: dict[str, Any] = field(default_factory=dict)  # Custom metadata\n</code></pre> <p>The state is updated in-place during training and can be accessed in callbacks.</p>"},{"location":"guides/integrations/torch/#callbacks","title":"Callbacks","text":""},{"location":"guides/integrations/torch/#torchtrainingcallback","title":"TorchTrainingCallback","text":"<p>Callbacks provide hooks to execute custom logic at various points during training.</p> <p>Hook execution order:</p> <ol> <li><code>on_training_start</code> - Once at the beginning</li> <li><code>on_epoch_start</code> - At the start of each epoch</li> <li><code>on_batch_start</code> - Before each training batch</li> <li><code>on_batch_end</code> - After each training batch</li> <li><code>on_eval_start</code> - Before evaluation (returns evaluator)</li> <li><code>on_eval_end</code> - After evaluation with computed metrics</li> <li><code>on_log</code> - When metrics are logged</li> <li><code>on_epoch_end</code> - At the end of each epoch</li> <li><code>on_training_end</code> - Once at the end</li> </ol>"},{"location":"guides/integrations/torch/#built-in-callbacks","title":"Built-in Callbacks","text":""},{"location":"guides/integrations/torch/#evaluationcallback","title":"EvaluationCallback","text":"<p>Computes metrics using a custom evaluator:</p> <pre><code>from formed.integrations.torch import EvaluationCallback\nfrom formed.integrations.ml import MulticlassAccuracy\n\n# Define evaluator\nclass MyEvaluator:\n    def __init__(self):\n        self.accuracy = MulticlassAccuracy()\n\n    def update(self, inputs, output):\n        predictions = output[\"logits\"].argmax(dim=-1).tolist()\n        targets = inputs.label.tolist()\n        self.accuracy.update(\n            self.accuracy.Input(predictions=predictions, targets=targets)\n        )\n\n    def compute(self):\n        return self.accuracy.compute()\n\n    def reset(self):\n        self.accuracy.reset()\n\n# Use in trainer\ntrainer = TorchTrainer(\n    ...,\n    callbacks=[EvaluationCallback(MyEvaluator())],\n)\n</code></pre>"},{"location":"guides/integrations/torch/#earlystoppingcallback","title":"EarlyStoppingCallback","text":"<p>Stops training when a metric stops improving:</p> <pre><code>from formed.integrations.torch import EarlyStoppingCallback\n\ncallback = EarlyStoppingCallback(\n    patience=5,              # Number of evaluations without improvement\n    metric=\"-loss\",          # Metric to monitor (- prefix for minimization)\n    min_delta=0.0,          # Minimum change to qualify as improvement\n    restore_best_weights=True,  # Restore model to best state\n)\n\ntrainer = TorchTrainer(\n    ...,\n    callbacks=[callback],\n)\n</code></pre> <p>Metric specification:</p> <ul> <li>Prefix with <code>-</code> for metrics to minimize (e.g., <code>\"-loss\"</code>)</li> <li>No prefix for metrics to maximize (e.g., <code>\"accuracy\"</code>)</li> </ul>"},{"location":"guides/integrations/torch/#mlflowcallback","title":"MlflowCallback","text":"<p>Logs metrics to MLflow:</p> <pre><code>from formed.integrations.torch import MlflowCallback\n\ncallback = MlflowCallback()\n\ntrainer = TorchTrainer(\n    ...,\n    callbacks=[callback],\n)\n</code></pre> <p>This callback automatically logs:</p> <ul> <li>Training and validation metrics</li> <li>Model parameters and hyperparameters</li> <li>System metrics (GPU usage, etc.)</li> </ul>"},{"location":"guides/integrations/torch/#custom-callbacks","title":"Custom Callbacks","text":"<p>Implement <code>TorchTrainingCallback</code> for custom behavior:</p> <pre><code>from formed.integrations.torch import TorchTrainingCallback\n\n@TorchTrainingCallback.register(\"my_callback\")\nclass MyCallback(TorchTrainingCallback):\n    def on_epoch_end(self, trainer, model, state, epoch):\n        print(f\"Completed epoch {epoch}\")\n        # Save checkpoint, log custom metrics, etc.\n\n    def on_eval_end(self, trainer, model, state, metrics):\n        print(f\"Validation metrics: {metrics}\")\n</code></pre>"},{"location":"guides/integrations/torch/#distributed-training","title":"Distributed Training","text":""},{"location":"guides/integrations/torch/#basedistributor","title":"BaseDistributor","text":"<p><code>BaseDistributor</code> manages device placement and distributed training strategies.</p> <p>SingleDeviceDistributor - No distribution (default):</p> <pre><code>from formed.integrations.torch import SingleDeviceDistributor\n\ndistributor = SingleDeviceDistributor(device=\"cuda:0\")\n</code></pre> <p>DataParallelDistributor - Data parallelism across multiple GPUs:</p> <pre><code>from formed.integrations.torch import DataParallelDistributor\n\ndistributor = DataParallelDistributor(\n    device_ids=[0, 1, 2, 3],  # GPUs to use (None = all available)\n)\n</code></pre> <p>DistributedDataParallelDistributor - Distributed data parallelism:</p> <pre><code>from formed.integrations.torch import DistributedDataParallelDistributor\n\ndistributor = DistributedDataParallelDistributor(\n    backend=\"nccl\",           # Backend for distributed communication\n    init_method=\"env://\",     # Initialization method\n)\n</code></pre> <p>Using distributors:</p> <pre><code>trainer = TorchTrainer(\n    ...,\n    distributor=distributor,\n)\n</code></pre> <p>The distributor:</p> <ul> <li>Wraps the model for distributed training</li> <li>Handles device placement</li> <li>Reduces metrics across devices</li> <li>Manages process synchronization</li> </ul>"},{"location":"guides/integrations/torch/#workflow-integration","title":"Workflow Integration","text":""},{"location":"guides/integrations/torch/#train_torch_model","title":"train_torch_model","text":"<p>The <code>torch::train</code> workflow step trains a PyTorch model and caches the result:</p> <pre><code>{\n  steps: {\n    # Prepare data\n    datamodule_and_instances: {\n      type: 'ml::train_datamodule_with_instances',\n      dataset: { type: 'ref', ref: 'dataset' },\n      datamodule: { type: 'my_datamodule', ... },\n    },\n\n    # Train model\n    trained_model: {\n      type: 'torch::train',\n      model: {\n        type: 'text_classifier',\n        vocab_size: 10000,\n        embedding_dim: 128,\n        hidden_dim: 256,\n        num_classes: 2,\n      },\n      trainer: {\n        train_dataloader: {\n          type: 'formed.integrations.ml:DataLoader',\n          sampler: {\n            type: 'basic',\n            batch_size: 32,\n            shuffle: true,\n          },\n          collator: { type: 'ref', ref: 'datamodule_and_instances.datamodule.batch' },\n        },\n        engine: {\n          type: 'default',\n          optimizer: { type: 'torch.optim:Adam', lr: 0.001 },\n          loss: 'loss',\n        },\n        max_epochs: 10,\n        eval_strategy: 'epoch',\n        callbacks: [\n          { type: 'evaluation', evaluator: { type: 'my_evaluator' } },\n          { type: 'early_stopping', patience: 3, metric: '-loss' },\n        ],\n      },\n      train_dataset: { type: 'ref', ref: 'datamodule_and_instances.instances' },\n      val_dataset: { type: 'ref', ref: 'val_instances' },\n      random_seed: 42,\n      device: 'cuda:0',\n    },\n  },\n}\n</code></pre> <p>Parameters:</p> <ul> <li>model: Model configuration (Lazy-loaded)</li> <li>trainer: TorchTrainer configuration</li> <li>train_dataset: Training instances</li> <li>val_dataset: Optional validation instances</li> <li>random_seed: Random seed for reproducibility</li> <li>device: Device for training (optional, can be set via context)</li> </ul> <p>Model caching:</p> <p>Models are cached using <code>TorchModelFormat</code>:</p> <ul> <li>If model has <code>__model_config__</code>, saves config + state_dict separately</li> <li>Otherwise, pickles the entire model</li> <li>Enables efficient caching and model reuse across workflow runs</li> </ul>"},{"location":"guides/integrations/torch/#evaluate_torch_model","title":"evaluate_torch_model","text":"<p>The <code>torch::evaluate</code> workflow step evaluates a trained model:</p> <pre><code>{\n  steps: {\n    evaluation: {\n      type: 'torch::evaluate',\n      model: { type: 'ref', ref: 'trained_model' },\n      dataloader: {\n        type: 'formed.integrations.ml:DataLoader',\n        sampler: { type: 'basic', batch_size: 64 },\n        collator: { type: 'ref', ref: 'datamodule.batch' },\n      },\n      evaluator: { type: 'my_evaluator' },\n      dataset: { type: 'ref', ref: 'test_instances' },\n      device: 'cuda:0',\n    },\n  },\n}\n</code></pre>"},{"location":"guides/integrations/torch/#complete-example","title":"Complete Example","text":"<p>Here's a complete example combining all components with declarative model composition:</p> <pre><code>from formed.integrations.torch import (\n    BaseTorchModel,\n    TorchTrainer,\n    DefaultTorchTrainingEngine,\n    EvaluationCallback,\n    EarlyStoppingCallback,\n    modules as ftm,\n)\nfrom formed.integrations.ml import (\n    DataLoader,\n    BasicBatchSampler,\n    MulticlassAccuracy,\n    DataModule,\n    Tokenizer,\n    LabelIndexer,\n    Extra,\n)\nimport dataclasses\nimport torch\n\n# 1. Define DataModule\nclass TextClassificationDataModule(DataModule):\n    text: Tokenizer\n    label: Extra[LabelIndexer] = Extra.default()\n\n# 2. Define model using reusable modules\n@dataclasses.dataclass\nclass ClassifierOutput:\n    probs: torch.Tensor\n    label: torch.Tensor\n    loss: torch.Tensor | None = None\n\n@BaseTorchModel.register(\"text_classifier\")\nclass TextClassifier(BaseTorchModel):\n    def __init__(\n        self,\n        num_classes: int,\n        embedder: ftm.BaseEmbedder,\n        encoder: ftm.BaseSequenceEncoder,\n        vectorizer: ftm.BaseSequenceVectorizer,\n        dropout: float = 0.1,\n    ):\n        super().__init__()\n        self._embedder = embedder\n        self._encoder = encoder\n        self._vectorizer = vectorizer\n        self._dropout = torch.nn.Dropout(dropout)\n        self._classifier = torch.nn.Linear(\n            vectorizer.get_output_dim(), num_classes\n        )\n        self._loss = ftm.CrossEntropyLoss()\n\n    def forward(self, inputs, params=None):\n        embeddings, mask = self._embedder(inputs.text)\n        embeddings = self._encoder(embeddings, mask=mask)\n        vector = self._vectorizer(embeddings, mask=mask)\n        vector = self._dropout(vector)\n        logits = self._classifier(vector)\n        probs = torch.nn.functional.softmax(logits, dim=-1)\n        label = logits.argmax(dim=-1)\n\n        loss = None\n        if inputs.label is not None:\n            loss = self._loss(logits, inputs.label)\n\n        return ClassifierOutput(probs=probs, label=label, loss=loss)\n\n# 3. Prepare data\ndatamodule = TextClassificationDataModule(\n    text=Tokenizer(),\n    label=LabelIndexer(),\n)\n\nwith datamodule.train():\n    train_instances = [datamodule.instance(ex) for ex in train_data]\nval_instances = [datamodule.instance(ex) for ex in val_data]\n\n# 4. Create data loaders\ntrain_loader = DataLoader(\n    sampler=BasicBatchSampler(batch_size=32, shuffle=True),\n    collator=datamodule.batch,\n)\n\n# 5. Define evaluator\nclass Evaluator:\n    def __init__(self):\n        self.accuracy = MulticlassAccuracy()\n\n    def update(self, inputs, output):\n        preds = output.label.tolist()\n        targets = inputs.label.tolist()\n        self.accuracy.update(\n            self.accuracy.Input(predictions=preds, targets=targets)\n        )\n\n    def compute(self):\n        return self.accuracy.compute()\n\n    def reset(self):\n        self.accuracy.reset()\n\n# 6. Create model (can also be done from configuration)\nmodel = TextClassifier(\n    num_classes=2,\n    embedder=ftm.TokenEmbedder(\n        embedding_dim=128,\n        vocab_size=10000,\n    ),\n    encoder=ftm.LSTMSequenceEncoder(\n        input_size=128,\n        hidden_size=256,\n        num_layers=2,\n        bidirectional=True,\n    ),\n    vectorizer=ftm.BagOfEmbeddingsSequenceVectorizer(),\n    dropout=0.2,\n)\n\n# 7. Create trainer\ntrainer = TorchTrainer(\n    train_dataloader=train_loader,\n    engine=DefaultTorchTrainingEngine(\n        optimizer=torch.optim.Adam,\n        optimizer_params={\"lr\": 1e-3},\n        loss=\"loss\",  # Extract loss from ClassifierOutput\n    ),\n    max_epochs=10,\n    eval_strategy=\"epoch\",\n    callbacks=[\n        EvaluationCallback(Evaluator()),\n        EarlyStoppingCallback(patience=3, metric=\"-loss\"),\n    ],\n)\n\n# 8. Train model\nstate = trainer.train(model, train_instances, val_instances)\n</code></pre>"},{"location":"guides/integrations/torch/#best-practices","title":"Best Practices","text":""},{"location":"guides/integrations/torch/#model-design","title":"Model Design","text":"<ul> <li>Use reusable modules: Leverage <code>formed.integrations.torch.modules</code> for common components</li> <li>Return structured output: Use dataclasses instead of dicts for type safety</li> <li>Include loss in output: Return loss from forward pass for automatic training</li> <li>Make components optional: Allow optional encoder/feedforward for flexibility</li> <li>Keep forward pass composable: Chain modules in a clear pipeline (embed \u2192 encode \u2192 vectorize \u2192 classify)</li> </ul>"},{"location":"guides/integrations/torch/#training-configuration","title":"Training Configuration","text":"<ul> <li>Start with <code>DefaultTorchTrainingEngine</code> for standard training</li> <li>Use <code>eval_strategy=\"epoch\"</code> for small datasets, <code>\"step\"</code> for large ones</li> <li>Set <code>logging_interval</code> based on dataset size (more frequent for larger datasets)</li> <li>Always use EvaluationCallback for metric tracking</li> </ul>"},{"location":"guides/integrations/torch/#distributed-training_1","title":"Distributed Training","text":"<ul> <li>Use <code>DataParallelDistributor</code> for single-machine multi-GPU training</li> <li>Use <code>DistributedDataParallelDistributor</code> for multi-machine training</li> <li>Ensure batch size is divisible by number of GPUs</li> <li>Only save checkpoints from main process (distributor.is_main_process)</li> </ul>"},{"location":"guides/integrations/torch/#workflow-integration_1","title":"Workflow Integration","text":"<ul> <li>Use <code>torch::train</code> for training with automatic caching</li> <li>Reference DataModule's batch method as collator</li> <li>Set random seed for reproducibility</li> <li>Use device context managers for device management</li> </ul>"},{"location":"reference/","title":"API Reference","text":"<ul> <li>Workflow</li> <li>Integrations<ul> <li>Datasets</li> <li>Flax</li> <li>ML</li> <li>MLflow</li> <li>SentenceTransformers</li> <li>Torch</li> <li>Transformers</li> </ul> </li> </ul>"},{"location":"reference/workflow/","title":"Workflow","text":"<ul> <li>Archive</li> <li>Cache</li> <li>Callback</li> <li>Colt</li> <li>Constants</li> <li>Executor</li> <li>Format</li> <li>Graph</li> <li>JSON Schema</li> <li>Organizer</li> <li>Settings</li> <li>Step</li> <li>Utils</li> </ul>"},{"location":"reference/workflow/#formed.workflow.archive","title":"formed.workflow.archive","text":"<p>Archive data structures for workflow execution persistence.</p> <p>This module defines NamedTuple structures for serializing workflow executions to JSON format. These archives capture all metadata needed to restore past executions, including step fingerprints, source code hashes, and dependency information.</p>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive","title":"WorkflowStepArchive","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Archived snapshot of a WorkflowStep's execution-time metadata.</p> <p>This structure captures all information needed to:</p> <ol> <li>Look up cached results (<code>fingerprint</code>, <code>format_identifier</code>)</li> <li>Understand what ran (<code>version</code>, <code>source_hash</code>, <code>config</code>)</li> <li>Reconstruct dependency references (<code>dependency_fingerprints</code>)</li> </ol> <p>All steps are stored flat in <code>WorkflowGraphArchive.steps</code>, and dependencies are referenced by fingerprint rather than nested recursively.</p>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.step_type","title":"step_type  <code>instance-attribute</code>","text":"<pre><code>step_type\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.fingerprint","title":"fingerprint  <code>instance-attribute</code>","text":"<pre><code>fingerprint\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.format_identifier","title":"format_identifier  <code>instance-attribute</code>","text":"<pre><code>format_identifier\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.source_hash","title":"source_hash  <code>instance-attribute</code>","text":"<pre><code>source_hash\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.deterministic","title":"deterministic  <code>instance-attribute</code>","text":"<pre><code>deterministic\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.cacheable","title":"cacheable  <code>instance-attribute</code>","text":"<pre><code>cacheable\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.should_be_cached","title":"should_be_cached  <code>instance-attribute</code>","text":"<pre><code>should_be_cached\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.dependency_fingerprints","title":"dependency_fingerprints  <code>instance-attribute</code>","text":"<pre><code>dependency_fingerprints\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.fieldref","title":"fieldref  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>fieldref = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.json","title":"json","text":"<pre><code>json()\n</code></pre> <p>Convert to JSON-serializable dict.</p> Source code in <code>src/formed/workflow/archive.py</code> <pre><code>def json(self) -&gt; dict[str, JsonValue]:\n    \"\"\"Convert to JSON-serializable dict.\"\"\"\n    return self._asdict()\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowStepArchive.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data)\n</code></pre> <p>Create from JSON-deserialized dict.</p> Source code in <code>src/formed/workflow/archive.py</code> <pre><code>@classmethod\ndef from_json(cls, data: JsonValue) -&gt; Self:\n    \"\"\"Create from JSON-deserialized dict.\"\"\"\n    assert isinstance(data, dict)\n    return cls(**cast(dict, data))\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowGraphArchive","title":"WorkflowGraphArchive","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Archived snapshot of a WorkflowGraph's execution-time state.</p> <p>All steps are stored flat here (not nested). Dependencies between steps are represented by fingerprints in <code>WorkflowStepArchive.dependency_fingerprints</code>.</p>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowGraphArchive.steps","title":"steps  <code>instance-attribute</code>","text":"<pre><code>steps\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowGraphArchive.execution_order","title":"execution_order  <code>instance-attribute</code>","text":"<pre><code>execution_order\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowGraphArchive.json","title":"json","text":"<pre><code>json()\n</code></pre> <p>Convert to JSON-serializable dict.</p> Source code in <code>src/formed/workflow/archive.py</code> <pre><code>def json(self) -&gt; dict[str, JsonValue]:\n    \"\"\"Convert to JSON-serializable dict.\"\"\"\n    return {\n        \"steps\": {name: step.json() for name, step in self.steps.items()},\n        \"execution_order\": cast(list, self.execution_order),\n    }\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowGraphArchive.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data)\n</code></pre> <p>Create from JSON-deserialized dict.</p> Source code in <code>src/formed/workflow/archive.py</code> <pre><code>@classmethod\ndef from_json(cls, data: dict[str, JsonValue]) -&gt; Self:\n    \"\"\"Create from JSON-deserialized dict.\"\"\"\n    steps = {\n        name: WorkflowStepArchive.from_json(step_data) for name, step_data in cast(dict, data[\"steps\"]).items()\n    }\n    execution_order = data[\"execution_order\"]\n    return cls(steps=steps, execution_order=cast(list, execution_order))\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowExecutionArchive","title":"WorkflowExecutionArchive","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Complete execution snapshot saved to execution.json.</p> <p>This is the top-level structure that organizers save and restore. State is NOT included here - it's saved separately as it's mutable.</p>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowExecutionArchive.format_version","title":"format_version  <code>instance-attribute</code>","text":"<pre><code>format_version\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowExecutionArchive.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowExecutionArchive.graph","title":"graph  <code>instance-attribute</code>","text":"<pre><code>graph\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowExecutionArchive.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowExecutionArchive.json","title":"json","text":"<pre><code>json()\n</code></pre> <p>Convert to JSON-serializable dict.</p> Source code in <code>src/formed/workflow/archive.py</code> <pre><code>def json(self) -&gt; dict[str, JsonValue]:\n    \"\"\"Convert to JSON-serializable dict.\"\"\"\n    return {\n        \"format_version\": self.format_version,\n        \"id\": self.id,\n        \"graph\": self.graph.json(),\n        \"metadata\": self.metadata,\n    }\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.archive.WorkflowExecutionArchive.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data)\n</code></pre> <p>Create from JSON-deserialized dict.</p> Source code in <code>src/formed/workflow/archive.py</code> <pre><code>@classmethod\ndef from_json(cls, data: dict[str, JsonValue]) -&gt; Self:\n    \"\"\"Create from JSON-deserialized dict.\"\"\"\n    graph = WorkflowGraphArchive.from_json(cast(dict, data[\"graph\"]))\n    return cls(\n        format_version=cast(Literal[\"2.0\"], data[\"format_version\"]),\n        id=cast(str, data[\"id\"]),\n        graph=graph,\n        metadata=cast(dict, data[\"metadata\"]),\n    )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.cache","title":"formed.workflow.cache","text":"<p>Workflow step result caching implementations.</p> <p>This module provides caching backends for storing and retrieving workflow step results. Multiple cache implementations are available for different use cases.</p> Available Caches <ul> <li>EmptyWorkflowCache: No-op cache that never stores results</li> <li>MemoryWorkflowCache: In-memory cache for development/testing</li> <li>FilesystemWorkflowCache: Persistent file-based cache (default)</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.workflow.cache import FilesystemWorkflowCache\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create filesystem cache\n&gt;&gt;&gt; cache = FilesystemWorkflowCache(\".formed/cache\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check if step result is cached\n&gt;&gt;&gt; if step_info in cache:\n...     result = cache[step_info]\n... else:\n...     result = execute_step()\n...     cache[step_info] = result\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.cache.WorkflowCache","title":"WorkflowCache","text":"<p>               Bases: <code>Registrable</code></p> <p>Abstract base class for workflow step result caching.</p> <p>WorkflowCache provides a dict-like interface for storing and retrieving step execution results, keyed by WorkflowStepInfo (which includes the step's fingerprint).</p> <p>Subclasses implement different storage backends (memory, filesystem, etc.).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Implement custom cache\n&gt;&gt;&gt; class MyCache(WorkflowCache):\n...     def __getitem__(self, step_info):\n...         # Retrieve from custom backend\n...         pass\n...     def __setitem__(self, step_info, value):\n...         # Store to custom backend\n...         pass\n...     def __contains__(self, step_info):\n...         # Check if cached\n...         pass\n...     def __delitem__(self, step_info):\n...         # Remove from cache\n...         pass\n</code></pre> Note <ul> <li>Cache keys are WorkflowStepInfo instances</li> <li>Fingerprints uniquely identify step configurations</li> <li>Thread-safety depends on implementation</li> </ul>"},{"location":"reference/workflow/#formed.workflow.cache.EmptyWorkflowCache","title":"EmptyWorkflowCache","text":"<p>               Bases: <code>WorkflowCache</code></p> <p>No-op cache that never stores results.</p> <p>EmptyWorkflowCache disables caching entirely. All contains checks return False and all getitem calls raise KeyError, forcing steps to always re-execute.</p> <p>This is useful for debugging or when caching is undesirable.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cache = EmptyWorkflowCache()\n&gt;&gt;&gt; cache[step_info] = result  # Does nothing\n&gt;&gt;&gt; step_info in cache  # Always returns False\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.cache.MemoryWorkflowCache","title":"MemoryWorkflowCache","text":"<pre><code>MemoryWorkflowCache()\n</code></pre> <p>               Bases: <code>WorkflowCache</code></p> <p>In-memory cache for workflow step results.</p> <p>MemoryWorkflowCache stores results in a Python dictionary, providing fast access but no persistence across process restarts. Useful for development, testing, or when results don't need to survive process boundaries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cache = MemoryWorkflowCache()\n&gt;&gt;&gt; cache[step_info] = result\n&gt;&gt;&gt; if step_info in cache:\n...     result = cache[step_info]\n&gt;&gt;&gt; print(len(cache))  # Number of cached steps\n</code></pre> Note <ul> <li>Cache is lost when process ends</li> <li>Not suitable for production workflows</li> <li>No size limit - can grow unbounded</li> </ul> Source code in <code>src/formed/workflow/cache.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._cache: dict[\"WorkflowStepInfo\", Any] = {}\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.cache.FilesystemWorkflowCache","title":"FilesystemWorkflowCache","text":"<pre><code>FilesystemWorkflowCache(directory)\n</code></pre> <p>               Bases: <code>WorkflowCache</code></p> <p>Persistent file-based cache for workflow step results.</p> <p>FilesystemWorkflowCache stores step results in a directory structure organized by fingerprint. Each step's result is serialized using its configured Format and written to a subdirectory. File locking ensures thread-safe concurrent access.</p> ATTRIBUTE DESCRIPTION <code>_directory</code> <p>Root directory for cache storage.</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cache = FilesystemWorkflowCache(\".formed/cache\")\n&gt;&gt;&gt; cache[step_info] = result  # Writes to .formed/cache/&lt;fingerprint&gt;/\n&gt;&gt;&gt; if step_info in cache:\n...     result = cache[step_info]  # Reads from disk\n&gt;&gt;&gt; del cache[step_info]  # Removes cached result\n</code></pre> Note <ul> <li>Results persist across process restarts</li> <li>Thread-safe via file locking</li> <li>Cache directory structure: {cache_dir}/{fingerprint}/</li> <li>Each step uses its Format for serialization</li> <li>Suitable for production workflows</li> </ul> <p>Initialize filesystem cache.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Root directory for cache storage. Created if doesn't exist.</p> <p> TYPE: <code>str | PathLike</code> </p> Source code in <code>src/formed/workflow/cache.py</code> <pre><code>def __init__(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Initialize filesystem cache.\n\n    Args:\n        directory: Root directory for cache storage. Created if doesn't exist.\n\n    \"\"\"\n    self._directory = Path(directory)\n    self._directory.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback","title":"formed.workflow.callback","text":"<p>Callback system for workflow execution monitoring.</p> <p>This module provides a callback interface for monitoring and responding to workflow execution events. Callbacks can be used for logging, metrics collection, checkpointing, or custom workflow orchestration logic.</p> <p>Key Components:</p> <pre><code>- `WorkflowCallback`: Abstract base class for all callbacks\n- `EmptyWorkflowCallback`: No-op callback\n- `MultiWorkflowCallback`: Combines multiple callbacks\n</code></pre> Features <ul> <li>Hook points at execution and step start/end</li> <li>Access to execution and step contexts</li> <li>Composable callback system</li> <li>Registrable for configuration-based instantiation</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.workflow import WorkflowCallback\n&gt;&gt;&gt;\n&gt;&gt;&gt; @WorkflowCallback.register(\"custom\")\n... class CustomCallback(WorkflowCallback):\n...     def on_step_start(self, step_context, execution_context):\n...         print(f\"Starting step: {step_context.info.name}\")\n...\n...     def on_step_end(self, step_context, execution_context):\n...         print(f\"Finished step: {step_context.info.name}\")\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.WorkflowCallback","title":"WorkflowCallback","text":"<p>               Bases: <code>Registrable</code></p> <p>Abstract base class for workflow execution callbacks.</p> <p>Callbacks provide hooks to execute custom logic at various points during workflow execution. Subclasses can override hook methods to implement custom monitoring, logging, or orchestration behavior.</p> Hook execution order <ol> <li>on_execution_start - once at workflow start</li> <li>on_step_start - before each step execution</li> <li>on_step_end - after each step execution</li> <li>on_execution_end - once at workflow end</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class LoggingCallback(WorkflowCallback):\n...     def on_execution_start(self, execution_context):\n...         print(\"Workflow started\")\n...\n...     def on_step_end(self, step_context, execution_context):\n...         print(f\"Step {step_context.info.name} completed\")\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.WorkflowCallback.on_execution_start","title":"on_execution_start","text":"<pre><code>on_execution_start(execution_context)\n</code></pre> <p>Called once at the start of workflow execution.</p> PARAMETER DESCRIPTION <code>execution_context</code> <p>Context containing execution metadata and state.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_execution_start(\n    self,\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called once at the start of workflow execution.\n\n    Args:\n        execution_context: Context containing execution metadata and state.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.WorkflowCallback.on_execution_end","title":"on_execution_end","text":"<pre><code>on_execution_end(execution_context)\n</code></pre> <p>Called once at the end of workflow execution.</p> PARAMETER DESCRIPTION <code>execution_context</code> <p>Context containing execution metadata and state.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_execution_end(\n    self,\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called once at the end of workflow execution.\n\n    Args:\n        execution_context: Context containing execution metadata and state.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.WorkflowCallback.on_step_start","title":"on_step_start","text":"<pre><code>on_step_start(step_context, execution_context)\n</code></pre> <p>Called before each step execution.</p> PARAMETER DESCRIPTION <code>step_context</code> <p>Context for the step about to execute.</p> <p> TYPE: <code>WorkflowStepContext</code> </p> <code>execution_context</code> <p>Context for the overall execution.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_step_start(\n    self,\n    step_context: \"WorkflowStepContext\",\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called before each step execution.\n\n    Args:\n        step_context: Context for the step about to execute.\n        execution_context: Context for the overall execution.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.WorkflowCallback.on_step_end","title":"on_step_end","text":"<pre><code>on_step_end(step_context, execution_context)\n</code></pre> <p>Called after each step execution.</p> PARAMETER DESCRIPTION <code>step_context</code> <p>Context for the step that just executed.</p> <p> TYPE: <code>WorkflowStepContext</code> </p> <code>execution_context</code> <p>Context for the overall execution.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_step_end(\n    self,\n    step_context: \"WorkflowStepContext\",\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called after each step execution.\n\n    Args:\n        step_context: Context for the step that just executed.\n        execution_context: Context for the overall execution.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.EmptyWorkflowCallback","title":"EmptyWorkflowCallback","text":"<p>               Bases: <code>WorkflowCallback</code></p> <p>No-op callback that does nothing.</p> <p>This callback can be used as a placeholder or default when no callback behavior is needed.</p>"},{"location":"reference/workflow/#formed.workflow.callback.EmptyWorkflowCallback.on_execution_start","title":"on_execution_start","text":"<pre><code>on_execution_start(execution_context)\n</code></pre> <p>Called once at the start of workflow execution.</p> PARAMETER DESCRIPTION <code>execution_context</code> <p>Context containing execution metadata and state.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_execution_start(\n    self,\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called once at the start of workflow execution.\n\n    Args:\n        execution_context: Context containing execution metadata and state.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.EmptyWorkflowCallback.on_execution_end","title":"on_execution_end","text":"<pre><code>on_execution_end(execution_context)\n</code></pre> <p>Called once at the end of workflow execution.</p> PARAMETER DESCRIPTION <code>execution_context</code> <p>Context containing execution metadata and state.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_execution_end(\n    self,\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called once at the end of workflow execution.\n\n    Args:\n        execution_context: Context containing execution metadata and state.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.EmptyWorkflowCallback.on_step_start","title":"on_step_start","text":"<pre><code>on_step_start(step_context, execution_context)\n</code></pre> <p>Called before each step execution.</p> PARAMETER DESCRIPTION <code>step_context</code> <p>Context for the step about to execute.</p> <p> TYPE: <code>WorkflowStepContext</code> </p> <code>execution_context</code> <p>Context for the overall execution.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_step_start(\n    self,\n    step_context: \"WorkflowStepContext\",\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called before each step execution.\n\n    Args:\n        step_context: Context for the step about to execute.\n        execution_context: Context for the overall execution.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.EmptyWorkflowCallback.on_step_end","title":"on_step_end","text":"<pre><code>on_step_end(step_context, execution_context)\n</code></pre> <p>Called after each step execution.</p> PARAMETER DESCRIPTION <code>step_context</code> <p>Context for the step that just executed.</p> <p> TYPE: <code>WorkflowStepContext</code> </p> <code>execution_context</code> <p>Context for the overall execution.</p> <p> TYPE: <code>WorkflowExecutionContext</code> </p> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_step_end(\n    self,\n    step_context: \"WorkflowStepContext\",\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    \"\"\"Called after each step execution.\n\n    Args:\n        step_context: Context for the step that just executed.\n        execution_context: Context for the overall execution.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.MultiWorkflowCallback","title":"MultiWorkflowCallback","text":"<pre><code>MultiWorkflowCallback(callbacks)\n</code></pre> <p>               Bases: <code>WorkflowCallback</code></p> <p>Callback that executes multiple callbacks in sequence.</p> <p>This callback allows composing multiple callbacks together, calling each one in order for every hook.</p> PARAMETER DESCRIPTION <code>callbacks</code> <p>Sequence of callbacks to execute.</p> <p> TYPE: <code>Sequence[WorkflowCallback]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; callback1 = LoggingCallback()\n&gt;&gt;&gt; callback2 = MetricsCallback()\n&gt;&gt;&gt; multi = MultiWorkflowCallback([callback1, callback2])\n&gt;&gt;&gt; # Both callbacks will be called for each hook\n</code></pre> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def __init__(self, callbacks: Sequence[\"WorkflowCallback\"]) -&gt; None:\n    self._callbacks = callbacks\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.MultiWorkflowCallback.on_execution_start","title":"on_execution_start","text":"<pre><code>on_execution_start(execution_context)\n</code></pre> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_execution_start(\n    self,\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    for callback in self._callbacks:\n        callback.on_execution_start(execution_context)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.MultiWorkflowCallback.on_execution_end","title":"on_execution_end","text":"<pre><code>on_execution_end(execution_context)\n</code></pre> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_execution_end(\n    self,\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    for callback in self._callbacks:\n        callback.on_execution_end(execution_context)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.MultiWorkflowCallback.on_step_start","title":"on_step_start","text":"<pre><code>on_step_start(step_context, execution_context)\n</code></pre> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_step_start(\n    self,\n    step_context: \"WorkflowStepContext\",\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    for callback in self._callbacks:\n        callback.on_step_start(step_context, execution_context)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.callback.MultiWorkflowCallback.on_step_end","title":"on_step_end","text":"<pre><code>on_step_end(step_context, execution_context)\n</code></pre> Source code in <code>src/formed/workflow/callback.py</code> <pre><code>def on_step_end(\n    self,\n    step_context: \"WorkflowStepContext\",\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    for callback in self._callbacks:\n        callback.on_step_end(step_context, execution_context)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt","title":"formed.workflow.colt","text":""},{"location":"reference/workflow/#formed.workflow.colt.COLT_BUILDER","title":"COLT_BUILDER  <code>module-attribute</code>","text":"<pre><code>COLT_BUILDER = ColtBuilder(\n    typekey=COLT_TYPEKEY,\n    argskey=COLT_ARGSKEY,\n    callback=MultiCallback(\n        DatetimeCallback(), RefCallback()\n    ),\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.WorkflowRef","title":"WorkflowRef","text":"<pre><code>WorkflowRef(\n    annotation, path, step_name, config, field_name=None\n)\n</code></pre> <p>               Bases: <code>Generic[_T]</code>, <code>Placeholder[_T]</code></p> Source code in <code>src/formed/workflow/colt.py</code> <pre><code>def __init__(\n    self,\n    annotation: _T,\n    path: tuple[int | str, ...],\n    step_name: str,\n    config: Any,\n    field_name: str | None = None,\n) -&gt; None:\n    super().__init__(annotation)\n    self._path = path\n    self._step_name = step_name\n    self._config = config\n    self._field_name = field_name\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.WorkflowRef.path","title":"path  <code>property</code>","text":"<pre><code>path\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.WorkflowRef.step_name","title":"step_name  <code>property</code>","text":"<pre><code>step_name\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.WorkflowRef.config","title":"config  <code>property</code>","text":"<pre><code>config\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.WorkflowRef.field_name","title":"field_name  <code>property</code>","text":"<pre><code>field_name\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.WorkflowRef.is_ref","title":"is_ref  <code>staticmethod</code>","text":"<pre><code>is_ref(builder, config)\n</code></pre> Source code in <code>src/formed/workflow/colt.py</code> <pre><code>@staticmethod\ndef is_ref(builder: \"ColtBuilder\", config: Any) -&gt; bool:\n    return (\n        isinstance(config, Mapping)\n        and set(config) == {builder.typekey, WORKFLOW_REFKEY}\n        and config[builder.typekey] == WORKFLOW_REFTYPE\n        and isinstance(config[WORKFLOW_REFKEY], str)\n    )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.WorkflowRef.match_type_hint","title":"match_type_hint","text":"<pre><code>match_type_hint(annotation)\n</code></pre> Source code in <code>src/formed/workflow/colt.py</code> <pre><code>def match_type_hint(self, annotation: Any) -&gt; bool:\n    if self._annotation is Any:\n        return True  # Allow Any to match any type hint for flexibility\n    return super().match_type_hint(annotation)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.RefCallback","title":"RefCallback","text":"<p>               Bases: <code>ColtCallback</code></p> <p>Replace <code>ref</code> configs with <code>WorkflowRef</code> instances as placeholders</p>"},{"location":"reference/workflow/#formed.workflow.colt.RefCallback.on_build","title":"on_build","text":"<pre><code>on_build(path, config, builder, context, annotation=None)\n</code></pre> Source code in <code>src/formed/workflow/colt.py</code> <pre><code>def on_build(\n    self,\n    path: ParamPath,\n    config: Any,\n    builder: ColtBuilder,\n    context: ColtContext,\n    annotation: type[_T] | Callable[..., _T] | None = None,\n) -&gt; Any:\n    from .graph import WorkflowGraph\n\n    annotation = remove_optional(annotation)\n    if isinstance(annotation, type) and issubclass(annotation, WorkflowGraph):\n        if not isinstance(config, Mapping):\n            raise ConfigurationError(f\"[{get_path_name(path)}] Expected a mapping, got {config}\")\n        self._register_step_types(builder, path, config, context)\n        return config\n\n    if WorkflowRef.is_ref(builder, config):\n        step_name, field_name = WorkflowRef._parse_ref(config[WORKFLOW_REFKEY])\n        step_type = self._find_step_type(path, step_name, context)\n        step_output_annotation = step_type.get_output_type()\n        if field_name is not None:\n            try:\n                step_output_annotation = typing.get_type_hints(step_output_annotation).get(field_name, Any)\n            except TypeError:\n                step_output_annotation = Any\n        return WorkflowRef(\n            annotation=step_output_annotation,\n            path=path,\n            step_name=step_name,\n            config=config,\n            field_name=field_name,\n        )\n\n    raise SkipCallback\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.colt.DatetimeCallback","title":"DatetimeCallback","text":"<p>               Bases: <code>ColtCallback</code></p>"},{"location":"reference/workflow/#formed.workflow.colt.DatetimeCallback.on_build","title":"on_build","text":"<pre><code>on_build(path, config, builder, context, annotation=None)\n</code></pre> Source code in <code>src/formed/workflow/colt.py</code> <pre><code>def on_build(\n    self,\n    path: ParamPath,\n    config: Any,\n    builder: ColtBuilder,\n    context: ColtContext,\n    annotation: type[_T] | Callable[..., _T] | None = None,\n) -&gt; Any:\n    del path, builder, context\n    if isinstance(config, str) and annotation is datetime.datetime:\n        return datetime.datetime.fromisoformat(config)\n    raise SkipCallback\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.constants","title":"formed.workflow.constants","text":""},{"location":"reference/workflow/#formed.workflow.constants.WORKFLOW_REFKEY","title":"WORKFLOW_REFKEY  <code>module-attribute</code>","text":"<pre><code>WORKFLOW_REFKEY = 'ref'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.constants.WORKFLOW_REFTYPE","title":"WORKFLOW_REFTYPE  <code>module-attribute</code>","text":"<pre><code>WORKFLOW_REFTYPE = 'ref'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.constants.WORKFLOW_DEFAULT_DIRECTORY","title":"WORKFLOW_DEFAULT_DIRECTORY  <code>module-attribute</code>","text":"<pre><code>WORKFLOW_DEFAULT_DIRECTORY = (\n    DEFAULT_FORMED_DIRECTORY / \"workflow\"\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.constants.WORKFLOW_DEFAULT_SETTINGS_PATH","title":"WORKFLOW_DEFAULT_SETTINGS_PATH  <code>module-attribute</code>","text":"<pre><code>WORKFLOW_DEFAULT_SETTINGS_PATH = (\n    DEFAULT_WORKING_DIRECTORY / \"formed.yml\"\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.constants.WORKFLOW_INTEGRATION_DIRECTORY","title":"WORKFLOW_INTEGRATION_DIRECTORY  <code>module-attribute</code>","text":"<pre><code>WORKFLOW_INTEGRATION_DIRECTORY = (\n    DEFAULT_FORMED_DIRECTORY / \"integrations\"\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.constants.WORKFLOW_WORKSPACE_DIRECTORY","title":"WORKFLOW_WORKSPACE_DIRECTORY  <code>module-attribute</code>","text":"<pre><code>WORKFLOW_WORKSPACE_DIRECTORY = (\n    DEFAULT_FORMED_DIRECTORY / \"workspaces\"\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor","title":"formed.workflow.executor","text":"<p>Workflow execution engine and context management.</p> <p>This module provides the execution engine for workflows, coordinating step execution, caching, callbacks, and state management.</p> Key Components <ul> <li><code>WorkflowExecutor</code>: Abstract base for execution engines</li> <li><code>DefaultWorkflowExecutor</code>: Default sequential execution implementation</li> <li><code>WorkflowExecutionContext</code>: Runtime context for workflow execution</li> <li><code>WorkflowExecutionInfo</code>: Metadata about workflow execution</li> </ul> Features <ul> <li>Sequential step execution with dependency resolution</li> <li>Cache integration for step results</li> <li>Callback hooks for monitoring and logging</li> <li>Execution state tracking</li> <li>Git and environment metadata capture</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.workflow import WorkflowGraph, DefaultWorkflowExecutor\n&gt;&gt;&gt; from formed.workflow.cache import FilesystemWorkflowCache\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load workflow and create executor\n&gt;&gt;&gt; graph = WorkflowGraph.from_jsonnet(\"workflow.jsonnet\")\n&gt;&gt;&gt; executor = DefaultWorkflowExecutor()\n&gt;&gt;&gt; cache = FilesystemWorkflowCache(\".formed/cache\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Execute workflow\n&gt;&gt;&gt; with executor:\n...     context = executor(graph, cache=cache)\n&gt;&gt;&gt; print(context.state.status)  # \"completed\"\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T')\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutorT","title":"WorkflowExecutorT  <code>module-attribute</code>","text":"<pre><code>WorkflowExecutorT = TypeVar(\n    \"WorkflowExecutorT\", bound=\"WorkflowExecutor\"\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionID","title":"WorkflowExecutionID  <code>module-attribute</code>","text":"<pre><code>WorkflowExecutionID = NewType('WorkflowExecutionID', str)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionStatus","title":"WorkflowExecutionStatus","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionStatus.PENDING","title":"PENDING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PENDING = 'pending'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionStatus.RUNNING","title":"RUNNING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING = 'running'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionStatus.FAILURE","title":"FAILURE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAILURE = 'failure'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionStatus.CANCELED","title":"CANCELED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CANCELED = 'canceled'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionStatus.COMPLETED","title":"COMPLETED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMPLETED = 'completed'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionState","title":"WorkflowExecutionState  <code>dataclass</code>","text":"<pre><code>WorkflowExecutionState(\n    execution_id=None,\n    status=PENDING,\n    started_at=None,\n    finished_at=None,\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionState.execution_id","title":"execution_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>execution_id = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionState.status","title":"status  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status = PENDING\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionState.started_at","title":"started_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>started_at = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionState.finished_at","title":"finished_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>finished_at = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionMetadata","title":"WorkflowExecutionMetadata  <code>dataclass</code>","text":"<pre><code>WorkflowExecutionMetadata(\n    version=version(\"formed\"),\n    git=get_git_info(),\n    environment=dict(),\n    required_modules=list(),\n    dependent_packages=get_installed_packages(),\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionMetadata.version","title":"version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>version = version('formed')\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionMetadata.git","title":"git  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>git = field(default_factory=get_git_info)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionMetadata.environment","title":"environment  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>environment = field(default_factory=dict)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionMetadata.required_modules","title":"required_modules  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>required_modules = field(default_factory=list)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionMetadata.dependent_packages","title":"dependent_packages  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>dependent_packages = field(\n    default_factory=get_installed_packages\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionInfo","title":"WorkflowExecutionInfo  <code>dataclass</code>","text":"<pre><code>WorkflowExecutionInfo(\n    graph, id=None, metadata=WorkflowExecutionMetadata()\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionInfo.graph","title":"graph  <code>instance-attribute</code>","text":"<pre><code>graph\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionInfo.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionInfo.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata = field(default_factory=WorkflowExecutionMetadata)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionInfo.json","title":"json","text":"<pre><code>json()\n</code></pre> <p>Convert to JSON-serializable dict.</p> <p>Returns a dict that may contain types requiring <code>WorkflowJSONEncoder</code> for proper serialization (e.g., datetime, git info).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = execution_info.to_json_dict()\n&gt;&gt;&gt; json.dump(data, file, cls=WorkflowJSONEncoder)\n</code></pre> Source code in <code>src/formed/workflow/executor.py</code> <pre><code>def json(self) -&gt; dict[str, JsonValue]:\n    \"\"\"Convert to JSON-serializable dict.\n\n    Returns a dict that may contain types requiring `WorkflowJSONEncoder`\n    for proper serialization (e.g., datetime, git info).\n\n    Examples:\n        &gt;&gt;&gt; data = execution_info.to_json_dict()\n        &gt;&gt;&gt; json.dump(data, file, cls=WorkflowJSONEncoder)\n    \"\"\"\n    return {\n        \"format_version\": \"2.0\",\n        \"id\": self.id or \"\",\n        \"graph\": self.graph.to_archive().json(),\n        \"metadata\": as_jsonvalue(self.metadata),\n    }\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionInfo.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(data)\n</code></pre> <p>Reconstruct from JSON-serializable dict.</p> <p>Validates format version and reconstructs all fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; data = json.load(file, cls=WorkflowJSONDecoder)\n&gt;&gt;&gt; execution_info = WorkflowExecutionInfo.from_json_dict(data)\n</code></pre> Source code in <code>src/formed/workflow/executor.py</code> <pre><code>@classmethod\ndef from_json(cls, data: dict[str, JsonValue], /) -&gt; Self:\n    \"\"\"Reconstruct from JSON-serializable dict.\n\n    Validates format version and reconstructs all fields.\n\n    Examples:\n        &gt;&gt;&gt; data = json.load(file, cls=WorkflowJSONDecoder)\n        &gt;&gt;&gt; execution_info = WorkflowExecutionInfo.from_json_dict(data)\n    \"\"\"\n\n    if data.get(\"format_version\") != \"2.0\":\n        raise ValueError(f\"Unsupported format version '{data.get('format_version')}'. Expected '2.0'.\")\n\n    execution_id = WorkflowExecutionID(cast(str, data[\"id\"])) if data[\"id\"] else None\n    graph = WorkflowGraph.from_archive(WorkflowGraphArchive.from_json(cast(dict[str, JsonValue], data[\"graph\"])))\n    metadata: WorkflowExecutionMetadata = from_jsonvalue(data[\"metadata\"])\n\n    assert isinstance(metadata, WorkflowExecutionMetadata)\n\n    return cls(\n        graph=graph,\n        id=execution_id,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionContext","title":"WorkflowExecutionContext  <code>dataclass</code>","text":"<pre><code>WorkflowExecutionContext(\n    info,\n    state,\n    cache=EmptyWorkflowCache(),\n    callback=EmptyWorkflowCallback(),\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionContext.info","title":"info  <code>instance-attribute</code>","text":"<pre><code>info\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionContext.state","title":"state  <code>instance-attribute</code>","text":"<pre><code>state\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionContext.cache","title":"cache  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cache = field(default_factory=EmptyWorkflowCache)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutionContext.callback","title":"callback  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>callback = field(default_factory=EmptyWorkflowCallback)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.executor.WorkflowExecutor","title":"WorkflowExecutor","text":"<p>               Bases: <code>Registrable</code></p>"},{"location":"reference/workflow/#formed.workflow.executor.DefaultWorkflowExecutor","title":"DefaultWorkflowExecutor","text":"<p>               Bases: <code>WorkflowExecutor</code></p>"},{"location":"reference/workflow/#formed.workflow.executor.use_execution_context","title":"use_execution_context","text":"<pre><code>use_execution_context()\n</code></pre> Source code in <code>src/formed/workflow/executor.py</code> <pre><code>def use_execution_context() -&gt; Optional[WorkflowExecutionContext]:\n    return _EXECUTION_CONTEXT.get()\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format","title":"formed.workflow.format","text":"<p>Serialization formats for workflow step results.</p> <p>This module provides format abstractions for serializing and deserializing workflow step results. Multiple formats support different data types and use cases.</p> Key Components <ul> <li><code>Format</code>: Abstract base class for all formats</li> <li><code>PickleFormat</code>: Universal format using cloudpickle</li> <li><code>JsonFormat</code>: JSON format for JSON-serializable data</li> <li><code>MappingFormat</code>: JSON format for mappings/dicts</li> <li><code>AutoFormat</code>: Automatically selects appropriate format</li> </ul> Features <ul> <li>Support for iterators and streaming data</li> <li>Type-safe serialization/deserialization</li> <li>Format auto-detection based on data type</li> <li>Extensible via registration system</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.workflow import JsonFormat, PickleFormat\n&gt;&gt;&gt;\n&gt;&gt;&gt; # JSON format for simple data\n&gt;&gt;&gt; json_format = JsonFormat()\n&gt;&gt;&gt; json_format.write({\"key\": \"value\"}, directory)\n&gt;&gt;&gt; data = json_format.read(directory)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Pickle format for complex objects\n&gt;&gt;&gt; pickle_format = PickleFormat()\n&gt;&gt;&gt; pickle_format.write(my_model, directory)\n&gt;&gt;&gt; model = pickle_format.read(directory)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.Format","title":"Format","text":"<p>               Bases: <code>Generic[_T]</code>, <code>Registrable</code></p> <p>Abstract base class for serialization formats.</p> <p>Formats handle serialization and deserialization of workflow step results to/from disk. Each format is identified by a unique identifier and can indicate if it's the default format for a given type.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_T</code> <p>Type of data this format can serialize/deserialize.</p> <p> </p>"},{"location":"reference/workflow/#formed.workflow.format.Format.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/workflow/#formed.workflow.format.Format.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> <p>Write artifact to directory.</p> PARAMETER DESCRIPTION <code>artifact</code> <p>Data to serialize.</p> <p> TYPE: <code>_T</code> </p> <code>directory</code> <p>Directory to write to.</p> <p> TYPE: <code>Path</code> </p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def write(self, artifact: _T, directory: Path) -&gt; None:\n    \"\"\"Write artifact to directory.\n\n    Args:\n        artifact: Data to serialize.\n        directory: Directory to write to.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.Format.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> <p>Read artifact from directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory to read from.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Deserialized data.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def read(self, directory: Path) -&gt; _T:\n    \"\"\"Read artifact from directory.\n\n    Args:\n        directory: Directory to read from.\n\n    Returns:\n        Deserialized data.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.Format.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.PickleFormat","title":"PickleFormat","text":"<p>               Bases: <code>Format[_T]</code>, <code>Generic[_T]</code></p> <p>Universal serialization format using cloudpickle.</p> <p>This format can serialize almost any Python object, including functions, classes, and complex nested structures. It also supports streaming iterators.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format = PickleFormat()\n&gt;&gt;&gt; format.write(my_object, directory)\n&gt;&gt;&gt; obj = format.read(directory)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # For iterators\n&gt;&gt;&gt; format.write(iter(range(1000)), directory)\n&gt;&gt;&gt; iterator = format.read(directory)  # Returns iterator\n</code></pre> Note <p>This is the fallback format when no other format applies.</p>"},{"location":"reference/workflow/#formed.workflow.format.PickleFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/workflow/#formed.workflow.format.PickleFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def write(self, artifact: _T, directory: Path) -&gt; None:\n    artifact_path = self._get_artifact_path(directory)\n    with open(artifact_path, \"wb\") as f:\n        if isinstance(artifact, Iterator):\n            cloudpickle.dump(True, f)\n            for item in artifact:\n                cloudpickle.dump(item, f)\n        else:\n            cloudpickle.dump(False, f)\n            cloudpickle.dump(artifact, f)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.PickleFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def read(self, directory: Path) -&gt; _T:\n    artifact_path = self._get_artifact_path(directory)\n    with open(artifact_path, \"rb\") as f:\n        is_iterator = cloudpickle.load(f)\n        if is_iterator:\n            return cast(_T, self._IteratorWrapper(artifact_path))\n        return cast(_T, cloudpickle.load(f))\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.PickleFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.JsonFormat","title":"JsonFormat","text":"<p>               Bases: <code>Format[_JsonFormattableT]</code>, <code>Generic[_JsonFormattableT]</code></p> <p>JSON-based serialization format for JSON-compatible data.</p> <p>This format serializes data to JSON files (.json for single objects, .jsonl for iterators). It supports all JSON-serializable types plus dataclasses, named tuples, and Pydantic models.</p> Features <ul> <li>Human-readable format</li> <li>Support for iterators via JSON Lines format</li> <li>Automatic type reconstruction using metadata</li> <li>Custom JSON encoder/decoder for extended types</li> </ul>                CLASS TYPE PARAMETER              DESCRIPTION <code>_JsonFormattableT</code> <p>JSON-compatible type (primitives, containers, dataclasses, etc.)</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format = JsonFormat()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Single object\n&gt;&gt;&gt; format.write({\"key\": \"value\"}, directory)\n&gt;&gt;&gt; data = format.read(directory)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Iterator (uses JSONL)\n&gt;&gt;&gt; format.write(iter([{\"a\": 1}, {\"a\": 2}]), directory)\n&gt;&gt;&gt; iterator = format.read(directory)\n</code></pre> Note <p>This is the default format for JSON-serializable types. Objects are reconstructed with their original type using metadata.</p>"},{"location":"reference/workflow/#formed.workflow.format.JsonFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/workflow/#formed.workflow.format.JsonFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> <p>Write JSON-serializable artifact to directory.</p> <p>Writes artifact.json for single objects or <code>artifact.jsonl</code> for iterators. Also writes metadata.json containing type information for reconstruction.</p> PARAMETER DESCRIPTION <code>artifact</code> <p>Data to serialize (single object or iterator).</p> <p> TYPE: <code>_JsonFormattableT</code> </p> <code>directory</code> <p>Directory to write to.</p> <p> TYPE: <code>Path</code> </p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def write(self, artifact: _JsonFormattableT, directory: Path) -&gt; None:\n    \"\"\"Write JSON-serializable artifact to directory.\n\n    Writes artifact.json for single objects or `artifact.jsonl` for\n    iterators. Also writes metadata.json containing type information\n    for reconstruction.\n\n    Args:\n        artifact: Data to serialize (single object or iterator).\n        directory: Directory to write to.\n\n    \"\"\"\n    artifact_class: type[_JsonFormattableT] | None = None\n    if isinstance(artifact, Iterator):\n        artifact_path = directory / \"artifact.jsonl\"\n        with open(artifact_path, \"w\") as f:\n            for item in artifact:\n                artifact_class = cast(\n                    type[_JsonFormattableT],\n                    artifact_class or type(item),\n                )\n                json.dump(item, f, cls=WorkflowJSONEncoder, ensure_ascii=False)\n                f.write(\"\\n\")\n    else:\n        artifact_class = type(artifact)\n        artifact_path = directory / \"artifact.json\"\n        with open(artifact_path, \"w\") as f:\n            json.dump(artifact, f, cls=WorkflowJSONEncoder, ensure_ascii=False)\n    if artifact_class is not None:\n        metadata = {\n            \"module\": artifact_class.__module__,\n            \"class\": artifact_class.__name__,\n        }\n        metadata_path = directory / \"metadata.json\"\n        with open(metadata_path, \"w\") as f:\n            json.dump(metadata, f, ensure_ascii=False)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.JsonFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> <p>Read JSON artifact from directory.</p> <p>Reads <code>artifact.json</code> or artifact.jsonl and reconstructs the original type using <code>metadata.json</code> if available.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory to read from.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>_JsonFormattableT</code> <p>Deserialized data with original type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def read(self, directory: Path) -&gt; _JsonFormattableT:\n    \"\"\"Read JSON artifact from directory.\n\n    Reads `artifact.json` or artifact.jsonl and reconstructs the\n    original type using `metadata.json` if available.\n\n    Args:\n        directory: Directory to read from.\n\n    Returns:\n        Deserialized data with original type.\n\n    \"\"\"\n    metadata_path = directory / \"metadata.json\"\n    artifact_class: type[_JsonFormattableT] | None = None\n    if metadata_path.exists():\n        with open(metadata_path) as f:\n            metadata = json.load(f, cls=WorkflowJSONDecoder)\n        module = importlib.import_module(metadata[\"module\"])\n        artifact_class = getattr(module, metadata[\"class\"])\n\n    is_iterator = (directory / \"artifact.jsonl\").exists()\n    if is_iterator:\n        artifact_path = directory / \"artifact.jsonl\"\n        return cast(_JsonFormattableT, self._IteratorWrapper(artifact_path, artifact_class))\n\n    artifact_path = directory / \"artifact.json\"\n    with open(artifact_path) as f:\n        data = json.load(f, cls=WorkflowJSONDecoder)\n        if artifact_class is not None:\n            return colt.build(data, artifact_class)\n        return cast(_JsonFormattableT, data)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.JsonFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if JSON format is default for object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True for JSON-serializable types (primitives, containers,</p> <code>bool</code> <p>dataclasses, named tuples, Pydantic models).</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if JSON format is default for object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True for JSON-serializable types (primitives, containers,\n        dataclasses, named tuples, Pydantic models).\n\n    \"\"\"\n    return isinstance(\n        obj,\n        (\n            int,\n            float,\n            str,\n            bool,\n            dict,\n            list,\n            tuple,\n            IDataclass,\n            INamedTuple,\n            IPydanticModel,\n        ),\n    )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.MappingFormat","title":"MappingFormat","text":"<pre><code>MappingFormat(format)\n</code></pre> <p>               Bases: <code>Format[Mapping[str, _T]]</code>, <code>Generic[_T]</code></p> <p>Format for mappings using subdirectories for values.</p> <p>This format stores each mapping entry as a subdirectory, with the key as the directory name and the value serialized using a nested format. This allows mappings of complex objects to be stored in an organized directory structure.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_T</code> <p>Type of mapping values.</p> <p> </p> PARAMETER DESCRIPTION <code>format</code> <p>Format to use for serializing mapping values.</p> <p> TYPE: <code>Format[_T]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Mapping of strings to dataframes\n&gt;&gt;&gt; inner_format = PickleFormat()\n&gt;&gt;&gt; format = MappingFormat(inner_format)\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"train\": train_df,\n...     \"test\": test_df,\n... }\n&gt;&gt;&gt; format.write(data, directory)\n&gt;&gt;&gt; # Creates: directory/train/artifact.pkl\n&gt;&gt;&gt; #          directory/test/artifact.pkl\n&gt;&gt;&gt;\n&gt;&gt;&gt; loaded = format.read(directory)\n</code></pre> Note <p>Keys must be valid directory names (no special characters).</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def __init__(self, format: Format[_T]) -&gt; None:\n    self._format = format\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.MappingFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/workflow/#formed.workflow.format.MappingFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> <p>Write mapping to subdirectories.</p> <p>Each mapping entry is written to a subdirectory named after the key, with the value serialized using the nested format.</p> PARAMETER DESCRIPTION <code>artifact</code> <p>Mapping to serialize.</p> <p> TYPE: <code>Mapping[str, _T]</code> </p> <code>directory</code> <p>Directory to write to.</p> <p> TYPE: <code>Path</code> </p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def write(self, artifact: Mapping[str, _T], directory: Path) -&gt; None:\n    \"\"\"Write mapping to subdirectories.\n\n    Each mapping entry is written to a subdirectory named after\n    the key, with the value serialized using the nested format.\n\n    Args:\n        artifact: Mapping to serialize.\n        directory: Directory to write to.\n\n    \"\"\"\n    for key, value in artifact.items():\n        subdir = directory / key\n        subdir.mkdir(parents=True)\n        self._format.write(value, subdir)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.MappingFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> <p>Read mapping from subdirectories.</p> <p>Reconstructs the mapping by reading each subdirectory as a key-value pair.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory to read from.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>Mapping[str, _T]</code> <p>Reconstructed mapping.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def read(self, directory: Path) -&gt; Mapping[str, _T]:\n    \"\"\"Read mapping from subdirectories.\n\n    Reconstructs the mapping by reading each subdirectory as a\n    key-value pair.\n\n    Args:\n        directory: Directory to read from.\n\n    Returns:\n        Reconstructed mapping.\n\n    \"\"\"\n    artifact: dict[str, _T] = {}\n    for subdir in directory.glob(\"*\"):\n        artifact[subdir.name] = self._format.read(subdir)\n    return artifact\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.MappingFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.DatasetFormat","title":"DatasetFormat","text":"<p>               Bases: <code>Format[Dataset[_T]]</code>, <code>Generic[_T]</code></p>"},{"location":"reference/workflow/#formed.workflow.format.DatasetFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/workflow/#formed.workflow.format.DatasetFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def write(self, artifact: Dataset[_T], directory: Path) -&gt; None:\n    import shutil\n\n    shutil.copytree(artifact.path, directory / \"dataset\")\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.DatasetFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def read(self, directory: Path) -&gt; Dataset[_T]:\n    return Dataset[_T].from_path(directory / \"dataset\")\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.DatasetFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    return isinstance(obj, Dataset)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.AutoFormat","title":"AutoFormat","text":"<p>               Bases: <code>Format[_T]</code></p> <p>Automatic format selection based on object type.</p> <p>This format automatically selects the most appropriate format for an object by checking each registered format's <code>is_default_of()</code> method. It stores the chosen format name in metadata for correct deserialization.</p> Selection priority <ol> <li>Last registered format that claims the type (most specific)</li> <li>Falls back to pickle format if no format claims the type</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format = AutoFormat()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Automatically uses JsonFormat for dict\n&gt;&gt;&gt; format.write({\"key\": \"value\"}, directory)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Automatically uses PickleFormat for custom objects\n&gt;&gt;&gt; format.write(my_custom_object, directory)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Reads with the same format used during write\n&gt;&gt;&gt; obj = format.read(directory)\n</code></pre> Note <p>This is the recommended format for most use cases as it provides optimal serialization for each type.</p>"},{"location":"reference/workflow/#formed.workflow.format.AutoFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/workflow/#formed.workflow.format.AutoFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> <p>Write artifact using automatically selected format.</p> <p>Selects the appropriate format, writes the artifact, and stores the format name in metadata for deserialization.</p> PARAMETER DESCRIPTION <code>artifact</code> <p>Data to serialize.</p> <p> TYPE: <code>_T</code> </p> <code>directory</code> <p>Directory to write to.</p> <p> TYPE: <code>Path</code> </p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def write(self, artifact: _T, directory: Path) -&gt; None:\n    \"\"\"Write artifact using automatically selected format.\n\n    Selects the appropriate format, writes the artifact, and stores\n    the format name in metadata for deserialization.\n\n    Args:\n        artifact: Data to serialize.\n        directory: Directory to write to.\n\n    \"\"\"\n    format_name = self._get_default_format_name(artifact)\n    format = cast(type[Format[_T]], Format.by_name(format_name))()\n    format.write(artifact, directory)\n    (directory / self._FORMAT_FILENAME).write_text(json.dumps({\"name\": format_name}))\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.AutoFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> <p>Read artifact using the format recorded in metadata.</p> <p>Reads the format metadata and uses the same format that was used during writing.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory to read from.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Deserialized data.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>def read(self, directory: Path) -&gt; _T:\n    \"\"\"Read artifact using the format recorded in metadata.\n\n    Reads the format metadata and uses the same format that was\n    used during writing.\n\n    Args:\n        directory: Directory to read from.\n\n    Returns:\n        Deserialized data.\n\n    \"\"\"\n    format_metadata = json.loads((directory / self._FORMAT_FILENAME).read_text())\n    format_name = format_metadata[\"name\"]\n    format = cast(type[Format[_T]], Format.by_name(format_name))()\n    return format.read(directory)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.format.AutoFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph","title":"formed.workflow.graph","text":"<p>Workflow graph construction and dependency resolution.</p> <p>This module provides the WorkflowGraph class which parses workflow configurations and builds directed acyclic graphs (DAGs) of workflow steps with dependency tracking.</p> Key Features <ul> <li>Parse Jsonnet workflow configurations</li> <li>Automatic dependency detection via references</li> <li>Topological sorting for execution order</li> <li>Cycle detection in dependencies</li> <li>DAG-based workflow representation</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.workflow import WorkflowGraph\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load workflow from Jsonnet config\n&gt;&gt;&gt; graph = WorkflowGraph.from_jsonnet(\"workflow.jsonnet\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access steps in topological order\n&gt;&gt;&gt; for step_info in graph:\n...     print(f\"Step: {step_info.name}\")\n...     print(f\"Dependencies: {step_info.dependencies}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Get specific step\n&gt;&gt;&gt; preprocess_step = graph[\"preprocess\"]\n&gt;&gt;&gt; print(preprocess_step.fingerprint)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraphConfig","title":"WorkflowGraphConfig","text":"<p>               Bases: <code>TypedDict</code></p>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraphConfig.steps","title":"steps  <code>instance-attribute</code>","text":"<pre><code>steps\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph","title":"WorkflowGraph","text":"<pre><code>WorkflowGraph(steps)\n</code></pre> <p>               Bases: <code>FromJsonnet</code></p> Source code in <code>src/formed/workflow/graph.py</code> <pre><code>def __init__(\n    self,\n    steps: Mapping[str, Lazy[WorkflowStep]],\n) -&gt; None:\n    self._step_info = self._build_step_info(steps)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.get_subgraph","title":"get_subgraph","text":"<pre><code>get_subgraph(step_name)\n</code></pre> <p>Get a subgraph containing a step and all its dependencies.</p> <p>Only works with live (non-archived) graphs. For archived graphs, dependencies are already resolved in the archive.</p> Source code in <code>src/formed/workflow/graph.py</code> <pre><code>def get_subgraph(self, step_name: str) -&gt; \"WorkflowGraph\":\n    \"\"\"Get a subgraph containing a step and all its dependencies.\n\n    Only works with live (non-archived) graphs. For archived graphs,\n    dependencies are already resolved in the archive.\n    \"\"\"\n    if step_name not in self._step_info:\n        raise ValueError(f\"Step {step_name} not found in the graph\")\n    step_info = self._step_info[step_name]\n\n    # Type narrowing: ensure all steps are live\n    if not isinstance(step_info.step, Lazy):\n        raise TypeError(\n            f\"Cannot create subgraph from archived step '{step_name}'. \"\n            f\"Subgraph extraction only works with live workflows.\"\n        )\n\n    subgraph_steps: dict[str, Lazy[WorkflowStep]] = {step_name: step_info.step}\n    for _, dependant_step_info in step_info.dependencies:\n        if not isinstance(dependant_step_info.step, Lazy):\n            raise TypeError(f\"Cannot create subgraph: dependency '{dependant_step_info.name}' is archived.\")\n        for sub_step_info in self.get_subgraph(dependant_step_info.name):\n            if not isinstance(sub_step_info.step, Lazy):\n                raise TypeError(f\"Cannot create subgraph: nested dependency '{sub_step_info.name}' is archived.\")\n            subgraph_steps[sub_step_info.name] = sub_step_info.step\n    return WorkflowGraph(subgraph_steps)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.visualize","title":"visualize","text":"<pre><code>visualize(*, output=stdout, additional_info={})\n</code></pre> Source code in <code>src/formed/workflow/graph.py</code> <pre><code>def visualize(\n    self,\n    *,\n    output: TextIO = sys.stdout,\n    additional_info: Mapping[str, str] = {},\n) -&gt; None:\n    def get_node(name: str) -&gt; str:\n        if name in additional_info:\n            return f\"{name}: {additional_info[name]}\"\n        return name\n\n    dag = DAG(\n        {\n            get_node(name): {get_node(dep.name) for _, dep in info.dependencies}\n            for name, info in self._step_info.items()\n        }\n    )\n\n    dag.visualize(output=output)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.from_config","title":"from_config  <code>classmethod</code>","text":"<pre><code>from_config(config)\n</code></pre> Source code in <code>src/formed/workflow/graph.py</code> <pre><code>@classmethod\ndef from_config(cls, config: WorkflowGraphConfig) -&gt; \"WorkflowGraph\":\n    return cls.__COLT_BUILDER__(config, WorkflowGraph)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.to_archive","title":"to_archive","text":"<pre><code>to_archive()\n</code></pre> <p>Convert graph to archive format for serialization.</p> <p>This captures the execution-time state of all steps in a flat structure. Only works with live graphs.</p> Source code in <code>src/formed/workflow/graph.py</code> <pre><code>def to_archive(self) -&gt; WorkflowGraphArchive:\n    \"\"\"Convert graph to archive format for serialization.\n\n    This captures the execution-time state of all steps in a flat structure.\n    Only works with live graphs.\n    \"\"\"\n    # Ensure all steps are live before archiving\n    for step_info in self:\n        if not isinstance(step_info.step, Lazy):\n            raise TypeError(\n                f\"Cannot archive graph containing archived step '{step_info.name}'. \"\n                f\"Only live graphs can be converted to archives.\"\n            )\n\n    # Convert all steps to archives\n    steps: dict[str, WorkflowStepArchive] = {}\n    for step_info in self:\n        steps[step_info.name] = step_info.to_archive()\n\n    # Compute execution order (topological sort)\n    execution_order = [step_info.name for step_info in self]\n\n    return WorkflowGraphArchive(\n        steps=steps,\n        execution_order=execution_order,\n    )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.from_archive","title":"from_archive  <code>classmethod</code>","text":"<pre><code>from_archive(archive)\n</code></pre> <p>Reconstruct graph from archive.</p> <p>Handles all dependency resolution internally using a two-pass approach. Organizers don't need to know about the complexity.</p> Source code in <code>src/formed/workflow/graph.py</code> <pre><code>@classmethod\ndef from_archive(cls, archive: WorkflowGraphArchive) -&gt; \"WorkflowGraph\":\n    \"\"\"Reconstruct graph from archive.\n\n    Handles all dependency resolution internally using a two-pass approach.\n    Organizers don't need to know about the complexity.\n    \"\"\"\n    # First pass: Create all step infos without dependencies\n    # This builds a fingerprint -&gt; WorkflowStepInfo map\n    fingerprint_to_info: dict[str, WorkflowStepInfo] = {}\n\n    for step_name in archive.execution_order:\n        step_archive = archive.steps[step_name]\n        # Create WorkflowStepInfo with archive but no dependencies yet\n        step_info = WorkflowStepInfo(\n            name=step_archive.name,\n            step=step_archive,\n            dependencies=frozenset(),\n            fieldref=step_archive.fieldref,\n        )\n        fingerprint_to_info[step_archive.fingerprint] = step_info\n\n    # Second pass: Resolve dependencies using from_archive\n    step_name_to_info: dict[str, WorkflowStepInfo] = {}\n    for step_name in archive.execution_order:\n        step_archive = archive.steps[step_name]\n        step_info = WorkflowStepInfo.from_archive(step_archive, fingerprint_to_info)\n        step_name_to_info[step_name] = step_info\n\n    # Create graph directly by setting _step_info\n    graph = cls.__new__(cls)\n    graph._step_info = step_name_to_info\n    return graph\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.from_jsonnet","title":"from_jsonnet  <code>classmethod</code>","text":"<pre><code>from_jsonnet(filename, ext_vars=None, overrides=None)\n</code></pre> Source code in <code>src/formed/common/jsonnet.py</code> <pre><code>@classmethod\ndef from_jsonnet(\n    cls,\n    filename: Union[str, PathLike],\n    ext_vars: Optional[Mapping[str, Any]] = None,\n    overrides: Optional[str] = None,\n) -&gt; Self:\n    json_config = load_jsonnet(filename, ext_vars=ext_vars, overrides=overrides)\n    return cls.from_json(json_config)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.json","title":"json","text":"<pre><code>json()\n</code></pre> Source code in <code>src/formed/common/jsonnet.py</code> <pre><code>def json(self) -&gt; JsonValue:\n    if not hasattr(self, \"__json_config__\"):\n        raise RuntimeError(f\"{self.__class__.__name__} instance has no JSON config\")\n    return self.__json_config__\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.graph.WorkflowGraph.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(o)\n</code></pre> Source code in <code>src/formed/common/jsonnet.py</code> <pre><code>@classmethod\ndef from_json(cls, o: JsonValue, /) -&gt; Self:\n    obj = cls.__COLT_BUILDER__(cls.__pre_init__(o), cls)\n    obj.__json_config__ = o\n    return obj\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.jsonschema","title":"formed.workflow.jsonschema","text":""},{"location":"reference/workflow/#formed.workflow.jsonschema.generate_workflow_schema","title":"generate_workflow_schema","text":"<pre><code>generate_workflow_schema(title='formed Workflow Graph')\n</code></pre> Source code in <code>src/formed/workflow/jsonschema.py</code> <pre><code>def generate_workflow_schema(\n    title: str = \"formed Workflow Graph\",\n) -&gt; dict[str, Any]:\n    WorkflowGraphSchema = TypedDict(\"WorkflowGraphSchema\", {\"steps\": dict[str, WorkflowStep]})\n    definitions = {\"__ref__\": _REF_SCHEMA}\n    generator = JsonSchemaGenerator(\n        callback=_ref_callback,\n        typekey=COLT_TYPEKEY,\n        argskey=COLT_ARGSKEY,\n    )\n    schema = generator(\n        WorkflowGraphSchema,\n        definitions=definitions,\n        title=title,\n    )\n    if defs := schema.get(\"$defs\", None):\n        for key, defschema in defs.items():\n            defschema = _remove_ref_schema(defschema)\n            def_schema = _remove_importable_schema(defschema)\n            defs[key] = def_schema\n    return schema\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer","title":"formed.workflow.organizer","text":"<p>Workflow organizers for managing execution state and artifacts.</p> <p>This module provides organizers that coordinate workflow execution, managing caches, callbacks, and persistent storage of execution state.</p> Key Components <ul> <li><code>WorkflowOrganizer</code>: Abstract base class for organizers</li> <li><code>MemoryWorkflowOrganizer</code>: In-memory organizer for testing</li> <li><code>FilesystemWorkflowOrganizer</code>: Persistent filesystem-based organizer</li> </ul> Features <ul> <li>Execution lifecycle management</li> <li>Integration with caches and callbacks</li> <li>Persistent storage of execution metadata and results</li> <li>Thread-safe execution with file locking</li> <li>Automatic log capture and organization</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.workflow import FilesystemWorkflowOrganizer, DefaultWorkflowExecutor\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create filesystem organizer\n&gt;&gt;&gt; organizer = FilesystemWorkflowOrganizer(\n...     directory=\".formed\",\n...     callbacks=[my_callback]\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Run workflow\n&gt;&gt;&gt; executor = DefaultWorkflowExecutor()\n&gt;&gt;&gt; context = organizer.run(executor, workflow_graph)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access results\n&gt;&gt;&gt; print(context.state)\n&gt;&gt;&gt; print(context.results)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.T_WorkflowOrganizer","title":"T_WorkflowOrganizer  <code>module-attribute</code>","text":"<pre><code>T_WorkflowOrganizer = TypeVar(\n    \"T_WorkflowOrganizer\", bound=\"WorkflowOrganizer\"\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.WorkflowOrganizer","title":"WorkflowOrganizer","text":"<pre><code>WorkflowOrganizer(cache, callbacks)\n</code></pre> <p>               Bases: <code>Registrable</code></p> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def __init__(\n    self,\n    cache: \"WorkflowCache\",\n    callbacks: Optional[Union[WorkflowCallback, Sequence[WorkflowCallback]]],\n) -&gt; None:\n    if isinstance(callbacks, WorkflowCallback):\n        callbacks = [callbacks]\n\n    self.cache = cache\n    self.callback = MultiWorkflowCallback(callbacks or [])\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.WorkflowOrganizer.cache","title":"cache  <code>instance-attribute</code>","text":"<pre><code>cache = cache\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.WorkflowOrganizer.callback","title":"callback  <code>instance-attribute</code>","text":"<pre><code>callback = MultiWorkflowCallback(callbacks or [])\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.WorkflowOrganizer.run","title":"run","text":"<pre><code>run(executor, execution)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def run(\n    self,\n    executor: \"WorkflowExecutor\",\n    execution: Union[WorkflowGraph, WorkflowExecutionInfo],\n) -&gt; WorkflowExecutionContext:\n    with executor:\n        return executor(\n            execution,\n            cache=self.cache,\n            callback=self.callback,\n        )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.WorkflowOrganizer.get","title":"get","text":"<pre><code>get(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def get(self, execution_id: WorkflowExecutionID) -&gt; Optional[WorkflowExecutionContext]:\n    return None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.WorkflowOrganizer.exists","title":"exists","text":"<pre><code>exists(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def exists(self, execution_id: WorkflowExecutionID) -&gt; bool:\n    return self.get(execution_id) is not None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.WorkflowOrganizer.remove","title":"remove","text":"<pre><code>remove(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def remove(self, execution_id: WorkflowExecutionID) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.MemoryWorkflowOrganizer","title":"MemoryWorkflowOrganizer","text":"<pre><code>MemoryWorkflowOrganizer(callbacks=None)\n</code></pre> <p>               Bases: <code>WorkflowOrganizer</code></p> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def __init__(\n    self,\n    callbacks: Optional[Union[WorkflowCallback, Sequence[WorkflowCallback]]] = None,\n) -&gt; None:\n    super().__init__(MemoryWorkflowCache(), callbacks)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.MemoryWorkflowOrganizer.cache","title":"cache  <code>instance-attribute</code>","text":"<pre><code>cache = cache\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.MemoryWorkflowOrganizer.callback","title":"callback  <code>instance-attribute</code>","text":"<pre><code>callback = MultiWorkflowCallback(callbacks or [])\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.MemoryWorkflowOrganizer.run","title":"run","text":"<pre><code>run(executor, execution)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def run(\n    self,\n    executor: \"WorkflowExecutor\",\n    execution: Union[WorkflowGraph, WorkflowExecutionInfo],\n) -&gt; WorkflowExecutionContext:\n    with executor:\n        return executor(\n            execution,\n            cache=self.cache,\n            callback=self.callback,\n        )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.MemoryWorkflowOrganizer.get","title":"get","text":"<pre><code>get(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def get(self, execution_id: WorkflowExecutionID) -&gt; Optional[WorkflowExecutionContext]:\n    return None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.MemoryWorkflowOrganizer.exists","title":"exists","text":"<pre><code>exists(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def exists(self, execution_id: WorkflowExecutionID) -&gt; bool:\n    return self.get(execution_id) is not None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.MemoryWorkflowOrganizer.remove","title":"remove","text":"<pre><code>remove(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def remove(self, execution_id: WorkflowExecutionID) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer","title":"FilesystemWorkflowOrganizer","text":"<pre><code>FilesystemWorkflowOrganizer(directory=None, callbacks=None)\n</code></pre> <p>               Bases: <code>WorkflowOrganizer</code></p> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def __init__(\n    self,\n    directory: Optional[Union[str, PathLike]] = None,\n    callbacks: Optional[Union[WorkflowCallback, Sequence[WorkflowCallback]]] = None,\n) -&gt; None:\n    self._directory = Path(directory or self._DEFAULT_DIRECTORY).expanduser().resolve().absolute()\n\n    if isinstance(callbacks, WorkflowCallback):\n        callbacks = [callbacks]\n    callbacks = [self._Callback(self)] + list(callbacks or [])\n\n    super().__init__(FilesystemWorkflowCache(self.cache_directory), callbacks)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.directory","title":"directory  <code>property</code>","text":"<pre><code>directory\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.cache_directory","title":"cache_directory  <code>property</code>","text":"<pre><code>cache_directory\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.executions_directory","title":"executions_directory  <code>property</code>","text":"<pre><code>executions_directory\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.cache","title":"cache  <code>instance-attribute</code>","text":"<pre><code>cache = cache\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.callback","title":"callback  <code>instance-attribute</code>","text":"<pre><code>callback = MultiWorkflowCallback(callbacks or [])\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.get","title":"get","text":"<pre><code>get(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def get(self, execution_id: WorkflowExecutionID) -&gt; Optional[WorkflowExecutionContext]:\n    execution_directory = self.executions_directory / execution_id\n    if not execution_directory.exists():\n        return None\n\n    execution_path = execution_directory / self._Callback._EXECUTION_FILENAME\n    if not execution_path.exists():\n        return None\n\n    # Use helper method to load execution info\n    execution_info = WorkflowExecutionInfo.from_json(json.loads(execution_path.read_text()))\n\n    # Use helper method to load execution state\n    state_path = execution_directory / self._Callback._STATE_FILENAME\n    if state_path.exists():\n        with state_path.open(\"r\") as jsonfile:\n            execution_state = json.load(jsonfile, cls=WorkflowJSONDecoder)\n    else:\n        logger.warning(f\"State file not found for execution {execution_id}\")\n        execution_state = WorkflowExecutionState(execution_id=execution_info.id)\n\n    return WorkflowExecutionContext(execution_info, execution_state, self.cache, self.callback)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.exists","title":"exists","text":"<pre><code>exists(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def exists(self, execution_id: WorkflowExecutionID) -&gt; bool:\n    execution_directory = self.executions_directory / execution_id\n    return execution_directory.exists()\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.remove","title":"remove","text":"<pre><code>remove(execution_id)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def remove(self, execution_id: WorkflowExecutionID) -&gt; None:\n    execution_directory = self.executions_directory / execution_id\n    if not execution_directory.exists():\n        return\n\n    shutil.rmtree(execution_directory)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.organizer.FilesystemWorkflowOrganizer.run","title":"run","text":"<pre><code>run(executor, execution)\n</code></pre> Source code in <code>src/formed/workflow/organizer.py</code> <pre><code>def run(\n    self,\n    executor: \"WorkflowExecutor\",\n    execution: Union[WorkflowGraph, WorkflowExecutionInfo],\n) -&gt; WorkflowExecutionContext:\n    with executor:\n        return executor(\n            execution,\n            cache=self.cache,\n            callback=self.callback,\n        )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.settings","title":"formed.workflow.settings","text":""},{"location":"reference/workflow/#formed.workflow.settings.WorkflowSettings","title":"WorkflowSettings  <code>dataclass</code>","text":"<pre><code>WorkflowSettings(\n    executor=_default_executor(),\n    organizer=_default_organizer(),\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.settings.WorkflowSettings.executor","title":"executor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>executor = field(default_factory=_default_executor)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.settings.WorkflowSettings.organizer","title":"organizer  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>organizer = field(default_factory=_default_organizer)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step","title":"formed.workflow.step","text":""},{"location":"reference/workflow/#formed.workflow.step.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T')\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.OutputT","title":"OutputT  <code>module-attribute</code>","text":"<pre><code>OutputT = TypeVar('OutputT')\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.StepFunctionT","title":"StepFunctionT  <code>module-attribute</code>","text":"<pre><code>StepFunctionT = TypeVar(\n    \"StepFunctionT\", bound=Callable[..., Any]\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepT","title":"WorkflowStepT  <code>module-attribute</code>","text":"<pre><code>WorkflowStepT = TypeVar(\n    \"WorkflowStepT\", bound=\"WorkflowStep\"\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepArgFlag","title":"WorkflowStepArgFlag","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepArgFlag.IGNORE","title":"IGNORE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>IGNORE = 'ignore'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepResultFlag","title":"WorkflowStepResultFlag","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepResultFlag.METRICS","title":"METRICS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>METRICS = 'metrics'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepResultFlag.get_flags","title":"get_flags  <code>classmethod</code>","text":"<pre><code>get_flags(step_or_annotation)\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@classmethod\ndef get_flags(cls, step_or_annotation: Any) -&gt; frozenset[\"WorkflowStepResultFlag\"]:\n    if isinstance(step_or_annotation, WorkflowStepInfo):\n        step_or_annotation = step_or_annotation.step_class.get_output_type()\n    if isinstance(step_or_annotation, WorkflowStep):\n        step_or_annotation = step_or_annotation.get_output_type()\n    origin = typing.get_origin(step_or_annotation)\n    if origin is not Annotated:\n        return frozenset()\n    return frozenset(a for a in typing.get_args(step_or_annotation) if isinstance(a, WorkflowStepResultFlag))\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepStatus","title":"WorkflowStepStatus","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepStatus.PENDING","title":"PENDING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PENDING = 'pending'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepStatus.RUNNING","title":"RUNNING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING = 'running'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepStatus.FAILURE","title":"FAILURE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAILURE = 'failure'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepStatus.CANCELED","title":"CANCELED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CANCELED = 'canceled'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepStatus.COMPLETED","title":"COMPLETED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMPLETED = 'completed'\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepState","title":"WorkflowStepState  <code>dataclass</code>","text":"<pre><code>WorkflowStepState(\n    fingerprint,\n    status=PENDING,\n    started_at=None,\n    finished_at=None,\n)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepState.fingerprint","title":"fingerprint  <code>instance-attribute</code>","text":"<pre><code>fingerprint\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepState.status","title":"status  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status = PENDING\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepState.started_at","title":"started_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>started_at = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepState.finished_at","title":"finished_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>finished_at = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepContext","title":"WorkflowStepContext  <code>dataclass</code>","text":"<pre><code>WorkflowStepContext(info, state)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepContext.info","title":"info  <code>instance-attribute</code>","text":"<pre><code>info\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepContext.state","title":"state  <code>instance-attribute</code>","text":"<pre><code>state\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep","title":"WorkflowStep","text":"<pre><code>WorkflowStep(*args, **kwargs)\n</code></pre> <p>               Bases: <code>Generic[OutputT]</code>, <code>Registrable</code></p> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any):\n    self._args = args\n    self._kwargs = kwargs\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.VERSION","title":"VERSION  <code>class-attribute</code>","text":"<pre><code>VERSION = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.DETERMINISTIC","title":"DETERMINISTIC  <code>class-attribute</code>","text":"<pre><code>DETERMINISTIC = True\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.CACHEABLE","title":"CACHEABLE  <code>class-attribute</code>","text":"<pre><code>CACHEABLE = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.FORMAT","title":"FORMAT  <code>instance-attribute</code>","text":"<pre><code>FORMAT\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.FUNCTION","title":"FUNCTION  <code>instance-attribute</code>","text":"<pre><code>FUNCTION\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.get_output_type","title":"get_output_type  <code>classmethod</code>","text":"<pre><code>get_output_type(field=None)\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@classmethod\ndef get_output_type(cls, field: Optional[str] = None) -&gt; type[OutputT]:\n    return_annotation = cls.FUNCTION.__annotations__.get(\"return\", Any)\n    if field is not None:\n        return_annotation = typing.get_type_hints(return_annotation).get(field, Any)\n    if getattr(return_annotation, \"__parameters__\", None):\n        # This is a workaround for generic steps to skip the type checking.\n        # We need to infer the output type from the configuration.\n        return cast(type[OutputT], TypeVar(\"T\"))\n    return cast(type[OutputT], return_annotation)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.from_callable","title":"from_callable  <code>classmethod</code>","text":"<pre><code>from_callable(\n    func,\n    *,\n    version=None,\n    deterministic=True,\n    cacheable=None,\n    format=None,\n)\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@classmethod\ndef from_callable(\n    cls,\n    func: Callable[..., OutputT],\n    *,\n    version: Optional[str] = None,\n    deterministic: bool = True,\n    cacheable: Optional[bool] = None,\n    format: Optional[Union[str, Format[OutputT]]] = None,\n) -&gt; type[\"WorkflowStep[OutputT]\"]:\n    if isinstance(format, str):\n        format = cast(type[Format[OutputT]], Format.by_name(format))()\n    if version is None:\n        version = object_fingerprint(normalize_source(inspect.getsource(func)))\n\n    class WrapperStep(WorkflowStep):\n        VERSION = version\n        DETERMINISTIC = deterministic\n        CACHEABLE = cacheable\n        FUNCTION = func\n        FORMAT = format or AutoFormat()\n\n        def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n            super().__init__(*args, **kwargs)\n\n    signature = inspect.signature(func)\n    annotations = typing.get_type_hints(func)\n    init_annotations = {k: v for k, v in annotations.items() if k != \"return\"}\n    setattr(WrapperStep, \"__name__\", func.__name__)\n    setattr(WrapperStep, \"__qualname__\", func.__qualname__)\n    setattr(WrapperStep, \"__doc__\", func.__doc__)\n    setattr(getattr(WrapperStep, \"__init__\"), \"__annotations__\", init_annotations)\n    setattr(\n        getattr(WrapperStep, \"__init__\"),\n        \"__signature__\",\n        signature.replace(return_annotation=annotations.get(\"return\", inspect.Signature.empty)),\n    )\n\n    return WrapperStep\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.get_source","title":"get_source  <code>classmethod</code>","text":"<pre><code>get_source()\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@classmethod\ndef get_source(cls) -&gt; str:\n    return inspect.getsource(cls.FUNCTION)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.get_normalized_source","title":"get_normalized_source  <code>classmethod</code>","text":"<pre><code>get_normalized_source()\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@classmethod\ndef get_normalized_source(cls) -&gt; str:\n    return normalize_source(cls.get_source())\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStep.get_ignore_args","title":"get_ignore_args  <code>classmethod</code>","text":"<pre><code>get_ignore_args()\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@classmethod\ndef get_ignore_args(cls) -&gt; frozenset[str]:\n    annotations = cls.FUNCTION.__annotations__\n    return frozenset(k for k, v in annotations.items() if WorkflowStepArgFlag.IGNORE in typing.get_args(v))\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo","title":"WorkflowStepInfo  <code>dataclass</code>","text":"<pre><code>WorkflowStepInfo(name, step, dependencies, fieldref=None)\n</code></pre> <p>               Bases: <code>Generic[WorkflowStepT]</code></p> <p>Unified step info that works for both live and archived steps.</p> <p>The <code>step</code> field determines the mode:</p> <ul> <li><code>Lazy[WorkflowStepT]</code>: Live mode - can be constructed and executed</li> <li><code>WorkflowStepArchive</code>: Archived mode - immutable snapshot from past execution</li> </ul> <p>Live mode (before execution):</p> <ul> <li>step: <code>Lazy[WorkflowStepT]</code> that can be constructed</li> <li>dependencies: references to other live <code>WorkflowStepInfo</code> objects</li> <li>Properties computed from <code>step_class</code></li> </ul> <p>Archived mode (after execution):</p> <ul> <li>step: <code>WorkflowStepArchive</code> with pre-computed metadata</li> <li>dependencies: references to other archived <code>WorkflowStepInfo</code> objects</li> <li>Properties returned from archive</li> </ul>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.step","title":"step  <code>instance-attribute</code>","text":"<pre><code>step\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.dependencies","title":"dependencies  <code>instance-attribute</code>","text":"<pre><code>dependencies\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.fieldref","title":"fieldref  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>fieldref = None\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.step_class","title":"step_class  <code>cached</code> <code>property</code>","text":"<pre><code>step_class\n</code></pre> <p>Get the step class. Only works in live mode.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.archive","title":"archive  <code>cached</code> <code>property</code>","text":"<pre><code>archive\n</code></pre> <p>Get the archive. Only works in archived mode.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.format","title":"format  <code>cached</code> <code>property</code>","text":"<pre><code>format\n</code></pre> <p>Get the format. Works in both modes.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.version","title":"version  <code>cached</code> <code>property</code>","text":"<pre><code>version\n</code></pre> <p>Get the version. Works in both modes.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.deterministic","title":"deterministic  <code>cached</code> <code>property</code>","text":"<pre><code>deterministic\n</code></pre> <p>Get deterministic flag. Works in both modes.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.cacheable","title":"cacheable  <code>cached</code> <code>property</code>","text":"<pre><code>cacheable\n</code></pre> <p>Get cacheable flag. Works in both modes.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.should_be_cached","title":"should_be_cached  <code>cached</code> <code>property</code>","text":"<pre><code>should_be_cached\n</code></pre> <p>Check if step should be cached. Works in both modes.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.fingerprint","title":"fingerprint  <code>cached</code> <code>property</code>","text":"<pre><code>fingerprint\n</code></pre> <p>Get fingerprint. Works in both modes.</p>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.is_live","title":"is_live","text":"<pre><code>is_live()\n</code></pre> <p>Check if this is a live step.</p> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def is_live(self) -&gt; bool:\n    \"\"\"Check if this is a live step.\"\"\"\n    return isinstance(self.step, Lazy)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.is_archived","title":"is_archived","text":"<pre><code>is_archived()\n</code></pre> <p>Check if this is an archived step.</p> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def is_archived(self) -&gt; bool:\n    \"\"\"Check if this is an archived step.\"\"\"\n    return isinstance(self.step, WorkflowStepArchive)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.to_archive","title":"to_archive","text":"<pre><code>to_archive()\n</code></pre> <p>Convert to archive format for serialization.</p> <p>This is called at execution time to capture the current state. Only works in live mode.</p> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def to_archive(self) -&gt; WorkflowStepArchive:\n    \"\"\"Convert to archive format for serialization.\n\n    This is called at execution time to capture the current state.\n    Only works in live mode.\n    \"\"\"\n    if isinstance(self.step, WorkflowStepArchive):\n        # Already archived, return as-is\n        return self.step\n\n    if not isinstance(self.step, Lazy):\n        raise TypeError(\"Step must be either Lazy or dict\")\n\n    # Capture source code if available\n    normalized_source: str | None = None\n    try:\n        normalized_source = self.step_class.get_normalized_source()\n    except (OSError, TypeError):\n        # Built-in functions or C extensions don't have source\n        pass\n\n    # Build dependency fingerprint map with fieldrefs\n    dependency_fingerprints: dict[str, dict[str, Any]] = {}\n    for path, dep_info in self.dependencies:\n        param_path_str = \".\".join(str(p) for p in (path if isinstance(path, tuple) else (path,)))\n        dependency_fingerprints[param_path_str] = {\n            \"fingerprint\": dep_info.fingerprint,\n            \"fieldref\": dep_info.fieldref,\n        }\n\n    # Get step type name (the registered name in Colt)\n    step_type: str\n    if hasattr(self.step.constructor, \"__registered_name__\"):\n        step_type = self.step.constructor.__registered_name__  # type: ignore\n    else:\n        # Fallback to class name\n        step_type = self.step.constructor.__name__  # type: ignore\n\n    # Build the archive using NamedTuple constructor\n    return WorkflowStepArchive(\n        name=self.name,\n        step_type=step_type,\n        fingerprint=self.fingerprint,\n        format_identifier=self.format.identifier,\n        version=self.version,\n        source_hash=object_fingerprint(normalized_source) if normalized_source else \"\",\n        config=dict(self.step.config) if isinstance(self.step.config, Mapping) else {},\n        deterministic=self.deterministic,\n        cacheable=self.cacheable,\n        should_be_cached=self.should_be_cached,\n        dependency_fingerprints=dependency_fingerprints,\n        fieldref=self.fieldref,\n    )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.from_archive","title":"from_archive  <code>classmethod</code>","text":"<pre><code>from_archive(archive, dependency_map)\n</code></pre> <p>Reconstruct WorkflowStepInfo from an archive.</p> PARAMETER DESCRIPTION <code>archive</code> <p>The archived step metadata</p> <p> TYPE: <code>WorkflowStepArchive</code> </p> <code>dependency_map</code> <p>Map from fingerprint to <code>WorkflowStepInfo</code> for all dependencies</p> <p> TYPE: <code>Mapping[str, WorkflowStepInfo]</code> </p> RETURNS DESCRIPTION <code>WorkflowStepInfo</code> <p><code>WorkflowStepInfo</code> in archived mode (step field is <code>WorkflowStepArchive</code>)</p> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@classmethod\ndef from_archive(\n    cls,\n    archive: WorkflowStepArchive,\n    dependency_map: Mapping[str, \"WorkflowStepInfo\"],\n) -&gt; \"WorkflowStepInfo\":\n    \"\"\"Reconstruct WorkflowStepInfo from an archive.\n\n    Args:\n        archive: The archived step metadata\n        dependency_map: Map from fingerprint to `WorkflowStepInfo` for all dependencies\n\n    Returns:\n        `WorkflowStepInfo` in archived mode (step field is `WorkflowStepArchive`)\n    \"\"\"\n    # Reconstruct dependencies using the dependency_map\n    dependencies: set[tuple[StrictParamPath, WorkflowStepInfo]] = set()\n    for param_path_str, dep_data in archive.dependency_fingerprints.items():\n        dep_fingerprint = dep_data[\"fingerprint\"]\n        assert isinstance(dep_fingerprint, str)\n\n        dep_fieldref = dep_data[\"fieldref\"] if \"fieldref\" in dep_data else None\n        assert dep_fieldref is None or isinstance(dep_fieldref, str)\n\n        if dep_fingerprint not in dependency_map:\n            raise ValueError(\n                f\"Dependency with fingerprint {dep_fingerprint} not found in dependency_map for step {archive.name}\"\n            )\n        path_parts = tuple(param_path_str.split(\".\"))\n        base_dep_info = dependency_map[dep_fingerprint]\n\n        # If the dependency has a fieldref, create a new WorkflowStepInfo with fieldref set\n        if dep_fieldref:\n            dep_info = WorkflowStepInfo(\n                name=base_dep_info.name,\n                step=base_dep_info.step,\n                dependencies=base_dep_info.dependencies,\n                fieldref=dep_fieldref,\n            )\n        else:\n            dep_info = base_dep_info\n\n        dependencies.add((path_parts, dep_info))\n\n    return cls(\n        name=archive.name,\n        step=archive,  # Store the archive directly, not a Lazy\n        dependencies=frozenset(dependencies),\n        fieldref=archive.fieldref,\n    )\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.WorkflowStepInfo.json","title":"json","text":"<pre><code>json()\n</code></pre> <p>Convert to dict for JSON serialization (legacy compatibility).</p> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def json(self) -&gt; dict[str, JsonValue]:\n    \"\"\"Convert to dict for JSON serialization (legacy compatibility).\"\"\"\n    if isinstance(self.step, WorkflowStepArchive):\n        config = self.step.config\n    elif isinstance(self.step, Lazy):\n        config = self.step.config\n    else:\n        config = {}\n\n    return {\n        \"name\": self.name,\n        \"version\": self.version,\n        \"format\": self.format.identifier,\n        \"deterministic\": self.deterministic,\n        \"cacheable\": self.cacheable,\n        \"fingerprint\": self.fingerprint,\n        \"config\": config,\n    }\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.step","title":"step","text":"<pre><code>step(\n    name: str,\n    *,\n    version: Optional[str] = ...,\n    deterministic: bool = ...,\n    cacheable: Optional[bool] = ...,\n    exist_ok: bool = ...,\n    format: Optional[Union[str, Format]] = ...,\n) -&gt; Callable[[StepFunctionT], StepFunctionT]\n</code></pre><pre><code>step(\n    name: StepFunctionT,\n    *,\n    version: Optional[str] = ...,\n    deterministic: bool = ...,\n    cacheable: Optional[bool] = ...,\n    exist_ok: bool = ...,\n    format: Optional[Union[str, Format]] = ...,\n) -&gt; StepFunctionT\n</code></pre><pre><code>step(\n    *,\n    version: Optional[str] = ...,\n    deterministic: bool = ...,\n    cacheable: Optional[bool] = ...,\n    exist_ok: bool = ...,\n    format: Optional[Union[str, Format]] = ...,\n) -&gt; Callable[[StepFunctionT], StepFunctionT]\n</code></pre> <pre><code>step(\n    name=None,\n    *,\n    version=None,\n    deterministic=True,\n    cacheable=None,\n    exist_ok=False,\n    format=None,\n)\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def step(\n    name: Optional[Union[str, StepFunctionT]] = None,\n    *,\n    version: Optional[str] = None,\n    deterministic: bool = True,\n    cacheable: Optional[bool] = None,\n    exist_ok: bool = False,\n    format: Optional[Union[str, Format]] = None,\n) -&gt; Union[StepFunctionT, Callable[[StepFunctionT], StepFunctionT]]:\n    def register(name: str, func: StepFunctionT) -&gt; None:\n        step_class = WorkflowStep[Any].from_callable(\n            func,\n            version=version,\n            deterministic=deterministic,\n            cacheable=cacheable,\n            format=format,\n        )\n        WorkflowStep.register(name, exist_ok=exist_ok)(step_class)\n\n    def decorator(func: StepFunctionT) -&gt; StepFunctionT:\n        nonlocal name\n        name = name or func.__name__\n        assert isinstance(name, str)\n        register(name, func)\n        return func\n\n    if name is None:\n        return decorator\n\n    if not isinstance(name, str):\n        func = name\n        register(func.__name__, func)\n        return func\n\n    return decorator\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.use_step_context","title":"use_step_context","text":"<pre><code>use_step_context()\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def use_step_context() -&gt; Optional[WorkflowStepContext]:\n    return _STEP_CONTEXT.get()\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.use_step_logger","title":"use_step_logger","text":"<pre><code>use_step_logger(default: Union[str, Logger]) -&gt; Logger\n</code></pre><pre><code>use_step_logger(default: None = ...) -&gt; Optional[Logger]\n</code></pre> <pre><code>use_step_logger(default=None)\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def use_step_logger(default: Optional[Union[str, Logger]] = None) -&gt; Optional[Logger]:\n    context = use_step_context()\n    if context is not None:\n        return get_step_logger_from_info(context.info)\n    if default is None:\n        return None\n    if isinstance(default, str):\n        return getLogger(default)\n    return default\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.use_step_workdir","title":"use_step_workdir","text":"<pre><code>use_step_workdir()\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def use_step_workdir() -&gt; Path:\n    context = use_step_context()\n    if context is None:\n        raise RuntimeError(\"No step context found\")\n    workdir = WORKFLOW_WORKSPACE_DIRECTORY / context.info.fingerprint\n    workdir.mkdir(parents=True, exist_ok=True)\n    return workdir\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.get_step_logger_from_info","title":"get_step_logger_from_info","text":"<pre><code>get_step_logger_from_info(info)\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>def get_step_logger_from_info(info: WorkflowStepInfo) -&gt; Logger:\n    return getLogger(f\"formed.workflow.step.{info.name}.{info.fingerprint[:8]}\")\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.step.load_artifact","title":"load_artifact","text":"<pre><code>load_artifact(path, format)\n</code></pre> Source code in <code>src/formed/workflow/step.py</code> <pre><code>@step(\"formed::load_artifact\", cacheable=False)\ndef load_artifact(path: str | PathLike, format: Format):\n    path = minato.cached_path(path)\n    return format.read(path)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.utils","title":"formed.workflow.utils","text":""},{"location":"reference/workflow/#formed.workflow.utils.WorkflowJSONEncoder","title":"WorkflowJSONEncoder","text":"<p>               Bases: <code>JSONEncoder</code></p>"},{"location":"reference/workflow/#formed.workflow.utils.WorkflowJSONEncoder.default","title":"default","text":"<pre><code>default(o)\n</code></pre> Source code in <code>src/formed/workflow/utils.py</code> <pre><code>def default(self, o: Any) -&gt; Any:\n    if isinstance(o, IJsonCompatible):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.CONTAINER,\n            _PYTHON_DATA_VALUE_KEY: o.json(),\n            _PYTHON_DATA_CONTAINER_KEY: f\"{o.__class__.__module__}.{o.__class__.__qualname__}\",\n        }\n    if isinstance(o, IJsonSerializable):\n        return o.json()\n    if isinstance(o, datetime.datetime):\n        return {_PYTHON_DATA_TYPE_KEY: _JSONDataType.DATETIME, _PYTHON_DATA_VALUE_KEY: o.isoformat()}\n    if is_namedtuple(o):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.CONTAINER,\n            _PYTHON_DATA_VALUE_KEY: o._asdict(),\n            _PYTHON_DATA_CONTAINER_KEY: f\"{o.__class__.__module__}.{o.__class__.__qualname__}\",\n        }\n    if isinstance(o, tuple):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.CONTAINER,\n            _PYTHON_DATA_VALUE_KEY: [self.default(i) for i in o],\n            _PYTHON_DATA_CONTAINER_KEY: f\"{o.__class__.__module__}.{o.__class__.__qualname__}\",\n        }\n    if isinstance(o, (set, frozenset)):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.CONTAINER,\n            _PYTHON_DATA_VALUE_KEY: sorted((self.default(i) for i in o), key=lambda x: (hash(x), str(x))),\n            _PYTHON_DATA_CONTAINER_KEY: f\"{o.__class__.__module__}.{o.__class__.__qualname__}\",\n        }\n    if dataclasses.is_dataclass(o) and not isinstance(o, type):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.CONTAINER,\n            _PYTHON_DATA_VALUE_KEY: {\n                field.name: self.default(getattr(o, field.name))\n                for field in dataclasses.fields(o)\n                if hasattr(o, field.name)\n            },\n            _PYTHON_DATA_CONTAINER_KEY: f\"{o.__class__.__module__}.{o.__class__.__qualname__}\",\n        }\n    if isinstance(o, IPydanticModel):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.CONTAINER,\n            _PYTHON_DATA_VALUE_KEY: o.model_dump(mode=\"json\"),\n            _PYTHON_DATA_CONTAINER_KEY: f\"{o.__class__.__module__}.{o.__class__.__qualname__}\",\n        }\n    if isinstance(o, type):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.CLASS,\n            _PYTHON_DATA_VALUE_KEY: f\"{o.__module__}.{o.__qualname__}\",\n        }\n    if isinstance(o, Counter):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.COUNTER,\n            _PYTHON_DATA_VALUE_KEY: dict(o),\n        }\n    if isinstance(o, numpy.ndarray):\n        return {\n            _PYTHON_DATA_TYPE_KEY: _JSONDataType.NDARRAY,\n            _PYTHON_DATA_VALUE_KEY: {\n                \"dtype\": str(o.dtype),\n                \"shape\": o.shape,\n                \"data\": base64.b85encode(o.tobytes()).decode(),\n            },\n        }\n    if isinstance(o, list):\n        return [self.default(i) for i in o]\n    if isinstance(o, dict):\n        return {k: self.default(v) for k, v in o.items()}\n    if isinstance(o, (bool, int, float, str)) or o is None:\n        return o\n    return {\n        _PYTHON_DATA_TYPE_KEY: _JSONDataType.PICKLE,\n        _PYTHON_DATA_VALUE_KEY: base64.b85encode(cloudpickle.dumps(o)).decode(),\n    }\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.utils.WorkflowJSONDecoder","title":"WorkflowJSONDecoder","text":"<pre><code>WorkflowJSONDecoder()\n</code></pre> <p>               Bases: <code>JSONDecoder</code></p> Source code in <code>src/formed/workflow/utils.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__(object_hook=self._reconstruct)\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.utils.object_fingerprint","title":"object_fingerprint","text":"<pre><code>object_fingerprint(obj)\n</code></pre> Source code in <code>src/formed/workflow/utils.py</code> <pre><code>def object_fingerprint(obj: Any) -&gt; str:\n    with suppress(TypeError, ValueError):\n        # This is a workaround for fingerprint consistency.\n        obj = json.loads(json.dumps(obj, cls=WorkflowJSONEncoder, sort_keys=True))\n    return b58encode(hash_object_bytes(obj)).decode()\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.utils.as_jsonvalue","title":"as_jsonvalue","text":"<pre><code>as_jsonvalue(value)\n</code></pre> Source code in <code>src/formed/workflow/utils.py</code> <pre><code>def as_jsonvalue(value: Any) -&gt; JsonValue:\n    return cast(JsonValue, json.loads(json.dumps(value, cls=WorkflowJSONEncoder)))\n</code></pre>"},{"location":"reference/workflow/#formed.workflow.utils.from_jsonvalue","title":"from_jsonvalue","text":"<pre><code>from_jsonvalue(value)\n</code></pre> Source code in <code>src/formed/workflow/utils.py</code> <pre><code>def from_jsonvalue(value: JsonValue) -&gt; Any:\n    return WorkflowJSONDecoder._reconstruct(value)\n</code></pre>"},{"location":"reference/integrations/datasets/","title":"Datasets","text":""},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow","title":"formed.integrations.datasets.workflow","text":"<p>Workflow steps for Hugging Face Datasets integration.</p> <p>This module provides workflow steps for loading, processing, and manipulating datasets using the Hugging Face Datasets library.</p> Available Steps <ul> <li><code>datasets::load</code>: Load a dataset from disk or the Hugging Face Hub.</li> <li><code>datasets::compose</code>: Compose multiple Dataset objects into a DatasetDict.</li> <li><code>datasets::concatenate</code>: Concatenate multiple datasets into a single dataset.</li> <li><code>datasets::train_test_split</code>: Split a dataset into train and test sets.</li> </ul>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.DatasetFormat","title":"DatasetFormat","text":"<p>               Bases: <code>Generic[DatasetOrMappingT]</code>, <code>Format[DatasetOrMappingT]</code></p>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.DatasetFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.DatasetFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/integrations/datasets/workflow.py</code> <pre><code>def write(self, artifact: DatasetOrMappingT, directory: Path) -&gt; None:\n    if isinstance(artifact, Mapping):\n        for key, dataset in artifact.items():\n            dataset.save_to_disk(str(directory / f\"data.{key}\"))\n    else:\n        artifact.save_to_disk(str(directory / \"data\"))\n</code></pre>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.DatasetFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/integrations/datasets/workflow.py</code> <pre><code>def read(self, directory: Path) -&gt; DatasetOrMappingT:\n    if (directory / \"data\").exists():\n        return cast(DatasetOrMappingT, datasets.load_from_disk(str(directory / \"data\")))\n    return cast(\n        DatasetOrMappingT,\n        {datadir.name[5:]: datasets.load_from_disk(str(datadir)) for datadir in directory.glob(\"data.*\")},\n    )\n</code></pre>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.DatasetFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.load_dataset","title":"load_dataset","text":"<pre><code>load_dataset(path, **kwargs)\n</code></pre> <p>Load a dataset from disk or the Hugging Face Hub.</p> <p>This step loads a dataset from a local path or downloads it from the Hugging Face Hub. The dataset can be either a Dataset or DatasetDict.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to the dataset (local or remote).</p> <p> TYPE: <code>str | PathLike</code> </p> <code>**kwargs</code> <p>Additional arguments to pass to <code>datasets.load_dataset</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Dataset</code> <p>Loaded Dataset or DatasetDict.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the loaded object is not a Dataset or DatasetDict.</p> Source code in <code>src/formed/integrations/datasets/workflow.py</code> <pre><code>@step(\"datasets::load\", cacheable=False, format=DatasetFormat())\ndef load_dataset(\n    path: str | PathLike,\n    **kwargs: Any,\n) -&gt; Dataset:\n    \"\"\"Load a dataset from disk or the Hugging Face Hub.\n\n    This step loads a dataset from a local path or downloads it from the\n    Hugging Face Hub. The dataset can be either a Dataset or DatasetDict.\n\n    Args:\n        path: Path to the dataset (local or remote).\n        **kwargs: Additional arguments to pass to `datasets.load_dataset`.\n\n    Returns:\n        Loaded Dataset or DatasetDict.\n\n    Raises:\n        ValueError: If the loaded object is not a Dataset or DatasetDict.\n    \"\"\"\n    with suppress(FileNotFoundError):\n        path = minato.cached_path(path)\n    if Path(path).exists():\n        dataset = datasets.load_from_disk(str(path))\n    else:\n        dataset = cast(Dataset, datasets.load_dataset(str(path), **kwargs))\n    if not isinstance(dataset, (datasets.Dataset, datasets.DatasetDict)):\n        raise ValueError(\"Only Dataset or DatasetDict is supported\")\n    return dataset\n</code></pre>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.compose_datasetdict","title":"compose_datasetdict","text":"<pre><code>compose_datasetdict(**kwargs)\n</code></pre> <p>Compose multiple Dataset objects into a single DatasetDict.</p> <p>This step combines individual Dataset objects into a DatasetDict, filtering out any non-Dataset values.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>Named datasets to compose. Only Dataset instances are included.</p> <p> TYPE: <code>Dataset</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DatasetDict</code> <p>DatasetDict containing all provided Dataset instances.</p> Source code in <code>src/formed/integrations/datasets/workflow.py</code> <pre><code>@step(\"datasets::compose\", format=DatasetFormat())\ndef compose_datasetdict(**kwargs: Dataset) -&gt; datasets.DatasetDict:\n    \"\"\"Compose multiple Dataset objects into a single DatasetDict.\n\n    This step combines individual Dataset objects into a DatasetDict,\n    filtering out any non-Dataset values.\n\n    Args:\n        **kwargs: Named datasets to compose. Only Dataset instances are included.\n\n    Returns:\n        DatasetDict containing all provided Dataset instances.\n    \"\"\"\n    datasets_: dict[str, datasets.Dataset] = {\n        key: dataset for key, dataset in kwargs.items() if isinstance(dataset, datasets.Dataset)\n    }\n    if len(datasets_) != len(kwargs):\n        logger = use_step_logger(__name__)\n        logger.warning(\n            \"Following keys are ignored since they are not Dataset instances: %s\",\n            set(kwargs) - set(datasets_),\n        )\n    return datasets.DatasetDict(**datasets_)\n</code></pre>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.concatenate_datasets","title":"concatenate_datasets","text":"<pre><code>concatenate_datasets(dsets, **kwargs)\n</code></pre> <p>Concatenate multiple datasets into a single dataset.</p> PARAMETER DESCRIPTION <code>dsets</code> <p>List of datasets to concatenate.</p> <p> TYPE: <code>list[Dataset]</code> </p> <code>**kwargs</code> <p>Additional arguments to pass to <code>datasets.concatenate_datasets</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Dataset</code> <p>Concatenated dataset.</p> Source code in <code>src/formed/integrations/datasets/workflow.py</code> <pre><code>@step(\"datasets::concatenate\", format=DatasetFormat())\ndef concatenate_datasets(dsets: list[datasets.Dataset], **kwargs: Any) -&gt; datasets.Dataset:\n    \"\"\"Concatenate multiple datasets into a single dataset.\n\n    Args:\n        dsets: List of datasets to concatenate.\n        **kwargs: Additional arguments to pass to `datasets.concatenate_datasets`.\n\n    Returns:\n        Concatenated dataset.\n    \"\"\"\n    return cast(datasets.Dataset, datasets.concatenate_datasets(dsets, **kwargs))\n</code></pre>"},{"location":"reference/integrations/datasets/#formed.integrations.datasets.workflow.train_test_split","title":"train_test_split","text":"<pre><code>train_test_split(\n    dataset, train_key=\"train\", test_key=\"test\", **kwargs\n)\n</code></pre> <p>Split a dataset into train and test sets.</p> <p>This step splits a Dataset or DatasetDict into training and test sets. For DatasetDict inputs, each split is performed independently.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>Dataset or DatasetDict to split.</p> <p> TYPE: <code>Dataset</code> </p> <code>train_key</code> <p>Key name for the training split.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'train'</code> </p> <code>test_key</code> <p>Key name for the test split.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'test'</code> </p> <code>**kwargs</code> <p>Additional arguments to pass to <code>train_test_split</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>dict[str, Dataset]</code> <p>Dictionary with train and test splits.</p> Source code in <code>src/formed/integrations/datasets/workflow.py</code> <pre><code>@step(\"datasets::train_test_split\", format=DatasetFormat())\ndef train_test_split(\n    dataset: Dataset,\n    train_key: str = \"train\",\n    test_key: str = \"test\",\n    **kwargs: Any,\n) -&gt; dict[str, Dataset]:\n    \"\"\"Split a dataset into train and test sets.\n\n    This step splits a Dataset or DatasetDict into training and test sets.\n    For DatasetDict inputs, each split is performed independently.\n\n    Args:\n        dataset: Dataset or DatasetDict to split.\n        train_key: Key name for the training split.\n        test_key: Key name for the test split.\n        **kwargs: Additional arguments to pass to `train_test_split`.\n\n    Returns:\n        Dictionary with train and test splits.\n    \"\"\"\n    if isinstance(dataset, datasets.Dataset):\n        split = dataset.train_test_split(**kwargs)\n        return {train_key: split[\"train\"], test_key: split[\"test\"]}\n    else:\n        train_datasets: dict[str, datasets.Dataset] = {}\n        test_datasets: dict[str, datasets.Dataset] = {}\n        for key, dset in dataset.items():\n            split = dset.train_test_split(**kwargs)\n            train_datasets[str(key)] = split[\"train\"]\n            test_datasets[str(key)] = split[\"test\"]\n        return {\n            train_key: datasets.DatasetDict(**train_datasets),\n            test_key: datasets.DatasetDict(**test_datasets),\n        }\n</code></pre>"},{"location":"reference/integrations/flax/","title":"Flax","text":"<ul> <li>Distributors</li> <li>Model</li> <li>Modules<ul> <li>Embedders</li> <li>Encoders</li> <li>Feedforward</li> <li>Losses</li> <li>Samplers</li> <li>Vectorizers</li> <li>Weighters</li> </ul> </li> <li>Training<ul> <li>Callbacks</li> <li>Engine</li> <li>Exceptions</li> <li>State</li> <li>Trainer</li> </ul> </li> <li>Random</li> <li>Utils</li> <li>Workflow</li> </ul>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors","title":"formed.integrations.flax.distributors","text":"<p>Distributed computing abstractions for Flax models.</p> <p>This module provides abstractions for distributed training across multiple devices, supporting both single-device and data-parallel training strategies.</p> Key Components <ul> <li><code>BaseDistributor</code>: Abstract interface for device distribution strategies</li> <li><code>SingleDeviceDistributor</code>: No-op distributor for single-device training</li> <li><code>DataParallelDistributor</code>: Data-parallel training using JAX pmap</li> </ul> Features <ul> <li>Transparent device sharding and replication</li> <li>JIT compilation with device-specific optimizations</li> <li>Reduction operations (mean, sum) across devices</li> <li>Compatible with FlaxTrainer</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax import DataParallelDistributor\n&gt;&gt;&gt; import jax\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create data-parallel distributor for all available devices\n&gt;&gt;&gt; distributor = DataParallelDistributor(axis_name=\"batch\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Shard batch across devices\n&gt;&gt;&gt; sharded_batch = distributor.shard(batch)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Map function across devices\n&gt;&gt;&gt; train_step = distributor.map(training_function)\n&gt;&gt;&gt; outputs = train_step(sharded_batch, state)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.BaseDistributor","title":"BaseDistributor","text":"<p>               Bases: <code>Registrable</code>, <code>ABC</code>, <code>Generic[ModelInputT]</code></p> <p>Abstract base class for device distribution strategies.</p> <p>BaseDistributor defines the interface for distributing computations across devices in a JAX/Flax training pipeline. It handles data sharding, replication, and reduction operations.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ModelInputT</code> <p>Type of model input data.</p> <p> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.BaseDistributor.shard","title":"shard","text":"<pre><code>shard(inputs)\n</code></pre> <p>Shard inputs across devices.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input data to shard.</p> <p> TYPE: <code>ModelInputT</code> </p> RETURNS DESCRIPTION <code>ModelInputT</code> <p>Sharded input data with an additional device dimension.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def shard(self, inputs: ModelInputT) -&gt; ModelInputT:\n    \"\"\"Shard inputs across devices.\n\n    Args:\n        inputs: Input data to shard.\n\n    Returns:\n        Sharded input data with an additional device dimension.\n\n    \"\"\"\n    return inputs\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.BaseDistributor.replicate","title":"replicate","text":"<pre><code>replicate(inputs)\n</code></pre> <p>Replicate data across all devices.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Data to replicate.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Replicated data with device dimension.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def replicate(self, inputs: _T) -&gt; _T:\n    \"\"\"Replicate data across all devices.\n\n    Args:\n        inputs: Data to replicate.\n\n    Returns:\n        Replicated data with device dimension.\n\n    \"\"\"\n    return inputs\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.BaseDistributor.unreplicate","title":"unreplicate","text":"<pre><code>unreplicate(inputs)\n</code></pre> <p>Extract data from the first device, removing device dimension.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Replicated data with device dimension.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Data from first device without device dimension.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def unreplicate(self, inputs: _T) -&gt; _T:\n    \"\"\"Extract data from the first device, removing device dimension.\n\n    Args:\n        inputs: Replicated data with device dimension.\n\n    Returns:\n        Data from first device without device dimension.\n\n    \"\"\"\n    return inputs\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.BaseDistributor.map","title":"map  <code>abstractmethod</code>","text":"<pre><code>map(fn, static_argnums=())\n</code></pre> <p>Map a function across devices with JIT compilation.</p> PARAMETER DESCRIPTION <code>fn</code> <p>Function to map across devices.</p> <p> TYPE: <code>_CallableT</code> </p> <code>static_argnums</code> <p>Indices of static arguments.</p> <p> TYPE: <code>Sequence[int]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>_CallableT</code> <p>Mapped and compiled function.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>@abc.abstractmethod\ndef map(self, fn: _CallableT, static_argnums: Sequence[int] = ()) -&gt; _CallableT:\n    \"\"\"Map a function across devices with JIT compilation.\n\n    Args:\n        fn: Function to map across devices.\n        static_argnums: Indices of static arguments.\n\n    Returns:\n        Mapped and compiled function.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.BaseDistributor.reduce","title":"reduce  <code>abstractmethod</code>","text":"<pre><code>reduce(array, op='mean')\n</code></pre> <p>Reduce an array across devices.</p> PARAMETER DESCRIPTION <code>array</code> <p>Array to reduce.</p> <p> TYPE: <code>_ArrayT</code> </p> <code>op</code> <p>Reduction operation (<code>\"mean\"</code> or <code>\"sum\"</code>).</p> <p> TYPE: <code>_ReduceOp</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>_ArrayT</code> <p>Reduced array.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>@abc.abstractmethod\ndef reduce(self, array: _ArrayT, op: _ReduceOp = \"mean\") -&gt; _ArrayT:\n    \"\"\"Reduce an array across devices.\n\n    Args:\n        array: Array to reduce.\n        op: Reduction operation (`\"mean\"` or `\"sum\"`).\n\n    Returns:\n        Reduced array.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.SingleDeviceDistributor","title":"SingleDeviceDistributor","text":"<p>               Bases: <code>BaseDistributor[ModelInputT]</code></p> <p>Distributor for single-device training.</p> <p>This distributor applies JIT compilation without any device distribution. All shard, replicate, and unreplicate operations are no-ops.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; distributor = SingleDeviceDistributor()\n&gt;&gt;&gt; train_step = distributor.map(my_train_function)\n&gt;&gt;&gt; output = train_step(batch, state, trainer)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.SingleDeviceDistributor.map","title":"map","text":"<pre><code>map(fn, static_argnums=())\n</code></pre> <p>Apply JIT compilation to a function.</p> PARAMETER DESCRIPTION <code>fn</code> <p>Function to compile.</p> <p> TYPE: <code>_CallableT</code> </p> <code>static_argnums</code> <p>Indices of static arguments.</p> <p> TYPE: <code>Sequence[int]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>_CallableT</code> <p>JIT-compiled function.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def map(self, fn: _CallableT, static_argnums: Sequence[int] = ()) -&gt; _CallableT:\n    \"\"\"Apply JIT compilation to a function.\n\n    Args:\n        fn: Function to compile.\n        static_argnums: Indices of static arguments.\n\n    Returns:\n        JIT-compiled function.\n\n    \"\"\"\n    return cast(_CallableT, nnx.jit(fn, static_argnums=static_argnums))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.SingleDeviceDistributor.reduce","title":"reduce","text":"<pre><code>reduce(array, op='mean')\n</code></pre> <p>Return array unchanged (no reduction needed for single device).</p> PARAMETER DESCRIPTION <code>array</code> <p>Input array.</p> <p> TYPE: <code>_ArrayT</code> </p> <code>op</code> <p>Reduction operation (ignored).</p> <p> TYPE: <code>_ReduceOp</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>_ArrayT</code> <p>Input array unchanged.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def reduce(self, array: _ArrayT, op: _ReduceOp = \"mean\") -&gt; _ArrayT:\n    \"\"\"Return array unchanged (no reduction needed for single device).\n\n    Args:\n        array: Input array.\n        op: Reduction operation (ignored).\n\n    Returns:\n        Input array unchanged.\n\n    \"\"\"\n    return array\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.SingleDeviceDistributor.shard","title":"shard","text":"<pre><code>shard(inputs)\n</code></pre> <p>Shard inputs across devices.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input data to shard.</p> <p> TYPE: <code>ModelInputT</code> </p> RETURNS DESCRIPTION <code>ModelInputT</code> <p>Sharded input data with an additional device dimension.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def shard(self, inputs: ModelInputT) -&gt; ModelInputT:\n    \"\"\"Shard inputs across devices.\n\n    Args:\n        inputs: Input data to shard.\n\n    Returns:\n        Sharded input data with an additional device dimension.\n\n    \"\"\"\n    return inputs\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.SingleDeviceDistributor.replicate","title":"replicate","text":"<pre><code>replicate(inputs)\n</code></pre> <p>Replicate data across all devices.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Data to replicate.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Replicated data with device dimension.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def replicate(self, inputs: _T) -&gt; _T:\n    \"\"\"Replicate data across all devices.\n\n    Args:\n        inputs: Data to replicate.\n\n    Returns:\n        Replicated data with device dimension.\n\n    \"\"\"\n    return inputs\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.SingleDeviceDistributor.unreplicate","title":"unreplicate","text":"<pre><code>unreplicate(inputs)\n</code></pre> <p>Extract data from the first device, removing device dimension.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Replicated data with device dimension.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Data from first device without device dimension.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def unreplicate(self, inputs: _T) -&gt; _T:\n    \"\"\"Extract data from the first device, removing device dimension.\n\n    Args:\n        inputs: Replicated data with device dimension.\n\n    Returns:\n        Data from first device without device dimension.\n\n    \"\"\"\n    return inputs\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.DataParallelDistributor","title":"DataParallelDistributor","text":"<pre><code>DataParallelDistributor(\n    axis_name=\"batch\", num_devices=None\n)\n</code></pre> <p>               Bases: <code>BaseDistributor[ModelInputT]</code></p> <p>Distributor for data-parallel training across multiple devices.</p> <p>This distributor uses JAX's pmap to execute the same computation on different data shards across multiple devices. Data is automatically sharded along the batch dimension.</p> PARAMETER DESCRIPTION <code>axis_name</code> <p>Name for the device axis (used in reduction operations).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'batch'</code> </p> <code>num_devices</code> <p>Number of devices to use. Defaults to all local devices.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Train on 4 GPUs with data parallelism\n&gt;&gt;&gt; distributor = DataParallelDistributor(\n...     axis_name=\"batch\",\n...     num_devices=4\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Shard batch of size 32 into 4 shards of size 8\n&gt;&gt;&gt; sharded = distributor.shard(batch)\n&gt;&gt;&gt; assert sharded.shape == (4, 8, ...)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Map training step across devices\n&gt;&gt;&gt; train_step = distributor.map(my_train_step)\n</code></pre> Note <p>Batch size must be divisible by num_devices for proper sharding.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def __init__(\n    self,\n    axis_name: str = \"batch\",\n    num_devices: int | None = None,\n) -&gt; None:\n    self._axis_name = axis_name\n    self._num_devices = num_devices or jax.local_device_count()\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.DataParallelDistributor.shard","title":"shard","text":"<pre><code>shard(inputs)\n</code></pre> <p>Shard inputs along the batch dimension across devices.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input data with batch dimension.</p> <p> TYPE: <code>ModelInputT</code> </p> RETURNS DESCRIPTION <code>ModelInputT</code> <p>Sharded inputs with shape (num_devices, batch_per_device, ...).</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def shard(self, inputs: ModelInputT) -&gt; ModelInputT:\n    \"\"\"Shard inputs along the batch dimension across devices.\n\n    Args:\n        inputs: Input data with batch dimension.\n\n    Returns:\n        Sharded inputs with shape (num_devices, batch_per_device, ...).\n\n    \"\"\"\n    return jax.tree_util.tree_map(lambda x: x.reshape((self._num_devices, -1) + x.shape[1:]), inputs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.DataParallelDistributor.replicate","title":"replicate","text":"<pre><code>replicate(inputs)\n</code></pre> <p>Replicate data across all devices.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Data to replicate.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Replicated data with device dimension.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def replicate(self, inputs: _T) -&gt; _T:\n    \"\"\"Replicate data across all devices.\n\n    Args:\n        inputs: Data to replicate.\n\n    Returns:\n        Replicated data with device dimension.\n\n    \"\"\"\n    return flax.jax_utils.replicate(inputs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.DataParallelDistributor.unreplicate","title":"unreplicate","text":"<pre><code>unreplicate(inputs)\n</code></pre> <p>Extract data from the first device.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Replicated data.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>_T</code> <p>Data from first device.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def unreplicate(self, inputs: _T) -&gt; _T:\n    \"\"\"Extract data from the first device.\n\n    Args:\n        inputs: Replicated data.\n\n    Returns:\n        Data from first device.\n\n    \"\"\"\n    return flax.jax_utils.unreplicate(inputs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.DataParallelDistributor.map","title":"map","text":"<pre><code>map(fn, static_argnums=())\n</code></pre> <p>Map function across devices using pmap.</p> PARAMETER DESCRIPTION <code>fn</code> <p>Function to parallelize.</p> <p> TYPE: <code>_CallableT</code> </p> <code>static_argnums</code> <p>Indices of static arguments to broadcast.</p> <p> TYPE: <code>Sequence[int]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>_CallableT</code> <p>Parallelized function using pmap.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def map(self, fn: _CallableT, static_argnums: Sequence[int] = ()) -&gt; _CallableT:\n    \"\"\"Map function across devices using pmap.\n\n    Args:\n        fn: Function to parallelize.\n        static_argnums: Indices of static arguments to broadcast.\n\n    Returns:\n        Parallelized function using pmap.\n\n    \"\"\"\n    return nnx.pmap(fn, axis_name=self._axis_name, static_broadcasted_argnums=static_argnums)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.distributors.DataParallelDistributor.reduce","title":"reduce","text":"<pre><code>reduce(array, op='mean')\n</code></pre> <p>Reduce array across devices.</p> PARAMETER DESCRIPTION <code>array</code> <p>Array to reduce across device dimension.</p> <p> TYPE: <code>_ArrayT</code> </p> <code>op</code> <p>Reduction operation - <code>\"sum\"</code> or <code>\"mean\"</code>.</p> <p> TYPE: <code>_ReduceOp</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>_ArrayT</code> <p>Reduced array.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported reduction operation is specified.</p> Source code in <code>src/formed/integrations/flax/distributors.py</code> <pre><code>def reduce(self, array: _ArrayT, op: _ReduceOp = \"mean\") -&gt; _ArrayT:\n    \"\"\"Reduce array across devices.\n\n    Args:\n        array: Array to reduce across device dimension.\n        op: Reduction operation - `\"sum\"` or `\"mean\"`.\n\n    Returns:\n        Reduced array.\n\n    Raises:\n        ValueError: If unsupported reduction operation is specified.\n\n    \"\"\"\n    if op == \"sum\":\n        return jax.lax.psum(array, axis_name=self._axis_name)\n    elif op == \"mean\":\n        return jax.lax.pmean(array, axis_name=self._axis_name)\n    raise ValueError(f\"Unsupported reduce operation: {op}\")\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.model","title":"formed.integrations.flax.model","text":"<p>Base model abstraction for Flax NNX models.</p> <p>This module provides the base class for all Flax models in the framework, integrating Flax NNX with the registrable pattern for configuration-based model instantiation.</p> Key Features <ul> <li>Integration with Flax NNX Module system</li> <li>Registrable pattern for configuration-based instantiation</li> <li>Generic type support for inputs, outputs, and parameters</li> <li>Compatible with FlaxTrainer for end-to-end training</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax import BaseFlaxModel\n&gt;&gt;&gt; from flax import nnx\n&gt;&gt;&gt; import jax\n&gt;&gt;&gt;\n&gt;&gt;&gt; @BaseFlaxModel.register(\"my_model\")\n... class MyModel(BaseFlaxModel[dict, jax.Array, None]):\n...     def __init__(self, rngs: nnx.Rngs, hidden_dim: int):\n...         self.linear = nnx.Linear(10, hidden_dim, rngs=rngs)\n...\n...     def __call__(self, inputs: dict, params: None = None) -&gt; jax.Array:\n...         return self.linear(inputs[\"features\"])\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.model.BaseFlaxModel","title":"BaseFlaxModel","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>Base class for all Flax NNX models in the framework.</p> <p>This class combines Flax's NNX Module with the registrable pattern, allowing models to be instantiated from configuration files and seamlessly integrated with the training infrastructure.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ModelInputT</code> <p>Type of input data to the model.</p> <p> </p> <code>ModelOutputT</code> <p>Type of model output.</p> <p> </p> <code>ModelParamsT</code> <p>Type of additional parameters (typically <code>None</code> or a dataclass).</p> <p> </p> Note <p>Subclasses should implement <code>__call__</code> to define the forward pass. Models are automatically compatible with <code>FlaxTrainer</code> when registered.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders","title":"formed.integrations.flax.modules.embedders","text":"<p>Text embedding modules for Flax models.</p> <p>This module provides embedders that convert tokenized text into dense vector representations. Embedders handle various text representations including surface forms, part-of-speech tags, and character sequences.</p> Key Components <ul> <li>BaseEmbedder: Abstract base class for all embedders</li> <li>TokenEmbedder: Embeds token ID sequences into dense vectors</li> <li>AnalyzedTextEmbedder: Combines multiple embedding types (surface, POS, chars)</li> </ul> Features <ul> <li>Support for nested token sequences (e.g., word -&gt; character)</li> <li>Automatic masking and padding handling</li> <li>Configurable vectorization for character-level embeddings</li> <li>Concatenation of multiple embedding types</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax.modules import TokenEmbedder, AnalyzedTextEmbedder\n&gt;&gt;&gt; from flax import nnx\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Simple token embedder\n&gt;&gt;&gt; embedder = TokenEmbedder(\n...     vocab_size=10000,\n...     embedding_dim=128,\n...     rngs=nnx.Rngs(0)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Multi-feature embedder\n&gt;&gt;&gt; embedder = AnalyzedTextEmbedder(\n...     surface=TokenEmbedder(vocab_size=10000, embedding_dim=128, rngs=rngs),\n...     postag=TokenEmbedder(vocab_size=50, embedding_dim=32, rngs=rngs)\n... )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.EmbedderOutput","title":"EmbedderOutput","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Output from an embedder.</p> ATTRIBUTE DESCRIPTION <code>embeddings</code> <p>Dense embeddings of shape (batch_size, seq_len, embedding_dim).</p> <p> TYPE: <code>Array</code> </p> <code>mask</code> <p>Attention mask of shape (batch_size, seq_len).</p> <p> TYPE: <code>Array</code> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.EmbedderOutput.embeddings","title":"embeddings  <code>instance-attribute</code>","text":"<pre><code>embeddings\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.EmbedderOutput.mask","title":"mask  <code>instance-attribute</code>","text":"<pre><code>mask\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.BaseEmbedder","title":"BaseEmbedder","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_TextBatchT]</code>, <code>ABC</code></p> <p>Abstract base class for text embedders.</p> <p>Embedders convert tokenized text into dense vector representations. They output both embeddings and attention masks.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_TextBatchT</code> <p>Type of input batch (e.g., IIDSequenceBatch, IAnalyzedTextBatch).</p> <p> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.BaseEmbedder.get_output_dim","title":"get_output_dim  <code>abstractmethod</code>","text":"<pre><code>get_output_dim()\n</code></pre> <p>Get the output embedding dimension.</p> RETURNS DESCRIPTION <code>int</code> <p>Embedding dimension.</p> Source code in <code>src/formed/integrations/flax/modules/embedders.py</code> <pre><code>@abc.abstractmethod\ndef get_output_dim(self) -&gt; int:\n    \"\"\"Get the output embedding dimension.\n\n    Returns:\n        Embedding dimension.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.TokenEmbedder","title":"TokenEmbedder","text":"<pre><code>TokenEmbedder(\n    vocab_size, embedding_dim, *, vectorizer=None, rngs=None\n)\n</code></pre> <p>               Bases: <code>BaseEmbedder[IIDSequenceBatch]</code></p> <p>Embedder for token ID sequences.</p> <p>This embedder converts token IDs into dense embeddings using a learned embedding matrix. It supports both 2D (batch_size, seq_len) and 3D (batch_size, seq_len, char_len) token ID tensors.</p> <p>For 3D inputs (e.g., character-level tokens within words), the embedder can either average the embeddings or apply a custom vectorizer.</p> PARAMETER DESCRIPTION <code>vocab_size</code> <p>Size of the vocabulary.</p> <p> TYPE: <code>int</code> </p> <code>embedding_dim</code> <p>Dimension of the embedding vectors.</p> <p> TYPE: <code>int</code> </p> <code>vectorizer</code> <p>Optional vectorizer for 3D inputs (character sequences).</p> <p> TYPE: <code>BaseSequenceVectorizer | None</code> DEFAULT: <code>None</code> </p> <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple word embeddings\n&gt;&gt;&gt; embedder = TokenEmbedder(vocab_size=10000, embedding_dim=128, rngs=rngs)\n&gt;&gt;&gt; output = embedder(word_ids_batch)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Character-level embeddings with pooling\n&gt;&gt;&gt; from formed.integrations.flax.modules import BagOfEmbeddingsSequenceVectorizer\n&gt;&gt;&gt; embedder = TokenEmbedder(\n...     vocab_size=256,\n...     embedding_dim=32,\n...     vectorizer=BagOfEmbeddingsSequenceVectorizer(pooling=\"max\"),\n...     rngs=rngs\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/embedders.py</code> <pre><code>def __init__(\n    self,\n    vocab_size: int,\n    embedding_dim: int,\n    *,\n    vectorizer: BaseSequenceVectorizer | None = None,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    rngs = rngs or require_rngs()\n    self._embedding = nnx.Embed(num_embeddings=vocab_size, features=embedding_dim, rngs=rngs)\n    self._vectorizer = vectorizer\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.TokenEmbedder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/embedders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._embedding.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.AnalyzedTextEmbedder","title":"AnalyzedTextEmbedder","text":"<pre><code>AnalyzedTextEmbedder(\n    surface=None, postag=None, character=None\n)\n</code></pre> <p>               Bases: <code>BaseEmbedder[IAnalyzedTextBatch]</code></p> <p>Embedder for analyzed text with multiple linguistic features.</p> <p>This embedder combines embeddings from multiple linguistic representations (surface forms, part-of-speech tags, character sequences) by concatenating them along the feature dimension.</p> PARAMETER DESCRIPTION <code>surface</code> <p>Optional embedder for surface form tokens.</p> <p> TYPE: <code>BaseEmbedder[IIDSequenceBatch] | None</code> DEFAULT: <code>None</code> </p> <code>postag</code> <p>Optional embedder for part-of-speech tags.</p> <p> TYPE: <code>BaseEmbedder[IIDSequenceBatch] | None</code> DEFAULT: <code>None</code> </p> <code>character</code> <p>Optional embedder for character sequences.</p> <p> TYPE: <code>BaseEmbedder[IIDSequenceBatch] | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If all embedders are None (at least one is required).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax.modules import (\n...     AnalyzedTextEmbedder,\n...     TokenEmbedder\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; embedder = AnalyzedTextEmbedder(\n...     surface=TokenEmbedder(vocab_size=10000, embedding_dim=128, rngs=rngs),\n...     postag=TokenEmbedder(vocab_size=50, embedding_dim=32, rngs=rngs),\n...     character=TokenEmbedder(vocab_size=256, embedding_dim=32, rngs=rngs)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Output dimension is sum of all embedding dimensions (128 + 32 + 32 = 192)\n&gt;&gt;&gt; assert embedder.get_output_dim() == 192\n</code></pre> Note <p>All provided embedders share the same mask, which is taken from the last non-None embedder processed.</p> Source code in <code>src/formed/integrations/flax/modules/embedders.py</code> <pre><code>def __init__(\n    self,\n    surface: BaseEmbedder[IIDSequenceBatch] | None = None,\n    postag: BaseEmbedder[IIDSequenceBatch] | None = None,\n    character: BaseEmbedder[IIDSequenceBatch] | None = None,\n) -&gt; None:\n    if all(embedder is None for embedder in (surface, postag, character)):\n        raise ValueError(\"At least one embedder must be provided for AnalyzedTextEmbedder.\")\n\n    self._surface = surface\n    self._postag = postag\n    self._character = character\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.embedders.AnalyzedTextEmbedder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/embedders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return sum(\n        embedder.get_output_dim()\n        for embedder in (self._surface, self._postag, self._character)\n        if embedder is not None\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders","title":"formed.integrations.flax.modules.encoders","text":"<p>Sequence encoding modules for Flax models.</p> <p>This module provides encoders that process sequential data, including position encoders, RNN-based encoders, and transformer encoders.</p> Key Components <p>Position Encoders: - BasePositionEncoder: Abstract base for position encoding - SinusoidalPositionEncoder: Sinusoidal position embeddings - LearnablePositionEncoder: Learned position embeddings</p> <p>Sequence Encoders: - BaseSequenceEncoder: Abstract base for sequence encoders - RNNSequenceEncoder: Generic RNN encoder (LSTM, GRU, vanilla RNN) - LSTMSequenceEncoder: LSTM-specific encoder - OptimizedLSTMSequenceEncoder: Optimized LSTM encoder - GRUSequenceEncoder: GRU-specific encoder - TransformerSequenceEncoder: Transformer encoder with multi-head attention</p> Features <ul> <li>Bidirectional RNN support</li> <li>Stacked layers with dropout</li> <li>Position encoding for transformers</li> <li>Efficient implementation using scan and vmap</li> <li>Masked sequence processing</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax.modules import (\n...     LSTMSequenceEncoder,\n...     TransformerSequenceEncoder,\n...     SinusoidalPositionEncoder\n... )\n&gt;&gt;&gt; from flax import nnx\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Bidirectional LSTM encoder\n&gt;&gt;&gt; encoder = LSTMSequenceEncoder(\n...     features=128,\n...     num_layers=2,\n...     bidirectional=True,\n...     dropout=0.1,\n...     rngs=nnx.Rngs(0)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Transformer encoder with sinusoidal positions\n&gt;&gt;&gt; encoder = TransformerSequenceEncoder(\n...     features=128,\n...     num_heads=8,\n...     num_layers=6,\n...     position_encoder=SinusoidalPositionEncoder(),\n...     rngs=rngs\n... )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.BasePositionEncoder","title":"BasePositionEncoder","text":"<p>               Bases: <code>Registrable</code>, <code>ABC</code></p> <p>Abstract base class for position encoders.</p> <p>Position encoders add positional information to input embeddings, allowing models to understand token positions in sequences.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.SinusoidalPositionEncoder","title":"SinusoidalPositionEncoder","text":"<pre><code>SinusoidalPositionEncoder(max_length=512)\n</code></pre> <p>               Bases: <code>BasePositionEncoder</code></p> <p>Sinusoidal position encoding from \"Attention Is All You Need\".</p> <p>This encoder uses sine and cosine functions of different frequencies to generate position embeddings without learnable parameters.</p> PARAMETER DESCRIPTION <code>max_length</code> <p>Maximum sequence length to support.</p> <p> TYPE: <code>int</code> DEFAULT: <code>512</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = SinusoidalPositionEncoder(max_length=512)\n&gt;&gt;&gt; encoded = encoder(embeddings)\n</code></pre> Note <p>Encodings are cached for efficiency.</p> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def __init__(self, max_length: int = 512) -&gt; None:\n    self.max_length = max_length\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.SinusoidalPositionEncoder.max_length","title":"max_length  <code>instance-attribute</code>","text":"<pre><code>max_length = max_length\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LearnablePositionEncoder","title":"LearnablePositionEncoder","text":"<pre><code>LearnablePositionEncoder(\n    features, *, max_length=512, rngs=None\n)\n</code></pre> <p>               Bases: <code>BasePositionEncoder</code></p> <p>Learnable position embeddings.</p> <p>This encoder uses a learned embedding matrix for position encoding, allowing the model to learn task-specific positional patterns.</p> PARAMETER DESCRIPTION <code>features</code> <p>Embedding dimension.</p> <p> TYPE: <code>int</code> </p> <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> <code>max_length</code> <p>Maximum sequence length to support.</p> <p> TYPE: <code>int</code> DEFAULT: <code>512</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = LearnablePositionEncoder(\n...     features=128,\n...     max_length=512,\n...     rngs=rngs\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    features: int,\n    *,\n    max_length: int = 512,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    rngs = rngs or require_rngs()\n    self.embed = nnx.Embed(max_length, features, rngs=rngs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LearnablePositionEncoder.embed","title":"embed  <code>instance-attribute</code>","text":"<pre><code>embed = Embed(max_length, features, rngs=rngs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.BaseSequenceEncoder","title":"BaseSequenceEncoder","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>ABC</code></p> <p>Abstract base class for sequence encoders.</p> <p>Sequence encoders process sequential data and output contextual representations for each position in the sequence.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.BaseSequenceEncoder.get_input_dim","title":"get_input_dim  <code>abstractmethod</code>","text":"<pre><code>get_input_dim()\n</code></pre> <p>Get the expected input dimension.</p> RETURNS DESCRIPTION <code>int | None</code> <p>Input feature dimension or None if dimension-agnostic.</p> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef get_input_dim(self) -&gt; int | None:\n    \"\"\"Get the expected input dimension.\n\n    Returns:\n        Input feature dimension or None if dimension-agnostic.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.BaseSequenceEncoder.get_output_dim","title":"get_output_dim  <code>abstractmethod</code>","text":"<pre><code>get_output_dim()\n</code></pre> <p>Get the output dimension.</p> RETURNS DESCRIPTION <code>int | Callable[[int], int]</code> <p>Output feature dimension or a function mapping input dim to output dim.</p> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef get_output_dim(self) -&gt; int | Callable[[int], int]:\n    \"\"\"Get the output dimension.\n\n    Returns:\n        Output feature dimension or a function mapping input dim to output dim.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.RNNSequenceEncoder","title":"RNNSequenceEncoder","text":"<pre><code>RNNSequenceEncoder(\n    cell_factory,\n    features,\n    num_layers=1,\n    bidirectional=False,\n    feedforward_layers=None,\n    dropout=0.0,\n    rngs=None,\n)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> <p>Generic RNN-based sequence encoder.</p> <p>This encoder supports various RNN cell types (LSTM, GRU, vanilla RNN) with optional bidirectionality, multiple layers, and dropout.</p> PARAMETER DESCRIPTION <code>cell_factory</code> <p>Function that creates an RNN cell given rngs.</p> <p> TYPE: <code>Callable[[Rngs], RNNCellBase]</code> </p> <code>num_layers</code> <p>Number of stacked RNN layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>bidirectional</code> <p>Whether to use bidirectional RNN.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dropout</code> <p>Dropout rate between layers.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>rngs</code> <p>Random number generators (int or nnx.Rngs).</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> Note <p>This is a base class. Use LSTMSequenceEncoder, GRUSequenceEncoder, or OptimizedLSTMSequenceEncoder for specific cell types.</p> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    cell_factory: Callable[[nnx.Rngs], nnx.RNNCellBase],\n    features: int,\n    num_layers: int = 1,\n    bidirectional: bool = False,\n    feedforward_layers: int | None = None,\n    dropout: float = 0.0,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    rngs = rngs or require_rngs()\n\n    @nnx.vmap(in_axes=0, out_axes=0)\n    def create_block(rngs: nnx.Rngs) -&gt; RNNSequenceEncoder._RNNBlock:\n        rnn: nnx.RNN | nnx.Bidirectional\n        if bidirectional:\n            forward_cell = cell_factory(rngs)\n            backward_cell = cell_factory(rngs)\n            rnn = nnx.Bidirectional(\n                forward_rnn=nnx.RNN(forward_cell, rngs=rngs),\n                backward_rnn=nnx.RNN(backward_cell, rngs=rngs),\n                rngs=rngs,\n            )\n        else:\n            rnn = nnx.RNN(cell_factory(rngs), rngs=rngs)\n        return self._RNNBlock(\n            rnn,\n            feedforward_layers=feedforward_layers or 0,\n            dropout=dropout,\n            rngs=rngs,\n        )\n\n    self.blocks = create_block(rngs.fork(split=num_layers))\n    self.num_layers = num_layers\n    self.bidirectional = bidirectional\n    self.features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.RNNSequenceEncoder.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = create_block(fork(split=num_layers))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.RNNSequenceEncoder.num_layers","title":"num_layers  <code>instance-attribute</code>","text":"<pre><code>num_layers = num_layers\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.RNNSequenceEncoder.bidirectional","title":"bidirectional  <code>instance-attribute</code>","text":"<pre><code>bidirectional = bidirectional\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.RNNSequenceEncoder.features","title":"features  <code>instance-attribute</code>","text":"<pre><code>features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.RNNSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.RNNSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LSTMSequenceEncoder","title":"LSTMSequenceEncoder","text":"<pre><code>LSTMSequenceEncoder(\n    features,\n    num_layers=1,\n    bidirectional=False,\n    feedforward_layers=None,\n    dropout=0.0,\n    rngs=None,\n)\n</code></pre> <p>               Bases: <code>RNNSequenceEncoder</code></p> <p>LSTM-based sequence encoder.</p> PARAMETER DESCRIPTION <code>features</code> <p>Hidden dimension.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of LSTM layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>bidirectional</code> <p>Whether to use bidirectional LSTM.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dropout</code> <p>Dropout rate between layers.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Bidirectional 2-layer LSTM\n&gt;&gt;&gt; encoder = LSTMSequenceEncoder(\n...     features=128,\n...     num_layers=2,\n...     bidirectional=True,\n...     dropout=0.1,\n...     rngs=0\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    features: int,\n    num_layers: int = 1,\n    bidirectional: bool = False,\n    feedforward_layers: int | None = None,\n    dropout: float = 0.0,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    rngs = rngs or require_rngs()\n    super().__init__(\n        cell_factory=lambda rngs: nnx.LSTMCell(features, features, rngs=rngs),\n        features=features,\n        num_layers=num_layers,\n        bidirectional=bidirectional,\n        feedforward_layers=feedforward_layers,\n        dropout=dropout,\n        rngs=rngs,\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LSTMSequenceEncoder.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = create_block(fork(split=num_layers))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LSTMSequenceEncoder.num_layers","title":"num_layers  <code>instance-attribute</code>","text":"<pre><code>num_layers = num_layers\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LSTMSequenceEncoder.bidirectional","title":"bidirectional  <code>instance-attribute</code>","text":"<pre><code>bidirectional = bidirectional\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LSTMSequenceEncoder.features","title":"features  <code>instance-attribute</code>","text":"<pre><code>features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LSTMSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.LSTMSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.OptimizedLSTMSequenceEncoder","title":"OptimizedLSTMSequenceEncoder","text":"<pre><code>OptimizedLSTMSequenceEncoder(\n    features,\n    num_layers=1,\n    bidirectional=False,\n    feedforward_layers=None,\n    dropout=0.0,\n    rngs=None,\n)\n</code></pre> <p>               Bases: <code>RNNSequenceEncoder</code></p> <p>Optimized LSTM sequence encoder.</p> <p>Uses Flax's optimized LSTM implementation for better performance.</p> PARAMETER DESCRIPTION <code>features</code> <p>Hidden dimension.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of LSTM layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>bidirectional</code> <p>Whether to use bidirectional LSTM.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dropout</code> <p>Dropout rate between layers.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    features: int,\n    num_layers: int = 1,\n    bidirectional: bool = False,\n    feedforward_layers: int | None = None,\n    dropout: float = 0.0,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    super().__init__(\n        cell_factory=lambda rngs: nnx.OptimizedLSTMCell(features, features, rngs=rngs),\n        features=features,\n        num_layers=num_layers,\n        bidirectional=bidirectional,\n        feedforward_layers=feedforward_layers,\n        dropout=dropout,\n        rngs=rngs,\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.OptimizedLSTMSequenceEncoder.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = create_block(fork(split=num_layers))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.OptimizedLSTMSequenceEncoder.num_layers","title":"num_layers  <code>instance-attribute</code>","text":"<pre><code>num_layers = num_layers\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.OptimizedLSTMSequenceEncoder.bidirectional","title":"bidirectional  <code>instance-attribute</code>","text":"<pre><code>bidirectional = bidirectional\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.OptimizedLSTMSequenceEncoder.features","title":"features  <code>instance-attribute</code>","text":"<pre><code>features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.OptimizedLSTMSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.OptimizedLSTMSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.GRUSequenceEncoder","title":"GRUSequenceEncoder","text":"<pre><code>GRUSequenceEncoder(\n    features,\n    num_layers=1,\n    bidirectional=False,\n    feedforward_layers=None,\n    dropout=0.0,\n    rngs=None,\n)\n</code></pre> <p>               Bases: <code>RNNSequenceEncoder</code></p> <p>GRU-based sequence encoder.</p> PARAMETER DESCRIPTION <code>features</code> <p>Hidden dimension.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of GRU layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>bidirectional</code> <p>Whether to use bidirectional GRU.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dropout</code> <p>Dropout rate between layers.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = GRUSequenceEncoder(\n...     features=256,\n...     num_layers=3,\n...     bidirectional=True,\n...     rngs=0\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    features: int,\n    num_layers: int = 1,\n    bidirectional: bool = False,\n    feedforward_layers: int | None = None,\n    dropout: float = 0.0,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    super().__init__(\n        cell_factory=lambda rngs: nnx.GRUCell(features, features, rngs=rngs),\n        features=features,\n        num_layers=num_layers,\n        bidirectional=bidirectional,\n        feedforward_layers=feedforward_layers,\n        dropout=dropout,\n        rngs=rngs,\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.GRUSequenceEncoder.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = create_block(fork(split=num_layers))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.GRUSequenceEncoder.num_layers","title":"num_layers  <code>instance-attribute</code>","text":"<pre><code>num_layers = num_layers\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.GRUSequenceEncoder.bidirectional","title":"bidirectional  <code>instance-attribute</code>","text":"<pre><code>bidirectional = bidirectional\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.GRUSequenceEncoder.features","title":"features  <code>instance-attribute</code>","text":"<pre><code>features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.GRUSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.GRUSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.TransformerSequenceEncoder","title":"TransformerSequenceEncoder","text":"<pre><code>TransformerSequenceEncoder(\n    features,\n    num_heads,\n    *,\n    num_layers=1,\n    dropout=0.0,\n    epsilon=1e-06,\n    feedworward_features=None,\n    activation=gelu,\n    position_encoder=None,\n    rngs=None,\n)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> <p>Transformer-based sequence encoder.</p> <p>This encoder uses multi-head self-attention and feed-forward layers to process sequences, following the Transformer architecture.</p> PARAMETER DESCRIPTION <code>features</code> <p>Model dimension.</p> <p> TYPE: <code>int</code> </p> <code>num_heads</code> <p>Number of attention heads.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of transformer layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>dropout</code> <p>Dropout rate.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>epsilon</code> <p>Layer normalization epsilon.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-06</code> </p> <code>feedworward_features</code> <p>Feed-forward hidden dimension (defaults to 4*features).</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>activation</code> <p>Activation function for feed-forward layers.</p> <p> TYPE: <code>Callable[[Array], Array]</code> DEFAULT: <code>gelu</code> </p> <code>position_encoder</code> <p>Optional position encoder.</p> <p> TYPE: <code>BasePositionEncoder | None</code> DEFAULT: <code>None</code> </p> <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Transformer with sinusoidal positions\n&gt;&gt;&gt; encoder = TransformerSequenceEncoder(\n...     features=512,\n...     num_heads=8,\n...     num_layers=6,\n...     dropout=0.1,\n...     position_encoder=SinusoidalPositionEncoder(),\n...     rngs=rngs\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Transformer with learnable positions\n&gt;&gt;&gt; encoder = TransformerSequenceEncoder(\n...     features=512,\n...     num_heads=8,\n...     num_layers=6,\n...     position_encoder=LearnablePositionEncoder(512, rngs=rngs),\n...     rngs=rngs\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    features: int,\n    num_heads: int,\n    *,\n    num_layers: int = 1,\n    dropout: float = 0.0,\n    epsilon: float = 1e-6,\n    feedworward_features: int | None = None,\n    activation: Callable[[jax.Array], jax.Array] = jax.nn.gelu,\n    position_encoder: BasePositionEncoder | None = None,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    rngs = rngs or require_rngs()\n\n    @nnx.vmap(in_axes=0, out_axes=0)\n    def create_block(rngs: nnx.Rngs) -&gt; TransformerSequenceEncoder._TransformerBlock:\n        return self._TransformerBlock(\n            features=features,\n            num_heads=num_heads,\n            dropout=dropout,\n            epsilon=epsilon,\n            feedworward_features=feedworward_features or 4 * features,\n            activation=activation,\n            rngs=rngs,\n        )\n\n    self.num_layers = num_layers\n    self.blocks = create_block(rngs.fork(split=num_layers))\n    self.position_encoder = position_encoder\n    self.features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.TransformerSequenceEncoder.num_layers","title":"num_layers  <code>instance-attribute</code>","text":"<pre><code>num_layers = num_layers\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.TransformerSequenceEncoder.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = create_block(fork(split=num_layers))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.TransformerSequenceEncoder.position_encoder","title":"position_encoder  <code>instance-attribute</code>","text":"<pre><code>position_encoder = position_encoder\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.TransformerSequenceEncoder.features","title":"features  <code>instance-attribute</code>","text":"<pre><code>features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.TransformerSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.encoders.TransformerSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward","title":"formed.integrations.flax.modules.feedforward","text":"<p>Feed-forward neural network modules for Flax models.</p> <p>This module provides feed-forward network layers with support for multiple layers, dropout, layer normalization, and residual connections.</p> Key Components <ul> <li>Block: Single feed-forward block with optional normalization and dropout</li> <li>FeedForward: Stacked feed-forward blocks with configurable connections</li> </ul> Features <ul> <li>Configurable activation functions</li> <li>Layer normalization with custom epsilon</li> <li>Dropout for regularization</li> <li>Dense residual connections</li> <li>Efficient implementation using scan</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax.modules import FeedForward\n&gt;&gt;&gt; from flax import nnx\n&gt;&gt;&gt; import jax.nn\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Simple 3-layer feed-forward network\n&gt;&gt;&gt; ffn = FeedForward(\n...     features=128,\n...     num_layers=3,\n...     dropout=0.1,\n...     activation=jax.nn.gelu,\n...     rngs=nnx.Rngs(0)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With dense residual connections\n&gt;&gt;&gt; ffn = FeedForward(\n...     features=128,\n...     num_layers=3,\n...     residual_connection=\"dense\",\n...     rngs=rngs\n... )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.Block","title":"Block","text":"<pre><code>Block(\n    input_dim,\n    output_dim,\n    dropout=0.0,\n    layer_norm_eps=None,\n    activation=relu,\n    rngs=None,\n)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Single feed-forward block with optional normalization and dropout.</p> <p>A block consists of a linear transformation, activation, optional dropout, and optional layer normalization. It can also accept a residual input.</p> PARAMETER DESCRIPTION <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> <code>input_dim</code> <p>Input dimension.</p> <p> TYPE: <code>int</code> </p> <code>output_dim</code> <p>Output dimension.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>Dropout rate (0 means no dropout).</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>layer_norm_eps</code> <p>Layer normalization epsilon (None means no layer norm).</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>activation</code> <p>Activation function (default: ReLU).</p> <p> TYPE: <code>Callable[[Array], Array]</code> DEFAULT: <code>relu</code> </p> Source code in <code>src/formed/integrations/flax/modules/feedforward.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    output_dim: int,\n    dropout: float = 0.0,\n    layer_norm_eps: float | None = None,\n    activation: Callable[[jax.Array], jax.Array] = jax.nn.relu,\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    rngs = rngs or require_rngs()\n    self.linear = nnx.Linear(input_dim, output_dim, rngs=rngs)\n    self.activation = activation\n    self.dropout = nnx.Dropout(dropout, rngs=rngs) if dropout &gt; 0.0 else None\n    self.layer_norm = (\n        nnx.LayerNorm(output_dim, epsilon=layer_norm_eps, rngs=rngs) if layer_norm_eps is not None else None\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.Block.linear","title":"linear  <code>instance-attribute</code>","text":"<pre><code>linear = Linear(input_dim, output_dim, rngs=rngs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.Block.activation","title":"activation  <code>instance-attribute</code>","text":"<pre><code>activation = activation\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.Block.dropout","title":"dropout  <code>instance-attribute</code>","text":"<pre><code>dropout = (\n    Dropout(dropout, rngs=rngs) if dropout &gt; 0.0 else None\n)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.Block.layer_norm","title":"layer_norm  <code>instance-attribute</code>","text":"<pre><code>layer_norm = (\n    LayerNorm(output_dim, epsilon=layer_norm_eps, rngs=rngs)\n    if layer_norm_eps is not None\n    else None\n)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.FeedForward","title":"FeedForward","text":"<pre><code>FeedForward(\n    features,\n    num_layers=1,\n    dropout=0.0,\n    layer_norm_eps=None,\n    activation=relu,\n    residual_connection=\"none\",\n    rngs=None,\n)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Multi-layer feed-forward neural network.</p> <p>This module stacks multiple feed-forward blocks with configurable activation, dropout, normalization, and residual connections.</p> PARAMETER DESCRIPTION <code>features</code> <p>Hidden dimension for all layers.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>dropout</code> <p>Dropout rate applied after each activation.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>layer_norm_eps</code> <p>Epsilon for layer normalization (None disables layer norm).</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>activation</code> <p>Activation function (default: ReLU).</p> <p> TYPE: <code>Callable[[Array], Array]</code> DEFAULT: <code>relu</code> </p> <code>residual_connection</code> <p>Type of residual connection: - \"none\": No residual connections (default) - \"dense\": Dense connections (each layer receives sum of all previous)</p> <p> TYPE: <code>Literal['none', 'dense']</code> DEFAULT: <code>'none'</code> </p> <code>rngs</code> <p>Random number generators (can be int seed or nnx.Rngs).</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple 3-layer network\n&gt;&gt;&gt; ffn = FeedForward(features=256, num_layers=3, rngs=0)\n&gt;&gt;&gt; output = ffn(x)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With dropout and layer norm\n&gt;&gt;&gt; ffn = FeedForward(\n...     features=256,\n...     num_layers=3,\n...     dropout=0.1,\n...     layer_norm_eps=1e-6,\n...     rngs=0\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With dense residual connections\n&gt;&gt;&gt; ffn = FeedForward(\n...     features=256,\n...     num_layers=4,\n...     residual_connection=\"dense\",\n...     rngs=0\n... )\n</code></pre> Note <p>When using residual_connection=\"dense\", each layer receives the sum of outputs from all previous layers, similar to DenseNet.</p> Source code in <code>src/formed/integrations/flax/modules/feedforward.py</code> <pre><code>def __init__(\n    self,\n    features: int,\n    num_layers: int = 1,\n    dropout: float = 0.0,\n    layer_norm_eps: float | None = None,\n    activation: Callable[[jax.Array], jax.Array] = jax.nn.relu,\n    residual_connection: Literal[\"none\", \"dense\"] = \"none\",\n    rngs: nnx.Rngs | None = None,\n) -&gt; None:\n    rngs = rngs or require_rngs()\n\n    @nnx.vmap(in_axes=0, out_axes=0)\n    def create_block(rngs: nnx.Rngs) -&gt; Block:\n        return Block(features, features, dropout, layer_norm_eps, activation, rngs=rngs)\n\n    self.features = features\n    self.num_layers = num_layers\n    self.blocks = create_block(rngs.fork(split=num_layers))\n    self.residual_connection = residual_connection\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.FeedForward.features","title":"features  <code>instance-attribute</code>","text":"<pre><code>features = features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.FeedForward.num_layers","title":"num_layers  <code>instance-attribute</code>","text":"<pre><code>num_layers = num_layers\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.FeedForward.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = create_block(fork(split=num_layers))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.FeedForward.residual_connection","title":"residual_connection  <code>instance-attribute</code>","text":"<pre><code>residual_connection = residual_connection\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.FeedForward.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/feedforward.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.feedforward.FeedForward.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/feedforward.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self.features\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.losses","title":"formed.integrations.flax.modules.losses","text":""},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.losses.BaseClassificationLoss","title":"BaseClassificationLoss","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for classification loss functions.</p> <p>A ClassificationLoss defines a strategy for computing loss based on model logits and true labels.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during loss computation.</p> <p> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.losses.CrossEntropyLoss","title":"CrossEntropyLoss","text":"<pre><code>CrossEntropyLoss(weighter=None, reduce='mean')\n</code></pre> <p>               Bases: <code>BaseClassificationLoss[_ParamsT]</code></p> <p>Cross-entropy loss for classification tasks.</p> PARAMETER DESCRIPTION <code>weighter</code> <p>An optional label weighter to assign weights to each class.</p> <p> TYPE: <code>BaseLabelWeighter[_ParamsT] | None</code> DEFAULT: <code>None</code> </p> <code>reduce</code> <p>Reduction method for loss computation (\"mean\" or \"sum\").</p> <p> TYPE: <code>Literal['mean', 'sum']</code> DEFAULT: <code>'mean'</code> </p> Source code in <code>src/formed/integrations/flax/modules/losses.py</code> <pre><code>def __init__(\n    self,\n    weighter: BaseLabelWeighter[_ParamsT] | None = None,\n    reduce: Literal[\"mean\", \"sum\"] = \"mean\",\n) -&gt; None:\n    super().__init__()\n    self._weighter = weighter\n    self._reduce = reduce\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers","title":"formed.integrations.flax.modules.samplers","text":""},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers.BaseLabelSampler","title":"BaseLabelSampler","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for label samplers.</p> <p>A LabelSampler defines a strategy for sampling labels based on model logits.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during sampling.</p> <p> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers.ArgmaxLabelSampler","title":"ArgmaxLabelSampler","text":"<p>               Bases: <code>BaseLabelSampler[None]</code></p> <p>Label sampler that selects the label with the highest logit.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers.MultinomialLabelSamplerParams","title":"MultinomialLabelSamplerParams","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Parameters for the MultinomialLabelSampler.</p> <p>This class can be extended in the future to include additional parameters for sampling if needed.</p> ATTRIBUTE DESCRIPTION <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs | None</code> </p> <code>templerature</code> <p>Sampling temperature to control randomness.</p> <p> TYPE: <code>float</code> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers.MultinomialLabelSamplerParams.rngs","title":"rngs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rngs = None\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers.MultinomialLabelSamplerParams.templerature","title":"templerature  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>templerature = 1.0\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers.MultinomialLabelSampler","title":"MultinomialLabelSampler","text":"<p>               Bases: <code>BaseLabelSampler[MultinomialLabelSamplerParams]</code></p> <p>Label sampler that samples labels from a multinomial distribution defined by the logits.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.samplers.MultinomialLabelSampler.Params","title":"Params  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Params = MultinomialLabelSamplerParams\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.vectorizers","title":"formed.integrations.flax.modules.vectorizers","text":"<p>Sequence vectorization modules for Flax models.</p> <p>This module provides vectorizers that convert variable-length sequences into fixed-size vectors. Vectorizers apply pooling operations over the sequence dimension to produce single vectors per sequence.</p> Key Components <ul> <li>BaseSequenceVectorizer: Abstract base class for vectorizers</li> <li>BagOfEmbeddingsSequenceVectorizer: Pools sequence embeddings</li> </ul> Features <ul> <li>Multiple pooling strategies (mean, max, min, sum, first, last, hier)</li> <li>Masked pooling to ignore padding tokens</li> <li>Optional normalization before pooling</li> <li>Hierarchical pooling with sliding windows</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax.modules import BagOfEmbeddingsSequenceVectorizer\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Mean pooling over sequence\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(pooling=\"mean\")\n&gt;&gt;&gt; vector = vectorizer(embeddings, mask=mask)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Max pooling with normalization\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(\n...     pooling=\"max\",\n...     normalize=True\n... )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.vectorizers.BaseSequenceVectorizer","title":"BaseSequenceVectorizer","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>ABC</code></p> <p>Abstract base class for sequence vectorizers.</p> <p>Vectorizers convert variable-length sequences into fixed-size vectors by applying pooling operations over the sequence dimension.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.vectorizers.BaseSequenceVectorizer.get_input_dim","title":"get_input_dim  <code>abstractmethod</code>","text":"<pre><code>get_input_dim()\n</code></pre> <p>Get the expected input dimension.</p> RETURNS DESCRIPTION <code>int | None</code> <p>Input dimension or None if dimension-agnostic.</p> Source code in <code>src/formed/integrations/flax/modules/vectorizers.py</code> <pre><code>@abc.abstractmethod\ndef get_input_dim(self) -&gt; int | None:\n    \"\"\"Get the expected input dimension.\n\n    Returns:\n        Input dimension or None if dimension-agnostic.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.vectorizers.BaseSequenceVectorizer.get_output_dim","title":"get_output_dim  <code>abstractmethod</code>","text":"<pre><code>get_output_dim()\n</code></pre> <p>Get the output dimension.</p> RETURNS DESCRIPTION <code>int | Callable[[int], int]</code> <p>Output feature dimension or a function mapping input dim to output dim.</p> Source code in <code>src/formed/integrations/flax/modules/vectorizers.py</code> <pre><code>@abc.abstractmethod\ndef get_output_dim(self) -&gt; int | Callable[[int], int]:\n    \"\"\"Get the output dimension.\n\n    Returns:\n        Output feature dimension or a function mapping input dim to output dim.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer","title":"BagOfEmbeddingsSequenceVectorizer","text":"<pre><code>BagOfEmbeddingsSequenceVectorizer(\n    pooling=\"mean\", normalize=False, window_size=None\n)\n</code></pre> <p>               Bases: <code>BaseSequenceVectorizer</code></p> <p>Bag-of-embeddings vectorizer using pooling operations.</p> <p>This vectorizer applies pooling over the sequence dimension to create fixed-size vectors. Multiple pooling strategies are supported, and padding tokens are properly masked during pooling.</p> PARAMETER DESCRIPTION <code>pooling</code> <p>Pooling strategy to use: - \"mean\": Average pooling (default) - \"max\": Max pooling - \"min\": Min pooling - \"sum\": Sum pooling - \"first\": Take first token - \"last\": Take last non-padding token - \"hier\": Hierarchical pooling with sliding window</p> <p> TYPE: <code>PoolingMethod | Sequence[PoolingMethod]</code> DEFAULT: <code>'mean'</code> </p> <code>normalize</code> <p>Whether to L2-normalize embeddings before pooling.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>window_size</code> <p>Window size for hierarchical pooling (required if pooling=\"hier\").</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Mean pooling\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(pooling=\"mean\")\n&gt;&gt;&gt; vector = vectorizer(embeddings, mask=mask)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Max pooling with normalization\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(\n...     pooling=\"max\",\n...     normalize=True\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Hierarchical pooling\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(\n...     pooling=\"hier\",\n...     window_size=3\n... )\n</code></pre> Note <p>This vectorizer is dimension-agnostic - it preserves the embedding dimension from input to output.</p> Source code in <code>src/formed/integrations/flax/modules/vectorizers.py</code> <pre><code>def __init__(\n    self,\n    pooling: PoolingMethod | Sequence[PoolingMethod] = \"mean\",\n    normalize: bool = False,\n    window_size: int | None = None,\n) -&gt; None:\n    self._pooling: PoolingMethod | Sequence[PoolingMethod] = pooling\n    self._normalize = normalize\n    self._window_size = window_size\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/vectorizers.py</code> <pre><code>def get_input_dim(self) -&gt; None:\n    return None\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/flax/modules/vectorizers.py</code> <pre><code>def get_output_dim(self) -&gt; Callable[[int], int]:\n    num_pooling = 1 if isinstance(self._pooling, str) else len(self._pooling)\n    return lambda input_dim: input_dim * num_pooling\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.weighters","title":"formed.integrations.flax.modules.weighters","text":""},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.weighters.BaseLabelWeighter","title":"BaseLabelWeighter","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for label weighters.</p> <p>A LabelWeighter defines a strategy for assigning weights to each label based on model logits and true targets.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during weighting.</p> <p> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.weighters.StaticLabelWeighter","title":"StaticLabelWeighter","text":"<pre><code>StaticLabelWeighter(weights)\n</code></pre> <p>               Bases: <code>BaseLabelWeighter</code></p> <p>Label weighter that assigns static weights to each class.</p> PARAMETER DESCRIPTION <code>weights</code> <p>An array of shape (num_classes,) containing the weight for each class.</p> <p> TYPE: <code>ArrayCompatible</code> </p> Source code in <code>src/formed/integrations/flax/modules/weighters.py</code> <pre><code>def __init__(self, weights: ArrayCompatible) -&gt; None:\n    super().__init__()\n    self._weights = nnx.Param(ensure_jax_array(weights), mutable=False)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.modules.weighters.BalancedByDistributionLabelWeighter","title":"BalancedByDistributionLabelWeighter","text":"<pre><code>BalancedByDistributionLabelWeighter(\n    distribution, eps=1e-08\n)\n</code></pre> <p>               Bases: <code>BaseLabelWeighter</code></p> <p>Label weighter that balances classes based on their distribution.</p> PARAMETER DESCRIPTION <code>distribution</code> <p>An array of shape (num_classes,) representing the class distribution.</p> <p> TYPE: <code>ArrayCompatible</code> </p> <code>eps</code> <p>A small epsilon value to avoid division by zero.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> Source code in <code>src/formed/integrations/flax/modules/weighters.py</code> <pre><code>def __init__(self, distribution: ArrayCompatible, eps: float = 1e-8) -&gt; None:\n    self._distribution = nnx.Param(ensure_jax_array(distribution), mutable=False)\n    self._eps = eps\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks","title":"formed.integrations.flax.training.callbacks","text":"<p>Training callbacks for monitoring and controlling Flax model training.</p> <p>This module provides a callback system for Flax training, allowing custom logic to be executed at various points in the training loop. Callbacks can monitor metrics, save checkpoints, implement early stopping, and integrate with experiment tracking systems.</p> Key Components <ul> <li>FlaxTrainingCallback: Base class for all callbacks</li> <li>EvaluationCallback: Computes metrics using custom evaluators</li> <li>EarlyStoppingCallback: Stops training based on metric improvements</li> <li>MlflowCallback: Logs metrics to MLflow</li> </ul> Features <ul> <li>Hook points at training/epoch/batch start and end</li> <li>Metric computation and logging</li> <li>Model checkpointing</li> <li>Early stopping with patience</li> <li>MLflow integration</li> <li>Extensible for custom callbacks</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax import (\n...     FlaxTrainer,\n...     EarlyStoppingCallback,\n...     EvaluationCallback,\n...     MlflowCallback\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; trainer = FlaxTrainer(\n...     train_dataloader=train_loader,\n...     val_dataloader=val_loader,\n...     callbacks=[\n...         EvaluationCallback(my_evaluator),\n...         EarlyStoppingCallback(patience=5, metric=\"-loss\"),\n...         MlflowCallback()\n...     ]\n... )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback","title":"FlaxTrainingCallback","text":"<p>               Bases: <code>Registrable</code></p> <p>Base class for training callbacks.</p> <p>Callbacks provide hooks to execute custom logic at various points during training. Subclasses can override any hook method to implement custom behavior such as logging, checkpointing, or early stopping.</p> Hook execution order <ol> <li>on_training_start - once at the beginning</li> <li>on_epoch_start - at the start of each epoch</li> <li>on_batch_start - before each training batch</li> <li>on_batch_end - after each training batch</li> <li>on_eval_start - before evaluation (returns evaluator)</li> <li>on_eval_end - after evaluation with computed metrics</li> <li>on_log - when metrics are logged</li> <li>on_epoch_end - at the end of each epoch</li> <li>on_training_end - once at the end (can modify final state)</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @FlaxTrainingCallback.register(\"my_callback\")\n... class MyCallback(FlaxTrainingCallback):\n...     def on_epoch_end(self, trainer, model, state, epoch):\n...         print(f\"Completed epoch {epoch} at step {state.step}\")\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    return state\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    class DummyMetric(IEvaluator):\n        def update(self, inputs, output, /) -&gt; None:\n            pass\n\n        def compute(self) -&gt; dict[str, float]:\n            return {}\n\n        def reset(self) -&gt; None:\n            pass\n\n    return DummyMetric()\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.FlaxTrainingCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback","title":"EvaluationCallback","text":"<pre><code>EvaluationCallback(evaluator)\n</code></pre> <p>               Bases: <code>FlaxTrainingCallback</code>, <code>Generic[ModelInputT, ModelOutputT]</code></p> <p>Callback for computing metrics using a custom evaluator.</p> <p>This callback integrates a custom evaluator into the training loop, resetting it before each evaluation phase and returning it for metric accumulation.</p> PARAMETER DESCRIPTION <code>evaluator</code> <p>Evaluator implementing the IEvaluator protocol.</p> <p> TYPE: <code>IEvaluator[ModelInputT, ModelOutputT]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.ml.metrics import MulticlassAccuracy\n&gt;&gt;&gt;\n&gt;&gt;&gt; evaluator = MulticlassAccuracy()\n&gt;&gt;&gt; callback = EvaluationCallback(evaluator)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def __init__(self, evaluator: IEvaluator[ModelInputT, ModelOutputT]) -&gt; None:\n    self._evaluator = evaluator\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_start(  # pyright: ignore[reportIncompatibleMethodOverride]\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    self._evaluator.reset()\n    return self._evaluator\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    return state\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EvaluationCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback","title":"EarlyStoppingCallback","text":"<pre><code>EarlyStoppingCallback(patience=5, metric='-loss')\n</code></pre> <p>               Bases: <code>FlaxTrainingCallback</code></p> <p>Callback for early stopping based on metric improvements.</p> <p>This callback monitors a specified metric and stops training if it doesn't improve for a given number of evaluations (patience). The best model is automatically saved and restored at the end of training.</p> PARAMETER DESCRIPTION <code>patience</code> <p>Number of evaluations without improvement before stopping.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>metric</code> <p>Metric to monitor. Prefix with \"-\" to maximize (e.g., \"-loss\"), or \"+\" to minimize (e.g., \"+error\"). Default is \"-loss\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'-loss'</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Stop if validation loss doesn't improve for 5 evaluations\n&gt;&gt;&gt; callback = EarlyStoppingCallback(patience=5, metric=\"-val/loss\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Stop if accuracy doesn't improve for 3 evaluations\n&gt;&gt;&gt; callback = EarlyStoppingCallback(patience=3, metric=\"+accuracy\")\n</code></pre> Note <p>The best model is saved to the step working directory and automatically restored when training ends early or completes.</p> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def __init__(\n    self,\n    patience: int = 5,\n    metric: str = \"-loss\",\n) -&gt; None:\n    self._patience = patience\n    self._metric = metric.lstrip(\"-+\")\n    self._direction = -1 if metric.startswith(\"-\") else 1\n    self._best_metric = -float(\"inf\")\n    self._best_step: int | None = None\n    self._counter = 0\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    self._best_metric = -float(\"inf\")\n    self._counter = 0\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    logger = use_step_logger(__name__)\n    if prefix:\n        metrics = {f\"{prefix}{key}\": value for key, value in metrics.items()}\n    try:\n        metric = self._direction * metrics[self._metric]\n    except KeyError:\n        return\n\n    if metric &gt; self._best_metric:\n        self._best_metric = metric\n        self._best_step = int(state.step)\n        self._counter = 0\n        self._checkpointer.save(int(state.step), state)\n        logger.info(f\"New best model saved with {self._metric}={self._best_metric:.4f}\")\n    else:\n        self._counter += 1\n        if self._counter &gt;= self._patience:\n            raise StopEarly()\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    logger = use_step_logger(__name__)\n    if self._best_step is not None:\n        logger.info(\"Restoring best state from early stopping checkpoint.\")\n        state = cast(TrainState, self._checkpointer.restore(self._best_step, items=state))\n    return state\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    class DummyMetric(IEvaluator):\n        def update(self, inputs, output, /) -&gt; None:\n            pass\n\n        def compute(self) -&gt; dict[str, float]:\n            return {}\n\n        def reset(self) -&gt; None:\n            pass\n\n    return DummyMetric()\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.EarlyStoppingCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback","title":"MlflowCallback","text":"<pre><code>MlflowCallback()\n</code></pre> <p>               Bases: <code>FlaxTrainingCallback</code></p> <p>Callback for logging metrics to MLflow.</p> <p>This callback automatically logs training and validation metrics to MLflow when used within a workflow step that has MLflow tracking enabled.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax import FlaxTrainer, MlflowCallback\n&gt;&gt;&gt;\n&gt;&gt;&gt; trainer = FlaxTrainer(\n...     train_dataloader=train_loader,\n...     val_dataloader=val_loader,\n...     callbacks=[MlflowCallback()]\n... )\n</code></pre> Note <p>Requires the formed mlflow integration and must be used within a workflow step with MLflow tracking configured.</p> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def __init__(self) -&gt; None:\n    from formed.integrations.mlflow.workflow import MlflowLogger\n\n    self._mlflow_logger: MlflowLogger | None = None\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    from formed.integrations.mlflow.workflow import use_mlflow_logger\n    from formed.workflow import use_step_logger\n\n    logger = use_step_logger(__name__)\n\n    self._mlflow_logger = use_mlflow_logger()\n    if self._mlflow_logger is None:\n        logger.warning(\"MlflowLogger not found. Skipping logging.\")\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    metrics = {prefix + key: value for key, value in metrics.items()}\n    if self._mlflow_logger is not None:\n        for key, value in metrics.items():\n            self._mlflow_logger.log_metric(key, value, step=int(state.step))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    if self._mlflow_logger is not None:\n        self._mlflow_logger.log_metric(\"epoch\", epoch, step=int(state.step))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    return state\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_start(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    class DummyMetric(IEvaluator):\n        def update(self, inputs, output, /) -&gt; None:\n            pass\n\n        def compute(self) -&gt; dict[str, float]:\n            return {}\n\n        def reset(self) -&gt; None:\n            pass\n\n    return DummyMetric()\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.callbacks.MlflowCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/flax/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"FlaxTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine","title":"formed.integrations.flax.training.engine","text":"<p>Training engine abstractions for Flax models.</p> <p>This module provides the training engine abstraction that defines how models are trained and evaluated. Engines handle loss computation, gradient calculation, and parameter updates.</p> Key Components <ul> <li>FlaxTrainingEngine: Abstract base class for training engines</li> <li>DefaultFlaxTrainingEngine: Default implementation with automatic differentiation</li> </ul> Features <ul> <li>Customizable loss functions</li> <li>Automatic gradient computation using JAX</li> <li>State creation and management</li> <li>Separate train and eval steps</li> <li>Compatible with FlaxTrainer and distributors</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax import DefaultFlaxTrainingEngine\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create engine with custom loss accessor\n&gt;&gt;&gt; engine = DefaultFlaxTrainingEngine(loss=\"total_loss\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Or with custom loss function\n&gt;&gt;&gt; def custom_loss(output):\n...     return output.loss + 0.1 * output.regularization\n&gt;&gt;&gt; engine = DefaultFlaxTrainingEngine(loss=custom_loss)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.FlaxTrainingEngine","title":"FlaxTrainingEngine","text":"<p>               Bases: <code>ABC</code>, <code>Registrable</code>, <code>Generic[ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>Abstract base class for Flax training engines.</p> <p>A training engine defines how models are trained by implementing state creation, training steps, and evaluation steps. This allows for custom training loops and loss computations.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ModelInputT</code> <p>Type of model input.</p> <p> </p> <code>ModelOutputT</code> <p>Type of model output.</p> <p> </p> <code>ModelParamsT</code> <p>Type of additional parameters.</p> <p> </p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.FlaxTrainingEngine.create_state","title":"create_state  <code>abstractmethod</code>","text":"<pre><code>create_state(rngs, trainer, model)\n</code></pre> <p>Create initial training state from model and trainer.</p> PARAMETER DESCRIPTION <code>rngs</code> <p>Random number generators.</p> <p> TYPE: <code>Rngs</code> </p> <code>trainer</code> <p>Trainer instance.</p> <p> TYPE: <code>FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]</code> </p> <code>model</code> <p>Model to train.</p> <p> TYPE: <code>BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT]</code> </p> RETURNS DESCRIPTION <code>TrainState</code> <p>Initial training state.</p> Source code in <code>src/formed/integrations/flax/training/engine.py</code> <pre><code>@abc.abstractmethod\ndef create_state(\n    self,\n    rngs: nnx.Rngs,\n    trainer: \"FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n) -&gt; TrainState:\n    \"\"\"Create initial training state from model and trainer.\n\n    Args:\n        rngs: Random number generators.\n        trainer: Trainer instance.\n        model: Model to train.\n\n    Returns:\n        Initial training state.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.FlaxTrainingEngine.train_step","title":"train_step  <code>abstractmethod</code>","text":"<pre><code>train_step(inputs, state, trainer)\n</code></pre> <p>Execute a single training step.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of training inputs.</p> <p> TYPE: <code>ModelInputT</code> </p> <code>state</code> <p>Current training state.</p> <p> TYPE: <code>TrainState</code> </p> <code>trainer</code> <p>Trainer instance.</p> <p> TYPE: <code>FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]</code> </p> RETURNS DESCRIPTION <code>tuple[TrainState, ModelOutputT]</code> <p>Tuple of (updated_state, model_output).</p> Source code in <code>src/formed/integrations/flax/training/engine.py</code> <pre><code>@abc.abstractmethod\ndef train_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; tuple[TrainState, ModelOutputT]:\n    \"\"\"Execute a single training step.\n\n    Args:\n        inputs: Batch of training inputs.\n        state: Current training state.\n        trainer: Trainer instance.\n\n    Returns:\n        Tuple of (updated_state, model_output).\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.FlaxTrainingEngine.eval_step","title":"eval_step  <code>abstractmethod</code>","text":"<pre><code>eval_step(inputs, state, trainer)\n</code></pre> <p>Execute a single evaluation step.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of evaluation inputs.</p> <p> TYPE: <code>ModelInputT</code> </p> <code>state</code> <p>Current training state.</p> <p> TYPE: <code>TrainState</code> </p> <code>trainer</code> <p>Trainer instance.</p> <p> TYPE: <code>FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]</code> </p> RETURNS DESCRIPTION <code>ModelOutputT</code> <p>Model output.</p> Source code in <code>src/formed/integrations/flax/training/engine.py</code> <pre><code>@abc.abstractmethod\ndef eval_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; ModelOutputT:\n    \"\"\"Execute a single evaluation step.\n\n    Args:\n        inputs: Batch of evaluation inputs.\n        state: Current training state.\n        trainer: Trainer instance.\n\n    Returns:\n        Model output.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.DefaultFlaxTrainingEngine","title":"DefaultFlaxTrainingEngine","text":"<pre><code>DefaultFlaxTrainingEngine(\n    loss=\"loss\", optimizer=adamw(0.001)\n)\n</code></pre> <p>               Bases: <code>FlaxTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>Default training engine using automatic differentiation.</p> <p>This engine computes gradients using JAX's automatic differentiation and updates parameters using the provided optimizer. Loss is extracted from model output either by attribute name or custom function.</p> PARAMETER DESCRIPTION <code>loss</code> <p>Loss accessor - either attribute name (e.g., \"loss\") or callable that extracts loss from model output.</p> <p> TYPE: <code>str | Callable[[ModelOutputT], Array]</code> DEFAULT: <code>'loss'</code> </p> <code>optimizer</code> <p>Optax optimizer or transformation.</p> <p> TYPE: <code>IOptimizer | MultiSteps | GradientTransformation</code> DEFAULT: <code>adamw(0.001)</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Use output.loss attribute\n&gt;&gt;&gt; engine = DefaultFlaxTrainingEngine(loss=\"loss\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use custom loss function\n&gt;&gt;&gt; engine = DefaultFlaxTrainingEngine(\n...     loss=lambda output: output.loss + 0.01 * output.regularization\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/training/engine.py</code> <pre><code>def __init__(\n    self,\n    loss: str | Callable[[ModelOutputT], jax.Array] = \"loss\",\n    optimizer: IOptimizer | optax.MultiSteps | optax.GradientTransformation = optax.adamw(1e-3),\n) -&gt; None:\n    if not isinstance(optimizer, optax.GradientTransformation):\n        optimizer = optax.GradientTransformation(optimizer.init, optimizer.update)  # pyright: ignore[reportArgumentType]\n\n    super().__init__()\n    self._loss = partial(xgetattr, name=loss) if isinstance(loss, str) else loss\n    self._optimizer = optimizer\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.DefaultFlaxTrainingEngine.create_state","title":"create_state","text":"<pre><code>create_state(rngs, trainer, model)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/engine.py</code> <pre><code>def create_state(\n    self,\n    rngs: nnx.Rngs,\n    trainer: \"FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n) -&gt; TrainState:\n    graphdef, params, *states = nnx.split(model, nnx.Param, nnx.BatchStat, nnx.RngState)\n    return cast(\n        TrainState,\n        TrainState.create(\n            apply_fn=None,\n            graphdef=graphdef,\n            additional_states=tuple(states),\n            params=params,\n            tx=self._optimizer,\n        ),\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.DefaultFlaxTrainingEngine.train_step","title":"train_step","text":"<pre><code>train_step(inputs, state, trainer)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/engine.py</code> <pre><code>def train_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; tuple[TrainState, ModelOutputT]:\n    def step(state: TrainState, inputs: ModelInputT) -&gt; tuple[TrainState, ModelOutputT]:\n        model = nnx.merge(state.graphdef, state.params, *state.additional_states)\n        model.train()\n\n        def loss_fn(\n            model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n        ) -&gt; tuple[jax.Array, ModelOutputT]:\n            output = model(inputs)\n            loss = self._loss(output)\n            return loss, output\n\n        (_, output), grads = nnx.value_and_grad(loss_fn, has_aux=True)(model)\n\n        graphdef, params, *additional_states = nnx.split(model, nnx.Param, nnx.BatchStat, nnx.RngState)\n\n        grads = trainer.distributor.reduce(grads)\n        state = state.replace(\n            graphdef=graphdef,\n            params=params,\n            additional_states=tuple(additional_states),\n        )\n        state = state.apply_gradients(grads=grads)\n        return state, output\n\n    return step(state, inputs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.engine.DefaultFlaxTrainingEngine.eval_step","title":"eval_step","text":"<pre><code>eval_step(inputs, state, trainer)\n</code></pre> Source code in <code>src/formed/integrations/flax/training/engine.py</code> <pre><code>def eval_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"FlaxTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; ModelOutputT:\n    del trainer\n\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT] = nnx.merge(\n        state.graphdef,\n        state.params,\n        *state.additional_states,\n    )\n    model.eval()\n    return model(inputs)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.exceptions","title":"formed.integrations.flax.training.exceptions","text":""},{"location":"reference/integrations/flax/#formed.integrations.flax.training.exceptions.StopEarly","title":"StopEarly","text":"<p>               Bases: <code>Exception</code></p> <p>Raised to stop training early.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.state","title":"formed.integrations.flax.training.state","text":"<p>Training state management for Flax NNX models.</p> <p>This module extends Flax's TrainState to support NNX models by storing the graph definition and additional states (BatchStat, RngState) separately from trainable parameters.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.state.Node","title":"Node  <code>module-attribute</code>","text":"<pre><code>Node = TypeVar('Node')\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.state.TrainState","title":"TrainState","text":"<p>               Bases: <code>TrainState</code>, <code>Generic[Node]</code></p> <p>Extended training state for Flax NNX models.</p> <p>This class extends flax.training.train_state.TrainState to work with Flax NNX models, storing the model's graph definition and additional states (like batch statistics and RNG states) separately from parameters.</p> ATTRIBUTE DESCRIPTION <code>graphdef</code> <p>NNX graph definition describing the model structure.</p> <p> TYPE: <code>GraphDef[Node]</code> </p> <code>additional_states</code> <p>Tuple of additional states (BatchStat, RngState, etc.).</p> <p> TYPE: <code>tuple[State, ...]</code> </p> <code>params</code> <p>Trainable parameters (inherited from TrainState).</p> <p> TYPE: <code>tuple[State, ...]</code> </p> <code>opt_state</code> <p>Optimizer state (inherited from TrainState).</p> <p> TYPE: <code>tuple[State, ...]</code> </p> <code>step</code> <p>Training step counter (inherited from TrainState).</p> <p> TYPE: <code>tuple[State, ...]</code> </p> <code>tx</code> <p>Optimizer transformation (inherited from TrainState).</p> <p> TYPE: <code>tuple[State, ...]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create state from model\n&gt;&gt;&gt; graphdef, params, *states = nnx.split(model, nnx.Param, nnx.BatchStat)\n&gt;&gt;&gt; state = TrainState.create(\n...     apply_fn=None,\n...     graphdef=graphdef,\n...     additional_states=tuple(states),\n...     params=params,\n...     tx=optimizer\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Reconstruct model\n&gt;&gt;&gt; model = nnx.merge(state.graphdef, state.params, *state.additional_states)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.state.TrainState.graphdef","title":"graphdef  <code>instance-attribute</code>","text":"<pre><code>graphdef\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.state.TrainState.additional_states","title":"additional_states  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>additional_states = ()\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.trainer","title":"formed.integrations.flax.training.trainer","text":"<p>High-level trainer for Flax models.</p> <p>This module provides the FlaxTrainer class, which orchestrates the complete training process for Flax models including data loading, optimization, evaluation, callbacks, and distributed training.</p> Key Features <ul> <li>Flexible training loop with epoch and step-based logging/evaluation</li> <li>Support for callbacks at various training stages</li> <li>Distributed training via data parallelism</li> <li>Rich progress bars with training metrics</li> <li>Early stopping and checkpointing</li> <li>MLflow integration</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax import (\n...     FlaxTrainer,\n...     EvaluationCallback,\n...     EarlyStoppingCallback\n... )\n&gt;&gt;&gt; from formed.integrations.ml import DataLoader, BasicBatchSampler\n&gt;&gt;&gt; import optax\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Setup data loaders\n&gt;&gt;&gt; train_dataloader = DataLoader(\n...     sampler=BasicBatchSampler(batch_size=32, shuffle=True),\n...     collator=datamodule.batch\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create trainer\n&gt;&gt;&gt; trainer = FlaxTrainer(\n...     train_dataloader=train_dataloader,\n...     val_dataloader=val_dataloader,\n...     optimizer=optax.adamw(learning_rate=1e-3),\n...     max_epochs=10,\n...     callbacks=[\n...         EvaluationCallback(my_evaluator),\n...         EarlyStoppingCallback(patience=3)\n...     ]\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Train model\n&gt;&gt;&gt; rngs = nnx.Rngs(42)\n&gt;&gt;&gt; state = trainer.train(rngs, model, train_dataset, val_dataset)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.trainer.FlaxTrainer","title":"FlaxTrainer","text":"<pre><code>FlaxTrainer(\n    *,\n    train_dataloader,\n    val_dataloader=None,\n    engine=None,\n    callbacks=(),\n    distributor=None,\n    max_epochs=10,\n    eval_strategy=\"epoch\",\n    eval_interval=1,\n    logging_strategy=\"epoch\",\n    logging_interval=1,\n    logging_first_step=True,\n    train_prefix=\"train/\",\n    val_prefix=\"val/\",\n)\n</code></pre> <p>               Bases: <code>Generic[ItemT, ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>High-level trainer for Flax models.</p> <p>FlaxTrainer provides a complete training loop with support for distributed training, callbacks, evaluation, and metric logging. It handles the coordination of data loading, model training, evaluation, and callback execution.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ItemT</code> <p>Type of raw dataset items.</p> <p> </p> <code>ModelInputT</code> <p>Type of batched model inputs.</p> <p> </p> <code>ModelOutputT</code> <p>Type of model outputs.</p> <p> </p> <code>ModelParamsT</code> <p>Type of additional model parameters.</p> <p> </p> PARAMETER DESCRIPTION <code>train_dataloader</code> <p>Data loader for training dataset.</p> <p> TYPE: <code>IDataLoader[ItemT, ModelInputT]</code> </p> <code>val_dataloader</code> <p>Optional data loader for validation dataset.</p> <p> TYPE: <code>IDataLoader[ItemT, ModelInputT] | None</code> DEFAULT: <code>None</code> </p> <code>engine</code> <p>Training engine (defaults to DefaultFlaxTrainingEngine).</p> <p> TYPE: <code>FlaxTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT] | None</code> DEFAULT: <code>None</code> </p> <code>callbacks</code> <p>Sequence of training callbacks.</p> <p> TYPE: <code>Sequence[FlaxTrainingCallback]</code> DEFAULT: <code>()</code> </p> <code>distributor</code> <p>Device distributor (defaults to SingleDeviceDistributor).</p> <p> TYPE: <code>BaseDistributor | None</code> DEFAULT: <code>None</code> </p> <code>max_epochs</code> <p>Maximum number of training epochs.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>eval_strategy</code> <p>When to evaluate - \"epoch\" or \"step\".</p> <p> TYPE: <code>Literal['epoch', 'step']</code> DEFAULT: <code>'epoch'</code> </p> <code>eval_interval</code> <p>Evaluation interval (epochs or steps).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>logging_strategy</code> <p>When to log - \"epoch\" or \"step\".</p> <p> TYPE: <code>Literal['epoch', 'step']</code> DEFAULT: <code>'epoch'</code> </p> <code>logging_interval</code> <p>Logging interval (epochs or steps).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>logging_first_step</code> <p>Whether to log after the first training step.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; trainer = FlaxTrainer(\n...     train_dataloader=train_loader,\n...     val_dataloader=val_loader,\n...     max_epochs=10,\n...     eval_strategy=\"epoch\",\n...     logging_strategy=\"step\",\n...     logging_interval=100\n...     engine=DefaultFlaxTrainingEngine(\n...         optimizer=optax.adamw(1e-3),\n...     ),\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/training/trainer.py</code> <pre><code>def __init__(\n    self,\n    *,\n    train_dataloader: IDataLoader[ItemT, ModelInputT],\n    val_dataloader: IDataLoader[ItemT, ModelInputT] | None = None,\n    engine: FlaxTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT] | None = None,\n    callbacks: Sequence[FlaxTrainingCallback] = (),\n    distributor: BaseDistributor | None = None,\n    max_epochs: int = 10,\n    eval_strategy: Literal[\"epoch\", \"step\"] = \"epoch\",\n    eval_interval: int = 1,\n    logging_strategy: Literal[\"epoch\", \"step\"] = \"epoch\",\n    logging_interval: int = 1,\n    logging_first_step: bool = True,\n    train_prefix: str = \"train/\",\n    val_prefix: str = \"val/\",\n) -&gt; None:\n    self._train_dataloader = train_dataloader\n    self._val_dataloader = val_dataloader\n    self._engine = engine or DefaultFlaxTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT]()\n    self._distributor = distributor or SingleDeviceDistributor()\n    self._max_epochs = max_epochs\n    self._eval_strategy = eval_strategy\n    self._eval_interval = eval_interval\n    self._logging_strategy = logging_strategy\n    self._logging_interval = logging_interval\n    self._logging_first_step = logging_first_step\n    self._callbacks = callbacks\n    self._train_prefix = train_prefix\n    self._val_prefix = val_prefix\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.trainer.FlaxTrainer.distributor","title":"distributor  <code>property</code>","text":"<pre><code>distributor\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.training.trainer.FlaxTrainer.train","title":"train","text":"<pre><code>train(\n    model,\n    train_dataset,\n    val_dataset=None,\n    state=None,\n    rngs=None,\n)\n</code></pre> <p>Train a model on the provided datasets.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model to train.</p> <p> TYPE: <code>BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT]</code> </p> <code>train_dataset</code> <p>Sequence of training items.</p> <p> TYPE: <code>Sequence[ItemT]</code> </p> <code>val_dataset</code> <p>Optional sequence of validation items.</p> <p> TYPE: <code>Sequence[ItemT] | None</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional pre-initialized training state (for resuming).</p> <p> TYPE: <code>TrainState | None</code> DEFAULT: <code>None</code> </p> <code>rngs</code> <p>Optional random number generators for initialization.</p> <p> TYPE: <code>Rngs | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>TrainState</code> <p>Final training state with trained parameters.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If val_dataset is provided but val_dataloader is not.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; state = trainer.train(\n...     model, train_items, val_items\n... )\n&gt;&gt;&gt; # Reconstruct trained model\n&gt;&gt;&gt; trained_model = nnx.merge(\n...     state.graphdef, state.params, *state.additional_states\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/training/trainer.py</code> <pre><code>def train(\n    self,\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    train_dataset: Sequence[ItemT],\n    val_dataset: Sequence[ItemT] | None = None,\n    state: TrainState | None = None,\n    rngs: nnx.Rngs | None = None,\n) -&gt; TrainState:\n    \"\"\"Train a model on the provided datasets.\n\n    Args:\n        model: Model to train.\n        train_dataset: Sequence of training items.\n        val_dataset: Optional sequence of validation items.\n        state: Optional pre-initialized training state (for resuming).\n        rngs: Optional random number generators for initialization.\n\n    Returns:\n        Final training state with trained parameters.\n\n    Raises:\n        ValueError: If val_dataset is provided but val_dataloader is not.\n\n    Examples:\n        &gt;&gt;&gt; state = trainer.train(\n        ...     model, train_items, val_items\n        ... )\n        &gt;&gt;&gt; # Reconstruct trained model\n        &gt;&gt;&gt; trained_model = nnx.merge(\n        ...     state.graphdef, state.params, *state.additional_states\n        ... )\n\n    \"\"\"\n    if val_dataset is not None and self._val_dataloader is None:\n        raise ValueError(\"Validation dataloader is not provided.\")\n\n    rngs = rngs or require_rngs()\n    logger = use_step_logger(__name__)\n\n    if state is None:\n        state = self._engine.create_state(rngs, self, model)\n\n    train_step = self._distributor.map(self._engine.train_step, static_argnums=(2,))\n    eval_step = partial(nnx.jit, static_argnames=(\"trainer\"))(self._engine.eval_step)  # pyright: ignore[reportArgumentType]\n\n    for callback in self._callbacks:\n        callback.on_training_start(self, model, state)\n\n    def get_total_training_steps() -&gt; int:\n        dataloader = self._train_dataloader(train_dataset)\n        return len(dataloader) * self._max_epochs\n\n    def get_total_eval_steps() -&gt; int:\n        assert val_dataset is not None and self._val_dataloader is not None\n        dataloader = self._val_dataloader(val_dataset)\n        return len(dataloader)\n\n    def new_epoch(epoch: int) -&gt; None:\n        assert state is not None\n        logger.info(f\"Starting epoch {epoch}/{self._max_epochs}\")\n        for callback in self._callbacks:\n            callback.on_epoch_start(self, model, state, epoch)\n\n    def finalize_epoch(epoch: int) -&gt; None:\n        assert state is not None\n        for callback in self._callbacks:\n            callback.on_epoch_end(self, model, state, epoch)\n\n    def new_batch(epoch: int) -&gt; None:\n        assert state is not None\n        for callback in self._callbacks:\n            callback.on_batch_start(self, model, state, epoch)\n\n    def finalize_batch(epoch: int, output: ModelOutputT) -&gt; None:\n        assert state is not None\n        for callback in self._callbacks:\n            callback.on_batch_end(self, model, state, epoch, output)\n\n    def new_evaluators() -&gt; list[IEvaluator[ModelInputT, ModelOutputT]]:\n        assert state is not None\n        return [callback.on_eval_start(self, model, state) for callback in self._callbacks]\n\n    def update_metrics(\n        evaluators: list[IEvaluator[ModelInputT, ModelOutputT]],\n        inputs: ModelInputT,\n        output: ModelOutputT,\n    ) -&gt; None:\n        assert state is not None\n        for evaluator in evaluators:\n            evaluator.update(inputs, output)\n\n    def compute_metrics(evaluators: list[IEvaluator[ModelInputT, ModelOutputT]]) -&gt; dict[str, float]:\n        assert state is not None\n        metrics = {}\n        for evaluator in evaluators:\n            metrics.update(evaluator.compute())\n        return metrics\n\n    def finalize_evaluation(metrics: Mapping[str, float], prefix: str) -&gt; None:\n        assert state is not None\n        for callback in self._callbacks:\n            callback.on_eval_end(self, model, state, metrics, prefix)\n\n    def log(metrics: Mapping[str, float], prefix: str) -&gt; None:\n        assert state is not None\n        if not metrics:\n            return\n        logger.info(\"%s\", \", \".join(f\"{prefix}{k}={v:.4f}\" for k, v in metrics.items()))\n        for callback in self._callbacks:\n            callback.on_log(self, model, state, metrics, prefix=prefix)\n\n    def do_evaluation(progress: Progress) -&gt; None:\n        if not val_dataset:\n            return\n\n        assert state is not None\n        assert self._val_dataloader is not None\n\n        evaluators = new_evaluators()\n\n        task = progress.add_task(\"Evaluation\", total=get_total_eval_steps())\n        with closing(self._val_dataloader(val_dataset)) as val_dataloader:\n            for batch in val_dataloader:\n                output = eval_step(batch, state, self)\n                update_metrics(evaluators, batch, output)\n                progress.advance(task)\n        progress.remove_task(task)\n\n        computed_metrics = compute_metrics(evaluators)\n        log(computed_metrics, prefix=self._val_prefix)\n        finalize_evaluation(computed_metrics, prefix=self._val_prefix)\n\n    def is_logging_step(step: int) -&gt; bool:\n        return (self._logging_strategy == \"step\" and step % self._logging_interval == 0) or (\n            self._logging_first_step and step == 1\n        )\n\n    def is_logging_epoch(epoch: int) -&gt; bool:\n        return self._logging_strategy == \"epoch\" and epoch % self._logging_interval == 0\n\n    def is_eval_step(step: int) -&gt; bool:\n        return self._eval_strategy == \"step\" and step % self._eval_interval == 0\n\n    def is_eval_eopch(epoch: int) -&gt; bool:\n        return self._eval_strategy == \"epoch\" and epoch % self._eval_interval == 0\n\n    evaluators = new_evaluators()\n\n    try:\n        with Progress(\n            SpinnerColumn(),\n            TextColumn(\"{task.description}\"),\n            BarColumn(),\n            MofNCompleteColumn(),\n            TimeRemainingColumn(),\n            console=STDERR_CONSOLE,\n        ) as progress:\n            task = progress.add_task(\"Training\", total=get_total_training_steps())\n            for epoch in range(1, self._max_epochs + 1):\n                assert state is not None\n                new_epoch(epoch)\n\n                with closing(self._train_dataloader(train_dataset)) as train_dataloader:\n                    for batch in train_dataloader:\n                        new_batch(epoch)\n\n                        sharded_batch = self._distributor.shard(batch)\n                        replicated_state = self._distributor.replicate(state)\n\n                        replicated_state, replicated_output = train_step(sharded_batch, replicated_state, self)\n\n                        state = self._distributor.unreplicate(replicated_state)\n                        output = self._distributor.unreplicate(replicated_output)\n                        assert state is not None\n\n                        update_metrics(evaluators, batch, output)\n\n                        if is_logging_step(int(state.step)):\n                            train_metrics = compute_metrics(evaluators)\n                            log(train_metrics, prefix=self._train_prefix)\n                            finalize_evaluation(train_metrics, prefix=self._train_prefix)\n                            evaluators = new_evaluators()\n\n                        finalize_batch(epoch, output)\n\n                        progress.advance(task)\n\n                        if is_eval_step(int(state.step)):\n                            do_evaluation(progress)\n\n                if is_logging_epoch(epoch):\n                    train_metrics = compute_metrics(evaluators)\n                    log(train_metrics, prefix=self._train_prefix)\n                    finalize_evaluation(train_metrics, prefix=self._train_prefix)\n                    evaluators = new_evaluators()\n\n                if is_eval_eopch(epoch):\n                    do_evaluation(progress)\n\n                finalize_epoch(epoch)\n    except StopEarly:\n        assert state is not None\n        logger.info(f\"Training stopped early at {state.step} steps.\")\n\n    for callback in self._callbacks:\n        state = callback.on_training_end(self, model, state)\n\n    return state\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.random","title":"formed.integrations.flax.random","text":""},{"location":"reference/integrations/flax/#formed.integrations.flax.random.use_rngs","title":"use_rngs","text":"<pre><code>use_rngs(default=None)\n</code></pre> <p>Context manager to set and restore nnx RNGs.</p> <p>This context manager allows temporarily setting the nnx RNGs used in Flax/nnx operations. It saves the current RNGs on entry and restores them on exit.</p> YIELDS DESCRIPTION <code>Rngs</code> <p>The current nnx RNGs within the context.</p> Source code in <code>src/formed/integrations/flax/random.py</code> <pre><code>@contextmanager\ndef use_rngs(default: int | None = None) -&gt; Iterator[nnx.Rngs]:\n    \"\"\"Context manager to set and restore nnx RNGs.\n\n    This context manager allows temporarily setting the nnx RNGs\n    used in Flax/nnx operations. It saves the current RNGs on entry\n    and restores them on exit.\n\n    Yields:\n        The current nnx RNGs within the context.\n\n    \"\"\"\n    token = _NNX_RNGS.set(nnx.Rngs(default))\n    try:\n        yield _NNX_RNGS.get()\n    finally:\n        _NNX_RNGS.reset(token)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.random.require_rngs","title":"require_rngs","text":"<pre><code>require_rngs()\n</code></pre> <p>Get the current nnx RNGs.</p> RETURNS DESCRIPTION <code>Rngs</code> <p>The current nnx RNGs.</p> Source code in <code>src/formed/integrations/flax/random.py</code> <pre><code>def require_rngs() -&gt; nnx.Rngs:\n    \"\"\"Get the current nnx RNGs.\n\n    Returns:\n        The current nnx RNGs.\n\n    \"\"\"\n    return _NNX_RNGS.get()\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.utils","title":"formed.integrations.flax.utils","text":""},{"location":"reference/integrations/flax/#formed.integrations.flax.utils.PoolingMethod","title":"PoolingMethod  <code>module-attribute</code>","text":"<pre><code>PoolingMethod = Literal[\n    \"mean\", \"max\", \"min\", \"sum\", \"hier\", \"first\", \"last\"\n]\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.utils.ensure_jax_array","title":"ensure_jax_array","text":"<pre><code>ensure_jax_array(x)\n</code></pre> Source code in <code>src/formed/integrations/flax/utils.py</code> <pre><code>def ensure_jax_array(x: ArrayCompatible) -&gt; jax.Array:\n    if isinstance(x, jax.Array):\n        return x\n    return jax.numpy.asarray(x)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.utils.masked_pool","title":"masked_pool","text":"<pre><code>masked_pool(\n    embeddings,\n    mask=None,\n    pooling=\"mean\",\n    normalize=False,\n    window_size=None,\n)\n</code></pre> <p>Pool embeddings with a mask.</p> PARAMETER DESCRIPTION <code>embeddings</code> <p>Embeddings to pool of shape (batch_size, sequence_length, embedding_size).</p> <p> TYPE: <code>Array</code> </p> <code>mask</code> <p>Mask of shape (batch_size, sequence_length).</p> <p> TYPE: <code>Array | None</code> DEFAULT: <code>None</code> </p> <code>pooling</code> <p> TYPE: <code>PoolingMethod | Sequence[PoolingMethod]</code> DEFAULT: <code>'mean'</code> </p> <code>normalize</code> <p>Whether to normalize the embeddings before pooling. Defaults to <code>False</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>window_size</code> <p>Window size for hierarchical pooling. Defaults to <code>None</code>.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/formed/integrations/flax/utils.py</code> <pre><code>def masked_pool(\n    embeddings: jax.Array,\n    mask: jax.Array | None = None,\n    pooling: PoolingMethod | Sequence[PoolingMethod] = \"mean\",\n    normalize: bool = False,\n    window_size: int | None = None,\n) -&gt; jax.Array:\n    \"\"\"\n    Pool embeddings with a mask.\n\n    Args:\n        embeddings: Embeddings to pool of shape (batch_size, sequence_length, embedding_size).\n        mask: Mask of shape (batch_size, sequence_length).\n        pooling:\n        normalize: Whether to normalize the embeddings before pooling. Defaults to `False`.\n        window_size: Window size for hierarchical pooling. Defaults to `None`.\n    \"\"\"\n\n    if not isinstance(pooling, str):\n        return jax.numpy.concatenate(\n            [\n                masked_pool(\n                    embeddings,\n                    mask=mask,\n                    pooling=method,\n                    normalize=normalize,\n                    window_size=window_size,\n                )\n                for method in pooling\n            ],\n            axis=-1,\n        )\n\n    batch_size, sequence_length, embedding_size = embeddings.shape\n\n    if normalize:\n        embeddings = embeddings / (jax.numpy.linalg.norm(embeddings, axis=-1, keepdims=True) + 1e-13)\n\n    if mask is None:\n        mask = jax.numpy.ones((batch_size, sequence_length), dtype=bool)\n\n    if pooling == \"mean\":\n        return embeddings.sum(axis=1) / (mask.sum(axis=1, keepdims=True) + 1e-13)\n\n    if pooling == \"max\":\n        embeddings = jax.numpy.where(mask[..., None], embeddings, -jax.numpy.inf)\n        return embeddings.max(axis=1)\n\n    if pooling == \"min\":\n        embeddings = jax.numpy.where(mask[..., None], embeddings, jax.numpy.inf)\n        return embeddings.min(axis=1)\n\n    if pooling == \"sum\":\n        embeddings = jax.numpy.where(mask[..., None], embeddings, 0)\n        return embeddings.sum(axis=1)\n\n    if pooling == \"first\":\n        return embeddings[:, 0, :]\n\n    if pooling == \"last\":\n        batch_indices = jax.numpy.arange(batch_size)\n        last_positions = mask.cumsum(axis=1).argmax(axis=1)\n        return embeddings[batch_indices, last_positions, :]\n\n    if pooling == \"hier\":\n\n        def _hierarchical_pooling(vectors: jax.Array, mask: jax.Array) -&gt; jax.Array:\n            assert window_size is not None\n            vectors = vectors[mask]\n            if len(vectors) &lt; window_size:\n                return vectors.mean(0)\n            output: jax.Array = -jax.numpy.inf * jax.numpy.ones(embedding_size)\n            for offset in range(len(vectors) - window_size + 1):\n                window = vectors[offset : offset + window_size]\n                output = jax.numpy.maximum(output, window.mean(0))\n            return output\n\n        output: jax.Array = jax.numpy.array(list(starmap(_hierarchical_pooling, zip(embeddings, mask))))\n        return output\n\n    raise ValueError(\n        f\"pooling must be one of 'mean', 'max', 'min', 'sum', 'hier', 'first', or 'last', but got {pooling}\"\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.utils.sequence_distribute","title":"sequence_distribute","text":"<pre><code>sequence_distribute(\n    inputs: Array,\n) -&gt; tuple[Array, tuple[int, int]]\n</code></pre><pre><code>sequence_distribute(\n    inputs: _MappingT, ignore: Sequence[str] = ...\n) -&gt; tuple[_MappingT, tuple[int, int]]\n</code></pre> <pre><code>sequence_distribute(inputs, ignore=())\n</code></pre> Source code in <code>src/formed/integrations/flax/utils.py</code> <pre><code>def sequence_distribute(\n    inputs: jax.Array | _MappingT,\n    ignore: Sequence[str] = (),\n) -&gt; tuple[jax.Array | _MappingT, tuple[int, int]]:\n    if isinstance(inputs, jax.Array):\n        if inputs.ndim &lt; 2:\n            return inputs, (-1, -1)\n        batch_size, max_length = inputs.shape[:2]\n        return inputs.reshape((batch_size * max_length, *inputs.shape[2:])), (batch_size, max_length)\n    distributed = [(key, sequence_distribute(value)) for key, value in inputs.items() if key not in ignore]\n    arrays = {key: value[0] for key, value in distributed}\n    shape = next(s for _, (_, s) in distributed if s != (-1, -1))\n    return cast(_MappingT, arrays), shape\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.utils.sequence_undistribute","title":"sequence_undistribute","text":"<pre><code>sequence_undistribute(\n    inputs: Array,\n    shape: tuple[int, int],\n    ignore: Sequence[str] = ...,\n) -&gt; Array\n</code></pre><pre><code>sequence_undistribute(\n    inputs: _MappingT,\n    shape: tuple[int, int],\n    ignore: Sequence[str] = ...,\n) -&gt; _MappingT\n</code></pre> <pre><code>sequence_undistribute(inputs, shape, ignore=())\n</code></pre> Source code in <code>src/formed/integrations/flax/utils.py</code> <pre><code>def sequence_undistribute(\n    inputs: jax.Array | _MappingT,\n    shape: tuple[int, int],\n    ignore: Sequence[str] = (),\n) -&gt; jax.Array | _MappingT:\n    if isinstance(inputs, jax.Array):\n        return inputs.reshape((shape[0], shape[1], *inputs.shape[1:]))\n    return cast(\n        _MappingT,\n        {key: sequence_undistribute(value, shape) for key, value in inputs.items() if key not in ignore},\n    )\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.utils.determine_ndim","title":"determine_ndim","text":"<pre><code>determine_ndim(first, *args)\n</code></pre> Source code in <code>src/formed/integrations/flax/utils.py</code> <pre><code>def determine_ndim(\n    first: int,\n    *args: int | Callable[[int], int] | None,\n) -&gt; int:\n    output_dim = first\n    for arg in args:\n        if arg is None:\n            continue\n        if callable(arg):\n            output_dim = arg(output_dim)\n        else:\n            output_dim = arg\n    return output_dim\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow","title":"formed.integrations.flax.workflow","text":"<p>Workflow integration for Flax model training.</p> <p>This module provides workflow steps for training Flax models, allowing them to be integrated into the formed workflow system with automatic caching and dependency tracking.</p> Available Steps <ul> <li><code>flax::train</code>: Train a Flax model using the provided trainer.</li> <li><code>flax::evaluate</code>: Evaluate a Flax model on a dataset.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.flax import train_flax_model\n&gt;&gt;&gt;\n&gt;&gt;&gt; # In workflow configuration (jsonnet):\n&gt;&gt;&gt; # {\n&gt;&gt;&gt; #   steps: {\n&gt;&gt;&gt; #     train: {\n&gt;&gt;&gt; #       type: \"flax::train\",\n&gt;&gt;&gt; #       model: { type: \"my_model\", ... },\n&gt;&gt;&gt; #       trainer: { type: \"flax_trainer\", ... },\n&gt;&gt;&gt; #       train_dataset: { type: \"ref\", ref: \"preprocess\" },\n&gt;&gt;&gt; #       random_seed: 42\n&gt;&gt;&gt; #     }\n&gt;&gt;&gt; #   }\n&gt;&gt;&gt; # }\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow.FlaxModelFormat","title":"FlaxModelFormat","text":"<p>               Bases: <code>Format[BaseFlaxModel]</code></p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow.FlaxModelFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow.FlaxModelFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/integrations/flax/workflow.py</code> <pre><code>def write(self, artifact: BaseFlaxModel, directory: Path) -&gt; None:\n    if (config := getattr(artifact, \"__model_config__\", None)) is not None:\n        config = dict(artifact.__model_config__)\n        config[COLT_TYPEKEY] = f\"{artifact.__class__.__module__}:{artifact.__class__.__name__}\"\n        del artifact.__model_config__\n        self._get_config_path(directory).write_text(json.dumps(config, cls=WorkflowJSONEncoder))\n        self._get_checkpointer(directory).save(0, artifact)\n    else:\n        with self._get_pickle_path(directory).open(\"wb\") as f:\n            cloudpickle.dump(artifact, f)\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow.FlaxModelFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/integrations/flax/workflow.py</code> <pre><code>def read(self, directory: Path) -&gt; BaseFlaxModel:\n    if (pickle_path := self._get_pickle_path(directory)).exists():\n        with pickle_path.open(\"rb\") as f:\n            return cloudpickle.load(f)\n\n    with use_rngs(0):\n        model = COLT_BUILDER(\n            json.loads(\n                self._get_config_path(directory).read_text(),\n                cls=WorkflowJSONDecoder,\n            )\n        )\n\n    return cast(BaseFlaxModel, self._get_checkpointer(directory).restore(0, items=model))\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow.FlaxModelFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow.train_flax_model","title":"train_flax_model","text":"<pre><code>train_flax_model(\n    model,\n    trainer,\n    train_dataset,\n    val_dataset=None,\n    random_seed=0,\n)\n</code></pre> <p>Train a Flax model using the provided trainer.</p> <p>This workflow step trains a Flax NNX model on the provided datasets, returning the trained model. The training process is cached based on the model architecture, trainer configuration, and dataset fingerprints.</p> PARAMETER DESCRIPTION <code>model</code> <p>Flax model to train.</p> <p> TYPE: <code>Lazy[BaseFlaxModel]</code> </p> <code>trainer</code> <p>Trainer configuration with dataloaders and callbacks.</p> <p> TYPE: <code>FlaxTrainer</code> </p> <code>train_dataset</code> <p>Training dataset items.</p> <p> TYPE: <code>Sequence[ItemT]</code> </p> <code>val_dataset</code> <p>Optional validation dataset items.</p> <p> TYPE: <code>Sequence[ItemT] | None</code> DEFAULT: <code>None</code> </p> <code>random_seed</code> <p>Random seed for reproducibility.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>BaseFlaxModel</code> <p>Trained Flax model with updated parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Use in Python code\n&gt;&gt;&gt; trained_model = train_flax_model(\n...     model=my_model,\n...     trainer=trainer,\n...     train_dataset=train_data,\n...     val_dataset=val_data,\n...     random_seed=42\n... )\n</code></pre> Source code in <code>src/formed/integrations/flax/workflow.py</code> <pre><code>@step(\"flax::train\", format=FlaxModelFormat())\ndef train_flax_model(\n    model: Lazy[BaseFlaxModel],\n    trainer: FlaxTrainer,\n    train_dataset: Sequence[ItemT],\n    val_dataset: Sequence[ItemT] | None = None,\n    random_seed: int = 0,\n) -&gt; BaseFlaxModel:\n    \"\"\"Train a Flax model using the provided trainer.\n\n    This workflow step trains a Flax NNX model on the provided datasets,\n    returning the trained model. The training process is cached based on\n    the model architecture, trainer configuration, and dataset fingerprints.\n\n    Args:\n        model: Flax model to train.\n        trainer: Trainer configuration with dataloaders and callbacks.\n        train_dataset: Training dataset items.\n        val_dataset: Optional validation dataset items.\n        random_seed: Random seed for reproducibility.\n\n    Returns:\n        Trained Flax model with updated parameters.\n\n    Examples:\n        &gt;&gt;&gt; # Use in Python code\n        &gt;&gt;&gt; trained_model = train_flax_model(\n        ...     model=my_model,\n        ...     trainer=trainer,\n        ...     train_dataset=train_data,\n        ...     val_dataset=val_data,\n        ...     random_seed=42\n        ... )\n\n    \"\"\"\n\n    with use_rngs(random_seed):\n        model_instance = model.construct()\n        state = trainer.train(model_instance, train_dataset, val_dataset)\n\n    model_instance = nnx.merge(state.graphdef, state.params, *state.additional_states)\n    model_instance.__model_config__ = model.config\n    return model_instance\n</code></pre>"},{"location":"reference/integrations/flax/#formed.integrations.flax.workflow.evaluate_flax_model","title":"evaluate_flax_model","text":"<pre><code>evaluate_flax_model(\n    model,\n    evaluator,\n    dataset,\n    dataloader,\n    params=None,\n    random_seed=None,\n)\n</code></pre> <p>Evaluate a Flax model on a dataset using the provided evaluator.</p> PARAMETER DESCRIPTION <code>model</code> <p>Flax model to evaluate.</p> <p> TYPE: <code>BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT]</code> </p> <code>evaluator</code> <p>Evaluator to compute metrics.</p> <p> TYPE: <code>IEvaluator[ModelInputT, ModelOutputT]</code> </p> <code>dataset</code> <p>Dataset items for evaluation.</p> <p> TYPE: <code>list[ItemT]</code> </p> <code>dataloader</code> <p>DataLoader to convert items to model inputs.</p> <p> TYPE: <code>IDataLoader[ItemT, ModelInputT]</code> </p> <code>params</code> <p>Optional model parameters to use for evaluation.</p> <p> TYPE: <code>ModelParamsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary of computed evaluation metrics.</p> Source code in <code>src/formed/integrations/flax/workflow.py</code> <pre><code>@step(\"flax::evaluate\", format=\"json\")\ndef evaluate_flax_model(\n    model: BaseFlaxModel[ModelInputT, ModelOutputT, ModelParamsT],\n    evaluator: IEvaluator[ModelInputT, ModelOutputT],\n    dataset: list[ItemT],\n    dataloader: IDataLoader[ItemT, ModelInputT],\n    params: ModelParamsT | None = None,\n    random_seed: int | None = None,\n) -&gt; Annotated[dict[str, float], WorkflowStepResultFlag.METRICS]:\n    \"\"\"Evaluate a Flax model on a dataset using the provided evaluator.\n\n    Args:\n        model: Flax model to evaluate.\n        evaluator: Evaluator to compute metrics.\n        dataset: Dataset items for evaluation.\n        dataloader: DataLoader to convert items to model inputs.\n        params: Optional model parameters to use for evaluation.\n\n    Returns:\n        Dictionary of computed evaluation metrics.\n    \"\"\"\n\n    logger = use_step_logger(__name__)\n\n    with use_rngs(random_seed):\n        model.eval()\n        evaluator.reset()\n\n        with (\n            closing(dataloader(dataset)) as loader,\n            progress(loader, desc=\"Evaluating model\") as iterator,\n        ):\n            for inputs in iterator:\n                output = model(inputs, params)\n                evaluator.update(inputs, output)\n\n        metrics = evaluator.compute()\n        logger.info(\"Evaluation metrics: %s\", \", \".join(f\"{k}={v:.4f}\" for k, v in metrics.items()))\n\n    return metrics\n</code></pre>"},{"location":"reference/integrations/ml/","title":"ML","text":"<ul> <li>DataLoader</li> <li>Metrics</li> <li>Transforms<ul> <li>Base</li> <li>Basic</li> <li>NLP</li> </ul> </li> <li>Workflow</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.dataloader","title":"formed.integrations.ml.dataloader","text":""},{"location":"reference/integrations/ml/#formed.integrations.ml.dataloader.BaseBatchSampler","title":"BaseBatchSampler","text":"<p>               Bases: <code>Registrable</code>, <code>ABC</code>, <code>Generic[_InputT]</code></p> <p>Abstract base class for batch samplers.</p> <p>Batch samplers generate sequences of indices for batching data.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.dataloader.BasicBatchSampler","title":"BasicBatchSampler","text":"<pre><code>BasicBatchSampler(\n    batch_size=1, shuffle=False, drop_last=False, seed=0\n)\n</code></pre> <p>               Bases: <code>BaseBatchSampler[_InputT]</code>, <code>Generic[_InputT]</code></p> <p>Basic batch sampler that supports shuffling and dropping incomplete batches.</p> PARAMETER DESCRIPTION <code>batch_size</code> <p>Number of samples per batch. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>shuffle</code> <p>Whether to shuffle the data before batching. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>drop_last</code> <p>Whether to drop the last incomplete batch. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>seed</code> <p>Random seed for shuffling. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sampler = BasicBatchSampler(batch_size=32, shuffle=True)\n&gt;&gt;&gt; dataset = list(range(100))\n&gt;&gt;&gt; batches = list(sampler(dataset))\n&gt;&gt;&gt; len(batches)\n4\n</code></pre> Source code in <code>src/formed/integrations/ml/dataloader.py</code> <pre><code>def __init__(\n    self,\n    batch_size: int = 1,\n    shuffle: bool = False,\n    drop_last: bool = False,\n    seed: int = 0,\n) -&gt; None:\n    self._batch_size = batch_size\n    self._shuffle = shuffle\n    self._drop_last = drop_last\n    self._rng = random.Random(seed)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.dataloader.SizeOrderedBucketBatchSampler","title":"SizeOrderedBucketBatchSampler","text":"<pre><code>SizeOrderedBucketBatchSampler(\n    attribute,\n    batch_size=1,\n    shuffle=False,\n    drop_last=False,\n    seed=0,\n)\n</code></pre> <p>               Bases: <code>BaseBatchSampler[_InputT]</code>, <code>Generic[_InputT]</code></p> <p>Batch sampler that orders data by size before batching.</p> <p>This sampler sorts the dataset based on a specified size attribute, then creates batches of a given size. It can optionally shuffle the batches after creation.</p> PARAMETER DESCRIPTION <code>attribute</code> <p>Attribute name or callable to determine the size of each item.</p> <p> TYPE: <code>str | Callable[[_InputT], Sized]</code> </p> <code>batch_size</code> <p>Number of samples per batch. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>shuffle</code> <p>Whether to shuffle the batches after creation. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>drop_last</code> <p>Whether to drop the last incomplete batch. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>seed</code> <p>Random seed for shuffling. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sampler = SizeOrderedBatchSampler(size_attr=\"length\", batch_size=16, shuffle=True)\n&gt;&gt;&gt; dataset = [{\"length\": i} for i in range(100)]\n&gt;&gt;&gt; batches = list(sampler(dataset))\n&gt;&gt;&gt; len(batches)\n7\n</code></pre> Source code in <code>src/formed/integrations/ml/dataloader.py</code> <pre><code>def __init__(\n    self,\n    attribute: str | Callable[[_InputT], Sized],\n    batch_size: int = 1,\n    shuffle: bool = False,\n    drop_last: bool = False,\n    seed: int = 0,\n) -&gt; None:\n    self._attribute = attribute if callable(attribute) else partial(xgetattr, name=attribute)\n    self._batch_size = batch_size\n    self._shuffle = shuffle\n    self._drop_last = drop_last\n    self._rng = random.Random(seed)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.dataloader.BatchIterator","title":"BatchIterator","text":"<pre><code>BatchIterator(data, sampler, collator)\n</code></pre> <p>               Bases: <code>Generic[_InputT, _BatchT]</code></p> <p>Iterator that generates batches from a dataset using a sampler and collator.</p> PARAMETER DESCRIPTION <code>data</code> <p>The dataset to iterate over.</p> <p> TYPE: <code>Sequence[_InputT]</code> </p> <code>sampler</code> <p>Batch sampler that generates batch indices.</p> <p> TYPE: <code>BaseBatchSampler</code> </p> <code>collator</code> <p>Function that collates a sequence of items into a batch.</p> <p> TYPE: <code>Callable[[Sequence[_InputT]], _BatchT]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def collator(batch):\n...     return [x * 2 for x in batch]\n&gt;&gt;&gt; sampler = BasicBatchSampler(batch_size=2)\n&gt;&gt;&gt; iterator = BatchIterator([1, 2, 3, 4], sampler, collator)\n&gt;&gt;&gt; list(iterator)\n[[2, 4], [6, 8]]\n</code></pre> Source code in <code>src/formed/integrations/ml/dataloader.py</code> <pre><code>def __init__(\n    self,\n    data: Sequence[_InputT],\n    sampler: BaseBatchSampler,\n    collator: Callable[[Sequence[_InputT]], _BatchT],\n) -&gt; None:\n    self._data = data\n    self._collator = collator\n    self._sampler = sampler\n    self._iterator: Iterator[Sequence[int]] | None = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.dataloader.DataLoader","title":"DataLoader","text":"<pre><code>DataLoader(sampler, collator, buffer_size=0)\n</code></pre> <p>               Bases: <code>Generic[_InputT, _BatchT]</code></p> <p>Data loader that creates batched iterators from datasets.</p> <p>The DataLoader combines a batch sampler and a collator function to create batched data iterators. It optionally supports buffering using a separate process to prefetch batches in the background, which can improve throughput when batch collation is expensive.</p> PARAMETER DESCRIPTION <code>sampler</code> <p>Batch sampler that generates batch indices.</p> <p> TYPE: <code>BaseBatchSampler</code> </p> <code>collator</code> <p>Function that collates a sequence of items into a batch.</p> <p> TYPE: <code>Callable[[Sequence[_InputT]], _BatchT]</code> </p> <code>buffer_size</code> <p>Size of the prefetch buffer. If 0, buffering is disabled. If &gt; 0, batches are prepared in a background process. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <p>Examples:</p> <p>Basic usage without buffering:</p> <pre><code>&gt;&gt;&gt; def collator(batch):\n...     return [x * 2 for x in batch]\n&gt;&gt;&gt; sampler = BasicBatchSampler(batch_size=4, shuffle=True)\n&gt;&gt;&gt; loader = DataLoader(sampler=sampler, collator=collator)\n&gt;&gt;&gt; dataset = list(range(10))\n&gt;&gt;&gt; batches = list(loader(dataset))\n</code></pre> <p>With buffering for better performance:</p> <pre><code>&gt;&gt;&gt; loader = DataLoader(\n...     sampler=sampler,\n...     collator=collator,\n...     buffer_size=10,  # Prefetch up to 10 batches\n... )\n&gt;&gt;&gt; from formed.common.ctxutils import closing\n&gt;&gt;&gt; with closing(loader(dataset)) as batches:\n...     for batch in batches:\n...         # Process batch\n...         pass\n</code></pre> Note <p>When using buffering (<code>buffer_size &gt; 0</code>), the collator function and any objects it references must be picklable, as they will be passed to a background process. Also, it's recommended to use the loader with a context manager (<code>closing</code>) to ensure proper cleanup of the background process.</p> Source code in <code>src/formed/integrations/ml/dataloader.py</code> <pre><code>def __init__(\n    self,\n    sampler: BaseBatchSampler,\n    collator: Callable[[Sequence[_InputT]], _BatchT],\n    buffer_size: int = 0,\n) -&gt; None:\n    self._collator = collator\n    self._sampler = sampler\n    self._buffer_size = buffer_size\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics","title":"formed.integrations.ml.metrics","text":"<p>Metrics for evaluating machine learning models.</p> <p>This module provides a comprehensive set of metrics for evaluating classification, regression, and ranking models. All metrics follow a common interface with reset, update, and compute methods.</p> Key Components <p>Base Classes:</p> <ul> <li><code>BaseMetric</code>: Abstract base for all metrics</li> <li><code>BinaryClassificationMetric</code>: Base for binary classification metrics</li> <li><code>MulticlassClassificationMetric</code>: Base for multiclass metrics</li> <li><code>MultilabelClassificationMetric</code>: Base for multilabel metrics</li> <li><code>RegressionMetric</code>: Base for regression metrics</li> <li><code>RankingMetric</code>: Base for ranking metrics</li> </ul> <p>Classification Metrics:</p> <ul> <li><code>BinaryAccuracy</code>: Binary classification accuracy</li> <li><code>BinaryFBeta</code>: Binary F-beta score (precision, recall, F1)</li> <li><code>BinaryROCAUC</code>: Binary ROC AUC (requires scores)</li> <li><code>BinaryPRAUC</code>: Binary PR AUC (Precision-Recall curve, requires scores)</li> <li><code>MulticlassAccuracy</code>: Multiclass accuracy (micro/macro)</li> <li><code>MulticlassFBeta</code>: Multiclass F-beta (micro/macro)</li> <li><code>MultilabelAccuracy</code>: Multilabel accuracy</li> <li><code>MultilabelFBeta</code>: Multilabel F-beta</li> </ul> <p>Regression Metrics:</p> <ul> <li><code>MeanAbsoluteError</code>: MAE metric</li> <li><code>MeanSquaredError</code>: MSE metric</li> </ul> <p>Ranking Metrics:</p> <ul> <li><code>MeanAveragePrecision</code>: MAP metric</li> <li><code>NDCG</code>: Normalized Discounted Cumulative Gain</li> </ul> <p>Utility Metrics:</p> <ul> <li><code>Average</code>: Simple averaging metric</li> <li><code>EmptyMetric</code>: No-op metric</li> </ul> Features <ul> <li>Stateful metrics with accumulation across batches</li> <li>Support for micro and macro averaging</li> <li>Flexible label types (<code>int</code>, <code>str</code>, <code>bool</code>)</li> <li>Registrable for configuration-based instantiation</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.ml.metrics import MulticlassAccuracy, ClassificationInput\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create metric\n&gt;&gt;&gt; metric = MulticlassAccuracy(average=\"macro\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Update with batch\n&gt;&gt;&gt; inputs = ClassificationInput(\n...     predictions=[0, 1, 2, 1],\n...     targets=[0, 1, 1, 1]\n... )\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compute final metrics\n&gt;&gt;&gt; results = metric.compute()\n&gt;&gt;&gt; print(results)  # {\"accuracy\": 0.75}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Reset for next evaluation\n&gt;&gt;&gt; metric.reset()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BaseMetric","title":"BaseMetric","text":"<p>               Bases: <code>Registrable</code>, <code>Generic[_T]</code>, <code>ABC</code></p> <p>Abstract base class for all metrics.</p> <p>Metrics are stateful objects that accumulate predictions and targets across multiple batches, then compute aggregate statistics.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_T</code> <p>Type of input data for this metric.</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @BaseMetric.register(\"my_metric\")\n... class MyMetric(BaseMetric[MyInputType]):\n...     def reset(self):\n...         self._state = 0\n...     def update(self, inputs):\n...         self._state += process(inputs)\n...     def compute(self):\n...         return {\"metric\": self._state}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BaseMetric.reset","title":"reset  <code>abstractmethod</code>","text":"<pre><code>reset()\n</code></pre> <p>Reset internal state for a new evaluation.</p> <p>This should clear all accumulated statistics.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef reset(self) -&gt; None:\n    \"\"\"Reset internal state for a new evaluation.\n\n    This should clear all accumulated statistics.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BaseMetric.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(inputs)\n</code></pre> <p>Update internal state with a batch of predictions.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of predictions and targets.</p> <p> TYPE: <code>_T</code> </p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef update(self, inputs: _T) -&gt; None:\n    \"\"\"Update internal state with a batch of predictions.\n\n    Args:\n        inputs: Batch of predictions and targets.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BaseMetric.compute","title":"compute  <code>abstractmethod</code>","text":"<pre><code>compute()\n</code></pre> <p>Compute metrics from accumulated state.</p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary mapping metric names to values.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef compute(self) -&gt; dict[str, float]:\n    \"\"\"Compute metrics from accumulated state.\n\n    Returns:\n        Dictionary mapping metric names to values.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.EmptyMetric","title":"EmptyMetric","text":"<p>               Bases: <code>BaseMetric[Any]</code></p> <p>No-op metric that does nothing.</p> <p>This metric can be used as a placeholder when no evaluation is needed.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.EmptyMetric.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.EmptyMetric.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: Any) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.EmptyMetric.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    return {}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.Average","title":"Average","text":"<pre><code>Average(name='average')\n</code></pre> <p>               Bases: <code>BaseMetric[Sequence[float]]</code></p> <p>Simple averaging metric for numeric values.</p> <p>Computes the mean of all values seen across batches.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name for the metric in output dictionary.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'average'</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metric = Average(name=\"loss\")\n&gt;&gt;&gt; metric.update([1.0, 2.0, 3.0])\n&gt;&gt;&gt; metric.update([4.0, 5.0])\n&gt;&gt;&gt; metric.compute()  # {\"loss\": 3.0}\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self, name: str = \"average\") -&gt; None:\n    self._name = name\n    self._total = 0.0\n    self._count = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.Average.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._total = 0.0\n    self._count = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.Average.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: Sequence[float]) -&gt; None:\n    self._total += sum(inputs)\n    self._count += len(inputs)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.Average.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    return {self._name: self._total / self._count if self._count &gt; 0 else 0.0}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.ClassificationInput","title":"ClassificationInput  <code>dataclass</code>","text":"<pre><code>ClassificationInput(predictions, targets)\n</code></pre> <p>               Bases: <code>Generic[_T]</code></p> <p>Input data for classification metrics.</p> ATTRIBUTE DESCRIPTION <code>predictions</code> <p>Sequence of predicted labels.</p> <p> TYPE: <code>Sequence[_T]</code> </p> <code>targets</code> <p>Sequence of ground truth labels.</p> <p> TYPE: <code>Sequence[_T]</code> </p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.ClassificationInput.predictions","title":"predictions  <code>instance-attribute</code>","text":"<pre><code>predictions\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.ClassificationInput.targets","title":"targets  <code>instance-attribute</code>","text":"<pre><code>targets\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationInput","title":"BinaryClassificationInput  <code>dataclass</code>","text":"<pre><code>BinaryClassificationInput(\n    predictions, targets, scores=None\n)\n</code></pre> <p>               Bases: <code>Generic[BinaryLabelT]</code></p> <p>Input data for binary classification metrics that require probability scores.</p> ATTRIBUTE DESCRIPTION <code>predictions</code> <p>Sequence of predicted labels.</p> <p> TYPE: <code>Sequence[BinaryLabelT]</code> </p> <code>scores</code> <p>Sequence of prediction scores (probabilities for positive class).</p> <p> TYPE: <code>Sequence[float] | None</code> </p> <code>targets</code> <p>Sequence of ground truth labels.</p> <p> TYPE: <code>Sequence[BinaryLabelT]</code> </p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationInput.predictions","title":"predictions  <code>instance-attribute</code>","text":"<pre><code>predictions\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationInput.targets","title":"targets  <code>instance-attribute</code>","text":"<pre><code>targets\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationInput.scores","title":"scores  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>scores = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationMetric","title":"BinaryClassificationMetric","text":"<p>               Bases: <code>BaseMetric[BinaryClassificationInput[BinaryLabelT]]</code>, <code>Generic[BinaryLabelT]</code></p> <p>Base class for binary classification metrics.</p> <p>Binary classification metrics work with two classes (<code>0 and</code>1<code>`, or</code>True<code>/</code>False`).</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>BinaryLabelT</code> <p>Type of labels (<code>int</code>, <code>bool</code>, etc.).</p> <p> </p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationMetric.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = BinaryClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationMetric.reset","title":"reset  <code>abstractmethod</code>","text":"<pre><code>reset()\n</code></pre> <p>Reset internal state for a new evaluation.</p> <p>This should clear all accumulated statistics.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef reset(self) -&gt; None:\n    \"\"\"Reset internal state for a new evaluation.\n\n    This should clear all accumulated statistics.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationMetric.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(inputs)\n</code></pre> <p>Update internal state with a batch of predictions.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of predictions and targets.</p> <p> TYPE: <code>_T</code> </p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef update(self, inputs: _T) -&gt; None:\n    \"\"\"Update internal state with a batch of predictions.\n\n    Args:\n        inputs: Batch of predictions and targets.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryClassificationMetric.compute","title":"compute  <code>abstractmethod</code>","text":"<pre><code>compute()\n</code></pre> <p>Compute metrics from accumulated state.</p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary mapping metric names to values.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef compute(self) -&gt; dict[str, float]:\n    \"\"\"Compute metrics from accumulated state.\n\n    Returns:\n        Dictionary mapping metric names to values.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryAccuracy","title":"BinaryAccuracy","text":"<pre><code>BinaryAccuracy()\n</code></pre> <p>               Bases: <code>BinaryClassificationMetric[BinaryLabelT]</code>, <code>Generic[BinaryLabelT]</code></p> <p>Binary classification accuracy metric.</p> <p>Computes the fraction of correct predictions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metric = BinaryAccuracy()\n&gt;&gt;&gt; inputs = ClassificationInput(\n...     predictions=[1, 0, 1, 1],\n...     targets=[1, 0, 0, 1]\n... )\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt; metric.compute()  # {\"accuracy\": 0.75}\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._correct = 0\n    self._total = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryAccuracy.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = BinaryClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryAccuracy.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._correct = 0\n    self._total = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryAccuracy.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: BinaryClassificationInput[BinaryLabelT]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred, target in zip(predictions, targets):\n        if pred == target:\n            self._correct += 1\n        self._total += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryAccuracy.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    accuracy = self._correct / self._total if self._total &gt; 0 else 0.0\n    return {\"accuracy\": accuracy}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryFBeta","title":"BinaryFBeta","text":"<pre><code>BinaryFBeta(beta=1.0)\n</code></pre> <p>               Bases: <code>BinaryClassificationMetric[BinaryLabelT]</code>, <code>Generic[BinaryLabelT]</code></p> <p>Binary F-beta score with precision and recall.</p> <p>Computes F-beta score, precision, and recall for binary classification. F-beta is the weighted harmonic mean of precision and recall, where beta controls the weight of recall relative to precision.</p> PARAMETER DESCRIPTION <code>beta</code> <p>Weight of recall relative to precision. Common values: - <code>1.0</code>: F1 score (balanced) - <code>0.5</code>: F0.5 (emphasizes precision) - <code>2.0</code>: F2 (emphasizes recall)</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> RETURNS DESCRIPTION <p>Dictionary with <code>\"fbeta\"</code>, <code>\"precision\"</code>, and <code>\"recall\"</code> metrics.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # F1 score (beta=1.0)\n&gt;&gt;&gt; metric = BinaryFBeta(beta=1.0)\n&gt;&gt;&gt; inputs = ClassificationInput(\n...     predictions=[1, 1, 0, 1],\n...     targets=[1, 0, 0, 1]\n... )\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt; result = metric.compute()\n&gt;&gt;&gt; # {\"fbeta\": 0.67, \"precision\": 0.67, \"recall\": 1.0}\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self, beta: float = 1.0) -&gt; None:\n    self._beta = beta\n    self._true_positive = 0\n    self._false_positive = 0\n    self._false_negative = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryFBeta.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = BinaryClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryFBeta.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._true_positive = 0\n    self._false_positive = 0\n    self._false_negative = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryFBeta.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: BinaryClassificationInput[BinaryLabelT]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred, target in zip(predictions, targets):\n        if pred == target == 1:\n            self._true_positive += 1\n        elif pred == 1 and target == 0:\n            self._false_positive += 1\n        elif pred == 0 and target == 1:\n            self._false_negative += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryFBeta.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    beta_sq = self._beta**2\n    precision_denominator = self._true_positive + self._false_positive\n    recall_denominator = self._true_positive + self._false_negative\n\n    precision = self._true_positive / precision_denominator if precision_denominator &gt; 0 else 0.0\n    recall = self._true_positive / recall_denominator if recall_denominator &gt; 0 else 0.0\n\n    if precision + recall == 0:\n        fbeta = 0.0\n    else:\n        fbeta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall)\n\n    return {\"fbeta\": fbeta, \"precision\": precision, \"recall\": recall}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryROCAUC","title":"BinaryROCAUC","text":"<pre><code>BinaryROCAUC()\n</code></pre> <p>               Bases: <code>BinaryClassificationMetric[BinaryLabelT]</code>, <code>Generic[BinaryLabelT]</code></p> <p>Binary ROC AUC (Area Under the Receiver Operating Characteristic Curve) metric.</p> <p>Computes the area under the ROC curve, which measures the model's ability to distinguish between positive and negative classes across all thresholds. ROC AUC ranges from 0 to 1, where 0.5 represents random guessing and 1.0 represents perfect classification.</p> RETURNS DESCRIPTION <p>Dictionary with <code>\"roc_auc\"</code> metric.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metric = BinaryROCAUC()\n&gt;&gt;&gt; inputs = BinaryClassificationInputWithScores(\n...     predictions=[1, 1, 0, 1],\n...     scores=[0.9, 0.8, 0.3, 0.7],\n...     targets=[1, 0, 0, 1]\n... )\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt; result = metric.compute()\n&gt;&gt;&gt; # {\"roc_auc\": 0.75}\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._scores: list[float] = []\n    self._targets: list[int] = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryROCAUC.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = BinaryClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryROCAUC.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._scores = []\n    self._targets = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryROCAUC.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: BinaryClassificationInput[BinaryLabelT]) -&gt; None:\n    assert inputs.scores is not None, \"Scores are required for ROC AUC computation\"\n\n    scores = inputs.scores\n    targets = inputs.targets\n    assert len(scores) == len(targets), \"Scores and targets must have the same length\"\n\n    for score, target in zip(scores, targets):\n        self._scores.append(score)\n        self._targets.append(1 if target == 1 or target is True else 0)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryROCAUC.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    if not self._scores:\n        return {\"roc_auc\": 0.0}\n\n    # Count total positives and negatives\n    n_pos = sum(self._targets)\n    n_neg = len(self._targets) - n_pos\n\n    if n_pos == 0 or n_neg == 0:\n        return {\"roc_auc\": 0.0}\n\n    # Sort by scores in descending order, with ties broken by target (negatives first)\n    sorted_pairs = sorted(zip(self._scores, self._targets), key=lambda x: (-x[0], x[1]))\n\n    # Calculate ROC curve points and AUC\n    tp = 0\n    fp = 0\n    prev_tp = 0\n    prev_fp = 0\n    prev_score = float(\"inf\")\n    auc = 0.0\n\n    for score, target in sorted_pairs:\n        # When score changes, add area for previous threshold\n        if score != prev_score:\n            # Add trapezoid area: width * average height\n            auc += (fp - prev_fp) * (tp + prev_tp) / 2.0\n            prev_tp = tp\n            prev_fp = fp\n            prev_score = score\n\n        if target == 1:\n            tp += 1\n        else:\n            fp += 1\n\n    # Add final trapezoid\n    auc += (fp - prev_fp) * (tp + prev_tp) / 2.0\n\n    # Normalize by total area\n    auc /= n_pos * n_neg\n\n    return {\"roc_auc\": auc}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryPRAUC","title":"BinaryPRAUC","text":"<pre><code>BinaryPRAUC()\n</code></pre> <p>               Bases: <code>BinaryClassificationMetric[BinaryLabelT]</code>, <code>Generic[BinaryLabelT]</code></p> <p>Binary PR AUC (Area Under the Precision-Recall Curve) metric.</p> <p>Computes the area under the Precision-Recall curve, which plots precision (y-axis) against recall (x-axis) at different classification thresholds. This metric is particularly useful for imbalanced datasets where ROC AUC might be overly optimistic.</p> <p>Unlike ROC AUC which uses false positive rate, PR AUC focuses on the positive class performance, making it more informative when the positive class is rare.</p> RETURNS DESCRIPTION <p>Dictionary with <code>\"pr_auc\"</code> metric.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metric = BinaryPRAUC()\n&gt;&gt;&gt; inputs = BinaryClassificationInputWithScores(\n...     predictions=[1, 1, 0, 1],\n...     scores=[0.9, 0.8, 0.3, 0.7],\n...     targets=[1, 0, 0, 1]\n... )\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt; result = metric.compute()\n&gt;&gt;&gt; # {\"pr_auc\": 0.833...}\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._scores: list[float] = []\n    self._targets: list[int] = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryPRAUC.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = BinaryClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryPRAUC.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._scores = []\n    self._targets = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryPRAUC.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: BinaryClassificationInput[BinaryLabelT]) -&gt; None:\n    assert inputs.scores is not None, \"Scores are required for PR AUC computation\"\n\n    scores = inputs.scores\n    targets = inputs.targets\n    assert len(scores) == len(targets), \"Scores and targets must have the same length\"\n\n    for score, target in zip(scores, targets):\n        self._scores.append(score)\n        self._targets.append(1 if target == 1 or target is True else 0)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.BinaryPRAUC.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    if not self._scores:\n        return {\"pr_auc\": 0.0}\n\n    # Count total positives\n    n_pos = sum(self._targets)\n    if n_pos == 0:\n        return {\"pr_auc\": 0.0}\n\n    # Sort by scores in descending order\n    sorted_pairs = sorted(zip(self._scores, self._targets), key=lambda x: (-x[0], x[1]))\n\n    # Calculate precision and recall at each threshold\n    precisions = []\n    recalls = []\n\n    tp = 0\n    fp = 0\n\n    for score, target in sorted_pairs:\n        if target == 1:\n            tp += 1\n        else:\n            fp += 1\n\n        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0.0\n        recall = tp / n_pos\n\n        precisions.append(precision)\n        recalls.append(recall)\n\n    # Add point (0, 1) at the beginning if not already there\n    if recalls[0] != 0:\n        recalls.insert(0, 0.0)\n        precisions.insert(0, precisions[0])\n\n    # Calculate AUC using trapezoidal rule\n    auc = 0.0\n    for i in range(len(recalls) - 1):\n        # Width in recall axis\n        width = recalls[i + 1] - recalls[i]\n        # Average height (precision)\n        height = (precisions[i] + precisions[i + 1]) / 2.0\n        auc += width * height\n\n    return {\"pr_auc\": auc}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassClassificationMetric","title":"MulticlassClassificationMetric","text":"<p>               Bases: <code>BaseMetric[ClassificationInput[LabelT]]</code>, <code>Generic[LabelT]</code></p> <p>Base class for multiclass classification metrics.</p> <p>Multiclass metrics work with any number of classes and support both micro and macro averaging strategies.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>LabelT</code> <p>Type of labels (<code>int</code>, <code>str</code>, etc.).</p> <p> </p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassClassificationMetric.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = ClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassClassificationMetric.reset","title":"reset  <code>abstractmethod</code>","text":"<pre><code>reset()\n</code></pre> <p>Reset internal state for a new evaluation.</p> <p>This should clear all accumulated statistics.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef reset(self) -&gt; None:\n    \"\"\"Reset internal state for a new evaluation.\n\n    This should clear all accumulated statistics.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassClassificationMetric.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(inputs)\n</code></pre> <p>Update internal state with a batch of predictions.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of predictions and targets.</p> <p> TYPE: <code>_T</code> </p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef update(self, inputs: _T) -&gt; None:\n    \"\"\"Update internal state with a batch of predictions.\n\n    Args:\n        inputs: Batch of predictions and targets.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassClassificationMetric.compute","title":"compute  <code>abstractmethod</code>","text":"<pre><code>compute()\n</code></pre> <p>Compute metrics from accumulated state.</p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary mapping metric names to values.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef compute(self) -&gt; dict[str, float]:\n    \"\"\"Compute metrics from accumulated state.\n\n    Returns:\n        Dictionary mapping metric names to values.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassAccuracy","title":"MulticlassAccuracy","text":"<pre><code>MulticlassAccuracy(average='micro')\n</code></pre> <p>               Bases: <code>MulticlassClassificationMetric[LabelT]</code>, <code>Generic[LabelT]</code></p> <p>Multiclass classification accuracy with averaging strategies.</p> <p>Computes accuracy for multiclass classification with support for micro (overall accuracy) and macro (per-class average) strategies.</p> PARAMETER DESCRIPTION <code>average</code> <p>Averaging strategy: - <code>\"micro\"</code>: Overall accuracy across all samples - <code>\"macro\"</code>: Average of per-class accuracies</p> <p> TYPE: <code>Literal['micro', 'macro']</code> DEFAULT: <code>'micro'</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Micro averaging (overall accuracy)\n&gt;&gt;&gt; metric = MulticlassAccuracy(average=\"micro\")\n&gt;&gt;&gt; inputs = ClassificationInput(\n...     predictions=[0, 1, 2, 1],\n...     targets=[0, 1, 1, 1]\n... )\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt; metric.compute()  # {\"accuracy\": 0.75}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Macro averaging (per-class average)\n&gt;&gt;&gt; metric = MulticlassAccuracy(average=\"macro\")\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt; metric.compute()  # Average of class-wise accuracies\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self, average: Literal[\"micro\", \"macro\"] = \"micro\") -&gt; None:\n    self._average = average\n    self._correct: dict[LabelT, int] = defaultdict(int)\n    self._total: dict[LabelT, int] = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassAccuracy.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = ClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassAccuracy.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._correct = defaultdict(int)\n    self._total = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassAccuracy.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: ClassificationInput[LabelT]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred, target in zip(predictions, targets):\n        if pred == target:\n            self._correct[target] += 1\n        self._total[target] += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassAccuracy.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    if self._average == \"micro\":\n        total_correct = sum(self._correct.values())\n        total_count = sum(self._total.values())\n        accuracy = total_correct / total_count if total_count &gt; 0 else 0.0\n        return {\"accuracy\": accuracy}\n    elif self._average == \"macro\":\n        accuracies = []\n        for label in self._total.keys():\n            correct = self._correct[label]\n            total = self._total[label]\n            accuracies.append(correct / total if total &gt; 0 else 0.0)\n        macro_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0.0\n        return {\"accuracy\": macro_accuracy}\n    else:\n        raise ValueError(f\"Unknown average type: {self._average}\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassFBeta","title":"MulticlassFBeta","text":"<pre><code>MulticlassFBeta(beta=1.0, average='micro')\n</code></pre> <p>               Bases: <code>MulticlassClassificationMetric[LabelT]</code>, <code>Generic[LabelT]</code></p> <p>Multiclass F-beta score with precision and recall.</p> <p>Computes F-beta, precision, and recall for multiclass classification with support for micro and macro averaging.</p> PARAMETER DESCRIPTION <code>beta</code> <p>Weight of recall relative to precision (default: <code>1.0</code> for F1).</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>average</code> <p>Averaging strategy: - <code>\"micro\"</code>: Compute globally across all classes - <code>\"macro\"</code>: Compute per-class then average</p> <p> TYPE: <code>Literal['micro', 'macro']</code> DEFAULT: <code>'micro'</code> </p> RETURNS DESCRIPTION <p>Dictionary with \"fbeta\", \"precision\", and \"recall\" metrics.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metric = MulticlassFBeta(beta=1.0, average=\"macro\")\n&gt;&gt;&gt; inputs = ClassificationInput(\n...     predictions=[0, 1, 2, 1],\n...     targets=[0, 1, 1, 1]\n... )\n&gt;&gt;&gt; metric.update(inputs)\n&gt;&gt;&gt; metric.compute()\n&gt;&gt;&gt; # {\"fbeta\": ..., \"precision\": ..., \"recall\": ...}\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self, beta: float = 1.0, average: Literal[\"micro\", \"macro\"] = \"micro\") -&gt; None:\n    self._beta = beta\n    self._average = average\n    self._true_positive: dict[LabelT, int] = defaultdict(int)\n    self._false_positive: dict[LabelT, int] = defaultdict(int)\n    self._false_negative: dict[LabelT, int] = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassFBeta.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = ClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassFBeta.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._true_positive = defaultdict(int)\n    self._false_positive = defaultdict(int)\n    self._false_negative = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassFBeta.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: ClassificationInput[LabelT]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred, target in zip(predictions, targets):\n        if pred == target:\n            self._true_positive[target] += 1\n        else:\n            self._false_positive[pred] += 1\n            self._false_negative[target] += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MulticlassFBeta.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    beta_sq = self._beta**2\n\n    if self._average == \"micro\":\n        total_true_positive = sum(self._true_positive.values())\n        total_false_positive = sum(self._false_positive.values())\n        total_false_negative = sum(self._false_negative.values())\n\n        precision_denominator = total_true_positive + total_false_positive\n        recall_denominator = total_true_positive + total_false_negative\n\n        precision = total_true_positive / precision_denominator if precision_denominator &gt; 0 else 0.0\n        recall = total_true_positive / recall_denominator if recall_denominator &gt; 0 else 0.0\n\n        if precision + recall == 0:\n            fbeta = 0.0\n        else:\n            fbeta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall)\n\n        return {\"fbeta\": fbeta, \"precision\": precision, \"recall\": recall}\n\n    elif self._average == \"macro\":\n        fbetas = []\n        precisions = []\n        recalls = []\n\n        for label in (\n            set(self._true_positive.keys()).union(self._false_positive.keys()).union(self._false_negative.keys())\n        ):\n            tp = self._true_positive[label]\n            fp = self._false_positive[label]\n            fn = self._false_negative[label]\n\n            precision_denominator = tp + fp\n            recall_denominator = tp + fn\n\n            precision = tp / precision_denominator if precision_denominator &gt; 0 else 0.0\n            recall = tp / recall_denominator if recall_denominator &gt; 0 else 0.0\n\n            if precision + recall == 0:\n                fbeta = 0.0\n            else:\n                fbeta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall)\n\n            fbetas.append(fbeta)\n            precisions.append(precision)\n            recalls.append(recall)\n        macro_fbeta = sum(fbetas) / len(fbetas) if fbetas else 0.0\n        macro_precision = sum(precisions) / len(precisions) if precisions else 0.0\n        macro_recall = sum(recalls) / len(recalls) if recalls else 0.0\n        return {\"fbeta\": macro_fbeta, \"precision\": macro_precision, \"recall\": macro_recall}\n    else:\n        raise ValueError(f\"Unknown average type: {self._average}\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelClassificationMetric","title":"MultilabelClassificationMetric","text":"<p>               Bases: <code>BaseMetric[ClassificationInput[Sequence[LabelT]]]</code>, <code>Generic[LabelT]</code></p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelClassificationMetric.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = ClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelClassificationMetric.reset","title":"reset  <code>abstractmethod</code>","text":"<pre><code>reset()\n</code></pre> <p>Reset internal state for a new evaluation.</p> <p>This should clear all accumulated statistics.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef reset(self) -&gt; None:\n    \"\"\"Reset internal state for a new evaluation.\n\n    This should clear all accumulated statistics.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelClassificationMetric.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(inputs)\n</code></pre> <p>Update internal state with a batch of predictions.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of predictions and targets.</p> <p> TYPE: <code>_T</code> </p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef update(self, inputs: _T) -&gt; None:\n    \"\"\"Update internal state with a batch of predictions.\n\n    Args:\n        inputs: Batch of predictions and targets.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelClassificationMetric.compute","title":"compute  <code>abstractmethod</code>","text":"<pre><code>compute()\n</code></pre> <p>Compute metrics from accumulated state.</p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary mapping metric names to values.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef compute(self) -&gt; dict[str, float]:\n    \"\"\"Compute metrics from accumulated state.\n\n    Returns:\n        Dictionary mapping metric names to values.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelAccuracy","title":"MultilabelAccuracy","text":"<pre><code>MultilabelAccuracy(average='micro')\n</code></pre> <p>               Bases: <code>MultilabelClassificationMetric[LabelT]</code>, <code>Generic[LabelT]</code></p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self, average: Literal[\"micro\", \"macro\"] = \"micro\") -&gt; None:\n    self._average = average\n    self._correct: dict[LabelT, int] = defaultdict(int)\n    self._total: dict[LabelT, int] = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelAccuracy.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = ClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelAccuracy.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._correct = defaultdict(int)\n    self._total = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelAccuracy.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: ClassificationInput[Sequence[LabelT]]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred_labels, target_labels in zip(predictions, targets):\n        pred_set = set(pred_labels)\n        target_set = set(target_labels)\n        for label in target_set.union(pred_set):\n            if label in target_set and label in pred_set:\n                self._correct[label] += 1\n            self._total[label] += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelAccuracy.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    if self._average == \"micro\":\n        total_correct = sum(self._correct.values())\n        total_count = sum(self._total.values())\n        accuracy = total_correct / total_count if total_count &gt; 0 else 0.0\n        return {\"accuracy\": accuracy}\n    elif self._average == \"macro\":\n        accuracies = []\n        for label in self._total.keys():\n            correct = self._correct[label]\n            total = self._total[label]\n            accuracies.append(correct / total if total &gt; 0 else 0.0)\n        macro_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0.0\n        return {\"accuracy\": macro_accuracy}\n    else:\n        raise ValueError(f\"Unknown average type: {self._average}\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelFBeta","title":"MultilabelFBeta","text":"<pre><code>MultilabelFBeta(beta=1.0, average='micro')\n</code></pre> <p>               Bases: <code>MultilabelClassificationMetric[LabelT]</code>, <code>Generic[LabelT]</code></p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self, beta: float = 1.0, average: Literal[\"micro\", \"macro\"] = \"micro\") -&gt; None:\n    self._beta = beta\n    self._average = average\n    self._true_positive: dict[LabelT, int] = defaultdict(int)\n    self._false_positive: dict[LabelT, int] = defaultdict(int)\n    self._false_negative: dict[LabelT, int] = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelFBeta.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = ClassificationInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelFBeta.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._true_positive = defaultdict(int)\n    self._false_positive = defaultdict(int)\n    self._false_negative = defaultdict(int)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelFBeta.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: ClassificationInput[Sequence[LabelT]]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred_labels, target_labels in zip(predictions, targets):\n        pred_set = set(pred_labels)\n        target_set = set(target_labels)\n        for label in target_set.union(pred_set):\n            if label in target_set and label in pred_set:\n                self._true_positive[label] += 1\n            elif label in pred_set and label not in target_set:\n                self._false_positive[label] += 1\n            elif label in target_set and label not in pred_set:\n                self._false_negative[label] += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MultilabelFBeta.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    beta_sq = self._beta**2\n\n    if self._average == \"micro\":\n        total_true_positive = sum(self._true_positive.values())\n        total_false_positive = sum(self._false_positive.values())\n        total_false_negative = sum(self._false_negative.values())\n\n        precision_denominator = total_true_positive + total_false_positive\n        recall_denominator = total_true_positive + total_false_negative\n\n        precision = total_true_positive / precision_denominator if precision_denominator &gt; 0 else 0.0\n        recall = total_true_positive / recall_denominator if recall_denominator &gt; 0 else 0.0\n\n        if precision + recall == 0:\n            fbeta = 0.0\n        else:\n            fbeta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall)\n\n        return {\"fbeta\": fbeta, \"precision\": precision, \"recall\": recall}\n    elif self._average == \"macro\":\n        fbetas = []\n        precisions = []\n        recalls = []\n\n        for label in (\n            set(self._true_positive.keys()).union(self._false_positive.keys()).union(self._false_negative.keys())\n        ):\n            tp = self._true_positive[label]\n            fp = self._false_positive[label]\n            fn = self._false_negative[label]\n\n            precision_denominator = tp + fp\n            recall_denominator = tp + fn\n\n            precision = tp / precision_denominator if precision_denominator &gt; 0 else 0.0\n            recall = tp / recall_denominator if recall_denominator &gt; 0 else 0.0\n\n            if precision + recall == 0:\n                fbeta = 0.0\n            else:\n                fbeta = (1 + beta_sq) * (precision * recall) / (beta_sq * precision + recall)\n\n            fbetas.append(fbeta)\n            precisions.append(precision)\n            recalls.append(recall)\n        macro_fbeta = sum(fbetas) / len(fbetas) if fbetas else 0.0\n        macro_precision = sum(precisions) / len(precisions) if precisions else 0.0\n        macro_recall = sum(recalls) / len(recalls) if recalls else 0.0\n        return {\"fbeta\": macro_fbeta, \"precision\": macro_precision, \"recall\": macro_recall}\n    else:\n        raise ValueError(f\"Unknown average type: {self._average}\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionInput","title":"RegressionInput  <code>dataclass</code>","text":"<pre><code>RegressionInput(predictions, targets)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionInput.predictions","title":"predictions  <code>instance-attribute</code>","text":"<pre><code>predictions\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionInput.targets","title":"targets  <code>instance-attribute</code>","text":"<pre><code>targets\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionMetric","title":"RegressionMetric","text":"<p>               Bases: <code>BaseMetric[RegressionInput]</code></p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionMetric.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = RegressionInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionMetric.reset","title":"reset  <code>abstractmethod</code>","text":"<pre><code>reset()\n</code></pre> <p>Reset internal state for a new evaluation.</p> <p>This should clear all accumulated statistics.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef reset(self) -&gt; None:\n    \"\"\"Reset internal state for a new evaluation.\n\n    This should clear all accumulated statistics.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionMetric.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(inputs)\n</code></pre> <p>Update internal state with a batch of predictions.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of predictions and targets.</p> <p> TYPE: <code>_T</code> </p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef update(self, inputs: _T) -&gt; None:\n    \"\"\"Update internal state with a batch of predictions.\n\n    Args:\n        inputs: Batch of predictions and targets.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RegressionMetric.compute","title":"compute  <code>abstractmethod</code>","text":"<pre><code>compute()\n</code></pre> <p>Compute metrics from accumulated state.</p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary mapping metric names to values.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef compute(self) -&gt; dict[str, float]:\n    \"\"\"Compute metrics from accumulated state.\n\n    Returns:\n        Dictionary mapping metric names to values.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanSquaredError","title":"MeanSquaredError","text":"<pre><code>MeanSquaredError()\n</code></pre> <p>               Bases: <code>RegressionMetric</code></p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._squared_error = 0.0\n    self._count = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanSquaredError.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = RegressionInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanSquaredError.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._squared_error = 0.0\n    self._count = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanSquaredError.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: RegressionInput) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred, target in zip(predictions, targets):\n        self._squared_error += (pred - target) ** 2\n        self._count += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanSquaredError.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    mse = self._squared_error / self._count if self._count &gt; 0 else 0.0\n    return {\"mean_squared_error\": mse}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAbsoluteError","title":"MeanAbsoluteError","text":"<pre><code>MeanAbsoluteError()\n</code></pre> <p>               Bases: <code>RegressionMetric</code></p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._absolute_error = 0.0\n    self._count = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAbsoluteError.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = RegressionInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAbsoluteError.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._absolute_error = 0.0\n    self._count = 0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAbsoluteError.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: RegressionInput) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred, target in zip(predictions, targets):\n        self._absolute_error += abs(pred - target)\n        self._count += 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAbsoluteError.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    mae = self._absolute_error / self._count if self._count &gt; 0 else 0.0\n    return {\"mean_absolute_error\": mae}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingInput","title":"RankingInput  <code>dataclass</code>","text":"<pre><code>RankingInput(predictions, targets)\n</code></pre> <p>               Bases: <code>Generic[LabelT]</code></p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingInput.predictions","title":"predictions  <code>instance-attribute</code>","text":"<pre><code>predictions\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingInput.targets","title":"targets  <code>instance-attribute</code>","text":"<pre><code>targets\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingMetric","title":"RankingMetric","text":"<p>               Bases: <code>BaseMetric[RankingInput[LabelT]]</code>, <code>Generic[LabelT]</code></p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingMetric.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = RankingInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingMetric.reset","title":"reset  <code>abstractmethod</code>","text":"<pre><code>reset()\n</code></pre> <p>Reset internal state for a new evaluation.</p> <p>This should clear all accumulated statistics.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef reset(self) -&gt; None:\n    \"\"\"Reset internal state for a new evaluation.\n\n    This should clear all accumulated statistics.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingMetric.update","title":"update  <code>abstractmethod</code>","text":"<pre><code>update(inputs)\n</code></pre> <p>Update internal state with a batch of predictions.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of predictions and targets.</p> <p> TYPE: <code>_T</code> </p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef update(self, inputs: _T) -&gt; None:\n    \"\"\"Update internal state with a batch of predictions.\n\n    Args:\n        inputs: Batch of predictions and targets.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.RankingMetric.compute","title":"compute  <code>abstractmethod</code>","text":"<pre><code>compute()\n</code></pre> <p>Compute metrics from accumulated state.</p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary mapping metric names to values.</p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>@abc.abstractmethod\ndef compute(self) -&gt; dict[str, float]:\n    \"\"\"Compute metrics from accumulated state.\n\n    Returns:\n        Dictionary mapping metric names to values.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAveragePrecision","title":"MeanAveragePrecision","text":"<pre><code>MeanAveragePrecision()\n</code></pre> <p>               Bases: <code>RankingMetric[LabelT]</code>, <code>Generic[LabelT]</code></p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._average_precisions: list[float] = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAveragePrecision.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = RankingInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAveragePrecision.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._average_precisions = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAveragePrecision.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: RankingInput[LabelT]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred_scores, target_labels in zip(predictions, targets):\n        sorted_labels = sorted(pred_scores.keys(), key=lambda x: pred_scores[x], reverse=True)\n        relevant_set = set(target_labels)\n\n        num_relevant = 0\n        precision_sum = 0.0\n\n        for rank, label in enumerate(sorted_labels, start=1):\n            if label in relevant_set:\n                num_relevant += 1\n                precision_sum += num_relevant / rank\n\n        average_precision = precision_sum / len(relevant_set) if relevant_set else 0.0\n        self._average_precisions.append(average_precision)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.MeanAveragePrecision.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    mean_ap = sum(self._average_precisions) / len(self._average_precisions) if self._average_precisions else 0.0\n    return {\"mean_average_precision\": mean_ap}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.NDCG","title":"NDCG","text":"<pre><code>NDCG(k=10)\n</code></pre> <p>               Bases: <code>RankingMetric[LabelT]</code>, <code>Generic[LabelT]</code></p> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def __init__(self, k: int = 10) -&gt; None:\n    self._k = k\n    self._ndcgs: list[float] = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.NDCG.Input","title":"Input  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Input = RankingInput\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.NDCG.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def reset(self) -&gt; None:\n    self._ndcgs = []\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.NDCG.update","title":"update","text":"<pre><code>update(inputs)\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def update(self, inputs: RankingInput[LabelT]) -&gt; None:\n    predictions = inputs.predictions\n    targets = inputs.targets\n    assert len(predictions) == len(targets), \"Predictions and targets must have the same length\"\n\n    for pred_scores, target_labels in zip(predictions, targets):\n        sorted_labels = sorted(pred_scores.keys(), key=lambda x: pred_scores[x], reverse=True)\n        relevant_set = set(target_labels)\n\n        dcg = 0.0\n        for rank, label in enumerate(sorted_labels[: self._k], start=1):\n            if label in relevant_set:\n                dcg += 1 / math.log2(rank + 1)\n\n        ideal_dcg = 0.0\n        for rank in range(1, min(len(relevant_set), self._k) + 1):\n            ideal_dcg += 1 / math.log2(rank + 1)\n\n        ndcg = dcg / ideal_dcg if ideal_dcg &gt; 0 else 0.0\n        self._ndcgs.append(ndcg)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.metrics.NDCG.compute","title":"compute","text":"<pre><code>compute()\n</code></pre> Source code in <code>src/formed/integrations/ml/metrics.py</code> <pre><code>def compute(self) -&gt; dict[str, float]:\n    mean_ndcg = sum(self._ndcgs) / len(self._ndcgs) if self._ndcgs else 0.0\n    return {\"ndcg\": mean_ndcg}\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base","title":"formed.integrations.ml.transforms.base","text":"<p>Base classes and utilities for data transformations.</p> <p>This module provides the core infrastructure for building type-safe, composable data transformations in machine learning pipelines. It supports both single-instance and batched processing with strong type guarantees.</p> Key Components <ul> <li>BaseTransform: Abstract base class for all transformations</li> <li>DataModule: Composable data transformation container</li> <li>Extra: Descriptor for optional fields (e.g., labels in test data)</li> <li>Param: Descriptor for non-transformed parameters</li> <li>register_dataclass: Function to register dataclasses with JAX pytree</li> </ul> Design Patterns <ul> <li>Descriptor protocol for field access control</li> <li>Generic type parameters for type safety</li> <li>Mode-based behavior (AsInstance, AsBatch, AsConverter)</li> <li>Automatic JAX pytree registration for compatibility with jax.jit/jax.vmap</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.ml import DataModule, TensorTransform, LabelIndexer, Extra\n&gt;&gt;&gt;\n&gt;&gt;&gt; class MyDataModule(DataModule[DataModuleModeT, dict, ...]):\n...     features: TensorTransform\n...     label: Extra[LabelIndexer] = Extra.default()\n&gt;&gt;&gt;\n&gt;&gt;&gt; dm = MyDataModule(features=TensorTransform(), label=LabelIndexer())\n&gt;&gt;&gt; with dm.train():\n...     instance = dm.instance({\"features\": [1.0, 2.0], \"label\": \"positive\"})\n&gt;&gt;&gt; batch = dm.batch([instance1, instance2, instance3])\n</code></pre> Note <p>If JAX is installed, all DataModule instances are automatically registered as JAX pytrees for compatibility with JAX transformations.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.Extra","title":"Extra","text":"<pre><code>Extra(*args, **kwargs)\n</code></pre> <p>               Bases: <code>Generic[_BaseTransformT_co]</code></p> <p>Descriptor marker for optional transformation fields in DataModule.</p> <p>Extra fields are optional and can be None, which is useful for fields that may not be present in all data (e.g., labels in test/inference data). When accessed, Extra fields return the transformed value in instance/batch mode, or the transform itself in converter mode.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_BaseTransformT_co</code> <p>The transform type (covariant).</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class MyDataModule(DataModule[...]):\n...     text: Tokenizer\n...     label: Extra[LabelIndexer] = Extra.default()  # Optional field\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Training mode with labels\n&gt;&gt;&gt; train_dm = MyDataModule(text=Tokenizer(), label=LabelIndexer())\n&gt;&gt;&gt; with train_dm.train():\n...     instance = train_dm.instance({\"text\": \"hello\", \"label\": \"positive\"})\n&gt;&gt;&gt; print(instance.label)  # Returns the transformed label index\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Inference mode without labels\n&gt;&gt;&gt; test_dm = MyDataModule(text=Tokenizer(), label=None)\n&gt;&gt;&gt; test_instance = test_dm.instance({\"text\": \"hello\"})\n&gt;&gt;&gt; print(test_instance.label)  # Returns None\n</code></pre> Note <p>Extra is a marker class and cannot be instantiated directly. Use Extra.default() to provide a default value.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    raise TypeError(\"Extra is a marker class and cannot be instantiated directly\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.Extra.default","title":"default  <code>classmethod</code>","text":"<pre><code>default(default=None)\n</code></pre> <p>Create a default Extra field with an optional default transform.</p> PARAMETER DESCRIPTION <code>default</code> <p>Optional default transform to use if not specified.</p> <p> TYPE: <code>_BaseTransformT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Extra[_BaseTransformT]</code> <p>An Extra field with the specified default.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef default(\n    cls: type[\"Extra[_BaseTransformT]\"],\n    default: _BaseTransformT | None = None,\n) -&gt; \"Extra[_BaseTransformT]\":\n    \"\"\"Create a default Extra field with an optional default transform.\n\n    Args:\n        default: Optional default transform to use if not specified.\n\n    Returns:\n        An Extra field with the specified default.\n\n    \"\"\"\n    return cast(Extra[_BaseTransformT], default)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.Extra.default_factory","title":"default_factory  <code>classmethod</code>","text":"<pre><code>default_factory(factory)\n</code></pre> <p>Create a factory for an Extra field with an optional default transform.</p> PARAMETER DESCRIPTION <code>factory</code> <p>A callable that returns the default transform.</p> <p> TYPE: <code>Callable[[], _BaseTransformT | None]</code> </p> RETURNS DESCRIPTION <code>Callable[[], Extra[_BaseTransformT]]</code> <p>A factory callable for creating Extra fields.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef default_factory(\n    cls: type[\"Extra[_BaseTransformT]\"],\n    factory: Callable[[], _BaseTransformT | None],\n) -&gt; Callable[[], \"Extra[_BaseTransformT]\"]:\n    \"\"\"Create a factory for an Extra field with an optional default transform.\n\n    Args:\n        factory: A callable that returns the default transform.\n\n    Returns:\n        A factory callable for creating Extra fields.\n\n    \"\"\"\n    return cast(Callable[[], Extra[_BaseTransformT]], factory)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.Param","title":"Param","text":"<pre><code>Param()\n</code></pre> <p>               Bases: <code>Generic[_T_co]</code></p> <p>Descriptor marker for non-transformed parameter fields in DataModule.</p> <p>Param fields represent parameters that pass through unchanged during instance/batch conversion. They are not transformed but remain accessible in all modes. This is useful for hyperparameters, configuration values, or other metadata that should be available but not processed.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_T_co</code> <p>The parameter type (covariant).</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class MyDataModule(DataModule[...]):\n...     text: Tokenizer\n...     max_length: Param[int] = Param.default(128)\n...     temperature: Param[float] = Param.default(1.0)\n&gt;&gt;&gt;\n&gt;&gt;&gt; dm = MyDataModule(text=Tokenizer(), max_length=256, temperature=0.8)\n&gt;&gt;&gt; instance = dm.instance({\"text\": \"hello\"})\n&gt;&gt;&gt; print(instance.max_length)  # Returns 256 (unchanged)\n&gt;&gt;&gt; batch = dm.batch([instance1, instance2])\n&gt;&gt;&gt; print(batch.max_length)  # Still returns 256\n</code></pre> Note <p>Param is a marker class and cannot be instantiated directly. Use <code>Param.default()</code> or <code>Param.default_factory()</code> to provide defaults.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def __init__(self) -&gt; None:\n    raise TypeError(\"Param is a marker class and cannot be instantiated directly\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.Param.default","title":"default  <code>classmethod</code>","text":"<pre><code>default(default)\n</code></pre> <p>Create a Param field with a default value.</p> PARAMETER DESCRIPTION <code>default</code> <p>The default value for this parameter.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>Param[_T]</code> <p>A Param field with the specified default.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef default(cls: type[\"Param[_T]\"], default: _T) -&gt; \"Param[_T]\":\n    \"\"\"Create a Param field with a default value.\n\n    Args:\n        default: The default value for this parameter.\n\n    Returns:\n        A Param field with the specified default.\n\n    \"\"\"\n    return cast(Param[_T], default)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.Param.cast","title":"cast  <code>classmethod</code>","text":"<pre><code>cast(value)\n</code></pre> <p>Wrap a value as a Param field.</p> PARAMETER DESCRIPTION <code>value</code> <p>The value to wrap as a Param.</p> <p> TYPE: <code>_T</code> </p> <p>Returns:     A Param field wrapping the given value.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef cast(cls: type[\"Param[_T]\"], value: _T) -&gt; \"Param[_T]\":\n    \"\"\"Wrap a value as a Param field.\n\n    Args:\n        value: The value to wrap as a Param.\n    Returns:\n        A Param field wrapping the given value.\n\n    \"\"\"\n    return cast(Param[_T], value)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.Param.default_factory","title":"default_factory  <code>classmethod</code>","text":"<pre><code>default_factory(factory)\n</code></pre> <p>Create a Param field with a default factory function.</p> PARAMETER DESCRIPTION <code>factory</code> <p>A callable that returns the default value.</p> <p> TYPE: <code>Callable[[], _T]</code> </p> RETURNS DESCRIPTION <code>Callable[[], Param[_T]]</code> <p>A factory callable for creating Param fields.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef default_factory(\n    cls: type[\"Param[_T]\"],\n    factory: Callable[[], _T],\n) -&gt; Callable[[], \"Param[_T]\"]:\n    \"\"\"Create a Param field with a default factory function.\n\n    Args:\n        factory: A callable that returns the default value.\n\n    Returns:\n        A factory callable for creating Param fields.\n\n    \"\"\"\n    return cast(Callable[[], Param[_T]], factory)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransformMeta","title":"BaseTransformMeta","text":"<p>               Bases: <code>ABCMeta</code></p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransform","title":"BaseTransform","text":"<p>               Bases: <code>Registrable</code>, <code>Generic[_S, _T, InstanceT_co, BatchT_co]</code>, <code>ABC</code></p> <p>Abstract base class for data transformations.</p> <p>BaseTransform provides a two-stage transformation pipeline: 1. Instance transformation: Convert raw data to per-instance representation 2. Batch transformation: Collate multiple instances into batched tensors</p> <p>The class uses descriptors for flexible field access and supports training/inference modes for stateful transformations (e.g., vocabulary building).</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor is applied</p> <p> </p> <code>_T</code> <p>Target data type after accessor is applied</p> <p> </p> <code>InstanceT_co</code> <p>Instance representation type (covariant)</p> <p> </p> <code>BatchT_co</code> <p>Batch representation type (covariant)</p> <p> </p> ATTRIBUTE DESCRIPTION <code>accessor</code> <p>Optional accessor to extract the relevant field from input data.       Can be a string (attribute/key name) or a callable.</p> <p> TYPE: <code>str | Callable[[_S], _T] | None</code> </p> Class Attributes <p>is_static: If True, indicates the batched value is static for JAX. process_parent: If True, the accessor receives the entire parent object.</p> Abstract Methods <p>instance: Transform a single data point to its instance representation. batch: Collate a sequence of instances into a batched representation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; class LowercaseTransform(BaseTransform[dict, str, str, list[str]]):\n...     def instance(self, text: str) -&gt; str:\n...         return text.lower()\n...\n...     def batch(self, instances: Sequence[str]) -&gt; list[str]:\n...         return list(instances)\n&gt;&gt;&gt;\n&gt;&gt;&gt; transform = LowercaseTransform(accessor=\"text\")\n&gt;&gt;&gt; instance = transform({\"text\": \"HELLO\"})  # Returns \"hello\"\n&gt;&gt;&gt; batch = transform.batch([\"hello\", \"world\"])  # Returns [\"hello\", \"world\"]\n</code></pre> Note <ul> <li>Subclasses are automatically converted to dataclasses via metaclass.</li> <li>Use the <code>train()</code> context manager for stateful transformations.</li> <li>Supports saving/loading with cloudpickle for persistence.</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransform.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransform.instance","title":"instance  <code>abstractmethod</code>","text":"<pre><code>instance(obj)\n</code></pre> <p>Transform a single data point to its instance representation.</p> PARAMETER DESCRIPTION <code>obj</code> <p>The input data after accessor extraction.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>InstanceT_co</code> <p>The transformed instance representation.</p> Note <p>This method is called for each individual data point.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@abc.abstractmethod\ndef instance(self, obj: _T, /) -&gt; InstanceT_co:\n    \"\"\"Transform a single data point to its instance representation.\n\n    Args:\n        obj: The input data after accessor extraction.\n\n    Returns:\n        The transformed instance representation.\n\n    Note:\n        This method is called for each individual data point.\n\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransform.batch","title":"batch  <code>abstractmethod</code>","text":"<pre><code>batch(batch)\n</code></pre> <p>Collate multiple instances into a batched representation.</p> PARAMETER DESCRIPTION <code>batch</code> <p>A sequence of instance representations from <code>instance()</code>.</p> <p> TYPE: <code>Sequence[InstanceT_co]</code> </p> RETURNS DESCRIPTION <code>BatchT_co</code> <p>The batched representation, typically as tensors or arrays.</p> Note <p>This method should handle padding, stacking, or other batching logic.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@abc.abstractmethod\ndef batch(self, batch: Sequence[InstanceT_co], /) -&gt; BatchT_co:\n    \"\"\"Collate multiple instances into a batched representation.\n\n    Args:\n        batch: A sequence of instance representations from `instance()`.\n\n    Returns:\n        The batched representation, typically as tensors or arrays.\n\n    Note:\n        This method should handle padding, stacking, or other batching logic.\n\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransform.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransform.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.BaseTransform.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.DataModule","title":"DataModule","text":"<p>               Bases: <code>BaseTransform[_T, _T, _InstanceT, _BatchT]</code>, <code>Generic[_DataModuleModeT_co, _T, _InstanceT, _BatchT]</code></p> <p>Composable container for multiple data transformations with mode-based behavior.</p> <p>DataModule orchestrates multiple BaseTransform fields and switches between three modes: - AsConverter: Configuration mode, holds transform logic - AsInstance: Single data point after per-instance transformation - AsBatch: Multiple instances collated into batched tensors</p> <p>This enables a single class definition to represent raw data, transformed instances, and batched tensors with full type safety.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_DataModuleModeT_co</code> <p>Current mode (AsConverter, AsInstance, or AsBatch)</p> <p> </p> <code>_T</code> <p>Input data type</p> <p> </p> <code>_InstanceT</code> <p>Instance mode type (self when mode=AsInstance)</p> <p> </p> <code>_BatchT</code> <p>Batch mode type (self when mode=AsBatch)</p> <p> </p> Field Types <ul> <li>Regular fields: BaseTransform subclasses that transform data</li> <li>Extra fields: Optional transforms (e.g., labels for test data)</li> <li>Param fields: Non-transformed parameters that pass through unchanged</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @dataclasses.dataclass\n... class TextExamples:\n...     text: str\n...     label: Optional[str] = None\n&gt;&gt;&gt;\n&gt;&gt;&gt; class TextDataModule(DataModule[DataModuleModeT, TextExample, ...]):\n...     text: Tokenizer\n...     label: Extra[LabelIndexer] = Extra.default()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create converter (configuration)\n&gt;&gt;&gt; dm = TextDataModule(\n...     text=Tokenizer(surfaces=TokenSequenceIndexer()),\n...     label=LabelIndexer()\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Training: build vocabularies\n&gt;&gt;&gt; with dm.train():\n...     train_instances = [\n...         dm.instance(TextExample(\"hello world\", \"positive\"))\n...         for example in train_data\n...     ]\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create batches\n&gt;&gt;&gt; batch = dm.batch(train_instances[:32])\n&gt;&gt;&gt; print(batch.text.surfaces.ids.shape)  # (32, max_length)\n&gt;&gt;&gt; print(batch.label.shape)  # (32,)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Inference without labels\n&gt;&gt;&gt; test_dm = TextDataModule(text=dm.text, label=None)\n&gt;&gt;&gt; test_instance = test_dm.instance(TextExample(\"test sentence\"))\n&gt;&gt;&gt; print(test_instance.label)  # None\n</code></pre> Note <ul> <li>Automatically registered as JAX pytree if JAX is available</li> <li>Mode transitions are enforced by type system</li> <li>Fields are descriptors with mode-dependent behavior</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.DataModule.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.DataModule.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for all field transforms.</p> <p>This propagates training mode to all BaseTransform fields, allowing them to build state (e.g., vocabularies) from training data.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n&gt;&gt;&gt; with dm.train():\n...     instances = [dm.instance(example) for example in train_data]\n&gt;&gt;&gt; # Vocabularies are now built and frozen\n</code></pre> Note <p>Can only be called in AsConverter mode.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for all field transforms.\n\n    This propagates training mode to all BaseTransform fields, allowing them\n    to build state (e.g., vocabularies) from training data.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n        &gt;&gt;&gt; with dm.train():\n        ...     instances = [dm.instance(example) for example in train_data]\n        &gt;&gt;&gt; # Vocabularies are now built and frozen\n\n    Note:\n        Can only be called in AsConverter mode.\n\n    \"\"\"\n    assert self.__mode__ in (None, DataModuleMode.AS_CONVERTER), (\n        \"DataModule must be in converter mode to enter training mode\"\n    )\n    with ExitStack() as stack:\n        for transform in self.__field_transforms__.values():\n            stack.enter_context(transform.train())\n        yield\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.DataModule.instance","title":"instance","text":"<pre><code>instance(obj)\n</code></pre> <p>Transform raw data into an instance representation.</p> <p>Applies all field transforms to create a DataModule in AsInstance mode. Each transform field processes the corresponding data attribute/key.</p> PARAMETER DESCRIPTION <code>obj</code> <p>The raw input data object.</p> <p> TYPE: <code>_T</code> </p> RETURNS DESCRIPTION <code>_InstanceT</code> <p>A DataModule in AsInstance mode with transformed fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n&gt;&gt;&gt; instance = dm.instance({\"text\": \"hello world\", \"label\": \"positive\"})\n&gt;&gt;&gt; print(instance.text.surfaces)  # Tokenized text\n&gt;&gt;&gt; print(instance.label)  # Label index\n</code></pre> Note <ul> <li>Can only be called in <code>AsConverter</code> mode</li> <li>Returns a new <code>DataModule</code> with <code>mode=AsInstance</code></li> <li>Extra fields can be <code>None</code> if data is missing</li> </ul> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def instance(self: \"DataModule[AsConverter]\", obj: _T, /) -&gt; _InstanceT:\n    \"\"\"Transform raw data into an instance representation.\n\n    Applies all field transforms to create a DataModule in AsInstance mode.\n    Each transform field processes the corresponding data attribute/key.\n\n    Args:\n        obj: The raw input data object.\n\n    Returns:\n        A DataModule in AsInstance mode with transformed fields.\n\n    Examples:\n        &gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n        &gt;&gt;&gt; instance = dm.instance({\"text\": \"hello world\", \"label\": \"positive\"})\n        &gt;&gt;&gt; print(instance.text.surfaces)  # Tokenized text\n        &gt;&gt;&gt; print(instance.label)  # Label index\n\n    Note:\n        - Can only be called in `AsConverter` mode\n        - Returns a new `DataModule` with `mode=AsInstance`\n        - Extra fields can be `None` if data is missing\n\n    \"\"\"\n    assert self.__mode__ in (None, DataModuleMode.AS_CONVERTER), (\n        \"DataModule must be in converter mode to create an instance\"\n    )\n\n    fields = {}\n    for name, transform in self.__field_transforms__.items():\n        fields[name] = transform(obj)\n    for name, field in self.__class__.__get_param_fields__().items():\n        if (\n            name not in fields\n            and field.default is not dataclasses.MISSING\n            and field.default_factory is dataclasses.MISSING\n        ):\n            fields[name] = _UNAVAILABLE\n\n    instance = cast(_InstanceT, dataclasses.replace(self, **fields))\n    setattr(instance, \"__mode__\", DataModuleMode.AS_INSTANCE)\n\n    return instance\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.DataModule.batch","title":"batch","text":"<pre><code>batch(instances)\n</code></pre> <p>Collate multiple instances into a batched representation.</p> <p>Takes a sequence of raw data or instances and creates a <code>DataModule</code> in <code>AsBatch</code> mode. Each transform field's <code>batch()</code> method is called to collate the corresponding field values.</p> PARAMETER DESCRIPTION <code>instances</code> <p>Sequence of raw data or <code>DataModule</code> instances.</p> <p> TYPE: <code>Sequence[_T | _InstanceT]</code> </p> RETURNS DESCRIPTION <code>_BatchT</code> <p>A <code>DataModule</code> in <code>AsBatch</code> mode with batched tensor fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n&gt;&gt;&gt; instances = [dm.instance(ex) for ex in examples]\n&gt;&gt;&gt; batch = dm.batch(instances)\n&gt;&gt;&gt; print(batch.text.surfaces.ids.shape)  # (batch_size, seq_length)\n&gt;&gt;&gt; print(batch.label.shape)  # (batch_size,)\n&gt;&gt;&gt; print(len(batch))  # batch_size\n</code></pre> Note <ul> <li>Can only be called in <code>AsConverter</code> mode</li> <li>Automatically converts raw data to instances if needed</li> <li>Returns a new <code>DataModule</code> with <code>mode=AsBatch</code></li> <li>Extra fields are <code>None</code> if all instances have None for that field</li> </ul> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def batch(self: \"DataModule[AsConverter]\", instances: Sequence[_T | _InstanceT]) -&gt; _BatchT:\n    \"\"\"Collate multiple instances into a batched representation.\n\n    Takes a sequence of raw data or instances and creates a `DataModule` in\n    `AsBatch` mode. Each transform field's `batch()` method is called to collate\n    the corresponding field values.\n\n    Args:\n        instances: Sequence of raw data or `DataModule` instances.\n\n    Returns:\n        A `DataModule` in `AsBatch` mode with batched tensor fields.\n\n    Examples:\n        &gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n        &gt;&gt;&gt; instances = [dm.instance(ex) for ex in examples]\n        &gt;&gt;&gt; batch = dm.batch(instances)\n        &gt;&gt;&gt; print(batch.text.surfaces.ids.shape)  # (batch_size, seq_length)\n        &gt;&gt;&gt; print(batch.label.shape)  # (batch_size,)\n        &gt;&gt;&gt; print(len(batch))  # batch_size\n\n    Note:\n        - Can only be called in `AsConverter` mode\n        - Automatically converts raw data to instances if needed\n        - Returns a new `DataModule` with `mode=AsBatch`\n        - Extra fields are `None` if all instances have None for that field\n\n    \"\"\"\n    assert self.__mode__ in (None, DataModuleMode.AS_CONVERTER), (\n        \"DataModule must be in converter mode to create a batch\"\n    )\n\n    instances = [item if isinstance(item, DataModule) else self.instance(item) for item in instances]\n    fields = {}\n    for name, transform in self.__field_transforms__.items():\n        can_be_optional = name in self.__class__.__get_extra_fields__()\n        values = [getattr(instance, name) for instance in instances]\n        if can_be_optional and all(value is None for value in values):\n            fields[name] = None\n        else:\n            fields[name] = transform.batch(values)\n    for name in self.__class__.__get_param_fields__().keys():\n        if name not in fields:\n            fields[name] = _UNAVAILABLE\n\n    batch = cast(_BatchT, dataclasses.replace(self, **fields))\n    setattr(batch, \"__mode__\", DataModuleMode.AS_BATCH)\n\n    batch._batch_size = len(instances)\n    return batch\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.DataModule.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.DataModule.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.base.register_dataclass","title":"register_dataclass","text":"<pre><code>register_dataclass(cls)\n</code></pre> <p>Register a dataclass with JAX pytree if JAX is available.</p> <p>This function automatically registers dataclasses as JAX pytrees, enabling them to be used with JAX transformations like jax.jit, jax.vmap, and jax.grad. It distinguishes between data fields, metadata fields, and fields to drop based on field metadata and the Param/Extra field markers.</p> PARAMETER DESCRIPTION <code>cls</code> <p>A dataclass type to register.</p> <p> TYPE: <code>_TypeT</code> </p> RETURNS DESCRIPTION <code>_TypeT</code> <p>The same class, now registered as a JAX pytree (if JAX is installed).</p> Note <ul> <li>If JAX is not installed, this function does nothing.</li> <li>Fields marked with JAX_STATIC_FIELD metadata become meta_fields.</li> <li>Fields with init=False and not marked as Param are dropped.</li> <li>Registration is idempotent; registering twice has no effect.</li> <li>If the class is a DataModule, recursively registers nested dataclasses.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @dataclasses.dataclass\n... class MyData:\n...     values: list[float]\n...     metadata: str = dataclasses.field(metadata={JAX_STATIC_FIELD: True})\n&gt;&gt;&gt; register_dataclass(MyData)\n&gt;&gt;&gt; # Now MyData can be used with JAX transformations\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def register_dataclass(cls: _TypeT) -&gt; _TypeT:\n    \"\"\"Register a dataclass with JAX pytree if JAX is available.\n\n    This function automatically registers dataclasses as JAX pytrees, enabling\n    them to be used with JAX transformations like jax.jit, jax.vmap, and jax.grad.\n    It distinguishes between data fields, metadata fields, and fields to drop based\n    on field metadata and the Param/Extra field markers.\n\n    Args:\n        cls: A dataclass type to register.\n\n    Returns:\n        The same class, now registered as a JAX pytree (if JAX is installed).\n\n    Note:\n        - If JAX is not installed, this function does nothing.\n        - Fields marked with JAX_STATIC_FIELD metadata become meta_fields.\n        - Fields with init=False and not marked as Param are dropped.\n        - Registration is idempotent; registering twice has no effect.\n        - If the class is a DataModule, recursively registers nested dataclasses.\n\n    Examples:\n        &gt;&gt;&gt; @dataclasses.dataclass\n        ... class MyData:\n        ...     values: list[float]\n        ...     metadata: str = dataclasses.field(metadata={JAX_STATIC_FIELD: True})\n        &gt;&gt;&gt; register_dataclass(MyData)\n        &gt;&gt;&gt; # Now MyData can be used with JAX transformations\n\n    \"\"\"\n    if cls in _DATACLASS_REGISTRY:\n        return cls\n\n    _DATACLASS_REGISTRY.add(cls)\n\n    with suppress(ImportError):\n        import jax\n\n        def _is_static_field(field: dataclasses.Field) -&gt; bool:\n            if field.metadata.get(JAX_STATIC_FIELD, False):\n                return True\n            field_class = _find_dataclass_field(field.type)\n            if field_class is not None:\n                return getattr(field_class, \"__is_static__\", False)\n            return False\n\n        if getattr(cls, \"__is_datamodule__\", False):\n            for field in dataclasses.fields(cls):\n                field_class = _find_dataclass_field(field.type)\n                if field_class is not None:\n                    register_dataclass(field_class)\n\n        drop_fields = [f.name for f in dataclasses.fields(cls) if not f.init and not _is_param_field(f.type)]\n        data_fields = [f.name for f in dataclasses.fields(cls) if not _is_static_field(f) and f.name not in drop_fields]\n        meta_fields = [f.name for f in dataclasses.fields(cls) if _is_static_field(f) and f.name not in drop_fields]\n\n        try:\n            jax.tree_util.register_dataclass(\n                cls,\n                data_fields=data_fields,\n                meta_fields=meta_fields,\n                drop_fields=drop_fields,\n            )\n        except ValueError as error:\n            if str(error.args[0]).startswith(\"Duplicate custom dataclass\"):\n                pass\n            else:\n                raise\n\n    return cls\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic","title":"formed.integrations.ml.transforms.basic","text":"<p>Basic data transformations for common machine learning tasks.</p> <p>This module provides fundamental transform classes for handling common data types in machine learning pipelines, including labels, scalars, tensors, and metadata.</p> Available Transforms <ul> <li>MetadataTransform: Pass-through transform for metadata (e.g., IDs, names)</li> <li>LabelIndexer: Map labels to integer indices with vocabulary building</li> <li>ScalarTransform: Convert scalar values to numpy arrays</li> <li>TensorTransform: Convert numpy arrays to batched tensors</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.ml import LabelIndexer, ScalarTransform\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Label indexing with vocabulary building\n&gt;&gt;&gt; label_indexer = LabelIndexer()\n&gt;&gt;&gt; with label_indexer.train():\n...     idx1 = label_indexer.instance(\"positive\")  # Returns 0\n...     idx2 = label_indexer.instance(\"negative\")  # Returns 1\n&gt;&gt;&gt; batch = label_indexer.batch([0, 1, 0])  # np.array([0, 1, 0])\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Scalar to tensor\n&gt;&gt;&gt; scalar_transform = ScalarTransform()\n&gt;&gt;&gt; values = [1.5, 2.3, 4.1]\n&gt;&gt;&gt; batch = scalar_transform.batch(values)  # np.array([1.5, 2.3, 4.1])\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.MetadataTransform","title":"MetadataTransform","text":"<p>               Bases: <code>Generic[_S, _T]</code>, <code>BaseTransform[_S, _T, _T, Sequence[_T]]</code></p> <p>Pass-through transform for metadata fields.</p> <p>MetadataTransform does not modify data during instance transformation and simply collects values into a list during batching. This is useful for metadata like IDs, filenames, or other non-numerical information that should be preserved but not transformed into tensors.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> <code>_T</code> <p>Value type (same as instance and element of batch)</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; transform = MetadataTransform(accessor=\"id\")\n&gt;&gt;&gt; instance = transform({\"id\": \"example_001\"})  # Returns \"example_001\"\n&gt;&gt;&gt; batch = transform.batch([\"example_001\", \"example_002\", \"example_003\"])\n&gt;&gt;&gt; print(batch)  # [\"example_001\", \"example_002\", \"example_003\"]\n</code></pre> Note <p>This transform is stateless and does not require training.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.MetadataTransform.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.MetadataTransform.instance","title":"instance","text":"<pre><code>instance(value)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def instance(self, value: _T, /) -&gt; _T:\n    return value\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.MetadataTransform.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def batch(self, batch: Sequence[_T], /) -&gt; Sequence[_T]:\n    return list(batch)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.MetadataTransform.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.MetadataTransform.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.MetadataTransform.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer","title":"LabelIndexer","text":"<p>               Bases: <code>BaseTransform[_S, LabelT, int, ndarray]</code>, <code>Generic[_S, LabelT]</code></p> <p>Map labels to integer indices with vocabulary building and statistics tracking.</p> <p>LabelIndexer maintains a bidirectional mapping between labels and integer indices. In training mode, it dynamically builds the label vocabulary and tracks label frequencies. The vocabulary can be frozen to prevent changes during inference.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> <code>LabelT</code> <p>Label type (must be hashable)</p> <p> </p> ATTRIBUTE DESCRIPTION <code>label2id</code> <p>Pre-defined label-to-index mapping. If empty, built during training.</p> <p> TYPE: <code>Sequence[tuple[LabelT, int]]</code> </p> <code>freeze</code> <p>If True, prevent vocabulary updates even in training mode.</p> <p> TYPE: <code>bool</code> </p> Properties <p>num_labels: Total number of unique labels in vocabulary. labels: List of labels sorted by their indices. occurrences: Dictionary mapping labels to their occurrence counts. distribution: Smoothed probability distribution over labels.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Dynamic vocabulary building\n&gt;&gt;&gt; indexer = LabelIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     idx1 = indexer.instance(\"positive\")  # 0\n...     idx2 = indexer.instance(\"negative\")  # 1\n...     idx3 = indexer.instance(\"positive\")  # 0 (already in vocab)\n&gt;&gt;&gt; print(indexer.labels)  # [\"positive\", \"negative\"]\n&gt;&gt;&gt; print(indexer.occurrences)  # {\"positive\": 2, \"negative\": 1}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Pre-defined vocabulary\n&gt;&gt;&gt; indexer = LabelIndexer(label2id=[(\"positive\", 0), (\"negative\", 1)])\n&gt;&gt;&gt; idx = indexer.instance(\"positive\")  # 0\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Batching and reconstruction\n&gt;&gt;&gt; batch = indexer.batch([0, 1, 0])  # np.array([0, 1, 0])\n&gt;&gt;&gt; labels = indexer.reconstruct(batch)  # [\"positive\", \"negative\", \"positive\"]\n</code></pre> Note <ul> <li>Raises KeyError if a label is not in vocabulary during inference</li> <li>Use freeze=True to prevent accidental vocabulary updates</li> <li>Distribution uses Laplace smoothing (add-one)</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.label2id","title":"label2id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>label2id = field(default_factory=list)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.freeze","title":"freeze  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>freeze = field(default=False)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.num_labels","title":"num_labels  <code>property</code>","text":"<pre><code>num_labels\n</code></pre> <p>Get the total number of unique labels in the vocabulary.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.labels","title":"labels  <code>property</code>","text":"<pre><code>labels\n</code></pre> <p>Get the list of labels sorted by their indices.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.occurrences","title":"occurrences  <code>property</code>","text":"<pre><code>occurrences\n</code></pre> <p>Get the occurrence counts for each label seen during training.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.distribution","title":"distribution  <code>property</code>","text":"<pre><code>distribution\n</code></pre> <p>Get the smoothed probability distribution over labels.</p> <p>Uses Laplace (add-one) smoothing to handle zero counts.</p> RETURNS DESCRIPTION <code>ndarray</code> <p>Array of probabilities summing to 1.0, one per label.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.get_index","title":"get_index","text":"<pre><code>get_index(value)\n</code></pre> <p>Get the integer index for a label.</p> PARAMETER DESCRIPTION <code>value</code> <p>The label to look up.</p> <p> TYPE: <code>LabelT</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The integer index associated with the label.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If the label is not in the vocabulary.</p> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def get_index(self, value: LabelT, /) -&gt; int:\n    \"\"\"Get the integer index for a label.\n\n    Args:\n        value: The label to look up.\n\n    Returns:\n        The integer index associated with the label.\n\n    Raises:\n        KeyError: If the label is not in the vocabulary.\n\n    \"\"\"\n    with suppress(StopIteration):\n        return next(label_id for label, label_id in self.label2id if label == value)\n    raise KeyError(value)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.get_value","title":"get_value","text":"<pre><code>get_value(index)\n</code></pre> <p>Get the label for an integer index.</p> PARAMETER DESCRIPTION <code>index</code> <p>The integer index to look up.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>LabelT</code> <p>The label associated with the index.</p> RAISES DESCRIPTION <code>KeyError</code> <p>If the index is not in the vocabulary.</p> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def get_value(self, index: int, /) -&gt; LabelT:\n    \"\"\"Get the label for an integer index.\n\n    Args:\n        index: The integer index to look up.\n\n    Returns:\n        The label associated with the index.\n\n    Raises:\n        KeyError: If the index is not in the vocabulary.\n\n    \"\"\"\n    for label, label_id in self.label2id:\n        if label_id == index:\n            return label\n    raise KeyError(index)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.ingest","title":"ingest","text":"<pre><code>ingest(value)\n</code></pre> <p>Add a label to the vocabulary and update statistics.</p> <p>This method is called internally during training to build the vocabulary and track label frequencies.</p> PARAMETER DESCRIPTION <code>value</code> <p>The label to ingest.</p> <p> TYPE: <code>LabelT</code> </p> Note <p>Only effective when in training mode and freeze=False. Logs a warning if called outside training mode.</p> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def ingest(self, value: LabelT, /) -&gt; None:\n    \"\"\"Add a label to the vocabulary and update statistics.\n\n    This method is called internally during training to build the vocabulary\n    and track label frequencies.\n\n    Args:\n        value: The label to ingest.\n\n    Note:\n        Only effective when in training mode and freeze=False.\n        Logs a warning if called outside training mode.\n\n    \"\"\"\n    if self.freeze:\n        return\n    if self._training:\n        try:\n            self.get_index(value)\n        except KeyError:\n            self.label2id = list(self.label2id) + [(value, len(self.label2id))]\n            self._label_counts.append((value, 0))\n        for index, (label, count) in enumerate(self._label_counts):\n            if label == value:\n                self._label_counts[index] = (label, count + 1)\n                break\n    else:\n        logger.warning(\"Ignoring ingest call when not in training mode\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.instance","title":"instance","text":"<pre><code>instance(label)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def instance(self, label: LabelT, /) -&gt; int:\n    if self._training:\n        self.ingest(label)\n    return self.get_index(label)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def batch(self, batch: Sequence[int], /) -&gt; numpy.ndarray:\n    return numpy.array(batch, dtype=numpy.int64)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(batch)\n</code></pre> <p>Convert a batch of indices back to labels.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Array of integer indices.</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>list[LabelT]</code> <p>List of labels corresponding to the indices.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = LabelIndexer(label2id=[(\"cat\", 0), (\"dog\", 1)])\n&gt;&gt;&gt; indices = numpy.array([0, 1, 0])\n&gt;&gt;&gt; labels = indexer.reconstruct(indices)\n&gt;&gt;&gt; print(labels)  # [\"cat\", \"dog\", \"cat\"]\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def reconstruct(self, batch: numpy.ndarray, /) -&gt; list[LabelT]:\n    \"\"\"Convert a batch of indices back to labels.\n\n    Args:\n        batch: Array of integer indices.\n\n    Returns:\n        List of labels corresponding to the indices.\n\n    Examples:\n        &gt;&gt;&gt; indexer = LabelIndexer(label2id=[(\"cat\", 0), (\"dog\", 1)])\n        &gt;&gt;&gt; indices = numpy.array([0, 1, 0])\n        &gt;&gt;&gt; labels = indexer.reconstruct(indices)\n        &gt;&gt;&gt; print(labels)  # [\"cat\", \"dog\", \"cat\"]\n\n    \"\"\"\n    return [self.get_value(index) for index in batch.tolist()]\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.LabelIndexer.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.ScalarTransform","title":"ScalarTransform","text":"<p>               Bases: <code>Generic[_S]</code>, <code>BaseTransform[_S, float, float, ndarray]</code></p> <p>Transform scalar values into batched numpy arrays.</p> <p>ScalarTransform is a simple pass-through transform that preserves scalar values during instance transformation and stacks them into a 1D numpy array during batching.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; transform = ScalarTransform(accessor=\"score\")\n&gt;&gt;&gt; value = transform({\"score\": 0.85})  # Returns 0.85\n&gt;&gt;&gt; batch = transform.batch([0.85, 0.92, 0.78])\n&gt;&gt;&gt; print(batch)  # np.array([0.85, 0.92, 0.78], dtype=float32)\n&gt;&gt;&gt; print(batch.shape)  # (3,)\n</code></pre> Note <ul> <li>Instance values remain as Python floats</li> <li>Batch values are converted to float32 numpy arrays</li> <li>Stateless transform, no training required</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.ScalarTransform.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.ScalarTransform.instance","title":"instance","text":"<pre><code>instance(value)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def instance(self, value: float, /) -&gt; float:\n    return value\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.ScalarTransform.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def batch(self, batch: Sequence[float], /) -&gt; numpy.ndarray:\n    return numpy.array(batch, dtype=numpy.float32)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.ScalarTransform.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.ScalarTransform.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.ScalarTransform.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorTransform","title":"TensorTransform","text":"<p>               Bases: <code>Generic[_S]</code>, <code>BaseTransform[_S, ndarray, ndarray, ndarray]</code></p> <p>Transform numpy arrays into batched tensors.</p> <p>TensorTransform preserves numpy arrays during instance transformation and stacks them along the batch dimension (axis 0) during batching. All arrays in a batch must have the same shape.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; transform = TensorTransform(accessor=\"features\")\n&gt;&gt;&gt; arr = transform({\"features\": np.array([1.0, 2.0, 3.0])})\n&gt;&gt;&gt; print(arr)  # np.array([1.0, 2.0, 3.0])\n&gt;&gt;&gt;\n&gt;&gt;&gt; batch = transform.batch([\n...     np.array([1.0, 2.0, 3.0]),\n...     np.array([4.0, 5.0, 6.0]),\n... ])\n&gt;&gt;&gt; print(batch.shape)  # (2, 3)\n</code></pre> Note <ul> <li>Requires all arrays in a batch to have compatible shapes</li> <li>Stacks along axis 0 (batch dimension)</li> <li>Stateless transform, no training required</li> </ul> RAISES DESCRIPTION <code>ValueError</code> <p>If arrays have incompatible shapes for stacking.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorTransform.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorTransform.instance","title":"instance","text":"<pre><code>instance(value)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def instance(self, value: numpy.ndarray, /) -&gt; numpy.ndarray:\n    return value\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorTransform.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def batch(self, batch: Sequence[numpy.ndarray], /) -&gt; numpy.ndarray:\n    return numpy.stack(batch, axis=0)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorTransform.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorTransform.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorTransform.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.VariableTensorTransform","title":"VariableTensorTransform","text":"<p>               Bases: <code>Generic[_S]</code>, <code>BaseTransform[_S, ndarray, ndarray, VariableTensorBatch[ndarray]]</code></p> <p>Transform variable-size numpy arrays into padded batched tensors.</p> <p>VariableTensorTransform preserves numpy arrays during instance transformation and pads them to the maximum shape in the batch during batching. It returns a TensorBatch containing the padded tensor and a mask indicating valid data.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; transform = VariableTensorTransform(accessor=\"sequences\")\n&gt;&gt;&gt; arr = transform({\"sequences\": np.array([1, 2, 3])})\n&gt;&gt;&gt; print(arr)  # np.array([1, 2, 3])\n&gt;&gt;&gt;\n&gt;&gt;&gt; batch = transform.batch([\n...     np.array([1, 2, 3]),\n...     np.array([4, 5]),\n...     np.array([6, 7, 8, 9]),\n... ])\n&gt;&gt;&gt; print(batch.tensor)\n&gt;&gt;&gt; # np.array([\n&gt;&gt;&gt; #   [1, 2, 3, 0],\n&gt;&gt;&gt; #   [4, 5, 0, 0],\n&gt;&gt;&gt; #   [6, 7, 8, 9]\n&gt;&gt;&gt; # ])\n&gt;&gt;&gt; print(batch.mask)\n&gt;&gt;&gt; # np.array([\n&gt;&gt;&gt; #   [True, True, True, False],\n&gt;&gt;&gt; #   [True, True, False, False],\n&gt;&gt;&gt; #   [True, True, True, True]\n&gt;&gt;&gt; # ])\n</code></pre> Note <ul> <li>Pads arrays with zeros to match the maximum shape in the batch</li> <li>Mask indicates which elements are valid (True) vs. padded (False)</li> <li>Stateless transform, no training required</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.VariableTensorTransform.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.VariableTensorTransform.instance","title":"instance","text":"<pre><code>instance(value)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def instance(self, value: numpy.ndarray, /) -&gt; numpy.ndarray:\n    return value\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.VariableTensorTransform.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def batch(self, batch: Sequence[numpy.ndarray], /) -&gt; VariableTensorBatch[numpy.ndarray]:\n    if len(batch) == 0:\n        return VariableTensorBatch(\n            tensor=numpy.array([], dtype=numpy.float32),\n            mask=numpy.array([], dtype=numpy.bool_),\n        )\n    max_ndim = max(arr.ndim for arr in batch)\n    max_shape = []\n    for dim in range(max_ndim):\n        dim_sizes = [arr.shape[dim] if dim &lt; arr.ndim else 1 for arr in batch]\n        max_shape.append(max(dim_sizes))\n\n    tensor = numpy.zeros((len(batch), *max_shape), dtype=batch[0].dtype)\n    mask = numpy.zeros((len(batch), *max_shape), dtype=numpy.bool_)\n\n    for i, arr in enumerate(batch):\n        slices = tuple(slice(0, dim_size) for dim_size in arr.shape)\n        tensor[i][slices] = arr\n        mask[i][slices] = True\n\n    return VariableTensorBatch[numpy.ndarray](tensor=tensor, mask=mask)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.VariableTensorTransform.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.VariableTensorTransform.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.VariableTensorTransform.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorSequenceTransform","title":"TensorSequenceTransform","text":"<p>               Bases: <code>Generic[_S]</code>, <code>BaseTransform[_S, Sequence[ndarray], ndarray, VariableTensorBatch[ndarray]]</code></p> <p>Transform sequences of numpy arrays into padded batched tensors.</p> <p>TensorSequenceTransform handles sequences of arrays (e.g., token-level embeddings) by stacking them into a 2D array during instance transformation, then padding across the batch dimension during batching.</p> <p>This is useful for token-level features where each token has its own vector, and different instances may have different numbers of tokens.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; transform = TensorSequenceTransform(accessor=\"token_vectors\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Each instance has a sequence of token vectors\n&gt;&gt;&gt; data1 = {\"token_vectors\": [np.array([1.0, 2.0]), np.array([3.0, 4.0])]}\n&gt;&gt;&gt; data2 = {\"token_vectors\": [np.array([5.0, 6.0])]}\n&gt;&gt;&gt;\n&gt;&gt;&gt; instance1 = transform(data1)  # Shape: (2, 2) - 2 tokens, 2 dims\n&gt;&gt;&gt; instance2 = transform(data2)  # Shape: (1, 2) - 1 token, 2 dims\n&gt;&gt;&gt;\n&gt;&gt;&gt; batch = transform.batch([instance1, instance2])\n&gt;&gt;&gt; print(batch.tensor.shape)  # (2, 2, 2) - batch_size, max_tokens, dims\n&gt;&gt;&gt; print(batch.mask.shape)    # (2, 2, 2)\n&gt;&gt;&gt; print(batch.mask[0])  # [[True, True], [True, True]]\n&gt;&gt;&gt; print(batch.mask[1])  # [[True, True], [False, False]]\n</code></pre> Note <ul> <li>Converts sequence of arrays to 2D array during instance transformation</li> <li>Pads to max token count during batching</li> <li>Mask indicates valid tokens vs. padding</li> <li>Empty sequences result in empty arrays</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorSequenceTransform.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorSequenceTransform.instance","title":"instance","text":"<pre><code>instance(value)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def instance(self, value: Sequence[numpy.ndarray], /) -&gt; numpy.ndarray:\n    if len(value) == 0:\n        return numpy.array([], dtype=numpy.float32)\n    # Stack sequence of arrays into 2D array (num_tokens, embedding_dim)\n    return numpy.stack([numpy.asarray(arr) for arr in value], axis=0)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorSequenceTransform.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/basic.py</code> <pre><code>def batch(self, batch: Sequence[numpy.ndarray], /) -&gt; VariableTensorBatch[numpy.ndarray]:\n    if len(batch) == 0:\n        return VariableTensorBatch(\n            tensor=numpy.array([], dtype=numpy.float32),\n            mask=numpy.array([], dtype=numpy.bool_),\n        )\n    max_ndim = max(arr.ndim for arr in batch)\n    max_shape = []\n    for dim in range(max_ndim):\n        dim_sizes = [arr.shape[dim] if dim &lt; arr.ndim else 1 for arr in batch]\n        max_shape.append(max(dim_sizes))\n\n    tensor = numpy.zeros((len(batch), *max_shape), dtype=batch[0].dtype)\n    mask = numpy.zeros((len(batch), *max_shape), dtype=numpy.bool_)\n\n    for i, arr in enumerate(batch):\n        slices = tuple(slice(0, dim_size) for dim_size in arr.shape)\n        tensor[i][slices] = arr\n        mask[i][slices] = True\n\n    return VariableTensorBatch[numpy.ndarray](tensor=tensor, mask=mask)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorSequenceTransform.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorSequenceTransform.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.basic.TensorSequenceTransform.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp","title":"formed.integrations.ml.transforms.nlp","text":"<p>NLP-specific data transformations for text processing.</p> <p>This module provides transformations for natural language processing tasks, including tokenization, vocabulary building, and sequence indexing with special tokens (PAD, UNK, BOS, EOS).</p> Available Transforms <ul> <li><code>TokenSequenceIndexer</code>: Convert token sequences to integer indices with vocab building</li> <li><code>TokenCharactersIndexer</code>: Character-level indexing for tokens</li> <li><code>Tokenizer</code>: Complete tokenization pipeline with surfaces, postags, and characters</li> </ul> Features <ul> <li>Dynamic vocabulary building with <code>min_df</code>/<code>max_df</code> filtering</li> <li>Document frequency tracking</li> <li>Special token handling (PAD, UNK, BOS, EOS)</li> <li>Automatic padding and masking</li> <li>Reconstruction support (indices -&gt; tokens)</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.ml import Tokenizer, TokenSequenceIndexer\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Simple tokenization\n&gt;&gt;&gt; tokenizer = Tokenizer(surfaces=TokenSequenceIndexer(\n...     unk_token=\"&lt;UNK&gt;\", pad_token=\"&lt;PAD&gt;\"\n... ))\n&gt;&gt;&gt;\n&gt;&gt;&gt; with tokenizer.train():\n...     instance = tokenizer.instance(\"Hello world!\")\n&gt;&gt;&gt; batch = tokenizer.batch([instance1, instance2, instance3])\n&gt;&gt;&gt; print(batch.surfaces.ids.shape)  # (3, max_length)\n&gt;&gt;&gt; print(batch.surfaces.mask.shape)  # (3, max_length)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Reconstruct tokens from indices\n&gt;&gt;&gt; tokens = tokenizer.surfaces.reconstruct(batch.surfaces)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer","title":"TokenSequenceIndexer","text":"<p>               Bases: <code>BaseTransform[_S, Sequence[str], Sequence[str], IDSequenceBatch]</code>, <code>Generic[_S]</code></p> <p>Convert token sequences to integer indices with vocabulary building and filtering.</p> <p>TokenSequenceIndexer builds and maintains a vocabulary, converting tokens to indices. It supports vocabulary filtering by document frequency (<code>min_df</code>/<code>max_df</code>), vocabulary size limits, and special tokens (PAD, UNK, BOS, EOS). During batching, sequences are padded to the same length and a mask is generated.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> ATTRIBUTE DESCRIPTION <code>vocab</code> <p>Pre-defined or built vocabulary mapping tokens to indices.</p> <p> TYPE: <code>Mapping[str, int]</code> </p> <code>pad_token</code> <p>Padding token (required).</p> <p> TYPE: <code>str</code> </p> <code>unk_token</code> <p>Unknown token for out-of-vocabulary tokens (optional).</p> <p> TYPE: <code>str | None</code> </p> <code>bos_token</code> <p>Beginning-of-sequence token (optional).</p> <p> TYPE: <code>str | None</code> </p> <code>eos_token</code> <p>End-of-sequence token (optional).</p> <p> TYPE: <code>str | None</code> </p> <code>min_df</code> <p>Minimum document frequency (int or fraction) to include token.</p> <p> TYPE: <code>int | float</code> </p> <code>max_df</code> <p>Maximum document frequency (int or fraction) to include token.</p> <p> TYPE: <code>int | float</code> </p> <code>max_vocab_size</code> <p>Maximum vocabulary size (excluding special tokens).</p> <p> TYPE: <code>int | None</code> </p> <code>freeze</code> <p>If True, prevent vocabulary updates.</p> <p> TYPE: <code>bool</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Build vocabulary with filtering\n&gt;&gt;&gt; indexer = TokenSequenceIndexer(\n...     unk_token=\"&lt;UNK&gt;\",\n...     min_df=2,  # Tokens must appear in at least 2 documents\n...     max_vocab_size=10000\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; with indexer.train():\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary: {\"&lt;PAD&gt;\": 0, \"&lt;UNK&gt;\": 1, \"hello\": 2, \"world\": 3, \"there\": 4}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create batch with padding\n&gt;&gt;&gt; batch = indexer.batch([\n...     [\"hello\", \"world\"],\n...     [\"hello\", \"there\", \"friend\"]\n... ])\n&gt;&gt;&gt; print(batch.ids.shape)  # (2, 3) - padded to max length\n&gt;&gt;&gt; print(batch.mask.shape)  # (2, 3) - True for real tokens\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Reconstruct original tokens\n&gt;&gt;&gt; tokens = indexer.reconstruct(batch)\n&gt;&gt;&gt; print(tokens)  # [[\"hello\", \"world\"], [\"hello\", \"there\", \"friend\"]]\n</code></pre> Note <ul> <li>Special tokens are always added first and never filtered</li> <li><code>min_df</code>/<code>max_df</code> require <code>unk_token</code> to handle filtered tokens</li> <li>Document frequency counts unique tokens per document</li> <li>BOS/EOS tokens are added during batching if specified</li> <li>Reconstruction removes special tokens and padding</li> </ul> RAISES DESCRIPTION <code>ValueError</code> <p>If configuration is invalid (e.g., min_df&gt;1 without unk_token).</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.vocab","title":"vocab  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>vocab = field(default_factory=dict)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.pad_token","title":"pad_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pad_token = '&lt;PAD&gt;'\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.unk_token","title":"unk_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>unk_token = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.bos_token","title":"bos_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bos_token = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.eos_token","title":"eos_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>eos_token = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.min_df","title":"min_df  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>min_df = 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.max_df","title":"max_df  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_df = 1.0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.max_vocab_size","title":"max_vocab_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_vocab_size = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.freeze","title":"freeze  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>freeze = False\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.pad_index","title":"pad_index  <code>property</code>","text":"<pre><code>pad_index\n</code></pre> <p>Index of the padding token.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.unk_index","title":"unk_index  <code>property</code>","text":"<pre><code>unk_index\n</code></pre> <p>Index of the unknown token, or <code>None</code> if not set.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.bos_index","title":"bos_index  <code>property</code>","text":"<pre><code>bos_index\n</code></pre> <p>Index of the beginning-of-sequence token, or <code>None</code> if not set.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.eos_index","title":"eos_index  <code>property</code>","text":"<pre><code>eos_index\n</code></pre> <p>Index of the end-of-sequence token, or <code>None</code> if not set.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.vocab_size","title":"vocab_size  <code>property</code>","text":"<pre><code>vocab_size\n</code></pre> <p>Total number of tokens in the vocabulary.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.get_index","title":"get_index","text":"<pre><code>get_index(value)\n</code></pre> <p>Get the index of a token, using unk_token if not found.</p> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def get_index(self, value: str, /) -&gt; int:\n    \"\"\"Get the index of a token, using unk_token if not found.\"\"\"\n    if value in self.vocab:\n        return self.vocab[value]\n    if self.unk_token is not None:\n        return self.vocab[self.unk_token]\n    raise KeyError(value)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.get_value","title":"get_value","text":"<pre><code>get_value(index)\n</code></pre> <p>Get the token corresponding to an index.</p> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def get_value(self, index: int, /) -&gt; str:\n    \"\"\"Get the token corresponding to an index.\"\"\"\n    if index in self._inverted_vocab:\n        return self._inverted_vocab[index]\n    raise KeyError(index)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.ingest","title":"ingest","text":"<pre><code>ingest(values)\n</code></pre> <p>Ingest a sequence of tokens to update counts for vocabulary building.</p> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def ingest(self, values: Sequence[str], /) -&gt; None:\n    \"\"\"Ingest a sequence of tokens to update counts for vocabulary building.\"\"\"\n    if self.freeze:\n        return\n    if self._training:\n        for token in values:\n            self._token_counts[token] = self._token_counts.get(token, 0) + 1\n        self._document_count += 1\n        for toke in set(values):\n            self._document_frequencies[toke] = self._document_frequencies.get(toke, 0) + 1\n    else:\n        logger.warning(\"Ignoring ingest call when not in training mode\")\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.instance","title":"instance","text":"<pre><code>instance(tokens)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def instance(self, tokens: Sequence[str], /) -&gt; Sequence[str]:\n    if self._training:\n        self.ingest(tokens)\n    return tokens\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def batch(self, batch: Sequence[Sequence[str]], /) -&gt; IDSequenceBatch:\n    batch_size = len(batch)\n    max_length = max(len(tokens) for tokens in batch)\n    if self.bos_token is not None:\n        max_length += 1\n    if self.eos_token is not None:\n        max_length += 1\n    ids = numpy.full((batch_size, max_length), self.pad_index, dtype=numpy.int64)\n    mask = numpy.zeros((batch_size, max_length), dtype=numpy.bool_)\n    for i, tokens in enumerate(batch):\n        indices = [self.get_index(token) for token in tokens]\n        if self.bos_token is not None:\n            indices = [self.vocab[self.bos_token]] + indices\n        if self.eos_token is not None:\n            indices = indices + [self.vocab[self.eos_token]]\n        length = len(indices)\n        ids[i, :length] = indices\n        mask[i, :length] = 1\n    return IDSequenceBatch(ids=ids, mask=mask)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(batch)\n</code></pre> <p>Reconstruct token sequences from a batch of indices.</p> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def reconstruct(self, batch: IDSequenceBatch, /) -&gt; list[Sequence[str]]:\n    \"\"\"Reconstruct token sequences from a batch of indices.\"\"\"\n    sequences = []\n    for i in range(batch.ids.shape[0]):\n        length = int(batch.mask[i].sum())\n        indices = batch.ids[i, :length].tolist()\n        tokens = [self.get_value(index) for index in indices]\n        if tokens and tokens[0] == self.bos_token:\n            tokens = tokens[1:]\n        if tokens and tokens[-1] == self.eos_token:\n            tokens = tokens[:-1]\n        tokens = [token for token in tokens if token != self.pad_token]\n        sequences.append(tokens)\n    return sequences\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenSequenceIndexer.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer","title":"TokenCharactersIndexer","text":"<p>               Bases: <code>TokenSequenceIndexer[_S]</code>, <code>Generic[_S]</code></p> <p>Character-level indexing for token sequences.</p> <p>TokenCharactersIndexer extends TokenSequenceIndexer to index individual characters within tokens. This is useful for character-level models or handling rare words. The batch output is a 3D tensor: (batch_size, num_tokens, max_characters).</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_S</code> <p>Source data type before accessor</p> <p> </p> ATTRIBUTE DESCRIPTION <code>min_characters</code> <p>Minimum character length per token (for padding).</p> <p> TYPE: <code>int</code> </p> Note <p>Inherits all attributes from TokenSequenceIndexer.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenCharactersIndexer(\n...     unk_token=\"&lt;UNK&gt;\",\n...     bos_token=\"&lt;BOS&gt;\",\n...     eos_token=\"&lt;EOS&gt;\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; with indexer.train():\n...     tokens = indexer.instance([\"hello\", \"world\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; batch = indexer.batch([[\"hello\", \"world\"], [\"hi\"]])\n&gt;&gt;&gt; print(batch.ids.shape)  # (2, 2, 7) - batch x tokens x chars\n&gt;&gt;&gt; print(batch.mask.shape)  # (2, 2, 7)\n</code></pre> Note <ul> <li>Each token is converted to a sequence of character indices</li> <li>BOS/EOS are added per token, not per sequence</li> <li>Vocabulary contains individual characters, not tokens</li> <li>Useful for morphologically rich languages or rare word handling</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.min_characters","title":"min_characters  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>min_characters = 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.vocab","title":"vocab  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>vocab = field(default_factory=dict)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.pad_token","title":"pad_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pad_token = '&lt;PAD&gt;'\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.unk_token","title":"unk_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>unk_token = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.bos_token","title":"bos_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bos_token = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.eos_token","title":"eos_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>eos_token = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.min_df","title":"min_df  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>min_df = 1\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.max_df","title":"max_df  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_df = 1.0\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.max_vocab_size","title":"max_vocab_size  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_vocab_size = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.freeze","title":"freeze  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>freeze = False\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.pad_index","title":"pad_index  <code>property</code>","text":"<pre><code>pad_index\n</code></pre> <p>Index of the padding token.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.unk_index","title":"unk_index  <code>property</code>","text":"<pre><code>unk_index\n</code></pre> <p>Index of the unknown token, or <code>None</code> if not set.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.bos_index","title":"bos_index  <code>property</code>","text":"<pre><code>bos_index\n</code></pre> <p>Index of the beginning-of-sequence token, or <code>None</code> if not set.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.eos_index","title":"eos_index  <code>property</code>","text":"<pre><code>eos_index\n</code></pre> <p>Index of the end-of-sequence token, or <code>None</code> if not set.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.vocab_size","title":"vocab_size  <code>property</code>","text":"<pre><code>vocab_size\n</code></pre> <p>Total number of tokens in the vocabulary.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.ingest","title":"ingest","text":"<pre><code>ingest(values)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def ingest(self, values: Sequence[str], /) -&gt; None:\n    super().ingest(\"\".join(values))\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.batch","title":"batch","text":"<pre><code>batch(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def batch(self, batch: Sequence[Sequence[str]], /) -&gt; IDSequenceBatch:\n    batch_size = len(batch)\n    max_tokens = max(len(tokens) for tokens in batch)\n    max_characters = max(self.min_characters, max(len(token) for tokens in batch for token in tokens))\n    ids = numpy.full((batch_size, max_tokens, max_characters), self.pad_index, dtype=numpy.int64)\n    mask = numpy.zeros((batch_size, max_tokens, max_characters), dtype=numpy.bool_)\n    for i, tokens in enumerate(batch):\n        for j, token in enumerate(tokens):\n            indices = [self.get_index(char) for char in token]\n            if self.bos_token is not None:\n                indices = [self.vocab[self.bos_token]] + indices\n            if self.eos_token is not None:\n                indices = indices + [self.vocab[self.eos_token]]\n            length = len(indices)\n            ids[i, j, :length] = indices\n            mask[i, j, :length] = 1\n    return IDSequenceBatch(ids=ids, mask=mask)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(batch)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def reconstruct(self, batch: IDSequenceBatch, /) -&gt; list[Sequence[str]]:\n    sequences = []\n    for i in range(batch.ids.shape[0]):\n        token_indices = batch.ids[i]\n        token_mask = batch.mask[i]\n        tokens = []\n        for j in range(token_indices.shape[0]):\n            if not token_mask[j].any():\n                break\n            length = int(token_mask[j].sum())\n            char_indices = token_indices[j, :length].tolist()\n            chars = [self.get_value(index) for index in char_indices]\n            tokens.append(\"\".join(chars))\n        if tokens and tokens[0] == self.bos_token:\n            tokens = tokens[1:]\n        if tokens and tokens[-1] == self.eos_token:\n            tokens = tokens[:-1]\n        tokens = [token for token in tokens if token != self.pad_token]\n        sequences.append(tokens)\n    return sequences\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.instance","title":"instance","text":"<pre><code>instance(tokens)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def instance(self, tokens: Sequence[str], /) -&gt; Sequence[str]:\n    if self._training:\n        self.ingest(tokens)\n    return tokens\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for stateful transformations.</p> <p>In training mode, transforms can build state (e.g., vocabularies, statistics) from the training data. Hooks <code>_on_start_training()</code> and <code>_on_end_training()</code> are called at the beginning and end of the training context.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; indexer = TokenSequenceIndexer()\n&gt;&gt;&gt; with indexer.train():\n...     # Build vocabulary from training data\n...     tokens1 = indexer.instance([\"hello\", \"world\"])\n...     tokens2 = indexer.instance([\"hello\", \"there\"])\n&gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n&gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n</code></pre> Note <p>Training mode is reentrant but nested calls won't trigger hooks again.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for stateful transformations.\n\n    In training mode, transforms can build state (e.g., vocabularies, statistics)\n    from the training data. Hooks `_on_start_training()` and `_on_end_training()`\n    are called at the beginning and end of the training context.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; indexer = TokenSequenceIndexer()\n        &gt;&gt;&gt; with indexer.train():\n        ...     # Build vocabulary from training data\n        ...     tokens1 = indexer.instance([\"hello\", \"world\"])\n        ...     tokens2 = indexer.instance([\"hello\", \"there\"])\n        &gt;&gt;&gt; # Vocabulary is now frozen, use for inference\n        &gt;&gt;&gt; test_tokens = indexer.instance([\"hello\", \"unknown\"])\n\n    Note:\n        Training mode is reentrant but nested calls won't trigger hooks again.\n\n    \"\"\"\n    original = self._training\n    self._training = True\n    try:\n        if not original:\n            self._on_start_training()\n        yield\n        if not original:\n            self._on_end_training()\n    finally:\n        self._training = original\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.get_index","title":"get_index","text":"<pre><code>get_index(value)\n</code></pre> <p>Get the index of a token, using unk_token if not found.</p> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def get_index(self, value: str, /) -&gt; int:\n    \"\"\"Get the index of a token, using unk_token if not found.\"\"\"\n    if value in self.vocab:\n        return self.vocab[value]\n    if self.unk_token is not None:\n        return self.vocab[self.unk_token]\n    raise KeyError(value)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.TokenCharactersIndexer.get_value","title":"get_value","text":"<pre><code>get_value(index)\n</code></pre> <p>Get the token corresponding to an index.</p> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def get_value(self, index: int, /) -&gt; str:\n    \"\"\"Get the token corresponding to an index.\"\"\"\n    if index in self._inverted_vocab:\n        return self._inverted_vocab[index]\n    raise KeyError(index)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer","title":"Tokenizer","text":"<p>               Bases: <code>DataModule[DataModuleModeT, Union[str, Sequence[str], AnalyzedText], 'Tokenizer[AsInstance]', 'Tokenizer[AsBatch]']</code>, <code>Generic[DataModuleModeT]</code></p> <p>Complete tokenization pipeline with multiple representation options.</p> <p>Tokenizer is a DataModule that provides a unified interface for text tokenization with support for surface forms, part-of-speech tags, and character-level representations. It accepts raw text, pre-tokenized sequences, or analyzed text and converts them to indexed representations suitable for neural models.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>DataModuleModeT</code> <p>Current mode (AsConverter, AsInstance, or AsBatch)</p> <p> </p> ATTRIBUTE DESCRIPTION <code>surfaces</code> <p>Required token sequence indexer for surface forms (words).</p> <p> TYPE: <code>TokenSequenceIndexer</code> </p> <code>postags</code> <p>Optional indexer for part-of-speech tags.</p> <p> TYPE: <code>Extra[TokenSequenceIndexer]</code> </p> <code>characters</code> <p>Optional character-level indexer for tokens.</p> <p> TYPE: <code>Extra[TokenCharactersIndexer]</code> </p> <code>analyzer</code> <p>Optional custom text analyzer/tokenizer function.</p> <p> TYPE: <code>Param[Callable[[str | Sequence[str] | AnalyzedText], AnalyzedText] | None]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic tokenization\n&gt;&gt;&gt; tokenizer = Tokenizer(\n...     surfaces=TokenSequenceIndexer(unk_token=\"&lt;UNK&gt;\")\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; with tokenizer.train():\n...     instance1 = tokenizer.instance(\"Hello world!\")\n...     instance2 = tokenizer.instance([\"Hello\", \"world\", \"!\"])\n&gt;&gt;&gt;\n&gt;&gt;&gt; batch = tokenizer.batch([instance1, instance2])\n&gt;&gt;&gt; print(batch.surfaces.ids.shape)  # (2, max_tokens)\n&gt;&gt;&gt; print(batch.surfaces.mask.shape)  # (2, max_tokens)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With POS tags and characters\n&gt;&gt;&gt; tokenizer = Tokenizer(\n...     surfaces=TokenSequenceIndexer(unk_token=\"&lt;UNK&gt;\"),\n...     postags=TokenSequenceIndexer(unk_token=\"&lt;UNK-POS&gt;\"),\n...     characters=TokenCharactersIndexer()\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; analyzed = AnalyzedText(\n...     surfaces=[\"Hello\", \"world\"],\n...     postags=[\"INTJ\", \"NOUN\"]\n... )\n&gt;&gt;&gt; instance = tokenizer.instance(analyzed)\n&gt;&gt;&gt; print(instance.surfaces)  # Indexed tokens\n&gt;&gt;&gt; print(instance.postags)  # Indexed POS tags\n&gt;&gt;&gt; print(instance.characters)  # Character indices\n</code></pre> Note <ul> <li>Default analyzer uses punkt tokenization for raw strings</li> <li>Accepts string, token list, or AnalyzedText as input</li> <li>Extra fields (postags, characters) can be None</li> <li>All indexers share the same training context</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.surfaces","title":"surfaces  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>surfaces = field(default_factory=TokenSequenceIndexer)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.postags","title":"postags  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>postags = default(None)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.characters","title":"characters  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>characters = default(None)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.text_vector","title":"text_vector  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>text_vector = default(None)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.token_vectors","title":"token_vectors  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>token_vectors = default(None)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.analyzer","title":"analyzer  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>analyzer = default(None)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.accessor","title":"accessor  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>accessor = None\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.instance","title":"instance","text":"<pre><code>instance(x)\n</code></pre> Source code in <code>src/formed/integrations/ml/transforms/nlp.py</code> <pre><code>def instance(self: \"Tokenizer[AsConverter]\", x: str | Sequence[str] | AnalyzedText, /) -&gt; \"Tokenizer[AsInstance]\":\n    analyzer = self.analyzer or self._default_analyzer\n    return cast(DataModule[AsConverter], super()).instance(analyzer(x))\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.batch","title":"batch","text":"<pre><code>batch(instances)\n</code></pre> <p>Collate multiple instances into a batched representation.</p> <p>Takes a sequence of raw data or instances and creates a <code>DataModule</code> in <code>AsBatch</code> mode. Each transform field's <code>batch()</code> method is called to collate the corresponding field values.</p> PARAMETER DESCRIPTION <code>instances</code> <p>Sequence of raw data or <code>DataModule</code> instances.</p> <p> TYPE: <code>Sequence[_T | _InstanceT]</code> </p> RETURNS DESCRIPTION <code>_BatchT</code> <p>A <code>DataModule</code> in <code>AsBatch</code> mode with batched tensor fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n&gt;&gt;&gt; instances = [dm.instance(ex) for ex in examples]\n&gt;&gt;&gt; batch = dm.batch(instances)\n&gt;&gt;&gt; print(batch.text.surfaces.ids.shape)  # (batch_size, seq_length)\n&gt;&gt;&gt; print(batch.label.shape)  # (batch_size,)\n&gt;&gt;&gt; print(len(batch))  # batch_size\n</code></pre> Note <ul> <li>Can only be called in <code>AsConverter</code> mode</li> <li>Automatically converts raw data to instances if needed</li> <li>Returns a new <code>DataModule</code> with <code>mode=AsBatch</code></li> <li>Extra fields are <code>None</code> if all instances have None for that field</li> </ul> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def batch(self: \"DataModule[AsConverter]\", instances: Sequence[_T | _InstanceT]) -&gt; _BatchT:\n    \"\"\"Collate multiple instances into a batched representation.\n\n    Takes a sequence of raw data or instances and creates a `DataModule` in\n    `AsBatch` mode. Each transform field's `batch()` method is called to collate\n    the corresponding field values.\n\n    Args:\n        instances: Sequence of raw data or `DataModule` instances.\n\n    Returns:\n        A `DataModule` in `AsBatch` mode with batched tensor fields.\n\n    Examples:\n        &gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n        &gt;&gt;&gt; instances = [dm.instance(ex) for ex in examples]\n        &gt;&gt;&gt; batch = dm.batch(instances)\n        &gt;&gt;&gt; print(batch.text.surfaces.ids.shape)  # (batch_size, seq_length)\n        &gt;&gt;&gt; print(batch.label.shape)  # (batch_size,)\n        &gt;&gt;&gt; print(len(batch))  # batch_size\n\n    Note:\n        - Can only be called in `AsConverter` mode\n        - Automatically converts raw data to instances if needed\n        - Returns a new `DataModule` with `mode=AsBatch`\n        - Extra fields are `None` if all instances have None for that field\n\n    \"\"\"\n    assert self.__mode__ in (None, DataModuleMode.AS_CONVERTER), (\n        \"DataModule must be in converter mode to create a batch\"\n    )\n\n    instances = [item if isinstance(item, DataModule) else self.instance(item) for item in instances]\n    fields = {}\n    for name, transform in self.__field_transforms__.items():\n        can_be_optional = name in self.__class__.__get_extra_fields__()\n        values = [getattr(instance, name) for instance in instances]\n        if can_be_optional and all(value is None for value in values):\n            fields[name] = None\n        else:\n            fields[name] = transform.batch(values)\n    for name in self.__class__.__get_param_fields__().keys():\n        if name not in fields:\n            fields[name] = _UNAVAILABLE\n\n    batch = cast(_BatchT, dataclasses.replace(self, **fields))\n    setattr(batch, \"__mode__\", DataModuleMode.AS_BATCH)\n\n    batch._batch_size = len(instances)\n    return batch\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.train","title":"train","text":"<pre><code>train()\n</code></pre> <p>Context manager to enable training mode for all field transforms.</p> <p>This propagates training mode to all BaseTransform fields, allowing them to build state (e.g., vocabularies) from training data.</p> YIELDS DESCRIPTION <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n&gt;&gt;&gt; with dm.train():\n...     instances = [dm.instance(example) for example in train_data]\n&gt;&gt;&gt; # Vocabularies are now built and frozen\n</code></pre> Note <p>Can only be called in AsConverter mode.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@contextmanager\ndef train(self) -&gt; Iterator[None]:\n    \"\"\"Context manager to enable training mode for all field transforms.\n\n    This propagates training mode to all BaseTransform fields, allowing them\n    to build state (e.g., vocabularies) from training data.\n\n    Yields:\n        None\n\n    Examples:\n        &gt;&gt;&gt; dm = TextDataModule(text=Tokenizer(), label=LabelIndexer())\n        &gt;&gt;&gt; with dm.train():\n        ...     instances = [dm.instance(example) for example in train_data]\n        &gt;&gt;&gt; # Vocabularies are now built and frozen\n\n    Note:\n        Can only be called in AsConverter mode.\n\n    \"\"\"\n    assert self.__mode__ in (None, DataModuleMode.AS_CONVERTER), (\n        \"DataModule must be in converter mode to enter training mode\"\n    )\n    with ExitStack() as stack:\n        for transform in self.__field_transforms__.values():\n            stack.enter_context(transform.train())\n        yield\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.save","title":"save","text":"<pre><code>save(directory)\n</code></pre> <p>Save the transform to a directory using cloudpickle.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path to save the transform.</p> <p> TYPE: <code>str | PathLike</code> </p> Note <p>The transform is saved as 'transform.pkl' in the specified directory. cloudpickle is used to handle complex objects like lambdas and closures.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>def save(self, directory: str | PathLike) -&gt; None:\n    \"\"\"Save the transform to a directory using cloudpickle.\n\n    Args:\n        directory: Directory path to save the transform.\n\n    Note:\n        The transform is saved as 'transform.pkl' in the specified directory.\n        cloudpickle is used to handle complex objects like lambdas and closures.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"wb\") as f:\n        cloudpickle.dump(self, f)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.transforms.nlp.Tokenizer.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(directory)\n</code></pre> <p>Load a transform from a directory.</p> PARAMETER DESCRIPTION <code>directory</code> <p>Directory path containing the saved transform.</p> <p> TYPE: <code>str | PathLike</code> </p> RETURNS DESCRIPTION <code>Self</code> <p>The loaded transform instance.</p> RAISES DESCRIPTION <code>TypeError</code> <p>If the loaded object is not an instance of this class.</p> Note <p>Expects a 'transform.pkl' file in the specified directory.</p> Source code in <code>src/formed/integrations/ml/transforms/base.py</code> <pre><code>@classmethod\ndef load(cls, directory: str | PathLike) -&gt; Self:\n    \"\"\"Load a transform from a directory.\n\n    Args:\n        directory: Directory path containing the saved transform.\n\n    Returns:\n        The loaded transform instance.\n\n    Raises:\n        TypeError: If the loaded object is not an instance of this class.\n\n    Note:\n        Expects a 'transform.pkl' file in the specified directory.\n\n    \"\"\"\n    filepath = Path(directory) / \"transform.pkl\"\n    with filepath.open(\"rb\") as f:\n        obj = cloudpickle.load(f)\n    if not isinstance(obj, cls):\n        raise TypeError(f\"Loaded object is not an instance of {cls.__name__}\")\n    return obj\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow","title":"formed.integrations.ml.workflow","text":"<p>Workflow steps for machine learning data module integration.</p> <p>This module provides workflow steps for training data modules and generating instances for machine learning tasks.</p> Available Steps <ul> <li><code>ml::train_datamodule</code>: Train a data module on a dataset.</li> <li><code>ml::train_datamodule_with_instances</code>: Train a data module and collect generated instances.</li> <li><code>ml::generate_instances</code>: Generate instances from a dataset using a data module.</li> <li><code>ml::generate_instances_without_caching</code>: Generate instances without caching (same as <code>ml::generate_instances</code> but uncached).</li> </ul>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstances","title":"DataModuleAndInstances  <code>dataclass</code>","text":"<pre><code>DataModuleAndInstances(datamodule, instances)\n</code></pre> <p>               Bases: <code>Generic[_InputT, _InstanceT]</code></p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstances.datamodule","title":"datamodule  <code>instance-attribute</code>","text":"<pre><code>datamodule\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstances.instances","title":"instances  <code>instance-attribute</code>","text":"<pre><code>instances\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstancesFormat","title":"DataModuleAndInstancesFormat","text":"<p>               Bases: <code>Format[DataModuleAndInstances[_InputT, _InstanceT]]</code>, <code>Generic[_InputT, _InstanceT]</code></p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstancesFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstancesFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/integrations/ml/workflow.py</code> <pre><code>def write(\n    self,\n    artifact: DataModuleAndInstances[_InputT, _InstanceT],\n    directory: Path,\n) -&gt; None:\n    instances_path = directory / \"instances\"\n    datamodule_path = directory / \"datamodule\"\n\n    instances_path.mkdir(parents=True, exist_ok=True)\n    datamodule_path.mkdir(parents=True, exist_ok=True)\n\n    self._INSTANCES_FORMAT.write(artifact.instances, instances_path)\n    self._DATAMODULE_FORMAT.write(artifact.datamodule, datamodule_path)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstancesFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/integrations/ml/workflow.py</code> <pre><code>def read(self, directory: Path) -&gt; DataModuleAndInstances[_InputT, _InstanceT]:\n    instances_path = directory / \"instances\"\n    datamodule_path = directory / \"datamodule\"\n\n    instances = self._INSTANCES_FORMAT.read(instances_path)\n    datamodule = self._DATAMODULE_FORMAT.read(datamodule_path)\n\n    return DataModuleAndInstances(datamodule=datamodule, instances=instances)\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.DataModuleAndInstancesFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.train_datamodule","title":"train_datamodule","text":"<pre><code>train_datamodule(datamodule, dataset)\n</code></pre> <p>Train a data module on a dataset.</p> <p>This step trains a DataModule on the provided dataset, allowing it to learn transformations and build vocabularies.</p> PARAMETER DESCRIPTION <code>datamodule</code> <p>DataModule to train.</p> <p> TYPE: <code>DataModule[AsConverter, _InputT]</code> </p> <code>dataset</code> <p>Training dataset.</p> <p> TYPE: <code>Iterable[_InputT]</code> </p> RETURNS DESCRIPTION <code>DataModule[AsConverter, _InputT]</code> <p>Trained DataModule.</p> Source code in <code>src/formed/integrations/ml/workflow.py</code> <pre><code>@step(\"ml::train_datamodule\", format=\"json\")\ndef train_datamodule(\n    datamodule: DataModule[AsConverter, _InputT],\n    dataset: Iterable[_InputT],\n) -&gt; DataModule[AsConverter, _InputT]:\n    \"\"\"Train a data module on a dataset.\n\n    This step trains a DataModule on the provided dataset, allowing it to\n    learn transformations and build vocabularies.\n\n    Args:\n        datamodule: DataModule to train.\n        dataset: Training dataset.\n\n    Returns:\n        Trained DataModule.\n    \"\"\"\n    with datamodule.train(), progress(dataset, desc=\"Training datamodule\") as dataset:\n        for example in dataset:\n            datamodule(example)\n    return datamodule\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.train_datamodule_with_instances","title":"train_datamodule_with_instances","text":"<pre><code>train_datamodule_with_instances(datamodule, dataset)\n</code></pre> <p>Train a data module and collect generated instances.</p> <p>This step trains a DataModule while collecting all instances generated during training, returning both the trained module and instances.</p> PARAMETER DESCRIPTION <code>datamodule</code> <p>DataModule to train.</p> <p> TYPE: <code>DataModule[AsConverter, _InputT, _InstanceT]</code> </p> <code>dataset</code> <p>Training dataset.</p> <p> TYPE: <code>Iterable[_InputT]</code> </p> RETURNS DESCRIPTION <code>DataModuleAndInstances[_InputT, _InstanceT]</code> <p>DataModuleAndInstances containing the trained module and generated instances.</p> Source code in <code>src/formed/integrations/ml/workflow.py</code> <pre><code>@step(\"ml::train_datamodule_with_instances\", format=DataModuleAndInstancesFormat())\ndef train_datamodule_with_instances(\n    datamodule: DataModule[AsConverter, _InputT, _InstanceT],\n    dataset: Iterable[_InputT],\n) -&gt; DataModuleAndInstances[_InputT, _InstanceT]:\n    \"\"\"Train a data module and collect generated instances.\n\n    This step trains a DataModule while collecting all instances generated\n    during training, returning both the trained module and instances.\n\n    Args:\n        datamodule: DataModule to train.\n        dataset: Training dataset.\n\n    Returns:\n        DataModuleAndInstances containing the trained module and generated instances.\n    \"\"\"\n\n    def generate_instances() -&gt; Iterator[_InstanceT]:\n        nonlocal datamodule, dataset\n\n        with datamodule.train(), progress(dataset, desc=\"Training datamodule\") as dataset:\n            for example in dataset:\n                instance = datamodule(example)\n                assert instance is not None\n                yield instance\n\n    return DataModuleAndInstances(datamodule=datamodule, instances=generate_instances())\n</code></pre>"},{"location":"reference/integrations/ml/#formed.integrations.ml.workflow.generate_instances","title":"generate_instances","text":"<pre><code>generate_instances(datamodule, dataset)\n</code></pre> <p>Generate instances from a dataset using a data module.</p> <p>This step applies a DataModule to each example in the dataset, generating processed instances.</p> PARAMETER DESCRIPTION <code>datamodule</code> <p>DataModule to use for instance generation.</p> <p> TYPE: <code>DataModule[AsConverter, _InputT, _InstanceT]</code> </p> <code>dataset</code> <p>Input dataset.</p> <p> TYPE: <code>Iterable[_InputT]</code> </p> RETURNS DESCRIPTION <code>Dataset[_InstanceT]</code> <p>Dataset of generated instances.</p> Source code in <code>src/formed/integrations/ml/workflow.py</code> <pre><code>@step(\"ml::generate_instances\", format=\"dataset\")\n@step(\"ml::generate_instances_without_caching\", cacheable=False)\ndef generate_instances(\n    datamodule: DataModule[AsConverter, _InputT, _InstanceT],\n    dataset: Iterable[_InputT],\n) -&gt; Dataset[_InstanceT]:\n    \"\"\"Generate instances from a dataset using a data module.\n\n    This step applies a DataModule to each example in the dataset,\n    generating processed instances.\n\n    Args:\n        datamodule: DataModule to use for instance generation.\n        dataset: Input dataset.\n\n    Returns:\n        Dataset of generated instances.\n    \"\"\"\n\n    def generator() -&gt; Iterator[_InstanceT]:\n        nonlocal datamodule, dataset\n        with progress(dataset, desc=\"Generating instances\") as dataset:\n            for example in dataset:\n                instance = datamodule(example)\n                assert instance is not None\n                yield instance\n\n    return Dataset.from_iterable(generator())\n</code></pre>"},{"location":"reference/integrations/mlflow/","title":"MLflow","text":""},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.constants","title":"formed.integrations.mlflow.constants","text":""},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.constants.DEFAULT_MLFLOW_EXPERIMENT_NAME","title":"DEFAULT_MLFLOW_EXPERIMENT_NAME  <code>module-attribute</code>","text":"<pre><code>DEFAULT_MLFLOW_EXPERIMENT_NAME = 'Default'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.constants.DEFAULT_MLFLOW_DIRECTORY","title":"DEFAULT_MLFLOW_DIRECTORY  <code>module-attribute</code>","text":"<pre><code>DEFAULT_MLFLOW_DIRECTORY = (\n    WORKFLOW_INTEGRATION_DIRECTORY / \"mlflow\"\n)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils","title":"formed.integrations.mlflow.utils","text":""},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowParamValue","title":"MlflowParamValue  <code>module-attribute</code>","text":"<pre><code>MlflowParamValue = Union[int, float, str, None]\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowParams","title":"MlflowParams  <code>module-attribute</code>","text":"<pre><code>MlflowParams = dict[str, MlflowParamValue]\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.WorkflowRunType","title":"WorkflowRunType","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.WorkflowRunType.STEP","title":"STEP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STEP = 'step'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.WorkflowRunType.EXECUTION","title":"EXECUTION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EXECUTION = 'execution'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.WorkflowCacheStatus","title":"WorkflowCacheStatus","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.WorkflowCacheStatus.PENDING","title":"PENDING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PENDING = 'pending'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.WorkflowCacheStatus.ACTIVE","title":"ACTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACTIVE = 'active'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.WorkflowCacheStatus.INACTIVE","title":"INACTIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INACTIVE = 'inactive'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus","title":"MlflowRunStatus","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.RUNNING","title":"RUNNING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING = 'RUNNING'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.SCHEDULED","title":"SCHEDULED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SCHEDULED = 'SCHEDULED'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.FINISHED","title":"FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED = 'FINISHED'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.FAILED","title":"FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAILED = 'FAILED'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.KILLED","title":"KILLED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>KILLED = 'KILLED'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.from_step_status","title":"from_step_status  <code>classmethod</code>","text":"<pre><code>from_step_status(status)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>@classmethod\ndef from_step_status(cls, status: WorkflowStepStatus) -&gt; \"MlflowRunStatus\":\n    if status == WorkflowStepStatus.PENDING:\n        return cls.SCHEDULED\n    if status == WorkflowStepStatus.RUNNING:\n        return cls.RUNNING\n    if status == WorkflowStepStatus.COMPLETED:\n        return cls.FINISHED\n    if status == WorkflowStepStatus.FAILURE:\n        return cls.FAILED\n    if status == WorkflowStepStatus.CANCELED:\n        return cls.KILLED\n    raise ValueError(f\"Invalid step status: {status}\")\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.from_execution_status","title":"from_execution_status  <code>classmethod</code>","text":"<pre><code>from_execution_status(status)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>@classmethod\ndef from_execution_status(cls, status: WorkflowExecutionStatus) -&gt; \"MlflowRunStatus\":\n    if status == WorkflowExecutionStatus.PENDING:\n        return cls.SCHEDULED\n    if status == WorkflowExecutionStatus.RUNNING:\n        return cls.RUNNING\n    if status == WorkflowExecutionStatus.COMPLETED:\n        return cls.FINISHED\n    if status == WorkflowExecutionStatus.FAILURE:\n        return cls.FAILED\n    if status == WorkflowExecutionStatus.CANCELED:\n        return cls.KILLED\n    raise ValueError(f\"Invalid execution status: {status}\")\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.to_step_status","title":"to_step_status","text":"<pre><code>to_step_status()\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def to_step_status(self) -&gt; WorkflowStepStatus:\n    if self == self.RUNNING:\n        return WorkflowStepStatus.RUNNING\n    if self == self.SCHEDULED:\n        return WorkflowStepStatus.PENDING\n    if self == self.FINISHED:\n        return WorkflowStepStatus.COMPLETED\n    if self == self.FAILED:\n        return WorkflowStepStatus.FAILURE\n    if self == self.KILLED:\n        return WorkflowStepStatus.CANCELED\n    raise ValueError(f\"Invalid run status: {self}\")\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowRunStatus.to_execution_status","title":"to_execution_status","text":"<pre><code>to_execution_status()\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def to_execution_status(self) -&gt; WorkflowExecutionStatus:\n    if self == self.RUNNING:\n        return WorkflowExecutionStatus.RUNNING\n    if self == self.SCHEDULED:\n        return WorkflowExecutionStatus.PENDING\n    if self == self.FINISHED:\n        return WorkflowExecutionStatus.COMPLETED\n    if self == self.FAILED:\n        return WorkflowExecutionStatus.FAILURE\n    if self == self.KILLED:\n        return WorkflowExecutionStatus.CANCELED\n    raise ValueError(f\"Invalid run status: {self}\")\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowTag","title":"MlflowTag","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowTag.MLFLOW_PARENT_RUN_ID","title":"MLFLOW_PARENT_RUN_ID  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MLFLOW_PARENT_RUN_ID = MLFLOW_PARENT_RUN_ID\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowTag.MLFLOW_RUN_NAME","title":"MLFLOW_RUN_NAME  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MLFLOW_RUN_NAME = MLFLOW_RUN_NAME\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowTag.MLFLOW_RUN_NOTE","title":"MLFLOW_RUN_NOTE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MLFLOW_RUN_NOTE = MLFLOW_RUN_NOTE\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowTag.MLFACTORY_RUN_TYPE","title":"MLFACTORY_RUN_TYPE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MLFACTORY_RUN_TYPE = 'formed.workflow.run_type'\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowTag.MLFACTORY_STEP_FINGERPRINT","title":"MLFACTORY_STEP_FINGERPRINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MLFACTORY_STEP_FINGERPRINT = (\n    \"formed.workflow.step.fingerprint\"\n)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.MlflowTag.MLFACTORY_STEP_CACHE_STATUS","title":"MLFACTORY_STEP_CACHE_STATUS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MLFACTORY_STEP_CACHE_STATUS = (\n    \"formed.workflow.step.cache_status\"\n)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.flatten_params","title":"flatten_params","text":"<pre><code>flatten_params(d)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def flatten_params(d: Mapping[str, JsonValue]) -&gt; MlflowParams:\n    result = {}\n    for key, value in d.items():\n        if isinstance(value, (list, tuple)):\n            value = {str(i): v for i, v in enumerate(value)}\n        if isinstance(value, dict):\n            result.update({f\"{key}.{k}\": v for k, v in flatten_params(value).items()})\n        else:\n            result[key] = value\n    return result\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.build_filter_string","title":"build_filter_string","text":"<pre><code>build_filter_string(\n    run_type=None,\n    step_info=None,\n    execution_info=None,\n    additional_filters=None,\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def build_filter_string(\n    run_type: Optional[WorkflowRunType] = None,\n    step_info: Optional[Union[str, WorkflowStepInfo]] = None,\n    execution_info: Optional[Union[str, WorkflowExecutionInfo]] = None,\n    additional_filters: Optional[str] = None,\n) -&gt; str:\n    conditions: list[str] = []\n    if run_type is not None:\n        conditions.append(f\"tags.{MlflowTag.MLFACTORY_RUN_TYPE.value} = '{run_type.value}'\")\n    if step_info is not None:\n        step_fingerprint = step_info.fingerprint if isinstance(step_info, WorkflowStepInfo) else step_info\n        conditions.append(f\"tags.{MlflowTag.MLFACTORY_STEP_FINGERPRINT.value} = '{step_fingerprint}'\")\n    if execution_info is not None:\n        execution_id = execution_info.id if isinstance(execution_info, WorkflowExecutionInfo) else execution_info\n        conditions.append(f\"tags.{MlflowTag.MLFLOW_RUN_NAME.value} = '{execution_id}'\")\n    if additional_filters is not None:\n        conditions.append(additional_filters)\n    return \" AND \".join(conditions)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.is_mlflow_using_local_artifact_storage","title":"is_mlflow_using_local_artifact_storage","text":"<pre><code>is_mlflow_using_local_artifact_storage(mlflow_run)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def is_mlflow_using_local_artifact_storage(\n    mlflow_run: Union[str, MlflowRun],\n) -&gt; bool:\n    mlflow_run_id = mlflow_run.info.run_id if isinstance(mlflow_run, MlflowRun) else mlflow_run\n    mlflow_artifact_uri = urlparse(artifact_utils.get_artifact_uri(run_id=mlflow_run_id))  # type: ignore[no-untyped-call]\n    return bool(mlflow_artifact_uri.scheme == \"file\")\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_mlflow_local_artifact_storage_path","title":"get_mlflow_local_artifact_storage_path","text":"<pre><code>get_mlflow_local_artifact_storage_path(mlflow_run)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_mlflow_local_artifact_storage_path(\n    mlflow_run: Union[str, MlflowRun],\n) -&gt; Optional[Path]:\n    mlflow_run_id = mlflow_run.info.run_id if isinstance(mlflow_run, MlflowRun) else mlflow_run\n    mlflow_artifact_uri = urlparse(artifact_utils.get_artifact_uri(run_id=mlflow_run_id))  # type: ignore[no-untyped-call]\n    if mlflow_artifact_uri.scheme == \"file\":\n        return Path(mlflow_artifact_uri.path)\n    return None\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.fetch_child_mlflow_runs","title":"fetch_child_mlflow_runs","text":"<pre><code>fetch_child_mlflow_runs(client, experiment, mlflow_run)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def fetch_child_mlflow_runs(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    mlflow_run: Union[str, MlflowRun],\n) -&gt; Iterator[MlflowRun]:\n    experiment = get_mlflow_experiment(experiment)\n    mlflow_run_id = mlflow_run.info.run_id if isinstance(mlflow_run, MlflowRun) else mlflow_run\n    page_token: Optional[str] = None\n    while True:\n        runs = client.search_runs(\n            experiment_ids=[experiment.experiment_id],\n            filter_string=f\"tags.{MlflowTag.MLFLOW_PARENT_RUN_ID.value} = '{mlflow_run_id}'\",\n            page_token=page_token,\n        )\n        yield from iter(runs)\n        if runs.token is None:\n            break\n        page_token = runs.token\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.update_mlflow_tags","title":"update_mlflow_tags","text":"<pre><code>update_mlflow_tags(client, run, tags)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def update_mlflow_tags(\n    client: MlflowClient,\n    run: Union[str, MlflowRun],\n    tags: dict[MlflowTag, str],\n) -&gt; None:\n    run_id = run.info.run_id if isinstance(run, MlflowRun) else run\n    for tag, value in tags.items():\n        client.set_tag(run_id=run_id, key=tag.value, value=value)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.fetch_mlflow_runs","title":"fetch_mlflow_runs","text":"<pre><code>fetch_mlflow_runs(\n    client,\n    experiment,\n    *,\n    run_type=None,\n    step_info=None,\n    execution_info=None,\n    with_children=False,\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def fetch_mlflow_runs(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    *,\n    run_type: Optional[WorkflowRunType] = None,\n    step_info: Optional[Union[str, WorkflowStepInfo]] = None,\n    execution_info: Optional[Union[str, WorkflowExecutionInfo]] = None,\n    with_children: bool = False,\n) -&gt; Iterator[MlflowRun]:\n    experiment = get_mlflow_experiment(experiment)\n\n    page_token: Optional[str] = None\n    filter_string = build_filter_string(run_type, step_info, execution_info)\n    while True:\n        runs = client.search_runs(\n            experiment_ids=[experiment.experiment_id],\n            filter_string=filter_string,\n            page_token=page_token,\n        )\n        for run in runs:\n            yield run\n            if with_children:\n                yield from fetch_child_mlflow_runs(client, experiment, run)\n        if runs.token is None:\n            break\n        page_token = runs.token\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.fetch_mlflow_run","title":"fetch_mlflow_run","text":"<pre><code>fetch_mlflow_run(\n    client,\n    experiment,\n    *,\n    run_type=None,\n    step_info=None,\n    execution_info=None,\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def fetch_mlflow_run(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    *,\n    run_type: Optional[WorkflowRunType] = None,\n    step_info: Optional[Union[str, WorkflowStepInfo]] = None,\n    execution_info: Optional[Union[str, WorkflowExecutionInfo]] = None,\n) -&gt; Optional[MlflowRun]:\n    return next(\n        fetch_mlflow_runs(\n            client,\n            experiment,\n            run_type=run_type,\n            step_info=step_info,\n            execution_info=execution_info,\n        ),\n        None,\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.generate_new_execution_id","title":"generate_new_execution_id","text":"<pre><code>generate_new_execution_id(client, experiment)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def generate_new_execution_id(client: MlflowClient, experiment: Union[str, MlflowExperiment]) -&gt; WorkflowExecutionID:\n    experiment = get_mlflow_experiment(experiment)\n    while True:\n        execution_id = uuid.uuid4().hex[:8]\n        if fetch_mlflow_run(client, experiment, execution_info=execution_id) is None:\n            return WorkflowExecutionID(execution_id)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.add_mlflow_run","title":"add_mlflow_run","text":"<pre><code>add_mlflow_run(\n    client,\n    experiment,\n    step_or_execution_info,\n    parent_run_id=None,\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def add_mlflow_run(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    step_or_execution_info: Union[WorkflowStepInfo, WorkflowExecutionInfo],\n    parent_run_id: Optional[str] = None,\n) -&gt; MlflowRun:\n    experiment = get_mlflow_experiment(experiment)\n\n    run_name: str\n    params: MlflowParams\n    tags: dict[MlflowTag, str]\n\n    if isinstance(step_or_execution_info, WorkflowStepInfo):\n        run_name = step_or_execution_info.name\n        params = get_step_params(step_or_execution_info)\n        tags = get_step_tags(step_or_execution_info)\n    elif isinstance(step_or_execution_info, WorkflowExecutionInfo):\n        assert step_or_execution_info.id is not None\n        run_name = step_or_execution_info.id\n        params = get_execution_params(step_or_execution_info)\n        tags = get_execution_tags(step_or_execution_info)\n    else:\n        raise ValueError(f\"Unsupported type: {type(step_or_execution_info)}\")\n\n    if parent_run_id is not None:\n        tags[MlflowTag.MLFLOW_PARENT_RUN_ID] = parent_run_id\n\n    run = client.create_run(\n        experiment_id=experiment.experiment_id,\n        run_name=run_name,\n        tags=context_registry.resolve_tags({tag.value: value for tag, value in tags.items()}),\n    )\n    for key, value in params.items():\n        client.log_param(run.info.run_id, key, value)\n\n    return run\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.download_mlflow_artifacts","title":"download_mlflow_artifacts","text":"<pre><code>download_mlflow_artifacts(\n    client,\n    experiment,\n    step_or_execution_info,\n    directory,\n    artifact_path=None,\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def download_mlflow_artifacts(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    step_or_execution_info: Union[WorkflowStepInfo, WorkflowExecutionInfo],\n    directory: Union[str, PathLike],\n    artifact_path: Optional[str] = None,\n) -&gt; None:\n    run_type = (\n        WorkflowRunType.STEP if isinstance(step_or_execution_info, WorkflowStepInfo) else WorkflowRunType.EXECUTION\n    )\n    step_info = step_or_execution_info if isinstance(step_or_execution_info, WorkflowStepInfo) else None\n    execution_info = step_or_execution_info if isinstance(step_or_execution_info, WorkflowExecutionInfo) else None\n    run = fetch_mlflow_run(\n        client,\n        experiment,\n        run_type=run_type,\n        step_info=step_info,\n        execution_info=execution_info,\n    )\n    if run is None:\n        raise FileNotFoundError(\"Run not found\")\n    directory = Path(directory)\n    with tempfile.TemporaryDirectory() as temp_dir:\n        mlflow.artifacts.download_artifacts(\n            run_id=run.info.run_id,\n            artifact_path=artifact_path,\n            dst_path=temp_dir,\n        )\n        download_path = Path(temp_dir)\n        if artifact_path is not None:\n            download_path = download_path / artifact_path\n        directory.mkdir(parents=True, exist_ok=True)\n        for path in download_path.glob(\"*\"):\n            shutil.move(path, directory / path.name)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.upload_mlflow_artifacts","title":"upload_mlflow_artifacts","text":"<pre><code>upload_mlflow_artifacts(\n    client,\n    experiment,\n    step_or_execution_info,\n    directory,\n    artifact_path=None,\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def upload_mlflow_artifacts(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    step_or_execution_info: Union[WorkflowStepInfo, WorkflowExecutionInfo],\n    directory: Union[str, PathLike],\n    artifact_path: Optional[str] = None,\n) -&gt; None:\n    run = fetch_mlflow_run(\n        client,\n        experiment,\n        step_info=step_or_execution_info if isinstance(step_or_execution_info, WorkflowStepInfo) else None,\n        execution_info=step_or_execution_info if isinstance(step_or_execution_info, WorkflowExecutionInfo) else None,\n    )\n    if run is None:\n        raise ValueError(\"Run not found\")\n    client.log_artifacts(\n        run_id=run.info.run_id,\n        local_dir=str(directory),\n        artifact_path=artifact_path,\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.terminate_mlflow_run","title":"terminate_mlflow_run","text":"<pre><code>terminate_mlflow_run(\n    client, experiment, step_or_execution_state\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def terminate_mlflow_run(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    step_or_execution_state: Union[WorkflowStepState, WorkflowExecutionState],\n) -&gt; None:\n    step_info: Optional[str] = None\n    execution_info: Optional[str] = None\n    run_status: MlflowRunStatus\n    end_time: Optional[int] = None\n    if isinstance(step_or_execution_state, WorkflowStepState):\n        if step_or_execution_state.status not in (\n            WorkflowStepStatus.COMPLETED,\n            WorkflowStepStatus.FAILURE,\n            WorkflowStepStatus.CANCELED,\n        ):\n            raise ValueError(f\"Invalid step status: {step_or_execution_state.status}\")\n        step_info = step_or_execution_state.fingerprint\n        run_status = MlflowRunStatus.from_step_status(step_or_execution_state.status)\n        end_time = (\n            int(step_or_execution_state.finished_at.timestamp() * 1000) if step_or_execution_state.finished_at else None\n        )\n    elif isinstance(step_or_execution_state, WorkflowExecutionState):\n        if step_or_execution_state.status not in (\n            WorkflowExecutionStatus.COMPLETED,\n            WorkflowExecutionStatus.FAILURE,\n            WorkflowExecutionStatus.CANCELED,\n        ):\n            raise ValueError(f\"Invalid execution status: {step_or_execution_state.status}\")\n        execution_info = step_or_execution_state.execution_id\n        run_status = MlflowRunStatus.from_execution_status(step_or_execution_state.status)\n        end_time = (\n            int(step_or_execution_state.finished_at.timestamp() * 1000) if step_or_execution_state.finished_at else None\n        )\n    experiment = get_mlflow_experiment(experiment)\n    run = fetch_mlflow_run(\n        client,\n        experiment,\n        step_info=step_info,\n        execution_info=execution_info,\n    )\n    if run is None:\n        raise ValueError(\"Run not found\")\n    client.set_terminated(\n        run_id=run.info.run_id,\n        status=run_status.value,\n        end_time=end_time,\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.remove_mlflow_run","title":"remove_mlflow_run","text":"<pre><code>remove_mlflow_run(\n    client, experiment, step_or_execution_info\n)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def remove_mlflow_run(\n    client: MlflowClient,\n    experiment: Union[str, MlflowExperiment],\n    step_or_execution_info: Union[WorkflowStepInfo, WorkflowExecutionInfo],\n) -&gt; None:\n    run = fetch_mlflow_run(\n        client,\n        experiment,\n        step_info=step_or_execution_info if isinstance(step_or_execution_info, WorkflowStepInfo) else None,\n        execution_info=step_or_execution_info if isinstance(step_or_execution_info, WorkflowExecutionInfo) else None,\n    )\n    if run is None:\n        raise ValueError(\"Run not found\")\n    client.delete_run(run.info.run_id)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_mlflow_experiment","title":"get_mlflow_experiment","text":"<pre><code>get_mlflow_experiment(experiment)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_mlflow_experiment(experiment: Union[str, MlflowExperiment]) -&gt; MlflowExperiment:\n    if isinstance(experiment, str):\n        client = MlflowClient()\n        experiment_or_none = client.get_experiment_by_name(experiment)\n        if experiment_or_none is None:\n            mlflow.create_experiment(experiment)\n            experiment_or_none = client.get_experiment_by_name(experiment)\n            assert experiment_or_none is not None\n        experiment = experiment_or_none\n    return experiment\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_step_params","title":"get_step_params","text":"<pre><code>get_step_params(step_info)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_step_params(step_info: WorkflowStepInfo) -&gt; MlflowParams:\n    config = as_jsonvalue(step_info.step.config)\n    assert isinstance(config, dict)\n    return flatten_params(config)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_execution_params","title":"get_execution_params","text":"<pre><code>get_execution_params(execution_info)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_execution_params(execution_info: WorkflowExecutionInfo) -&gt; MlflowParams:\n    config = execution_info.graph.json()\n    assert isinstance(config, dict)\n    return flatten_params(config)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_step_tags","title":"get_step_tags","text":"<pre><code>get_step_tags(step_info)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_step_tags(step_info: WorkflowStepInfo) -&gt; dict[MlflowTag, str]:\n    return {\n        MlflowTag.MLFACTORY_RUN_TYPE: WorkflowRunType.STEP.value,\n        MlflowTag.MLFACTORY_STEP_FINGERPRINT: step_info.fingerprint,\n    }\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_execution_tags","title":"get_execution_tags","text":"<pre><code>get_execution_tags(execution_info)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_execution_tags(execution_info: WorkflowExecutionInfo) -&gt; dict[MlflowTag, str]:\n    assert execution_info.id is not None\n    return {\n        MlflowTag.MLFLOW_RUN_NAME: execution_info.id,\n        MlflowTag.MLFACTORY_RUN_TYPE: WorkflowRunType.EXECUTION.value,\n    }\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_mlflow_tags_from_run","title":"get_mlflow_tags_from_run","text":"<pre><code>get_mlflow_tags_from_run(run)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_mlflow_tags_from_run(run: MlflowRun) -&gt; dict[MlflowTag, str]:\n    return {tag: run.data.tags[tag.value] for tag in MlflowTag if tag.value in run.data.tags}\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.utils.get_execution_state_from_run","title":"get_execution_state_from_run","text":"<pre><code>get_execution_state_from_run(run)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/utils.py</code> <pre><code>def get_execution_state_from_run(run: MlflowRun) -&gt; WorkflowExecutionState:\n    tags = get_mlflow_tags_from_run(run)\n    if MlflowTag.MLFACTORY_RUN_TYPE not in tags:\n        raise ValueError(\"Run type not found\")\n    if tags[MlflowTag.MLFACTORY_RUN_TYPE] != WorkflowRunType.EXECUTION.value:\n        raise ValueError(f\"Invalid run type: {tags[MlflowTag.MLFACTORY_RUN_TYPE]}\")\n    if run.info.run_name is None:\n        raise ValueError(\"Run name not found\")\n    execution_id = WorkflowExecutionID(run.info.run_name)\n    status = MlflowRunStatus(run.info.status).to_execution_status()\n    started_at = datetime.datetime.fromtimestamp(run.info.start_time / 1000)\n    finished_at = datetime.datetime.fromtimestamp(run.info.end_time / 1000) if run.info.end_time else None\n    return WorkflowExecutionState(\n        execution_id=execution_id,\n        status=status,\n        started_at=started_at,\n        finished_at=finished_at,\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow","title":"formed.integrations.mlflow.workflow","text":""},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T')\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowCache","title":"MlflowWorkflowCache","text":"<pre><code>MlflowWorkflowCache(\n    experiment_name=DEFAULT_MLFLOW_EXPERIMENT_NAME,\n    directory=None,\n    mlflow_client=None,\n)\n</code></pre> <p>               Bases: <code>WorkflowCache</code></p> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def __init__(\n    self,\n    experiment_name: str = DEFAULT_MLFLOW_EXPERIMENT_NAME,\n    directory: Optional[Union[str, PathLike]] = None,\n    mlflow_client: Optional[MlflowClient] = None,\n) -&gt; None:\n    self._client = mlflow_client or MlflowClient()\n    self._experiment_name = experiment_name\n    self._directory = Path(directory or self._DEFAULT_DIRECTORY)\n    self._directory.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowCallback","title":"MlflowWorkflowCallback","text":"<pre><code>MlflowWorkflowCallback(\n    experiment_name=DEFAULT_MLFLOW_EXPERIMENT_NAME,\n    mlflow_client=None,\n    log_execution_metrics=False,\n)\n</code></pre> <p>               Bases: <code>WorkflowCallback</code></p> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def __init__(\n    self,\n    experiment_name: str = DEFAULT_MLFLOW_EXPERIMENT_NAME,\n    mlflow_client: Optional[MlflowClient] = None,\n    log_execution_metrics: bool = False,\n) -&gt; None:\n    self._client = mlflow_client or MlflowClient()\n    self._experiment_name = experiment_name\n    self._execution_run: Optional[MlflowRun] = None\n    self._execution_log: Optional[LogCapture[StringIO]] = None\n    self._step_log: dict[WorkflowStepInfo, LogCapture[StringIO]] = {}\n    self._log_execution_metrics = log_execution_metrics\n    self._step_run_ids: dict[str, str] = {}\n    self._dependents_map: dict[str, set[str]] = {}\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowCallback.on_execution_start","title":"on_execution_start","text":"<pre><code>on_execution_start(execution_context)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def on_execution_start(\n    self,\n    execution_context: WorkflowExecutionContext,\n) -&gt; None:\n    assert self._execution_run is None\n    execution_info = execution_context.info\n    if execution_info.id is None:\n        execution_info.id = mlflow_utils.generate_new_execution_id(self._client, self._experiment_name)\n    self._execution_log = LogCapture(StringIO())\n    self._execution_log.start()\n    self._execution_run = mlflow_utils.add_mlflow_run(\n        self._client,\n        self._experiment_name,\n        execution_info,\n    )\n    # Use WorkflowExecutionInfo.to_json_dict() for proper serialization\n    self._client.log_dict(\n        run_id=self._execution_run.info.run_id,\n        dictionary=execution_info.json(),\n        artifact_file=self._EXECUTION_METADATA_ARTIFACT_FILENAME,\n    )\n\n    # Initialize tracking for notes\n    self._dependents_map = self._build_dependents_map(execution_info.graph)\n    self._step_run_ids = {}\n\n    # Set initial execution note\n    initial_note = self._generate_execution_note_markdown(\n        execution_info,\n        self._step_run_ids,\n        self._dependents_map,\n    )\n    self._update_run_note(self._execution_run.info.run_id, initial_note)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowCallback.on_execution_end","title":"on_execution_end","text":"<pre><code>on_execution_end(execution_context)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def on_execution_end(\n    self,\n    execution_context: \"WorkflowExecutionContext\",\n) -&gt; None:\n    assert self._execution_run is not None\n    mlflow_utils.terminate_mlflow_run(\n        self._client,\n        self._experiment_name,\n        execution_context.state,\n    )\n    if self._execution_log is not None:\n        self._execution_log.stop()\n        self._client.log_text(\n            run_id=self._execution_run.info.run_id,\n            text=self._execution_log.stream.getvalue(),\n            artifact_file=self._LOG_FILENAME,\n        )\n        self._execution_log.stream.close()\n    self._execution_run = None\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowCallback.on_step_start","title":"on_step_start","text":"<pre><code>on_step_start(step_context, execution_context)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def on_step_start(\n    self,\n    step_context: WorkflowStepContext,\n    execution_context: WorkflowExecutionContext,\n) -&gt; None:\n    assert self._execution_run is not None\n    step_info = step_context.info\n    run = mlflow_utils.add_mlflow_run(\n        self._client,\n        self._experiment_name,\n        step_info,\n        parent_run_id=self._execution_run.info.run_id,\n    )\n    self._client.log_dict(\n        run_id=run.info.run_id,\n        dictionary=step_info.json(),\n        artifact_file=self._STEP_METADATA_ARTIFACT_FILENAME,\n    )\n    self._step_log[step_info] = LogCapture(StringIO(), logger=get_step_logger_from_info(step_info))\n    self._step_log[step_info].start()\n\n    # Store step run ID\n    self._step_run_ids[step_info.name] = run.info.run_id\n\n    # Set step note\n    step_note = self._generate_step_note_markdown(\n        step_info,\n        execution_context.info,\n        self._step_run_ids,\n        self._dependents_map,\n    )\n    self._update_run_note(run.info.run_id, step_note)\n\n    # Update execution note with new run ID\n    execution_note = self._generate_execution_note_markdown(\n        execution_context.info,\n        self._step_run_ids,\n        self._dependents_map,\n    )\n    self._update_run_note(self._execution_run.info.run_id, execution_note)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowCallback.on_step_end","title":"on_step_end","text":"<pre><code>on_step_end(step_context, execution_context)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def on_step_end(\n    self,\n    step_context: WorkflowStepContext,\n    execution_context: WorkflowExecutionContext,\n) -&gt; None:\n    step_info = step_context.info\n    mlflow_utils.terminate_mlflow_run(\n        self._client,\n        self._experiment_name,\n        step_context.state,\n    )\n    if (step_log := self._step_log.pop(step_info, None)) is not None:\n        run = mlflow_utils.fetch_mlflow_run(\n            self._client,\n            self._experiment_name,\n            step_info=step_info,\n        )\n        if run is None:\n            raise RuntimeError(f\"Run for step {step_info} not found\")\n        step_log.stop()\n        self._client.log_text(\n            run_id=run.info.run_id,\n            text=step_log.stream.getvalue(),\n            artifact_file=self._LOG_FILENAME,\n        )\n        if (\n            WorkflowStepResultFlag.METRICS in WorkflowStepResultFlag.get_flags(step_info)\n            and step_context.state.status == WorkflowStepStatus.COMPLETED\n        ):\n            metrics = execution_context.cache[step_info]\n            assert isinstance(metrics, dict), f\"Expected dict, got {type(metrics)}\"\n            for key, value in metrics.items():\n                self._client.log_metric(run.info.run_id, key, value)\n            if self._log_execution_metrics:\n                assert self._execution_run is not None\n                for key, value in metrics.items():\n                    key = f\"{step_info.name}/{key}\"\n                    self._client.log_metric(self._execution_run.info.run_id, key, value)\n        step_log.stream.close()\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowOrganizer","title":"MlflowWorkflowOrganizer","text":"<pre><code>MlflowWorkflowOrganizer(\n    experiment_name=DEFAULT_MLFLOW_EXPERIMENT_NAME,\n    cache=None,\n    callbacks=None,\n    log_execution_metrics=None,\n)\n</code></pre> <p>               Bases: <code>WorkflowOrganizer</code></p> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def __init__(\n    self,\n    experiment_name: str = DEFAULT_MLFLOW_EXPERIMENT_NAME,\n    cache: Optional[WorkflowCache] = None,\n    callbacks: Optional[Union[WorkflowCallback, Sequence[WorkflowCallback]]] = None,\n    log_execution_metrics: Optional[bool] = None,\n) -&gt; None:\n    self._client = MlflowClient()\n    self._experiment_name = experiment_name\n\n    cache = cache or MlflowWorkflowCache(\n        experiment_name=experiment_name,\n        mlflow_client=self._client,\n    )\n    if callbacks is None:\n        callbacks = []\n    elif isinstance(callbacks, WorkflowCallback):\n        callbacks = [callbacks]\n    if any(isinstance(callback, MlflowWorkflowCallback) for callback in callbacks):\n        if log_execution_metrics is not None:\n            logger.warning(\n                \"Ignoring `log_execution_metrics` parameter because `MlflowWorkflowCallback` is already present\"\n            )\n    else:\n        mlflow_callback = MlflowWorkflowCallback(\n            experiment_name,\n            mlflow_client=self._client,\n            log_execution_metrics=log_execution_metrics or False,\n        )\n        callbacks = [mlflow_callback] + list(callbacks)\n\n    super().__init__(cache, callbacks)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowOrganizer.cache","title":"cache  <code>instance-attribute</code>","text":"<pre><code>cache = cache\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowOrganizer.callback","title":"callback  <code>instance-attribute</code>","text":"<pre><code>callback = MultiWorkflowCallback(callbacks or [])\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowOrganizer.run","title":"run","text":"<pre><code>run(executor, execution)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def run(\n    self,\n    executor: WorkflowExecutor,\n    execution: Union[WorkflowGraph, WorkflowExecutionInfo],\n) -&gt; WorkflowExecutionContext:\n    cxt = contextvars.copy_context()\n\n    super_run = super().run\n\n    def _run() -&gt; WorkflowExecutionContext:\n        experiment = get_mlflow_experiment(self._experiment_name)\n        _MLFLOW_EXPERIMENT.set(experiment)\n        return super_run(executor, execution)\n\n    return cxt.run(_run)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowOrganizer.get","title":"get","text":"<pre><code>get(execution_id)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def get(self, execution_id: WorkflowExecutionID) -&gt; Optional[WorkflowExecutionContext]:\n    run = mlflow_utils.fetch_mlflow_run(\n        self._client,\n        self._experiment_name,\n        execution_info=execution_id,\n    )\n    if run is None:\n        return None\n    artifact_uri = run.info.artifact_uri\n    if not artifact_uri:\n        raise RuntimeError(f\"Run {run.info.run_id} has no artifact URI\")\n\n    # Load execution data using proper deserialization\n    # Download artifact to temporary file\n    execution_data = mlflow.artifacts.load_dict(\n        artifact_uri + \"/\" + MlflowWorkflowCallback._EXECUTION_METADATA_ARTIFACT_FILENAME\n    )\n    execution_info = WorkflowExecutionInfo.from_json(execution_data)\n\n    execution_state = mlflow_utils.get_execution_state_from_run(run)\n    return WorkflowExecutionContext(execution_info, execution_state, self.cache, self.callback)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowOrganizer.exists","title":"exists","text":"<pre><code>exists(execution_id)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def exists(self, execution_id: WorkflowExecutionID) -&gt; bool:\n    run = mlflow_utils.fetch_mlflow_run(\n        self._client,\n        self._experiment_name,\n        execution_info=execution_id,\n    )\n    return run is not None\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowWorkflowOrganizer.remove","title":"remove","text":"<pre><code>remove(execution_id)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def remove(self, execution_id: WorkflowExecutionID) -&gt; None:\n    for run in mlflow_utils.fetch_mlflow_runs(\n        self._client,\n        self._experiment_name,\n        execution_info=execution_id,\n        with_children=True,\n    ):\n        logger.info(f\"Removing run {run.info.run_id}\")\n        self._client.delete_run(run.info.run_id)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger","title":"MlflowLogger","text":"<pre><code>MlflowLogger(run)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def __init__(self, run: MlflowRun):\n    self.run = run\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.run","title":"run  <code>instance-attribute</code>","text":"<pre><code>run = run\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.mlflow_client","title":"mlflow_client  <code>property</code>","text":"<pre><code>mlflow_client\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_metric","title":"log_metric","text":"<pre><code>log_metric(key, value, timestamp=None, step=None)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_metric(\n    self,\n    key: str,\n    value: float,\n    timestamp: Optional[int] = None,\n    step: Optional[int] = None,\n) -&gt; None:\n    self.mlflow_client.log_metric(\n        run_id=self.run.info.run_id,\n        key=key,\n        value=value,\n        timestamp=timestamp,\n        step=step,\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_metrics","title":"log_metrics","text":"<pre><code>log_metrics(metrics)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_metrics(self, metrics: dict[str, float]) -&gt; None:\n    for key, value in metrics.items():\n        self.log_metric(key, value)\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_table","title":"log_table","text":"<pre><code>log_table(data, artifact_path)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_table(\n    self,\n    data: Union[dict[str, Sequence[Union[str, bool, int, float]]], \"PandasDataFrame\"],\n    artifact_path: str,\n) -&gt; None:\n    self.mlflow_client.log_table(\n        run_id=self.run.info.run_id,\n        data=data,\n        artifact_file=self._get_artifact_path(artifact_path),\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_text","title":"log_text","text":"<pre><code>log_text(text, artifact_path)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_text(\n    self,\n    text: str,\n    artifact_path: str,\n) -&gt; None:\n    self.mlflow_client.log_text(\n        run_id=self.run.info.run_id,\n        text=text,\n        artifact_file=self._get_artifact_path(artifact_path),\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_dict","title":"log_dict","text":"<pre><code>log_dict(dictionary, artifact_path)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_dict(\n    self,\n    dictionary: dict[str, JsonValue],\n    artifact_path: str,\n) -&gt; None:\n    self.mlflow_client.log_dict(\n        run_id=self.run.info.run_id,\n        dictionary=dictionary,\n        artifact_file=self._get_artifact_path(artifact_path),\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_figure","title":"log_figure","text":"<pre><code>log_figure(figure, artifact_path)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_figure(\n    self,\n    figure: Union[\"MatplotlibFigure\", \"PlotlyFigure\"],\n    artifact_path: str,\n) -&gt; None:\n    self.mlflow_client.log_figure(\n        run_id=self.run.info.run_id,\n        figure=figure,\n        artifact_file=self._get_artifact_path(artifact_path),\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_image","title":"log_image","text":"<pre><code>log_image(image, artifact_path=None)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_image(\n    self,\n    image: Union[\"NumpyArray\", \"PILImage\", \"MlflowImage\"],\n    artifact_path: Optional[str] = None,\n) -&gt; None:\n    self.mlflow_client.log_image(\n        run_id=self.run.info.run_id,\n        image=image,\n        artifact_file=self._get_artifact_path(artifact_path),\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_artifact","title":"log_artifact","text":"<pre><code>log_artifact(local_path, artifact_path=None)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_artifact(\n    self,\n    local_path: Union[str, PathLike],\n    artifact_path: Optional[str] = None,\n) -&gt; None:\n    self.mlflow_client.log_artifact(\n        run_id=self.run.info.run_id,\n        local_path=local_path,\n        artifact_path=self._get_artifact_path(artifact_path),\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.MlflowLogger.log_artifacts","title":"log_artifacts","text":"<pre><code>log_artifacts(local_dir, artifact_path=None)\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def log_artifacts(\n    self,\n    local_dir: Union[str, PathLike],\n    artifact_path: Optional[str] = None,\n) -&gt; None:\n    self.mlflow_client.log_artifacts(\n        run_id=self.run.info.run_id,\n        local_dir=str(local_dir),\n        artifact_path=self._get_artifact_path(artifact_path),\n    )\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.use_mlflow_experiment","title":"use_mlflow_experiment","text":"<pre><code>use_mlflow_experiment()\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def use_mlflow_experiment() -&gt; Optional[MlflowExperiment]:\n    return _MLFLOW_EXPERIMENT.get()\n</code></pre>"},{"location":"reference/integrations/mlflow/#formed.integrations.mlflow.workflow.use_mlflow_logger","title":"use_mlflow_logger","text":"<pre><code>use_mlflow_logger()\n</code></pre> Source code in <code>src/formed/integrations/mlflow/workflow.py</code> <pre><code>def use_mlflow_logger() -&gt; Optional[MlflowLogger]:\n    if (experiment := use_mlflow_experiment()) is None:\n        return None\n\n    if (context := use_step_context()) is None:\n        return None\n\n    client = MlflowClient()\n    if (run := fetch_mlflow_run(client, experiment, step_info=context.info)) is None:\n        return None\n\n    return MlflowLogger(run)\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/","title":"SentenceTransformers","text":""},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.analyzers","title":"formed.integrations.sentence_transformers.analyzers","text":""},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.analyzers.SentenceTransformerAnalyzer","title":"SentenceTransformerAnalyzer  <code>dataclass</code>","text":"<pre><code>SentenceTransformerAnalyzer(\n    model_name_or_path, unicode_normalization=None\n)\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.analyzers.SentenceTransformerAnalyzer.model_name_or_path","title":"model_name_or_path  <code>instance-attribute</code>","text":"<pre><code>model_name_or_path\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.analyzers.SentenceTransformerAnalyzer.unicode_normalization","title":"unicode_normalization  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>unicode_normalization = None\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.utils","title":"formed.integrations.sentence_transformers.utils","text":""},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.utils.load_sentence_transformer","title":"load_sentence_transformer  <code>cached</code>","text":"<pre><code>load_sentence_transformer(model_name_or_path, **kwargs)\n</code></pre> Source code in <code>src/formed/integrations/sentence_transformers/utils.py</code> <pre><code>@lru_cache(maxsize=8)\ndef load_sentence_transformer(\n    model_name_or_path: str | PathLike,\n    **kwargs: Any,\n) -&gt; SentenceTransformer:\n    with suppress(FileNotFoundError):\n        model_name_or_path = minato.cached_path(model_name_or_path)\n    return SentenceTransformer(str(model_name_or_path), **kwargs)\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow","title":"formed.integrations.sentence_transformers.workflow","text":"<p>Workflow steps for Sentence Transformers integration.</p> <p>This module provides workflow steps for loading, training, and converting sentence transformer models.</p> Available Steps <ul> <li><code>sentence_transformers::load</code>: Load a pre-trained sentence transformer model.</li> <li><code>sentence_transformers::train</code>: Train a sentence transformer model.</li> <li><code>sentence_transformers::convert_tokenizer</code>: Convert a sentence transformer tokenizer to a formed Tokenizer (requires ml integration).</li> </ul>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.SentenceTransformerFormat","title":"SentenceTransformerFormat","text":"<p>               Bases: <code>Generic[SentenceTransformerT]</code>, <code>Format[SentenceTransformerT]</code></p>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.SentenceTransformerFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.SentenceTransformerFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/integrations/sentence_transformers/workflow.py</code> <pre><code>def write(self, artifact: SentenceTransformerT, directory: Path) -&gt; None:\n    artifact.save_pretrained(str(directory / \"model\"))\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.SentenceTransformerFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/integrations/sentence_transformers/workflow.py</code> <pre><code>def read(self, directory: Path) -&gt; SentenceTransformerT:\n    return cast(SentenceTransformerT, SentenceTransformer(str(directory / \"model\")))\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.SentenceTransformerFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.load_pretrained_model","title":"load_pretrained_model","text":"<pre><code>load_pretrained_model(model_name_or_path, **kwargs)\n</code></pre> <p>Load a pre-trained sentence transformer model.</p> PARAMETER DESCRIPTION <code>model_name_or_path</code> <p>Model identifier or path to model directory.</p> <p> TYPE: <code>str | PathLike</code> </p> <code>**kwargs</code> <p>Additional arguments to pass to SentenceTransformer constructor.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>SentenceTransformer</code> <p>Loaded SentenceTransformer model.</p> Source code in <code>src/formed/integrations/sentence_transformers/workflow.py</code> <pre><code>@step(\"sentence_transformers::load\", cacheable=False)\ndef load_pretrained_model(\n    model_name_or_path: str | PathLike,\n    **kwargs: Any,\n) -&gt; SentenceTransformer:\n    \"\"\"Load a pre-trained sentence transformer model.\n\n    Args:\n        model_name_or_path: Model identifier or path to model directory.\n        **kwargs: Additional arguments to pass to SentenceTransformer constructor.\n\n    Returns:\n        Loaded SentenceTransformer model.\n    \"\"\"\n    with suppress(Exception):\n        model_name_or_path = minato.cached_path(model_name_or_path)\n    return SentenceTransformer(str(model_name_or_path), **kwargs)\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.train_sentence_transformer","title":"train_sentence_transformer","text":"<pre><code>train_sentence_transformer(\n    model,\n    loss,\n    args,\n    dataset=None,\n    loss_modifier=None,\n    data_collator=None,\n    tokenizer=None,\n    evaluator=None,\n    callbacks=None,\n    model_init=None,\n    compute_metrics=None,\n    optimizers=(None, None),\n    preprocess_logits_for_metrics=None,\n    train_dataset_key=\"train\",\n    eval_dataset_key=\"validation\",\n)\n</code></pre> <p>Train a sentence transformer model.</p> <p>This step trains a SentenceTransformer model using the provided loss function, datasets, and training arguments.</p> PARAMETER DESCRIPTION <code>model</code> <p>SentenceTransformer model to train.</p> <p> TYPE: <code>SentenceTransformer</code> </p> <code>loss</code> <p>Loss function(s) for training (single or mapping by dataset key).</p> <p> TYPE: <code>Mapping[str, Lazy[Module]] | Lazy[Module]</code> </p> <code>args</code> <p>Training arguments configuration.</p> <p> TYPE: <code>Lazy[SentenceTransformerTrainingArguments]</code> </p> <code>dataset</code> <p>Training/validation datasets.</p> <p> TYPE: <code>None | (Dataset | DatasetDict | Mapping[str, Dataset | DatasetDict])</code> DEFAULT: <code>None</code> </p> <code>loss_modifier</code> <p>Optional modifier(s) to apply to the loss function.</p> <p> TYPE: <code>None | (Mapping[str, list[Lazy[Module]] | Lazy[Module]] | list[Lazy[Module]] | Lazy[Module])</code> DEFAULT: <code>None</code> </p> <code>data_collator</code> <p>Optional data collator for batching.</p> <p> TYPE: <code>DataCollator | None</code> DEFAULT: <code>None</code> </p> <code>tokenizer</code> <p>Optional tokenizer.</p> <p> TYPE: <code>PreTrainedTokenizerBase | None</code> DEFAULT: <code>None</code> </p> <code>evaluator</code> <p>Optional evaluator(s) for validation.</p> <p> TYPE: <code>SentenceEvaluator | list[SentenceEvaluator] | None</code> DEFAULT: <code>None</code> </p> <code>callbacks</code> <p>Optional training callbacks.</p> <p> TYPE: <code>list[TrainerCallback] | None</code> DEFAULT: <code>None</code> </p> <code>model_init</code> <p>Optional model initialization function.</p> <p> TYPE: <code>Callable[[], SentenceTransformer] | None</code> DEFAULT: <code>None</code> </p> <code>compute_metrics</code> <p>Optional metrics computation function.</p> <p> TYPE: <code>Callable[[EvalPrediction], dict] | None</code> DEFAULT: <code>None</code> </p> <code>optimizers</code> <p>Optional optimizer and learning rate scheduler.</p> <p> TYPE: <code>tuple[Lazy[Optimizer] | None, Lazy[LambdaLR] | None]</code> DEFAULT: <code>(None, None)</code> </p> <code>preprocess_logits_for_metrics</code> <p>Optional logits preprocessing function.</p> <p> TYPE: <code>Callable[[Tensor, Tensor], Tensor] | None</code> DEFAULT: <code>None</code> </p> <code>train_dataset_key</code> <p>Key for training dataset split.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'train'</code> </p> <code>eval_dataset_key</code> <p>Key for evaluation dataset split.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'validation'</code> </p> RETURNS DESCRIPTION <code>SentenceTransformer</code> <p>Trained SentenceTransformer model.</p> Source code in <code>src/formed/integrations/sentence_transformers/workflow.py</code> <pre><code>@step(\"sentence_transformers::train\", format=SentenceTransformerFormat())\ndef train_sentence_transformer(\n    model: SentenceTransformer,\n    loss: Mapping[str, Lazy[torch.nn.Module]] | Lazy[torch.nn.Module],\n    args: Lazy[SentenceTransformerTrainingArguments],\n    dataset: None\n    | (\n        datasets.Dataset\n        | datasets.DatasetDict\n        | Mapping[\n            str,\n            datasets.Dataset | datasets.DatasetDict,\n        ]\n    ) = None,\n    loss_modifier: None\n    | (\n        Mapping[str, list[Lazy[torch.nn.Module]] | Lazy[torch.nn.Module]]\n        | list[Lazy[torch.nn.Module]]\n        | Lazy[torch.nn.Module]\n    ) = None,\n    data_collator: DataCollator | None = None,  # pyright: ignore[reportInvalidTypeForm]\n    tokenizer: PreTrainedTokenizerBase | None = None,\n    evaluator: SentenceEvaluator | list[SentenceEvaluator] | None = None,\n    callbacks: list[TrainerCallback] | None = None,\n    model_init: Callable[[], SentenceTransformer] | None = None,\n    compute_metrics: Callable[[EvalPrediction], dict] | None = None,\n    optimizers: tuple[\n        Lazy[torch.optim.Optimizer] | None,\n        Lazy[torch.optim.lr_scheduler.LambdaLR] | None,\n    ] = (None, None),\n    preprocess_logits_for_metrics: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] | None = None,\n    train_dataset_key: str = \"train\",\n    eval_dataset_key: str = \"validation\",\n) -&gt; SentenceTransformer:\n    \"\"\"Train a sentence transformer model.\n\n    This step trains a SentenceTransformer model using the provided loss function,\n    datasets, and training arguments.\n\n    Args:\n        model: SentenceTransformer model to train.\n        loss: Loss function(s) for training (single or mapping by dataset key).\n        args: Training arguments configuration.\n        dataset: Training/validation datasets.\n        loss_modifier: Optional modifier(s) to apply to the loss function.\n        data_collator: Optional data collator for batching.\n        tokenizer: Optional tokenizer.\n        evaluator: Optional evaluator(s) for validation.\n        callbacks: Optional training callbacks.\n        model_init: Optional model initialization function.\n        compute_metrics: Optional metrics computation function.\n        optimizers: Optional optimizer and learning rate scheduler.\n        preprocess_logits_for_metrics: Optional logits preprocessing function.\n        train_dataset_key: Key for training dataset split.\n        eval_dataset_key: Key for evaluation dataset split.\n\n    Returns:\n        Trained SentenceTransformer model.\n    \"\"\"\n    workdir = use_step_workdir()\n\n    args_ = args.construct(output_dir=str(workdir))\n\n    if isinstance(dataset, datasets.Dataset):\n        train_dataset = dataset\n        eval_dataset = None\n    else:\n        train_dataset = dataset.get(train_dataset_key) if dataset and args_.do_train else None\n        eval_dataset = dataset.get(eval_dataset_key) if dataset and args_.do_eval else None\n\n    loss_: torch.nn.Module | dict[str, torch.nn.Module]\n    if isinstance(loss, Mapping):\n        loss_ = {k: ll.construct(model=model) for k, ll in loss.items()}\n    else:\n        loss_ = loss.construct(model=model)\n    if loss_modifier:\n        if isinstance(loss_modifier, Mapping):\n            assert isinstance(loss_, dict)\n            for k, m in loss_modifier.items():\n                if not isinstance(m, list):\n                    m = [m]\n                for n in m:\n                    loss_[k] = n.construct(model=model, loss=loss_[k])\n        else:\n            if not isinstance(loss_modifier, list):\n                loss_modifier = [loss_modifier]\n            if isinstance(loss_, dict):\n                for k, ll in loss_.items():\n                    for m in loss_modifier:\n                        loss_[k] = m.construct(model=model, loss=ll)\n            else:\n                for m in loss_modifier:\n                    loss_ = m.construct(model=model, loss=loss_)\n\n    lazy_optimizer, lazy_lr_scheduler = optimizers\n    optimizer = lazy_optimizer.construct(params=model.parameters()) if lazy_optimizer else None\n    lr_scheduler = lazy_lr_scheduler.construct(optimizer=optimizer) if lazy_lr_scheduler else None\n\n    trainer = SentenceTransformerTrainer(\n        model=model,\n        loss=loss_,\n        args=args_,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n        evaluator=evaluator,\n        callbacks=callbacks,\n        model_init=model_init,\n        compute_metrics=compute_metrics,\n        optimizers=(optimizer, lr_scheduler),  # type: ignore[arg-type]\n        preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n    )\n    trainer.train()\n    return model\n</code></pre>"},{"location":"reference/integrations/sentence_transformers/#formed.integrations.sentence_transformers.workflow.convert_tokenizer","title":"convert_tokenizer","text":"<pre><code>convert_tokenizer(\n    model_name_or_path,\n    pad_token=VALUE,\n    unk_token=VALUE,\n    bos_token=VALUE,\n    eos_token=VALUE,\n    freeze=True,\n    accessor=None,\n)\n</code></pre> <p>Convert a sentence transformer model's tokenizer to a formed Tokenizer.</p> <p>This step extracts the tokenizer from a sentence transformer model and converts it into a formed Tokenizer with specified special tokens.</p> PARAMETER DESCRIPTION <code>model_name_or_path</code> <p>Model identifier or path to model directory.</p> <p> TYPE: <code>str | PathLike</code> </p> <code>pad_token</code> <p>Padding token (uses model default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>unk_token</code> <p>Unknown token (uses model default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>bos_token</code> <p>Beginning-of-sequence token (uses model default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>eos_token</code> <p>End-of-sequence token (uses model default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>freeze</code> <p>Whether to freeze the vocabulary.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>accessor</code> <p>Optional accessor for token extraction.</p> <p> TYPE: <code>str | Callable | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tokenizer</code> <p>Converted formed Tokenizer.</p> RAISES DESCRIPTION <code>AssertionError</code> <p>If pad_token is not specified and not available in the model.</p> Source code in <code>src/formed/integrations/sentence_transformers/workflow.py</code> <pre><code>@step(\"sentence_transformers::convert_tokenizer\", format=\"json\")\ndef convert_tokenizer(\n    model_name_or_path: str | PathLike,\n    pad_token: str | None | NotSpecified = NotSpecified.VALUE,\n    unk_token: str | None | NotSpecified = NotSpecified.VALUE,\n    bos_token: str | None | NotSpecified = NotSpecified.VALUE,\n    eos_token: str | None | NotSpecified = NotSpecified.VALUE,\n    freeze: bool = True,\n    accessor: str | Callable | None = None,\n) -&gt; Tokenizer:\n    \"\"\"Convert a sentence transformer model's tokenizer to a formed Tokenizer.\n\n    This step extracts the tokenizer from a sentence transformer model and\n    converts it into a formed Tokenizer with specified special tokens.\n\n    Args:\n        model_name_or_path: Model identifier or path to model directory.\n        pad_token: Padding token (uses model default if not specified).\n        unk_token: Unknown token (uses model default if not specified).\n        bos_token: Beginning-of-sequence token (uses model default if not specified).\n        eos_token: End-of-sequence token (uses model default if not specified).\n        freeze: Whether to freeze the vocabulary.\n        accessor: Optional accessor for token extraction.\n\n    Returns:\n        Converted formed Tokenizer.\n\n    Raises:\n        AssertionError: If pad_token is not specified and not available in the model.\n    \"\"\"\n    model = load_sentence_transformer(model_name_or_path)\n\n    def get_token(given: str | None | NotSpecified, default: Any) -&gt; str | None:\n        if not isinstance(given, NotSpecified):\n            return given\n        if isinstance(default, str):\n            return default\n        return None\n\n    vocab = model.tokenizer.get_vocab().copy()\n    pad_token = get_token(pad_token, getattr(model.tokenizer, \"pad_token\", None))\n    unk_token = get_token(unk_token, getattr(model.tokenizer, \"unk_token\", None))\n    bos_token = get_token(bos_token, getattr(model.tokenizer, \"bos_token\", None))\n    eos_token = get_token(eos_token, getattr(model.tokenizer, \"eos_token\", None))\n\n    assert isinstance(pad_token, str), \"pad_token must be specified or available in the tokenizer\"\n\n    surface_indexer = TokenSequenceIndexer(\n        vocab=vocab,\n        pad_token=pad_token,\n        unk_token=unk_token,\n        bos_token=bos_token,\n        eos_token=eos_token,\n        freeze=freeze,\n    )\n    analyzer = SentenceTransformerAnalyzer(model_name_or_path)\n    return Tokenizer(\n        surfaces=surface_indexer,\n        analyzer=Param.cast(analyzer),\n        accessor=accessor,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/","title":"Torch","text":"<ul> <li>Context</li> <li>DataLoader</li> <li>Distributors</li> <li>Initializers</li> <li>Model</li> <li>Schedulers</li> <li>Utils</li> <li>Modules<ul> <li>Embedders</li> <li>Encoders</li> <li>Feedforward</li> <li>Losses</li> <li>Masks</li> <li>Samplers</li> <li>ScalarMix</li> <li>Vectorizers</li> <li>Weighters</li> </ul> </li> <li>Training<ul> <li>Callbacks</li> <li>Engine</li> <li>Exceptions</li> <li>State</li> <li>Trainer</li> </ul> </li> <li>Workflow</li> </ul>"},{"location":"reference/integrations/torch/#formed.integrations.torch.context","title":"formed.integrations.torch.context","text":"<p>Context management for PyTorch operations.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.context.use_device","title":"use_device","text":"<pre><code>use_device(device=None)\n</code></pre> <p>Context manager to set and restore the default PyTorch device.</p> <p>This context manager allows temporarily setting the default device used in PyTorch operations (e.g., in <code>ensure_torch_tensor</code>). It saves the current device on entry and restores it on exit.</p> PARAMETER DESCRIPTION <code>device</code> <p>Device to use within the context. Can be a torch.device, a string like <code>\"cuda:0\"</code> or <code>\"cpu\"</code>, or None.</p> <p> TYPE: <code>str | device | None</code> DEFAULT: <code>None</code> </p> YIELDS DESCRIPTION <code>device</code> <p>The current device within the context.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from formed.integrations.torch import use_device, ensure_torch_tensor\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; with use_device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n...     arr = np.array([1.0, 2.0, 3.0])\n...     tensor = ensure_torch_tensor(arr)\n...     print(tensor.device)\ncuda:0  # or cpu if CUDA not available\n</code></pre> Source code in <code>src/formed/integrations/torch/context.py</code> <pre><code>@contextmanager\ndef use_device(device: str | torch.device | None = None) -&gt; Iterator[torch.device]:\n    \"\"\"Context manager to set and restore the default PyTorch device.\n\n    This context manager allows temporarily setting the default device\n    used in PyTorch operations (e.g., in `ensure_torch_tensor`). It saves\n    the current device on entry and restores it on exit.\n\n    Args:\n        device: Device to use within the context. Can be a torch.device,\n            a string like `\"cuda:0\"` or `\"cpu\"`, or None.\n\n    Yields:\n        The current device within the context.\n\n    Examples:\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; from formed.integrations.torch import use_device, ensure_torch_tensor\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; with use_device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n        ...     arr = np.array([1.0, 2.0, 3.0])\n        ...     tensor = ensure_torch_tensor(arr)\n        ...     print(tensor.device)\n        cuda:0  # or cpu if CUDA not available\n    \"\"\"\n    if device is None:\n        if torch.cuda.is_available():\n            device = \"cuda:0\"\n        elif torch.backends.mps.is_available():\n            device = \"mps\"\n        else:\n            device = \"cpu\"\n    if isinstance(device, str):\n        device = torch.device(device)\n    token = _TORCH_DEVICE.set(torch.device(device))\n    try:\n        yield device\n    finally:\n        _TORCH_DEVICE.reset(token)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.context.get_device","title":"get_device","text":"<pre><code>get_device()\n</code></pre> <p>Get the current default PyTorch device from context.</p> RETURNS DESCRIPTION <code>device | None</code> <p>The current device set in the context, or <code>None</code> if not set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import use_device, get_device\n&gt;&gt;&gt; with use_device(\"cuda:0\"):\n...     print(get_device())\ncuda:0\n</code></pre> Source code in <code>src/formed/integrations/torch/context.py</code> <pre><code>def get_device() -&gt; torch.device | None:\n    \"\"\"Get the current default PyTorch device from context.\n\n    Returns:\n        The current device set in the context, or `None` if not set.\n\n    Examples:\n        &gt;&gt;&gt; from formed.integrations.torch import use_device, get_device\n        &gt;&gt;&gt; with use_device(\"cuda:0\"):\n        ...     print(get_device())\n        cuda:0\n    \"\"\"\n    return _TORCH_DEVICE.get()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader","title":"formed.integrations.torch.dataloader","text":"<p>DataLoader utilities for PyTorch training.</p> <p>This module provides convenient wrappers for creating PyTorch DataLoaders that work seamlessly with the formed training framework.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import DataLoader\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a simple dataloader\n&gt;&gt;&gt; train_loader = DataLoader(\n...     batch_size=32,\n...     shuffle=True,\n...     collate_fn=my_collate_fn\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use with trainer\n&gt;&gt;&gt; trainer = TorchTrainer(\n...     train_dataloader=train_loader,\n...     ...\n... )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.ItemT","title":"ItemT  <code>module-attribute</code>","text":"<pre><code>ItemT = TypeVar('ItemT')\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader","title":"DataLoader","text":"<pre><code>DataLoader(\n    batch_size,\n    shuffle=False,\n    collate_fn=None,\n    num_workers=0,\n    drop_last=False,\n    pin_memory=False,\n    **kwargs,\n)\n</code></pre> <p>Simple DataLoader wrapper for PyTorch training.</p> <p>This class wraps PyTorch's DataLoader with a simpler interface that works with the formed training framework.</p> PARAMETER DESCRIPTION <code>batch_size</code> <p>Number of samples per batch.</p> <p> TYPE: <code>int</code> </p> <code>shuffle</code> <p>Whether to shuffle the data at every epoch.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>collate_fn</code> <p>Function to collate samples into batches.</p> <p> TYPE: <code>Callable[[list[ItemT]], ModelInputT] | None</code> DEFAULT: <code>None</code> </p> <code>num_workers</code> <p>Number of subprocesses for data loading.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>drop_last</code> <p>Whether to drop the last incomplete batch.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>pin_memory</code> <p>If True, tensors are copied to CUDA pinned memory.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional arguments passed to torch.utils.data.DataLoader.</p> <p> DEFAULT: <code>{}</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; def collate_fn(batch):\n...     # Convert list of samples to batch tensors\n...     return {\"features\": torch.stack([x[\"features\"] for x in batch])}\n&gt;&gt;&gt;\n&gt;&gt;&gt; loader = DataLoader(\n...     batch_size=32,\n...     shuffle=True,\n...     collate_fn=collate_fn\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/dataloader.py</code> <pre><code>def __init__(\n    self,\n    batch_size: int,\n    shuffle: bool = False,\n    collate_fn: Callable[[list[ItemT]], ModelInputT] | None = None,\n    num_workers: int = 0,\n    drop_last: bool = False,\n    pin_memory: bool = False,\n    **kwargs,\n) -&gt; None:\n    self.batch_size = batch_size\n    self.shuffle = shuffle\n    self.collate_fn = collate_fn\n    self.num_workers = num_workers\n    self.drop_last = drop_last\n    self.pin_memory = pin_memory\n    self.kwargs = kwargs\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader.batch_size","title":"batch_size  <code>instance-attribute</code>","text":"<pre><code>batch_size = batch_size\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader.shuffle","title":"shuffle  <code>instance-attribute</code>","text":"<pre><code>shuffle = shuffle\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader.collate_fn","title":"collate_fn  <code>instance-attribute</code>","text":"<pre><code>collate_fn = collate_fn\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader.num_workers","title":"num_workers  <code>instance-attribute</code>","text":"<pre><code>num_workers = num_workers\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader.drop_last","title":"drop_last  <code>instance-attribute</code>","text":"<pre><code>drop_last = drop_last\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader.pin_memory","title":"pin_memory  <code>instance-attribute</code>","text":"<pre><code>pin_memory = pin_memory\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.dataloader.DataLoader.kwargs","title":"kwargs  <code>instance-attribute</code>","text":"<pre><code>kwargs = kwargs\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors","title":"formed.integrations.torch.distributors","text":"<p>Distributed computing abstractions for PyTorch models.</p> <p>This module provides abstractions for distributed training across multiple devices, supporting both single-device and data-parallel training strategies.</p> Key Components <ul> <li><code>BaseDistributor</code>: Abstract interface for device distribution strategies</li> <li><code>SingleDeviceDistributor</code>: No-op distributor for single-device training</li> <li><code>DataParallelDistributor</code>: Data-parallel training using torch.nn.DataParallel</li> </ul> Features <ul> <li>Transparent device sharding and replication</li> <li>Reduction operations (mean, sum) across devices</li> <li>Compatible with TorchTrainer</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import DataParallelDistributor\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create data-parallel distributor for all available GPUs\n&gt;&gt;&gt; distributor = DataParallelDistributor()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Shard batch across devices\n&gt;&gt;&gt; sharded_batch = distributor.shard(batch)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor","title":"BaseDistributor","text":"<p>               Bases: <code>Registrable</code>, <code>ABC</code>, <code>Generic[ModelInputT]</code></p> <p>Abstract base class for device distribution strategies.</p> <p>BaseDistributor defines the interface for distributing computations across devices in a PyTorch training pipeline. It provides a unified API for single-device, data-parallel, and distributed data-parallel training.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ModelInputT</code> <p>Type of model input data.</p> <p> </p> Key Methods <ul> <li>device: Primary device for computation</li> <li>is_main_process: Whether this is the main process (for logging, saving, etc.)</li> <li>wrap_model: Wrap model for distributed training</li> <li>prepare_data_loader: Prepare data loader with appropriate sampler</li> <li>reduce: Reduce tensor across devices/processes</li> <li>barrier: Synchronize all processes</li> <li>all_gather: Gather tensors from all processes</li> </ul>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.device","title":"device  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>device\n</code></pre> <p>Primary device for computation.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.is_main_process","title":"is_main_process  <code>property</code>","text":"<pre><code>is_main_process\n</code></pre> <p>Whether this is the main process.</p> <p>The main process is responsible for: - Logging to console - Saving models and checkpoints - Writing metrics to file</p> RETURNS DESCRIPTION <code>bool</code> <p>True if this is the main process (rank 0), False otherwise.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.world_size","title":"world_size  <code>property</code>","text":"<pre><code>world_size\n</code></pre> <p>Total number of processes/devices.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of processes in distributed training, or 1 for single device.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.rank","title":"rank  <code>property</code>","text":"<pre><code>rank\n</code></pre> <p>Global rank of this process.</p> RETURNS DESCRIPTION <code>int</code> <p>Rank of this process (0 for main process).</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.wrap_model","title":"wrap_model","text":"<pre><code>wrap_model(model)\n</code></pre> <p>Wrap model for distributed training.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model to wrap.</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Module</code> <p>Wrapped model (DataParallel, DDP, or unchanged).</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def wrap_model(self, model: nn.Module) -&gt; nn.Module:\n    \"\"\"Wrap model for distributed training.\n\n    Args:\n        model: Model to wrap.\n\n    Returns:\n        Wrapped model (DataParallel, DDP, or unchanged).\n\n    \"\"\"\n    return model\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.prepare_data_loader","title":"prepare_data_loader","text":"<pre><code>prepare_data_loader(\n    dataset,\n    batch_size,\n    shuffle=False,\n    num_workers=0,\n    drop_last=False,\n    **kwargs,\n)\n</code></pre> <p>Prepare data loader with appropriate sampler for this distributor.</p> <p>For single device: uses default sampler For DataParallel: uses default sampler (data split happens in forward) For DDP: uses DistributedSampler to split data across processes</p> PARAMETER DESCRIPTION <code>dataset</code> <p>Dataset to load.</p> <p> TYPE: <code>Sequence</code> </p> <code>batch_size</code> <p>Batch size per device/process.</p> <p> TYPE: <code>int</code> </p> <code>shuffle</code> <p>Whether to shuffle data.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>num_workers</code> <p>Number of worker processes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>drop_last</code> <p>Whether to drop last incomplete batch.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional arguments for DataLoader.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DataLoader</code> <p>Configured DataLoader.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def prepare_data_loader(\n    self,\n    dataset: Sequence,\n    batch_size: int,\n    shuffle: bool = False,\n    num_workers: int = 0,\n    drop_last: bool = False,\n    **kwargs,\n) -&gt; torch.utils.data.DataLoader:\n    \"\"\"Prepare data loader with appropriate sampler for this distributor.\n\n    For single device: uses default sampler\n    For DataParallel: uses default sampler (data split happens in forward)\n    For DDP: uses DistributedSampler to split data across processes\n\n    Args:\n        dataset: Dataset to load.\n        batch_size: Batch size per device/process.\n        shuffle: Whether to shuffle data.\n        num_workers: Number of worker processes.\n        drop_last: Whether to drop last incomplete batch.\n        **kwargs: Additional arguments for DataLoader.\n\n    Returns:\n        Configured DataLoader.\n\n    \"\"\"\n    from torch.utils.data import DataLoader\n\n    return DataLoader(\n        dataset,  # type: ignore[arg-type]\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=num_workers,\n        drop_last=drop_last,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.reduce","title":"reduce  <code>abstractmethod</code>","text":"<pre><code>reduce(tensor, op='mean')\n</code></pre> <p>Reduce a tensor across devices/processes.</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Tensor to reduce.</p> <p> TYPE: <code>_TensorT</code> </p> <code>op</code> <p>Reduction operation (<code>\"mean\"</code> or <code>\"sum\"</code>).</p> <p> TYPE: <code>_ReduceOp</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>_TensorT</code> <p>Reduced tensor.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>@abc.abstractmethod\ndef reduce(self, tensor: _TensorT, op: _ReduceOp = \"mean\") -&gt; _TensorT:\n    \"\"\"Reduce a tensor across devices/processes.\n\n    Args:\n        tensor: Tensor to reduce.\n        op: Reduction operation (`\"mean\"` or `\"sum\"`).\n\n    Returns:\n        Reduced tensor.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.barrier","title":"barrier","text":"<pre><code>barrier()\n</code></pre> <p>Synchronize all processes.</p> <p>This is a no-op for single device and DataParallel. For DDP, it blocks until all processes reach this point.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def barrier(self) -&gt; None:\n    \"\"\"Synchronize all processes.\n\n    This is a no-op for single device and DataParallel.\n    For DDP, it blocks until all processes reach this point.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.all_gather","title":"all_gather","text":"<pre><code>all_gather(tensor)\n</code></pre> <p>Gather tensors from all processes.</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Tensor to gather.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>List of tensors from all processes.</p> <code>list[Tensor]</code> <p>For single device/DataParallel, returns [tensor].</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def all_gather(self, tensor: torch.Tensor) -&gt; list[torch.Tensor]:\n    \"\"\"Gather tensors from all processes.\n\n    Args:\n        tensor: Tensor to gather.\n\n    Returns:\n        List of tensors from all processes.\n        For single device/DataParallel, returns [tensor].\n\n    \"\"\"\n    return [tensor]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.BaseDistributor.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> <p>Cleanup resources (e.g., distributed process group).</p> <p>This is a no-op for single device and DataParallel. For DDP, destroys the process group.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Cleanup resources (e.g., distributed process group).\n\n    This is a no-op for single device and DataParallel.\n    For DDP, destroys the process group.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor","title":"SingleDeviceDistributor","text":"<pre><code>SingleDeviceDistributor(device=None)\n</code></pre> <p>               Bases: <code>BaseDistributor[ModelInputT]</code></p> <p>Distributor for single-device training.</p> <p>This distributor operates on a single device without any distribution. All shard, replicate, and unreplicate operations are no-ops.</p> PARAMETER DESCRIPTION <code>device</code> <p>Device to use (default: <code>\"cuda\"</code> if available, else <code>\"cpu\"</code>).</p> <p> TYPE: <code>Optional[Union[str, device]]</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; distributor = SingleDeviceDistributor(device=\"cuda:0\")\n&gt;&gt;&gt; model = model.to(distributor.device)\n</code></pre> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def __init__(self, device: Optional[Union[str, torch.device]] = None) -&gt; None:\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    self._device = torch.device(device)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.device","title":"device  <code>property</code>","text":"<pre><code>device\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.is_main_process","title":"is_main_process  <code>property</code>","text":"<pre><code>is_main_process\n</code></pre> <p>Whether this is the main process.</p> <p>The main process is responsible for: - Logging to console - Saving models and checkpoints - Writing metrics to file</p> RETURNS DESCRIPTION <code>bool</code> <p>True if this is the main process (rank 0), False otherwise.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.world_size","title":"world_size  <code>property</code>","text":"<pre><code>world_size\n</code></pre> <p>Total number of processes/devices.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of processes in distributed training, or 1 for single device.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.rank","title":"rank  <code>property</code>","text":"<pre><code>rank\n</code></pre> <p>Global rank of this process.</p> RETURNS DESCRIPTION <code>int</code> <p>Rank of this process (0 for main process).</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.reduce","title":"reduce","text":"<pre><code>reduce(tensor, op='mean')\n</code></pre> <p>Return tensor unchanged (no reduction needed for single device).</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Input tensor.</p> <p> TYPE: <code>_TensorT</code> </p> <code>op</code> <p>Reduction operation (ignored).</p> <p> TYPE: <code>_ReduceOp</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>_TensorT</code> <p>Input tensor unchanged.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def reduce(self, tensor: _TensorT, op: _ReduceOp = \"mean\") -&gt; _TensorT:\n    \"\"\"Return tensor unchanged (no reduction needed for single device).\n\n    Args:\n        tensor: Input tensor.\n        op: Reduction operation (ignored).\n\n    Returns:\n        Input tensor unchanged.\n\n    \"\"\"\n    return tensor\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.wrap_model","title":"wrap_model","text":"<pre><code>wrap_model(model)\n</code></pre> <p>Wrap model for distributed training.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model to wrap.</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Module</code> <p>Wrapped model (DataParallel, DDP, or unchanged).</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def wrap_model(self, model: nn.Module) -&gt; nn.Module:\n    \"\"\"Wrap model for distributed training.\n\n    Args:\n        model: Model to wrap.\n\n    Returns:\n        Wrapped model (DataParallel, DDP, or unchanged).\n\n    \"\"\"\n    return model\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.prepare_data_loader","title":"prepare_data_loader","text":"<pre><code>prepare_data_loader(\n    dataset,\n    batch_size,\n    shuffle=False,\n    num_workers=0,\n    drop_last=False,\n    **kwargs,\n)\n</code></pre> <p>Prepare data loader with appropriate sampler for this distributor.</p> <p>For single device: uses default sampler For DataParallel: uses default sampler (data split happens in forward) For DDP: uses DistributedSampler to split data across processes</p> PARAMETER DESCRIPTION <code>dataset</code> <p>Dataset to load.</p> <p> TYPE: <code>Sequence</code> </p> <code>batch_size</code> <p>Batch size per device/process.</p> <p> TYPE: <code>int</code> </p> <code>shuffle</code> <p>Whether to shuffle data.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>num_workers</code> <p>Number of worker processes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>drop_last</code> <p>Whether to drop last incomplete batch.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional arguments for DataLoader.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DataLoader</code> <p>Configured DataLoader.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def prepare_data_loader(\n    self,\n    dataset: Sequence,\n    batch_size: int,\n    shuffle: bool = False,\n    num_workers: int = 0,\n    drop_last: bool = False,\n    **kwargs,\n) -&gt; torch.utils.data.DataLoader:\n    \"\"\"Prepare data loader with appropriate sampler for this distributor.\n\n    For single device: uses default sampler\n    For DataParallel: uses default sampler (data split happens in forward)\n    For DDP: uses DistributedSampler to split data across processes\n\n    Args:\n        dataset: Dataset to load.\n        batch_size: Batch size per device/process.\n        shuffle: Whether to shuffle data.\n        num_workers: Number of worker processes.\n        drop_last: Whether to drop last incomplete batch.\n        **kwargs: Additional arguments for DataLoader.\n\n    Returns:\n        Configured DataLoader.\n\n    \"\"\"\n    from torch.utils.data import DataLoader\n\n    return DataLoader(\n        dataset,  # type: ignore[arg-type]\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=num_workers,\n        drop_last=drop_last,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.barrier","title":"barrier","text":"<pre><code>barrier()\n</code></pre> <p>Synchronize all processes.</p> <p>This is a no-op for single device and DataParallel. For DDP, it blocks until all processes reach this point.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def barrier(self) -&gt; None:\n    \"\"\"Synchronize all processes.\n\n    This is a no-op for single device and DataParallel.\n    For DDP, it blocks until all processes reach this point.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.all_gather","title":"all_gather","text":"<pre><code>all_gather(tensor)\n</code></pre> <p>Gather tensors from all processes.</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Tensor to gather.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>List of tensors from all processes.</p> <code>list[Tensor]</code> <p>For single device/DataParallel, returns [tensor].</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def all_gather(self, tensor: torch.Tensor) -&gt; list[torch.Tensor]:\n    \"\"\"Gather tensors from all processes.\n\n    Args:\n        tensor: Tensor to gather.\n\n    Returns:\n        List of tensors from all processes.\n        For single device/DataParallel, returns [tensor].\n\n    \"\"\"\n    return [tensor]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.SingleDeviceDistributor.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> <p>Cleanup resources (e.g., distributed process group).</p> <p>This is a no-op for single device and DataParallel. For DDP, destroys the process group.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Cleanup resources (e.g., distributed process group).\n\n    This is a no-op for single device and DataParallel.\n    For DDP, destroys the process group.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor","title":"DataParallelDistributor","text":"<pre><code>DataParallelDistributor(\n    device_ids=None, output_device=None\n)\n</code></pre> <p>               Bases: <code>BaseDistributor[ModelInputT]</code></p> <p>Distributor for data-parallel training across multiple GPUs.</p> <p>This distributor uses <code>torch.nn.DataParallel</code> to execute the same computation on different data shards across multiple GPUs. Data is automatically sharded along the batch dimension.</p> PARAMETER DESCRIPTION <code>device_ids</code> <p>List of GPU device IDs to use. Defaults to all available GPUs.</p> <p> TYPE: <code>Optional[list[int]]</code> DEFAULT: <code>None</code> </p> <code>output_device</code> <p>Device for outputs. Defaults to device_ids[0].</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Train on GPUs 0 and 1 with data parallelism\n&gt;&gt;&gt; distributor = DataParallelDistributor(device_ids=[0, 1])\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Wrap model for data parallel training\n&gt;&gt;&gt; model = distributor.wrap_model(model)\n</code></pre> Note <p>Batch size must be divisible by the number of devices for proper sharding.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def __init__(\n    self,\n    device_ids: Optional[list[int]] = None,\n    output_device: Optional[int] = None,\n) -&gt; None:\n    if device_ids is None:\n        device_ids = list(range(torch.cuda.device_count()))\n    if not device_ids:\n        raise ValueError(\"No GPU devices available for DataParallelDistributor\")\n\n    self._device_ids = device_ids\n    self._output_device = output_device if output_device is not None else device_ids[0]\n    self._device = torch.device(f\"cuda:{self._output_device}\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.device","title":"device  <code>property</code>","text":"<pre><code>device\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.is_main_process","title":"is_main_process  <code>property</code>","text":"<pre><code>is_main_process\n</code></pre> <p>Whether this is the main process.</p> <p>The main process is responsible for: - Logging to console - Saving models and checkpoints - Writing metrics to file</p> RETURNS DESCRIPTION <code>bool</code> <p>True if this is the main process (rank 0), False otherwise.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.world_size","title":"world_size  <code>property</code>","text":"<pre><code>world_size\n</code></pre> <p>Total number of processes/devices.</p> RETURNS DESCRIPTION <code>int</code> <p>Number of processes in distributed training, or 1 for single device.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.rank","title":"rank  <code>property</code>","text":"<pre><code>rank\n</code></pre> <p>Global rank of this process.</p> RETURNS DESCRIPTION <code>int</code> <p>Rank of this process (0 for main process).</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.wrap_model","title":"wrap_model","text":"<pre><code>wrap_model(model)\n</code></pre> <p>Wrap model with <code>DataParallel</code>.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model to wrap.</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Module</code> <p><code>DataParallel</code> wrapped model.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def wrap_model(self, model: nn.Module) -&gt; nn.Module:\n    \"\"\"Wrap model with `DataParallel`.\n\n    Args:\n        model: Model to wrap.\n\n    Returns:\n        `DataParallel` wrapped model.\n\n    \"\"\"\n    return cast(nn.Module, nn.DataParallel(model, device_ids=self._device_ids, output_device=self._output_device))\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.reduce","title":"reduce","text":"<pre><code>reduce(tensor, op='mean')\n</code></pre> <p>Reduce tensor across devices.</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Tensor to reduce across device dimension.</p> <p> TYPE: <code>_TensorT</code> </p> <code>op</code> <p>Reduction operation - <code>\"sum\"</code> or <code>\"mean\"</code>.</p> <p> TYPE: <code>_ReduceOp</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>_TensorT</code> <p>Reduced tensor.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported reduction operation is specified.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def reduce(self, tensor: _TensorT, op: _ReduceOp = \"mean\") -&gt; _TensorT:\n    \"\"\"Reduce tensor across devices.\n\n    Args:\n        tensor: Tensor to reduce across device dimension.\n        op: Reduction operation - `\"sum\"` or `\"mean\"`.\n\n    Returns:\n        Reduced tensor.\n\n    Raises:\n        ValueError: If unsupported reduction operation is specified.\n\n    \"\"\"\n    if op == \"sum\":\n        return cast(_TensorT, tensor.sum())\n    elif op == \"mean\":\n        return cast(_TensorT, tensor.mean())\n    raise ValueError(f\"Unsupported reduce operation: {op}\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.prepare_data_loader","title":"prepare_data_loader","text":"<pre><code>prepare_data_loader(\n    dataset,\n    batch_size,\n    shuffle=False,\n    num_workers=0,\n    drop_last=False,\n    **kwargs,\n)\n</code></pre> <p>Prepare data loader with appropriate sampler for this distributor.</p> <p>For single device: uses default sampler For DataParallel: uses default sampler (data split happens in forward) For DDP: uses DistributedSampler to split data across processes</p> PARAMETER DESCRIPTION <code>dataset</code> <p>Dataset to load.</p> <p> TYPE: <code>Sequence</code> </p> <code>batch_size</code> <p>Batch size per device/process.</p> <p> TYPE: <code>int</code> </p> <code>shuffle</code> <p>Whether to shuffle data.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>num_workers</code> <p>Number of worker processes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>drop_last</code> <p>Whether to drop last incomplete batch.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional arguments for DataLoader.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DataLoader</code> <p>Configured DataLoader.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def prepare_data_loader(\n    self,\n    dataset: Sequence,\n    batch_size: int,\n    shuffle: bool = False,\n    num_workers: int = 0,\n    drop_last: bool = False,\n    **kwargs,\n) -&gt; torch.utils.data.DataLoader:\n    \"\"\"Prepare data loader with appropriate sampler for this distributor.\n\n    For single device: uses default sampler\n    For DataParallel: uses default sampler (data split happens in forward)\n    For DDP: uses DistributedSampler to split data across processes\n\n    Args:\n        dataset: Dataset to load.\n        batch_size: Batch size per device/process.\n        shuffle: Whether to shuffle data.\n        num_workers: Number of worker processes.\n        drop_last: Whether to drop last incomplete batch.\n        **kwargs: Additional arguments for DataLoader.\n\n    Returns:\n        Configured DataLoader.\n\n    \"\"\"\n    from torch.utils.data import DataLoader\n\n    return DataLoader(\n        dataset,  # type: ignore[arg-type]\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=num_workers,\n        drop_last=drop_last,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.barrier","title":"barrier","text":"<pre><code>barrier()\n</code></pre> <p>Synchronize all processes.</p> <p>This is a no-op for single device and DataParallel. For DDP, it blocks until all processes reach this point.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def barrier(self) -&gt; None:\n    \"\"\"Synchronize all processes.\n\n    This is a no-op for single device and DataParallel.\n    For DDP, it blocks until all processes reach this point.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.all_gather","title":"all_gather","text":"<pre><code>all_gather(tensor)\n</code></pre> <p>Gather tensors from all processes.</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Tensor to gather.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>List of tensors from all processes.</p> <code>list[Tensor]</code> <p>For single device/DataParallel, returns [tensor].</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def all_gather(self, tensor: torch.Tensor) -&gt; list[torch.Tensor]:\n    \"\"\"Gather tensors from all processes.\n\n    Args:\n        tensor: Tensor to gather.\n\n    Returns:\n        List of tensors from all processes.\n        For single device/DataParallel, returns [tensor].\n\n    \"\"\"\n    return [tensor]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DataParallelDistributor.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> <p>Cleanup resources (e.g., distributed process group).</p> <p>This is a no-op for single device and DataParallel. For DDP, destroys the process group.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Cleanup resources (e.g., distributed process group).\n\n    This is a no-op for single device and DataParallel.\n    For DDP, destroys the process group.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor","title":"DistributedDataParallelDistributor","text":"<pre><code>DistributedDataParallelDistributor(\n    backend=None,\n    init_method=\"env://\",\n    world_size=None,\n    rank=None,\n    local_rank=None,\n    find_unused_parameters=False,\n    broadcast_buffers=True,\n    bucket_cap_mb=25,\n)\n</code></pre> <p>               Bases: <code>BaseDistributor[ModelInputT]</code></p> <p>Distributor for distributed data-parallel training using DDP.</p> <p>This distributor uses torch.nn.parallel.DistributedDataParallel to execute training across multiple processes and devices. This is more efficient than DataParallel for multi-GPU training as it uses one process per GPU.</p> PARAMETER DESCRIPTION <code>backend</code> <p>Backend to use for distributed training (<code>\"nccl\"</code>, <code>\"gloo\"</code>, <code>\"mpi\"</code>). Defaults to <code>\"nccl\"</code> for GPU and <code>\"gloo\"</code> for CPU.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>init_method</code> <p>URL specifying how to initialize the process group. Defaults to <code>\"env://\"</code> which uses environment variables.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'env://'</code> </p> <code>world_size</code> <p>Total number of processes. If <code>None</code>, reads from environment.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>rank</code> <p>Rank of this process. If None, reads from environment.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>local_rank</code> <p>Local rank on this machine. If <code>None</code>, uses rank.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>find_unused_parameters</code> <p>Whether to find unused parameters. Default <code>False</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>broadcast_buffers</code> <p>Whether to broadcast buffers. Default <code>True</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>bucket_cap_mb</code> <p>Bucket size in MB for gradient allreduce. Default <code>25</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>25</code> </p> Environment Variables <ul> <li><code>RANK</code>: Global rank of the process</li> <li><code>LOCAL_RANK</code>: Local rank on the machine</li> <li><code>WORLD_SIZE</code>: Total number of processes</li> <li><code>MASTER_ADDR</code>: Address of the master node</li> <li><code>MASTER_PORT</code>: Port of the master node</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # On each process, initialize the distributor\n&gt;&gt;&gt; distributor = DistributedDataParallelDistributor(\n...     backend=\"nccl\",\n...     init_method=\"env://\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Wrap model with DDP\n&gt;&gt;&gt; model = distributor.wrap_model(model)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Train as usual - gradients are automatically synchronized\n</code></pre> Note <ul> <li>Requires launching multiple processes (e.g., using <code>torch.distributed.launch</code>)</li> <li>Each process should initialize its own distributor</li> <li>Batch size should be per-process batch size</li> </ul> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def __init__(\n    self,\n    backend: Optional[str] = None,\n    init_method: str = \"env://\",\n    world_size: Optional[int] = None,\n    rank: Optional[int] = None,\n    local_rank: Optional[int] = None,\n    find_unused_parameters: bool = False,\n    broadcast_buffers: bool = True,\n    bucket_cap_mb: int = 25,\n) -&gt; None:\n    import os\n\n    import torch.distributed as dist\n\n    # Determine backend\n    if backend is None:\n        backend = \"nccl\" if torch.cuda.is_available() else \"gloo\"\n\n    # Get rank and world_size from environment if not provided\n    if rank is None:\n        rank = int(os.environ.get(\"RANK\", 0))\n    if world_size is None:\n        world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n    if local_rank is None:\n        local_rank = int(os.environ.get(\"LOCAL_RANK\", rank))\n\n    self._backend = backend\n    self._init_method = init_method\n    self._world_size = world_size\n    self._rank = rank\n    self._local_rank = local_rank\n    self._find_unused_parameters = find_unused_parameters\n    self._broadcast_buffers = broadcast_buffers\n    self._bucket_cap_mb = bucket_cap_mb\n\n    # Initialize process group if not already initialized\n    if not dist.is_initialized():\n        try:\n            dist.init_process_group(\n                backend=backend,\n                init_method=init_method,\n                world_size=world_size,\n                rank=rank,\n            )\n        except Exception as e:\n            raise RuntimeError(\n                f\"Failed to initialize distributed process group. \"\n                f\"Backend: {backend}, init_method: {init_method}, \"\n                f\"world_size: {world_size}, rank: {rank}. \"\n                f\"Error: {e}. \"\n                \"Please ensure all processes are launched correctly using torchrun \"\n                \"and required environment variables (RANK, WORLD_SIZE, MASTER_ADDR, MASTER_PORT) are set.\"\n            ) from e\n\n    # Set device based on local rank\n    if torch.cuda.is_available():\n        self._device = torch.device(f\"cuda:{local_rank}\")\n        torch.cuda.set_device(self._device)\n    else:\n        self._device = torch.device(\"cpu\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.device","title":"device  <code>property</code>","text":"<pre><code>device\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.is_main_process","title":"is_main_process  <code>property</code>","text":"<pre><code>is_main_process\n</code></pre> <p>Whether this is the main process (rank 0).</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.rank","title":"rank  <code>property</code>","text":"<pre><code>rank\n</code></pre> <p>Global rank of this process.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.local_rank","title":"local_rank  <code>property</code>","text":"<pre><code>local_rank\n</code></pre> <p>Local rank on this machine.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.world_size","title":"world_size  <code>property</code>","text":"<pre><code>world_size\n</code></pre> <p>Total number of processes.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.wrap_model","title":"wrap_model","text":"<pre><code>wrap_model(model)\n</code></pre> <p>Wrap model with DistributedDataParallel.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model to wrap.</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Module</code> <p>DDP wrapped model.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def wrap_model(self, model: nn.Module) -&gt; nn.Module:\n    \"\"\"Wrap model with DistributedDataParallel.\n\n    Args:\n        model: Model to wrap.\n\n    Returns:\n        DDP wrapped model.\n\n    \"\"\"\n    return cast(\n        nn.Module,\n        nn.parallel.DistributedDataParallel(\n            model,\n            device_ids=[self._local_rank] if torch.cuda.is_available() else None,\n            output_device=self._local_rank if torch.cuda.is_available() else None,\n            find_unused_parameters=self._find_unused_parameters,\n            broadcast_buffers=self._broadcast_buffers,\n            bucket_cap_mb=self._bucket_cap_mb,\n        ),\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.prepare_data_loader","title":"prepare_data_loader","text":"<pre><code>prepare_data_loader(\n    dataset,\n    batch_size,\n    shuffle=False,\n    num_workers=0,\n    drop_last=False,\n    **kwargs,\n)\n</code></pre> <p>Prepare data loader with DistributedSampler for DDP.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>Dataset to load.</p> <p> TYPE: <code>Sequence</code> </p> <code>batch_size</code> <p>Batch size per process.</p> <p> TYPE: <code>int</code> </p> <code>shuffle</code> <p>Whether to shuffle data.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>num_workers</code> <p>Number of worker processes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>drop_last</code> <p>Whether to drop last incomplete batch.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional arguments for DataLoader.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>DataLoader</code> <p>DataLoader with DistributedSampler.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def prepare_data_loader(\n    self,\n    dataset: Sequence,\n    batch_size: int,\n    shuffle: bool = False,\n    num_workers: int = 0,\n    drop_last: bool = False,\n    **kwargs,\n) -&gt; torch.utils.data.DataLoader:\n    \"\"\"Prepare data loader with DistributedSampler for DDP.\n\n    Args:\n        dataset: Dataset to load.\n        batch_size: Batch size per process.\n        shuffle: Whether to shuffle data.\n        num_workers: Number of worker processes.\n        drop_last: Whether to drop last incomplete batch.\n        **kwargs: Additional arguments for DataLoader.\n\n    Returns:\n        DataLoader with DistributedSampler.\n\n    \"\"\"\n    from torch.utils.data import DataLoader\n    from torch.utils.data.distributed import DistributedSampler\n\n    sampler = DistributedSampler(\n        dataset,  # type: ignore[arg-type]\n        num_replicas=self._world_size,\n        rank=self._rank,\n        shuffle=shuffle,\n        drop_last=drop_last,\n    )\n\n    return DataLoader(\n        dataset,  # type: ignore[arg-type]\n        batch_size=batch_size,\n        sampler=sampler,\n        num_workers=num_workers,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.reduce","title":"reduce","text":"<pre><code>reduce(tensor, op='mean')\n</code></pre> <p>Reduce tensor across all processes.</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Tensor to reduce.</p> <p> TYPE: <code>_TensorT</code> </p> <code>op</code> <p>Reduction operation - <code>\"sum\"</code> or <code>\"mean\"</code>.</p> <p> TYPE: <code>_ReduceOp</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>_TensorT</code> <p>Reduced tensor.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If unsupported reduction operation is specified.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def reduce(self, tensor: _TensorT, op: _ReduceOp = \"mean\") -&gt; _TensorT:\n    \"\"\"Reduce tensor across all processes.\n\n    Args:\n        tensor: Tensor to reduce.\n        op: Reduction operation - `\"sum\"` or `\"mean\"`.\n\n    Returns:\n        Reduced tensor.\n\n    Raises:\n        ValueError: If unsupported reduction operation is specified.\n\n    \"\"\"\n    import torch.distributed as dist\n\n    if op == \"sum\":\n        dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n        return tensor\n    elif op == \"mean\":\n        dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n        return cast(_TensorT, tensor / self._world_size)\n    raise ValueError(f\"Unsupported reduce operation: {op}\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.all_gather","title":"all_gather","text":"<pre><code>all_gather(tensor)\n</code></pre> <p>Gather tensors from all processes.</p> PARAMETER DESCRIPTION <code>tensor</code> <p>Tensor to gather.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>List of tensors from all processes.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def all_gather(self, tensor: torch.Tensor) -&gt; list[torch.Tensor]:\n    \"\"\"Gather tensors from all processes.\n\n    Args:\n        tensor: Tensor to gather.\n\n    Returns:\n        List of tensors from all processes.\n\n    \"\"\"\n    import torch.distributed as dist\n\n    gathered = [torch.zeros_like(tensor) for _ in range(self._world_size)]\n    dist.all_gather(gathered, tensor)\n    return gathered\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.barrier","title":"barrier","text":"<pre><code>barrier()\n</code></pre> <p>Synchronize all processes.</p> <p>This creates a barrier that blocks until all processes reach this point.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def barrier(self) -&gt; None:\n    \"\"\"Synchronize all processes.\n\n    This creates a barrier that blocks until all processes reach this point.\n\n    \"\"\"\n    import torch.distributed as dist\n\n    dist.barrier()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.distributors.DistributedDataParallelDistributor.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> <p>Cleanup distributed process group.</p> <p>This should be called at the end of training.</p> Source code in <code>src/formed/integrations/torch/distributors.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Cleanup distributed process group.\n\n    This should be called at the end of training.\n\n    \"\"\"\n    import torch.distributed as dist\n\n    if dist.is_initialized():\n        dist.destroy_process_group()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers","title":"formed.integrations.torch.initializers","text":""},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.BaseTensorInitializer","title":"BaseTensorInitializer","text":"<p>               Bases: <code>Registrable</code></p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.UniformTensorInitializer","title":"UniformTensorInitializer","text":"<pre><code>UniformTensorInitializer(shape, low=0.0, high=1.0)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int], low: float = 0.0, high: float = 1.0):\n    self._shape = shape\n    self._low = low\n    self._high = high\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.NormalTensorInitializer","title":"NormalTensorInitializer","text":"<pre><code>NormalTensorInitializer(shape, mean=0.0, std=1.0)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int], mean: float = 0.0, std: float = 1.0):\n    self._shape = shape\n    self._mean = mean\n    self._std = std\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.XavierUniformTensorInitializer","title":"XavierUniformTensorInitializer","text":"<pre><code>XavierUniformTensorInitializer(shape, gain=1.0)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int], gain: float = 1.0):\n    self._shape = shape\n    self._gain = gain\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.XavierNormalTensorInitializer","title":"XavierNormalTensorInitializer","text":"<pre><code>XavierNormalTensorInitializer(shape, gain=1.0)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int], gain: float = 1.0):\n    self._shape = shape\n    self._gain = gain\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.KaimingUniformTensorInitializer","title":"KaimingUniformTensorInitializer","text":"<pre><code>KaimingUniformTensorInitializer(\n    shape, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\"\n)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(\n    self,\n    shape: Sequence[int],\n    a: float = 0,\n    mode: torch.nn.init._FanMode = \"fan_in\",\n    nonlinearity: torch.nn.init._NonlinearityType = \"leaky_relu\",\n):\n    self._shape = shape\n    self._a = a\n    self._mode: torch.nn.init._FanMode = mode\n    self._nonlinearity: torch.nn.init._NonlinearityType = nonlinearity\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.KaimingNormalTensorInitializer","title":"KaimingNormalTensorInitializer","text":"<pre><code>KaimingNormalTensorInitializer(\n    shape, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\"\n)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(\n    self,\n    shape: Sequence[int],\n    a: float = 0,\n    mode: torch.nn.init._FanMode = \"fan_in\",\n    nonlinearity: torch.nn.init._NonlinearityType = \"leaky_relu\",\n):\n    self._shape = shape\n    self._a = a\n    self._mode: torch.nn.init._FanMode = mode\n    self._nonlinearity: torch.nn.init._NonlinearityType = nonlinearity\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.OrthogonalTensorInitializer","title":"OrthogonalTensorInitializer","text":"<pre><code>OrthogonalTensorInitializer(shape, gain=1.0)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int], gain: float = 1.0):\n    self._shape = shape\n    self._gain = gain\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.SparseTensorInitializer","title":"SparseTensorInitializer","text":"<pre><code>SparseTensorInitializer(shape, sparsity=0.1, std=0.01)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int], sparsity: float = 0.1, std: float = 0.01):\n    self._shape = shape\n    self._sparsity = sparsity\n    self._std = std\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.ZerosTensorInitializer","title":"ZerosTensorInitializer","text":"<pre><code>ZerosTensorInitializer(shape)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int]):\n    self._shape = shape\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.initializers.OnesTensorInitializer","title":"OnesTensorInitializer","text":"<pre><code>OnesTensorInitializer(shape)\n</code></pre> <p>               Bases: <code>BaseTensorInitializer</code></p> Source code in <code>src/formed/integrations/torch/initializers.py</code> <pre><code>def __init__(self, shape: Sequence[int]):\n    self._shape = shape\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.model","title":"formed.integrations.torch.model","text":"<p>Base model abstraction for PyTorch models.</p> <p>This module provides the base class for all PyTorch models in the framework, integrating torch.nn.Module with the registrable pattern for configuration-based model instantiation.</p> Key Features <ul> <li>Integration with PyTorch Module system</li> <li>Registrable pattern for configuration-based instantiation</li> <li>Generic type support for inputs, outputs, and parameters</li> <li>Compatible with TorchTrainer for end-to-end training</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import BaseTorchModel\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import torch.nn as nn\n&gt;&gt;&gt;\n&gt;&gt;&gt; @BaseTorchModel.register(\"my_model\")\n... class MyModel(BaseTorchModel[dict, torch.Tensor, None]):\n...     def __init__(self, hidden_dim: int):\n...         super().__init__()\n...         self.linear = nn.Linear(10, hidden_dim)\n...\n...     def forward(self, inputs: dict, params: None = None) -&gt; torch.Tensor:\n...         return self.linear(inputs[\"features\"])\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.model.BaseTorchModel","title":"BaseTorchModel","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>Base class for all PyTorch models in the framework.</p> <p>This class combines PyTorch's nn.Module with the registrable pattern, allowing models to be instantiated from configuration files and seamlessly integrated with the training infrastructure.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ModelInputT</code> <p>Type of input data to the model.</p> <p> </p> <code>ModelOutputT</code> <p>Type of model output.</p> <p> </p> <code>ModelParamsT</code> <p>Type of additional parameters (typically None or a dataclass).</p> <p> </p> Note <p>Subclasses should implement <code>forward()</code> to define the forward pass. Models are automatically compatible with <code>TorchTrainer</code> when registered.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.model.BaseTorchModel.forward","title":"forward","text":"<pre><code>forward(inputs, params=None)\n</code></pre> <p>Forward pass of the model.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input data to the model.</p> <p> TYPE: <code>ModelInputT</code> </p> <code>params</code> <p>Optional additional parameters for the forward pass.</p> <p> TYPE: <code>ModelParamsT | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ModelOutputT</code> <p>Model output.</p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>This method must be implemented by subclasses.</p> Source code in <code>src/formed/integrations/torch/model.py</code> <pre><code>def forward(self, inputs: ModelInputT, params: ModelParamsT | None = None) -&gt; ModelOutputT:\n    \"\"\"Forward pass of the model.\n\n    Args:\n        inputs: Input data to the model.\n        params: Optional additional parameters for the forward pass.\n\n    Returns:\n        Model output.\n\n    Raises:\n        NotImplementedError: This method must be implemented by subclasses.\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers","title":"formed.integrations.torch.schedulers","text":"<p>Learning rate schedulers for PyTorch models.</p> <p>This module provides custom learning rate schedulers that extend PyTorch's standard scheduler functionality, including cosine annealing with warm restarts and warmup phases.</p> Available Schedulers <ul> <li><code>CosineLRScheduler</code>: Cosine annealing with optional restarts and warmup</li> </ul> Features <ul> <li>Cosine decay with configurable cycle length</li> <li>Warm restarts with cycle multiplier</li> <li>Learning rate warmup phase</li> <li>Cycle-based decay multiplier</li> <li>Compatible with Colt registration system</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.schedulers import CosineLRScheduler\n&gt;&gt;&gt;\n&gt;&gt;&gt; scheduler = CosineLRScheduler(\n...     optimizer,\n...     t_initial=100,\n...     lr_min=1e-6,\n...     warmup_t=5,\n...     warmup_lr_init=1e-5\n... )\n&gt;&gt;&gt; for epoch in range(num_epochs):\n...     train(...)\n...     scheduler.step(epoch + 1)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler","title":"CosineLRScheduler","text":"<pre><code>CosineLRScheduler(\n    optimizer,\n    t_initial,\n    lr_min=0.0,\n    cycle_mul=1.0,\n    cycle_decay=1.0,\n    cycle_limit=1,\n    warmup_t=0,\n    warmup_lr_init=0.0,\n    warmup_prefix=False,\n    t_in_epochs=True,\n    last_epoch=-1,\n)\n</code></pre> <p>               Bases: <code>LRScheduler</code></p> <p>Cosine annealing learning rate scheduler with warm restarts.</p> <p>Implements the SGDR (Stochastic Gradient Descent with Warm Restarts) algorithm described in https://arxiv.org/abs/1608.03983.</p> <p>This scheduler decreases the learning rate following a cosine curve, optionally restarting the schedule multiple times during training. It also supports a warmup phase at the beginning.</p> PARAMETER DESCRIPTION <code>optimizer</code> <p>Wrapped optimizer.</p> <p> TYPE: <code>Optimizer</code> </p> <code>t_initial</code> <p>Number of iterations/epochs for the first cycle.</p> <p> TYPE: <code>int</code> </p> <code>lr_min</code> <p>Minimum learning rate. Default: <code>0</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>cycle_mul</code> <p>Multiplier for cycle length after each restart. Default: <code>1.0</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>cycle_decay</code> <p>Decay factor applied to learning rate at each restart. Default: <code>1.0</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <code>cycle_limit</code> <p>Maximum number of restart cycles (0 means no limit). Default: <code>1</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>warmup_t</code> <p>Number of warmup iterations/epochs. Default: <code>0</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>warmup_lr_init</code> <p>Initial learning rate during warmup. Default: <code>0</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>warmup_prefix</code> <p>If <code>True</code>, warmup iterations don't count toward t_initial. Default: <code>False</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>t_in_epochs</code> <p>If <code>True</code>, t values are in epochs; otherwise in iterations. Default: <code>True</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>last_epoch</code> <p>The index of last epoch. Default: <code>-1</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create scheduler with 100 epoch cycles and 5 epoch warmup\n&gt;&gt;&gt; scheduler = CosineLRScheduler(\n...     optimizer,\n...     t_initial=100,\n...     lr_min=1e-6,\n...     cycle_mul=2.0,  # Each cycle is 2x longer\n...     warmup_t=5,\n...     warmup_lr_init=1e-5\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Update learning rate each epoch\n&gt;&gt;&gt; for epoch in range(num_epochs):\n...     train_one_epoch(...)\n...     scheduler.step(epoch + 1)\n</code></pre> Source code in <code>src/formed/integrations/torch/schedulers.py</code> <pre><code>def __init__(\n    self,\n    optimizer: optim.Optimizer,\n    t_initial: int,\n    lr_min: float = 0.0,\n    cycle_mul: float = 1.0,\n    cycle_decay: float = 1.0,\n    cycle_limit: int = 1,\n    warmup_t: int = 0,\n    warmup_lr_init: float = 0.0,\n    warmup_prefix: bool = False,\n    t_in_epochs: bool = True,\n    last_epoch: int = -1,\n) -&gt; None:\n    assert t_initial &gt; 0, \"t_initial must be positive\"\n    assert lr_min &gt;= 0, \"lr_min must be non-negative\"\n\n    self.t_initial = t_initial\n    self.lr_min = lr_min\n    self.cycle_mul = cycle_mul\n    self.cycle_decay = cycle_decay\n    self.cycle_limit = cycle_limit\n    self.warmup_t = warmup_t\n    self.warmup_lr_init = warmup_lr_init\n    self.warmup_prefix = warmup_prefix\n    self.t_in_epochs = t_in_epochs\n\n    # Store base learning rates\n    self.base_lrs = [group[\"lr\"] for group in optimizer.param_groups]\n\n    # Initialize warmup steps\n    if self.warmup_t:\n        self.warmup_steps = [(base_lr - warmup_lr_init) / self.warmup_t for base_lr in self.base_lrs]\n    else:\n        self.warmup_steps = [1.0 for _ in self.base_lrs]\n\n    super().__init__(optimizer, last_epoch)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.t_initial","title":"t_initial  <code>instance-attribute</code>","text":"<pre><code>t_initial = t_initial\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.lr_min","title":"lr_min  <code>instance-attribute</code>","text":"<pre><code>lr_min = lr_min\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_mul","title":"cycle_mul  <code>instance-attribute</code>","text":"<pre><code>cycle_mul = cycle_mul\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_decay","title":"cycle_decay  <code>instance-attribute</code>","text":"<pre><code>cycle_decay = cycle_decay\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.cycle_limit","title":"cycle_limit  <code>instance-attribute</code>","text":"<pre><code>cycle_limit = cycle_limit\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_t","title":"warmup_t  <code>instance-attribute</code>","text":"<pre><code>warmup_t = warmup_t\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_lr_init","title":"warmup_lr_init  <code>instance-attribute</code>","text":"<pre><code>warmup_lr_init = warmup_lr_init\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_prefix","title":"warmup_prefix  <code>instance-attribute</code>","text":"<pre><code>warmup_prefix = warmup_prefix\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.t_in_epochs","title":"t_in_epochs  <code>instance-attribute</code>","text":"<pre><code>t_in_epochs = t_in_epochs\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.base_lrs","title":"base_lrs  <code>instance-attribute</code>","text":"<pre><code>base_lrs = [(group['lr']) for group in (param_groups)]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.warmup_steps","title":"warmup_steps  <code>instance-attribute</code>","text":"<pre><code>warmup_steps = [\n    ((base_lr - warmup_lr_init) / warmup_t)\n    for base_lr in (base_lrs)\n]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.get_lr","title":"get_lr","text":"<pre><code>get_lr()\n</code></pre> <p>Compute learning rate at the current step.</p> RETURNS DESCRIPTION <code>list[float]</code> <p>List of learning rates for each parameter group.</p> Source code in <code>src/formed/integrations/torch/schedulers.py</code> <pre><code>def get_lr(self) -&gt; list[float]:\n    \"\"\"Compute learning rate at the current step.\n\n    Returns:\n        List of learning rates for each parameter group.\n\n    \"\"\"\n    # Current timestep (starts from 0 after first step())\n    t = self.last_epoch\n\n    # Warmup phase: linearly interpolate from warmup_lr_init to base_lr\n    if t &lt; self.warmup_t:\n        lrs = [self.warmup_lr_init + (t + 1) * step for step in self.warmup_steps]\n        return lrs\n\n    # Adjust t if warmup is a prefix\n    if self.warmup_prefix:\n        t = t - self.warmup_t\n\n    # Determine current cycle\n    if self.cycle_mul == 1.0:\n        # Simple case: equal cycles\n        cycle = t // self.t_initial\n        t_curr = t % self.t_initial\n        t_i = self.t_initial\n    else:\n        # Geometric progression of cycle lengths\n        # Find which cycle we're in using logarithmic calculation\n        cycle = int(math.log(1 - t / self.t_initial * (1 - self.cycle_mul), self.cycle_mul))\n        # Compute cumulative time up to current cycle\n        t_prev = self.t_initial * (1 - self.cycle_mul**cycle) / (1 - self.cycle_mul)\n        t_curr = t - t_prev\n        t_i = self.t_initial * (self.cycle_mul**cycle)\n\n    # Apply cycle limit\n    if self.cycle_limit &gt; 0 and cycle &gt;= self.cycle_limit:\n        return [self.lr_min for _ in self.base_lrs]\n\n    # Compute cycle decay\n    cycle_decay = self.cycle_decay**cycle\n\n    # Cosine annealing\n    lrs = [\n        self.lr_min + (base_lr - self.lr_min) * cycle_decay * 0.5 * (1 + math.cos(math.pi * t_curr / t_i))\n        for base_lr in self.base_lrs\n    ]\n\n    return lrs\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.get_cycle_length","title":"get_cycle_length","text":"<pre><code>get_cycle_length(cycles=0)\n</code></pre> <p>Calculate total number of iterations for a given number of cycles.</p> PARAMETER DESCRIPTION <code>cycles</code> <p>Number of cycles (<code>0</code> means current cycle).</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>int</code> <p>Total number of iterations.</p> Source code in <code>src/formed/integrations/torch/schedulers.py</code> <pre><code>def get_cycle_length(self, cycles: int = 0) -&gt; int:\n    \"\"\"Calculate total number of iterations for a given number of cycles.\n\n    Args:\n        cycles: Number of cycles (`0` means current cycle).\n\n    Returns:\n        Total number of iterations.\n\n    \"\"\"\n    if cycles &lt;= 0:\n        cycles = self.cycle_limit if self.cycle_limit &gt; 0 else 1\n\n    if self.cycle_mul == 1.0:\n        length = self.t_initial * cycles\n    else:\n        length = int(self.t_initial * (1 - self.cycle_mul**cycles) / (1 - self.cycle_mul))\n\n    if self.warmup_prefix:\n        length += self.warmup_t\n\n    return length\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.state_dict","title":"state_dict","text":"<pre><code>state_dict()\n</code></pre> <p>Return the state of the scheduler as a dict.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>Dictionary containing scheduler state.</p> Source code in <code>src/formed/integrations/torch/schedulers.py</code> <pre><code>def state_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Return the state of the scheduler as a dict.\n\n    Returns:\n        Dictionary containing scheduler state.\n\n    \"\"\"\n    state = {\n        key: value\n        for key, value in self.__dict__.items()\n        if key not in (\"optimizer\", \"_get_lr_called_within_step\", \"_step_count\")\n    }\n    return state\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.schedulers.CosineLRScheduler.load_state_dict","title":"load_state_dict","text":"<pre><code>load_state_dict(state_dict)\n</code></pre> <p>Load the scheduler state.</p> PARAMETER DESCRIPTION <code>state_dict</code> <p>Scheduler state dict.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/formed/integrations/torch/schedulers.py</code> <pre><code>def load_state_dict(self, state_dict: dict[str, Any]) -&gt; None:\n    \"\"\"Load the scheduler state.\n\n    Args:\n        state_dict: Scheduler state dict.\n\n    \"\"\"\n    self.__dict__.update(state_dict)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.utils","title":"formed.integrations.torch.utils","text":"<p>Utility functions for PyTorch integration.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.utils.PoolingMethod","title":"PoolingMethod  <code>module-attribute</code>","text":"<pre><code>PoolingMethod = Literal[\n    \"mean\", \"max\", \"min\", \"sum\", \"first\", \"last\", \"hier\"\n]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.utils.set_random_seed","title":"set_random_seed","text":"<pre><code>set_random_seed(seed)\n</code></pre> <p>Set random seed for reproducibility across torch, numpy, and random.</p> PARAMETER DESCRIPTION <code>seed</code> <p>Random seed value.</p> <p> TYPE: <code>int</code> </p> Source code in <code>src/formed/integrations/torch/utils.py</code> <pre><code>def set_random_seed(seed: int) -&gt; None:\n    \"\"\"Set random seed for reproducibility across torch, numpy, and random.\n\n    Args:\n        seed: Random seed value.\n    \"\"\"\n    torch.manual_seed(seed)\n    numpy.random.seed(seed)\n    random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.utils.ensure_torch_tensor","title":"ensure_torch_tensor","text":"<pre><code>ensure_torch_tensor(x, dtype=None, device=None)\n</code></pre> <p>Convert array-like objects to PyTorch tensors.</p> <p>This function converts various array-like objects (numpy arrays, lists, etc.) to PyTorch tensors. If the input is already a tensor, it returns it with the appropriate dtype and device.</p> <p>The device can be specified explicitly via the <code>device</code> parameter, or it will be taken from the context set by <code>use_device()</code>. If neither is provided and the input is not already a tensor, the tensor will be created on CPU.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input data (tensor, numpy array, list, etc.)</p> <p> TYPE: <code>TensorCompatible</code> </p> <code>dtype</code> <p>Optional dtype for the output tensor.</p> <p> TYPE: <code>Optional[dtype]</code> DEFAULT: <code>None</code> </p> <code>device</code> <p>Optional device for the output tensor. If None, uses the device from context (set by <code>use_device()</code>). If the input is already a tensor, its device is preserved unless explicitly specified.</p> <p> TYPE: <code>Optional[Union[device, str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>PyTorch tensor on the specified device with the specified dtype.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from formed.integrations.torch import ensure_torch_tensor, use_device\n&gt;&gt;&gt; arr = np.array([1, 2, 3])\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Without context\n&gt;&gt;&gt; tensor = ensure_torch_tensor(arr)\n&gt;&gt;&gt; tensor.device\ndevice(type='cpu')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With context\n&gt;&gt;&gt; with use_device(\"cuda:0\"):\n...     tensor = ensure_torch_tensor(arr)\n...     print(tensor.device)\ncuda:0\n</code></pre> Source code in <code>src/formed/integrations/torch/utils.py</code> <pre><code>def ensure_torch_tensor(\n    x: TensorCompatible,\n    dtype: Optional[torch.dtype] = None,\n    device: Optional[Union[torch.device, str]] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Convert array-like objects to PyTorch tensors.\n\n    This function converts various array-like objects (numpy arrays, lists, etc.)\n    to PyTorch tensors. If the input is already a tensor, it returns it with the\n    appropriate dtype and device.\n\n    The device can be specified explicitly via the `device` parameter, or it will\n    be taken from the context set by `use_device()`. If neither is provided and\n    the input is not already a tensor, the tensor will be created on CPU.\n\n    Args:\n        x: Input data (tensor, numpy array, list, etc.)\n        dtype: Optional dtype for the output tensor.\n        device: Optional device for the output tensor. If None, uses the device\n            from context (set by `use_device()`). If the input is already a tensor,\n            its device is preserved unless explicitly specified.\n\n    Returns:\n        PyTorch tensor on the specified device with the specified dtype.\n\n    Examples:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from formed.integrations.torch import ensure_torch_tensor, use_device\n        &gt;&gt;&gt; arr = np.array([1, 2, 3])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Without context\n        &gt;&gt;&gt; tensor = ensure_torch_tensor(arr)\n        &gt;&gt;&gt; tensor.device\n        device(type='cpu')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # With context\n        &gt;&gt;&gt; with use_device(\"cuda:0\"):\n        ...     tensor = ensure_torch_tensor(arr)\n        ...     print(tensor.device)\n        cuda:0\n    \"\"\"\n    # Determine target device\n    if device is None:\n        device = get_device()\n\n    if isinstance(x, torch.Tensor):\n        # If already a tensor, convert dtype/device as needed\n        needs_dtype_conversion = dtype is not None and x.dtype != dtype\n        needs_device_conversion = device is not None and x.device != torch.device(device)\n\n        if needs_dtype_conversion or needs_device_conversion:\n            kwargs = {}\n            if dtype is not None:\n                kwargs[\"dtype\"] = dtype\n            if device is not None:\n                kwargs[\"device\"] = device\n            return x.to(**kwargs)\n        return x\n\n    # Convert numpy arrays, handling float64 -&gt; float32 conversion\n    import numpy as np\n\n    if isinstance(x, np.ndarray):\n        if dtype is None and x.dtype == np.float64:\n            # Default: convert float64 to float32 for PyTorch\n            dtype = torch.float32\n        tensor = torch.from_numpy(x)\n        if dtype is not None:\n            tensor = tensor.to(dtype)\n        if device is not None:\n            tensor = tensor.to(device)\n        return tensor\n\n    # Convert other array-like objects\n    tensor = torch.as_tensor(x)\n    if dtype is not None:\n        tensor = tensor.to(dtype)\n    if device is not None:\n        tensor = tensor.to(device)\n    return tensor\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.utils.move_to_device","title":"move_to_device","text":"<pre><code>move_to_device(inputs, device)\n</code></pre> <p>Move tensor inputs to the appropriate device.</p> <p>This function only moves existing torch.Tensor objects to the target device. Other types (numpy arrays, primitives, etc.) are left unchanged. Users should explicitly convert numpy arrays to tensors in their model's forward method using <code>ensure_torch_tensor()</code>.</p> Source code in <code>src/formed/integrations/torch/utils.py</code> <pre><code>def move_to_device(inputs: ModelInputT, device: Optional[Union[torch.device, str]]) -&gt; ModelInputT:\n    \"\"\"Move tensor inputs to the appropriate device.\n\n    This function only moves existing torch.Tensor objects to the target device.\n    Other types (numpy arrays, primitives, etc.) are left unchanged.\n    Users should explicitly convert numpy arrays to tensors in their model's\n    forward method using `ensure_torch_tensor()`.\n    \"\"\"\n    from typing import Any\n\n    visited: set[int] = set()\n\n    def _move(obj: Any) -&gt; Any:\n        # Handle tensors - move to device\n        if isinstance(obj, torch.Tensor):\n            return obj.to(device)\n\n        # Handle primitives and None - no conversion needed\n        if obj is None or isinstance(obj, (int, float, str, bool, type)):\n            return obj\n\n        # Check if already visited to avoid infinite recursion\n        obj_id = id(obj)\n        if obj_id in visited:\n            return obj\n        visited.add(obj_id)\n\n        # Handle dict\n        if isinstance(obj, dict):\n            return {k: _move(v) for k, v in obj.items()}\n\n        # Handle list/tuple\n        if isinstance(obj, (list, tuple)):\n            return type(obj)(_move(x) for x in obj)\n\n        # Handle objects with __dict__ (but not built-in types)\n        if hasattr(obj, \"__dict__\") and not isinstance(obj, type):\n            try:\n                for key, value in list(obj.__dict__.items()):\n                    # Skip dunder attributes\n                    if not key.startswith(\"__\"):\n                        setattr(obj, key, _move(value))\n            except (TypeError, AttributeError):\n                # Skip objects that don't allow attribute modification\n                pass\n            return obj\n\n        return obj\n\n    return cast(ModelInputT, _move(inputs))\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.utils.determine_ndim","title":"determine_ndim","text":"<pre><code>determine_ndim(first, *args)\n</code></pre> Source code in <code>src/formed/integrations/torch/utils.py</code> <pre><code>def determine_ndim(\n    first: int,\n    *args: Optional[Union[int, Callable[[int], int]]],\n) -&gt; int:\n    output_dim = first\n    for arg in args:\n        if arg is None:\n            continue\n        if callable(arg):\n            output_dim = arg(output_dim)\n        else:\n            output_dim = arg\n    return output_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.utils.masked_pool","title":"masked_pool","text":"<pre><code>masked_pool(\n    inputs,\n    *,\n    mask=None,\n    pooling=\"mean\",\n    normalize=False,\n    window_size=None,\n)\n</code></pre> <p>Apply masked pooling over the sequence dimension.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input tensor of shape <code>(batch_size, seq_len, feature_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Mask tensor of shape <code>(batch_size, seq_len)</code>. <code>True</code>/<code>1</code> indicates valid positions.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> <code>pooling</code> <p>Pooling method or sequence of methods.</p> <p> TYPE: <code>Union[PoolingMethod, Sequence[PoolingMethod]]</code> DEFAULT: <code>'mean'</code> </p> <code>normalize</code> <p>Whether to L2-normalize before pooling.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>window_size</code> <p>Window size for hierarchical pooling (required if <code>pooling=\"hier\"</code>).</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Pooled tensor of shape <code>(batch_size, feature_dim * num_pooling_methods)</code>.</p> Source code in <code>src/formed/integrations/torch/utils.py</code> <pre><code>def masked_pool(\n    inputs: torch.Tensor,\n    *,\n    mask: Optional[torch.Tensor] = None,\n    pooling: Union[PoolingMethod, Sequence[PoolingMethod]] = \"mean\",\n    normalize: bool = False,\n    window_size: Optional[int] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Apply masked pooling over the sequence dimension.\n\n    Args:\n        inputs: Input tensor of shape `(batch_size, seq_len, feature_dim)`.\n        mask: Mask tensor of shape `(batch_size, seq_len)`. `True`/`1` indicates valid positions.\n        pooling: Pooling method or sequence of methods.\n        normalize: Whether to L2-normalize before pooling.\n        window_size: Window size for hierarchical pooling (required if `pooling=\"hier\"`).\n\n    Returns:\n        Pooled tensor of shape `(batch_size, feature_dim * num_pooling_methods)`.\n\n    \"\"\"\n    if normalize:\n        inputs = F.normalize(inputs, p=2, dim=-1)\n\n    if mask is None:\n        mask = torch.ones(inputs.shape[:-1], dtype=torch.bool, device=inputs.device)\n\n    # Convert mask to boolean if needed\n    if mask.dtype != torch.bool:\n        mask = mask.bool()\n\n    pooling_methods = [pooling] if isinstance(pooling, str) else list(pooling)\n    results = []\n\n    for method in pooling_methods:\n        if method == \"mean\":\n            # Masked mean\n            masked_inputs = inputs * mask.unsqueeze(-1)\n            pooled = masked_inputs.sum(dim=1) / mask.sum(dim=1, keepdim=True).clamp(min=1)\n        elif method == \"max\":\n            # Masked max\n            masked_inputs = inputs.masked_fill(~mask.unsqueeze(-1), float(\"-inf\"))\n            pooled, _ = masked_inputs.max(dim=1)\n        elif method == \"min\":\n            # Masked min\n            masked_inputs = inputs.masked_fill(~mask.unsqueeze(-1), float(\"inf\"))\n            pooled, _ = masked_inputs.min(dim=1)\n        elif method == \"sum\":\n            # Masked sum\n            masked_inputs = inputs * mask.unsqueeze(-1)\n            pooled = masked_inputs.sum(dim=1)\n        elif method == \"first\":\n            # First token\n            pooled = inputs[:, 0, :]\n        elif method == \"last\":\n            # Last valid token\n            # Find the index of the last valid token for each sequence\n            lengths = mask.sum(dim=1).clamp(min=1) - 1  # -1 because indices are 0-based\n            batch_indices = torch.arange(inputs.size(0), device=inputs.device)\n            pooled = inputs[batch_indices, lengths.long()]\n        elif method == \"hier\":\n            # Hierarchical pooling with sliding window\n            if window_size is None:\n                raise ValueError(\"window_size must be specified for hierarchical pooling\")\n\n            batch_size = inputs.size(0)\n            feature_dim = inputs.size(-1)\n            pooled_list = []\n\n            for i in range(batch_size):\n                # Get valid vectors for this sequence\n                valid_vectors = inputs[i][mask[i]]\n                seq_len = valid_vectors.size(0)\n\n                if seq_len &lt; window_size:\n                    # If sequence is shorter than window, just take mean\n                    pooled_list.append(valid_vectors.mean(dim=0))\n                else:\n                    # Slide window and compute max of means\n                    output = torch.full((feature_dim,), float(\"-inf\"), device=inputs.device)\n                    for offset in range(seq_len - window_size + 1):\n                        window = valid_vectors[offset : offset + window_size]\n                        window_mean = window.mean(dim=0)\n                        output = torch.maximum(output, window_mean)\n                    pooled_list.append(output)\n\n            pooled = torch.stack(pooled_list)\n        else:\n            raise ValueError(f\"Unknown pooling method: {method}\")\n\n        results.append(pooled)\n\n    return torch.cat(results, dim=-1) if len(results) &gt; 1 else results[0]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders","title":"formed.integrations.torch.modules.embedders","text":"<p>Text embedding modules for PyTorch models.</p> <p>This module provides embedders that convert tokenized text into dense vector representations. Embedders handle various text representations including surface forms, part-of-speech tags, and character sequences.</p> Key Components <ul> <li><code>BaseEmbedder</code>: Abstract base class for all embedders</li> <li><code>TokenEmbedder</code>: Embeds token ID sequences into dense vectors</li> <li><code>AnalyzedTextEmbedder</code>: Combines multiple embedding types (surface, POS, chars)</li> </ul> Features <ul> <li>Support for nested token sequences (e.g., word -&gt; character)</li> <li>Automatic masking and padding handling</li> <li>Configurable vectorization for character-level embeddings</li> <li>Concatenation of multiple embedding types</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import TokenEmbedder, AnalyzedTextEmbedder\n&gt;&gt;&gt; import torch.nn as nn\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Simple token embedder\n&gt;&gt;&gt; embedder = TokenEmbedder(\n...     vocab_size=10000,\n...     embedding_dim=128\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Multi-feature embedder\n&gt;&gt;&gt; embedder = AnalyzedTextEmbedder(\n...     surface=TokenEmbedder(vocab_size=10000, embedding_dim=128),\n...     postag=TokenEmbedder(vocab_size=50, embedding_dim=32)\n... )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.SurfaceBatchT","title":"SurfaceBatchT  <code>module-attribute</code>","text":"<pre><code>SurfaceBatchT = TypeVar(\n    \"SurfaceBatchT\", bound=\"IIDSequenceBatch\", default=Any\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PostagBatchT","title":"PostagBatchT  <code>module-attribute</code>","text":"<pre><code>PostagBatchT = TypeVar(\n    \"PostagBatchT\",\n    bound=Union[\"IIDSequenceBatch\", None],\n    default=Any,\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.CharacterBatchT","title":"CharacterBatchT  <code>module-attribute</code>","text":"<pre><code>CharacterBatchT = TypeVar(\n    \"CharacterBatchT\",\n    bound=Union[\"IIDSequenceBatch\", None],\n    default=Any,\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.TokenVectorBatchT","title":"TokenVectorBatchT  <code>module-attribute</code>","text":"<pre><code>TokenVectorBatchT = TypeVar(\n    \"TokenVectorBatchT\",\n    bound=Union[\"IVariableTensorBatch\", None],\n    default=Any,\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IVariableTensorBatch","title":"IVariableTensorBatch","text":"<p>               Bases: <code>Protocol[TensorCompatibleT]</code></p> <p>Protocol for variable-length tensor batches.</p> ATTRIBUTE DESCRIPTION <code>tensor</code> <p>Tensor of shape <code>(batch_size, seq_len, feature_dim)</code>.</p> <p> TYPE: <code>TensorCompatibleT</code> </p> <code>mask</code> <p>Attention mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>TensorCompatibleT</code> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IVariableTensorBatch.tensor","title":"tensor  <code>instance-attribute</code>","text":"<pre><code>tensor\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IVariableTensorBatch.mask","title":"mask  <code>instance-attribute</code>","text":"<pre><code>mask\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch","title":"IAnalyzedTextBatch","text":"<p>               Bases: <code>Protocol[SurfaceBatchT, PostagBatchT, CharacterBatchT, TokenVectorBatchT]</code></p> <p>Protocol for analyzed text batches with multiple linguistic features.</p> ATTRIBUTE DESCRIPTION <code>surfaces</code> <p>Surface form token IDs.</p> <p> TYPE: <code>SurfaceBatchT</code> </p> <code>postags</code> <p>Part-of-speech tag IDs (optional).</p> <p> TYPE: <code>PostagBatchT</code> </p> <code>characters</code> <p>Character sequence IDs (optional).</p> <p> TYPE: <code>CharacterBatchT</code> </p> <code>token_vectors</code> <p>Token-level dense vectors (optional).</p> <p> TYPE: <code>TokenVectorBatchT</code> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.surfaces","title":"surfaces  <code>instance-attribute</code>","text":"<pre><code>surfaces\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.postags","title":"postags  <code>instance-attribute</code>","text":"<pre><code>postags\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.characters","title":"characters  <code>instance-attribute</code>","text":"<pre><code>characters\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.IAnalyzedTextBatch.token_vectors","title":"token_vectors  <code>instance-attribute</code>","text":"<pre><code>token_vectors\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.EmbedderOutput","title":"EmbedderOutput","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Output from an embedder.</p> ATTRIBUTE DESCRIPTION <code>embeddings</code> <p>Dense embeddings of shape <code>(batch_size, seq_len, embedding_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Attention mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Tensor</code> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.EmbedderOutput.embeddings","title":"embeddings  <code>instance-attribute</code>","text":"<pre><code>embeddings\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.EmbedderOutput.mask","title":"mask  <code>instance-attribute</code>","text":"<pre><code>mask\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.BaseEmbedder","title":"BaseEmbedder","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_TextBatchT]</code>, <code>ABC</code></p> <p>Abstract base class for text embedders.</p> <p>Embedders convert tokenized text into dense vector representations. They output both embeddings and attention masks.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_TextBatchT</code> <p>Type of input batch (e.g., <code>IIDSequenceBatch</code>, <code>IAnalyzedTextBatch</code>).</p> <p> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.BaseEmbedder.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(inputs)\n</code></pre> <p>Embed input tokens into dense vectors.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of tokenized text.</p> <p> TYPE: <code>_TextBatchT</code> </p> RETURNS DESCRIPTION <code>EmbedderOutput</code> <p>EmbedderOutput containing embeddings and mask.</p> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>@abc.abstractmethod\ndef forward(self, inputs: _TextBatchT) -&gt; EmbedderOutput:\n    \"\"\"Embed input tokens into dense vectors.\n\n    Args:\n        inputs: Batch of tokenized text.\n\n    Returns:\n        EmbedderOutput containing embeddings and mask.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.BaseEmbedder.get_output_dim","title":"get_output_dim  <code>abstractmethod</code>","text":"<pre><code>get_output_dim()\n</code></pre> <p>Get the output embedding dimension.</p> RETURNS DESCRIPTION <code>int</code> <p>Embedding dimension.</p> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>@abc.abstractmethod\ndef get_output_dim(self) -&gt; int:\n    \"\"\"Get the output embedding dimension.\n\n    Returns:\n        Embedding dimension.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PassThroughEmbedder","title":"PassThroughEmbedder","text":"<p>               Bases: <code>BaseEmbedder[IVariableTensorBatch[TensorCompatibleT]]</code></p> <p>Embedder that passes through input tensors unchanged.</p> <p>This embedder is useful when the input tensors are already in the desired embedding format. It simply returns the input tensors and their masks.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import PassThroughEmbedder\n&gt;&gt;&gt;\n&gt;&gt;&gt; embedder = PassThroughEmbedder()\n&gt;&gt;&gt; output = embedder(variable_tensor_batch)\n&gt;&gt;&gt; assert torch.equal(output.embeddings, variable_tensor_batch.tensor)\n&gt;&gt;&gt; assert torch.equal(output.mask, variable_tensor_batch.mask)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PassThroughEmbedder.forward","title":"forward","text":"<pre><code>forward(inputs)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def forward(\n    self,\n    inputs: IVariableTensorBatch[TensorCompatibleT],\n) -&gt; EmbedderOutput:\n    tensor = ensure_torch_tensor(inputs.tensor)\n    mask = ensure_torch_tensor(inputs.mask).bool()\n    return EmbedderOutput(embeddings=tensor, mask=mask)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PassThroughEmbedder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    raise NotImplementedError(\"PassThroughEmbedder does not have a fixed output dimension.\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.TokenEmbedder","title":"TokenEmbedder","text":"<pre><code>TokenEmbedder(\n    initializer,\n    *,\n    padding_idx=0,\n    freeze=False,\n    vectorizer=None,\n)\n</code></pre> <p>               Bases: <code>BaseEmbedder['IIDSequenceBatch']</code></p> <p>Embedder for token ID sequences.</p> <p>This embedder converts token IDs into dense embeddings using a learned embedding matrix. It supports both 2D <code>(batch_size, seq_len)</code> and 3D <code>(batch_size, seq_len, char_len)</code> token ID tensors.</p> <p>For 3D inputs (e.g., character-level tokens within words), the embedder can either average the embeddings or apply a custom vectorizer.</p> PARAMETER DESCRIPTION <code>initializer</code> <p>Tensor initializer or callable that returns the embedding tensor.</p> <p> TYPE: <code>BaseTensorInitializer | Callable[[], TensorCompatible]</code> </p> <code>padding_idx</code> <p>Index of the padding token (default: <code>0</code>).</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>vectorizer</code> <p>Optional vectorizer for 3D inputs (character sequences).</p> <p> TYPE: <code>Optional[BaseSequenceVectorizer]</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Simple word embeddings\n&gt;&gt;&gt; embedder = TokenEmbedder(vocab_size=10000, embedding_dim=128)\n&gt;&gt;&gt; output = embedder(word_ids_batch)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Character-level embeddings with pooling\n&gt;&gt;&gt; from formed.integrations.torch.modules import BagOfEmbeddingsSequenceVectorizer\n&gt;&gt;&gt; embedder = TokenEmbedder(\n...     vocab_size=256,\n...     embedding_dim=32,\n...     vectorizer=BagOfEmbeddingsSequenceVectorizer(pooling=\"max\")\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def __init__(\n    self,\n    initializer: BaseTensorInitializer | Callable[[], TensorCompatible],\n    *,\n    padding_idx: int = 0,\n    freeze: bool = False,\n    vectorizer: Optional[BaseSequenceVectorizer] = None,\n) -&gt; None:\n    weight = ensure_torch_tensor(initializer())\n\n    super().__init__()\n    self._embedding = nn.Embedding.from_pretrained(weight, padding_idx=padding_idx, freeze=freeze)\n    self._vectorizer = vectorizer\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.TokenEmbedder.forward","title":"forward","text":"<pre><code>forward(inputs)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def forward(self, inputs: \"IIDSequenceBatch\") -&gt; EmbedderOutput:\n    token_ids = ensure_torch_tensor(inputs.ids)\n    mask = ensure_torch_tensor(inputs.mask).bool()\n\n    nested = False\n    if token_ids.ndim &gt; 2:\n        if token_ids.ndim != 3:\n            raise ValueError(\"Token ids must be of shape (batch_size, seq_len) or (batch_size, seq_len, char_len)\")\n        nested = True\n\n    if token_ids.shape != mask.shape:\n        raise ValueError(f\"Token ids and mask must have the same shape, got {token_ids.shape} and {mask.shape}\")\n\n    embeddings = self._embedding(token_ids)\n\n    if nested:\n        if self._vectorizer is None:\n            # Average pooling over character dimension\n            embeddings = (embeddings * mask.unsqueeze(-1)).sum(dim=-2) / mask.sum(dim=-1, keepdim=True).clamp(min=1)\n            mask = mask.any(dim=-1)\n        else:\n            # Flatten batch and sequence dimensions for vectorizer\n            batch_size, seq_len, char_len = token_ids.shape\n            flat_embeddings = embeddings.view(batch_size * seq_len, char_len, -1)\n            flat_mask = mask.view(batch_size * seq_len, char_len)\n\n            # Apply vectorizer\n            flat_embeddings = self._vectorizer(flat_embeddings, mask=flat_mask)\n\n            # Reshape back\n            embeddings = flat_embeddings.view(batch_size, seq_len, -1)\n            mask = mask.any(dim=-1)\n\n    return EmbedderOutput(embeddings=embeddings, mask=mask)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.TokenEmbedder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._embedding.embedding_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder","title":"PretrainedTransformerEmbedder","text":"<pre><code>PretrainedTransformerEmbedder(\n    model,\n    auto_class=None,\n    subcmodule=None,\n    freeze=False,\n    eval_mode=False,\n    layer_to_use=\"last\",\n    gradient_checkpointing=None,\n    **kwargs,\n)\n</code></pre> <p>               Bases: <code>BaseEmbedder[IIDSequenceBatch]</code></p> <p>Embedder using pretrained transformer models from Hugging Face.</p> <p>This embedder wraps pretrained transformer models (BERT, RoBERTa, etc.) to extract contextualized embeddings. It uses the last hidden state from the transformer as the embedding representation.</p> PARAMETER DESCRIPTION <code>model</code> <p>Either a model name/path string, <code>PathLike</code> object, or a <code>PreTrainedModel</code> instance. If a string or <code>PathLike</code>, the model will be loaded using transformers auto classes.</p> <p> TYPE: <code>Union[str, PathLike, PreTrainedModel]</code> </p> <code>auto_class</code> <p>The auto class to use for loading the model.</p> <p> TYPE: <code>str | type[_BaseAutoModelClass] | None</code> DEFAULT: <code>None</code> </p> <code>subcmodule</code> <p>Optional submodule path to extract from the loaded model (e.g., <code>\"encoder\"</code>).</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>freeze</code> <p>If <code>True</code>, freezes all model parameters (no gradient computation).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p>Additional keyword arguments passed to the model loader.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load a pretrained BERT model\n&gt;&gt;&gt; embedder = PretrainedTransformerEmbedder(\n...     model=\"bert-base-uncased\",\n...     freeze=True\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use a specific auto class\n&gt;&gt;&gt; from transformers import AutoModel\n&gt;&gt;&gt; embedder = PretrainedTransformerEmbedder(\n...     model=\"roberta-base\",\n...     auto_class=AutoModel,\n...     freeze=False\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use an already loaded model\n&gt;&gt;&gt; from transformers import AutoModel\n&gt;&gt;&gt; model = AutoModel.from_pretrained(\"bert-base-uncased\")\n&gt;&gt;&gt; embedder = PretrainedTransformerEmbedder(model=model)\n</code></pre> Note <p>Models are cached using LRU cache by the <code>load_pretrained_transformer</code> utility. When <code>freeze=True</code>, all model parameters have <code>requires_grad=False</code>.</p> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def __init__(\n    self,\n    model: Union[str, PathLike, \"PreTrainedModel\"],\n    auto_class: str | type[\"_BaseAutoModelClass\"] | None = None,\n    subcmodule: str | None = None,\n    freeze: bool = False,\n    eval_mode: bool = False,\n    layer_to_use: Literal[\"embeddings\", \"last\", \"all\"] = \"last\",\n    gradient_checkpointing: bool | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    if isinstance(model, (str, PathLike)):\n        from formed.integrations.transformers import load_pretrained_transformer\n\n        model = load_pretrained_transformer.__wrapped__(\n            model,\n            auto_class=auto_class,\n            submodule=subcmodule,\n            **kwargs,\n        )\n\n    super().__init__()\n\n    self._model = model\n    self._scalar_mix: ScalarMix | None = None\n    self._eval_mode = eval_mode\n    self._output_dim = model.config.hidden_size\n    self._vocab_size = model.config.vocab_size\n\n    if gradient_checkpointing is not None:\n        self._model.config.update({\"gradient_checkpointing\": gradient_checkpointing})\n\n    if self._eval_mode:\n        self._model.eval()\n\n    if freeze:\n        for param in self._model.parameters():\n            param.requires_grad = False\n\n    if layer_to_use == \"all\":\n        self._scalar_mix = ScalarMix(self._model.config.num_hidden_layers)\n        self._model.config.output_hidden_states = True\n    elif layer_to_use == \"embeddings\":\n        self._model = PretrainedTransformerEmbedder._Embedding(self._model)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.forward","title":"forward","text":"<pre><code>forward(inputs)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def forward(self, inputs: IIDSequenceBatch) -&gt; EmbedderOutput:\n    input_ids = ensure_torch_tensor(inputs.ids)\n    mask = ensure_torch_tensor(inputs.mask)\n\n    if isinstance(self._model, PretrainedTransformerEmbedder._Embedding):\n        embeddings = self._model(input_ids)\n    else:\n        transformer_outputs = self._model(input_ids=input_ids, attention_mask=mask)\n        if self._scalar_mix is not None:\n            # The hidden states will also include the embedding layer, which we don't\n            # include in the scalar mix. Hence the `[1:]` slicing.\n            hidden_states = transformer_outputs.hidden_states[1:]\n            embeddings = self._scalar_mix(hidden_states)\n        else:\n            embeddings = transformer_outputs.last_hidden_state\n    return EmbedderOutput(embeddings, mask)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._output_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.get_vocab_size","title":"get_vocab_size","text":"<pre><code>get_vocab_size()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def get_vocab_size(self) -&gt; int:\n    return self._vocab_size\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.PretrainedTransformerEmbedder.train","title":"train","text":"<pre><code>train(mode=True)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def train(self, mode: bool = True) -&gt; Self:\n    self.training = mode\n    for name, module in self.named_children():\n        if self._eval_mode and name == \"_model\":\n            module.eval()\n        else:\n            module.train(mode)\n    return self\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder","title":"AnalyzedTextEmbedder","text":"<pre><code>AnalyzedTextEmbedder(\n    surface=None,\n    postag=None,\n    character=None,\n    token_vector=None,\n)\n</code></pre> <p>               Bases: <code>BaseEmbedder['IAnalyzedTextBatch']</code></p> <p>Embedder for analyzed text with multiple linguistic features.</p> <p>This embedder combines embeddings from multiple linguistic representations (surface forms, part-of-speech tags, character sequences) by concatenating them along the feature dimension.</p> PARAMETER DESCRIPTION <code>surface</code> <p>Optional embedder for surface form tokens.</p> <p> TYPE: <code>Optional[BaseEmbedder[IIDSequenceBatch]]</code> DEFAULT: <code>None</code> </p> <code>postag</code> <p>Optional embedder for part-of-speech tags.</p> <p> TYPE: <code>Optional[BaseEmbedder[IIDSequenceBatch]]</code> DEFAULT: <code>None</code> </p> <code>character</code> <p>Optional embedder for character sequences.</p> <p> TYPE: <code>Optional[BaseEmbedder[IIDSequenceBatch]]</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If all embedders are None (at least one is required).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import (\n...     AnalyzedTextEmbedder,\n...     TokenEmbedder\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; embedder = AnalyzedTextEmbedder(\n...     surface=TokenEmbedder(vocab_size=10000, embedding_dim=128),\n...     postag=TokenEmbedder(vocab_size=50, embedding_dim=32),\n...     character=TokenEmbedder(vocab_size=256, embedding_dim=32)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Output dimension is sum of all embedding dimensions (128 + 32 + 32 = 192)\n&gt;&gt;&gt; assert embedder.get_output_dim() == 192\n</code></pre> Note <p>All provided embedders share the same mask, which is taken from the last non-None embedder processed.</p> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def __init__(\n    self,\n    surface: Optional[\"BaseEmbedder[IIDSequenceBatch]\"] = None,\n    postag: Optional[\"BaseEmbedder[IIDSequenceBatch]\"] = None,\n    character: Optional[\"BaseEmbedder[IIDSequenceBatch]\"] = None,\n    token_vector: Optional[\"BaseEmbedder[IVariableTensorBatch]\"] = None,\n) -&gt; None:\n    super().__init__()\n    if all(embedder is None for embedder in (surface, postag, character)):\n        raise ValueError(\"At least one embedder must be provided for AnalyzedTextEmbedder.\")\n\n    self._surface = surface\n    self._postag = postag\n    self._character = character\n    self._token_vector = token_vector\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.forward","title":"forward","text":"<pre><code>forward(inputs)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def forward(self, inputs: \"IAnalyzedTextBatch\") -&gt; EmbedderOutput:\n    embeddings: list[torch.Tensor] = []\n    mask: Optional[torch.Tensor] = None\n\n    for embedder, ids in (\n        (self._surface, inputs.surfaces),\n        (self._postag, inputs.postags),\n        (self._character, inputs.characters),\n    ):\n        if embedder is not None and ids is not None:\n            output = embedder(ids)\n            embeddings.append(output.embeddings)\n            mask = output.mask\n\n    if self._token_vector is not None and inputs.token_vectors is not None:\n        output = self._token_vector(inputs.token_vectors)\n        embeddings.append(output.embeddings)\n\n    if not embeddings:\n        raise ValueError(\"No embeddings were computed in AnalyzedTextEmbedder.\")\n    assert mask is not None\n\n    return EmbedderOutput(embeddings=torch.cat(embeddings, dim=-1), mask=mask)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.embedders.AnalyzedTextEmbedder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/embedders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return sum(\n        embedder.get_output_dim()\n        for embedder in (self._surface, self._postag, self._character)\n        if embedder is not None\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders","title":"formed.integrations.torch.modules.encoders","text":"<p>Sequence encoding modules for PyTorch models.</p> <p>This module provides encoders that process sequential data, including RNN-based encoders, positional encoders, and Transformer encoders.</p> Key Components <ul> <li><code>BaseSequenceEncoder</code>: Abstract base for sequence encoders</li> <li><code>LSTMSequenceEncoder</code>: LSTM-specific encoder</li> <li><code>GRUSequenceEncoder</code>: GRU-specific encoder</li> <li><code>BasePositionalEncoder</code>: Abstract base for positional encoders</li> <li><code>SinusoidalPositionalEncoder</code>: Sinusoidal positional encoding</li> <li><code>RotaryPositionalEncoder</code>: Rotary positional encoding (RoPE)</li> <li><code>LearnablePositionalEncoder</code>: Learnable positional embeddings</li> <li><code>TransformerEncoder</code>: Transformer-based encoder with configurable masking</li> </ul> Features <ul> <li>Bidirectional RNN support</li> <li>Stacked layers with dropout</li> <li>Masked sequence processing</li> <li>Various positional encoding strategies</li> <li>Flexible attention masking</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import LSTMSequenceEncoder\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Bidirectional LSTM encoder\n&gt;&gt;&gt; encoder = LSTMSequenceEncoder(\n...     input_dim=128,\n...     hidden_dim=256,\n...     num_layers=2,\n...     bidirectional=True,\n...     dropout=0.1\n... )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BaseSequenceEncoder","title":"BaseSequenceEncoder","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>ABC</code></p> <p>Abstract base class for sequence encoders.</p> <p>Sequence encoders process sequential data and output encoded representations.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Encode input sequence.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Encode input sequence.\n\n    Args:\n        inputs: Input sequence of shape `(batch_size, seq_len, input_dim)`.\n        mask: Optional mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Encoded sequence of shape `(batch_size, seq_len, output_dim)`.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_input_dim","title":"get_input_dim  <code>abstractmethod</code>","text":"<pre><code>get_input_dim()\n</code></pre> <p>Get the expected input dimension.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef get_input_dim(self) -&gt; int:\n    \"\"\"Get the expected input dimension.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BaseSequenceEncoder.get_output_dim","title":"get_output_dim  <code>abstractmethod</code>","text":"<pre><code>get_output_dim()\n</code></pre> <p>Get the output dimension.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef get_output_dim(self) -&gt; int:\n    \"\"\"Get the output dimension.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder","title":"LSTMSequenceEncoder","text":"<pre><code>LSTMSequenceEncoder(\n    input_dim,\n    hidden_dim,\n    num_layers=1,\n    bidirectional=False,\n    dropout=0.0,\n    batch_first=True,\n)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> <p>LSTM-based sequence encoder.</p> PARAMETER DESCRIPTION <code>input_dim</code> <p>Input dimension.</p> <p> TYPE: <code>int</code> </p> <code>hidden_dim</code> <p>Hidden state dimension.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of LSTM layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>bidirectional</code> <p>Whether to use bidirectional LSTM.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dropout</code> <p>Dropout rate between layers.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>batch_first</code> <p>Whether input is batch-first (default: <code>True</code>).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = LSTMSequenceEncoder(\n...     input_dim=128,\n...     hidden_dim=256,\n...     num_layers=2,\n...     bidirectional=True\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    hidden_dim: int,\n    num_layers: int = 1,\n    bidirectional: bool = False,\n    dropout: float = 0.0,\n    batch_first: bool = True,\n) -&gt; None:\n    super().__init__()\n    self._input_dim = input_dim\n    self._hidden_dim = hidden_dim\n    self._num_layers = num_layers\n    self._bidirectional = bidirectional\n\n    self.lstm = nn.LSTM(\n        input_size=input_dim,\n        hidden_size=hidden_dim,\n        num_layers=num_layers,\n        bidirectional=bidirectional,\n        dropout=dropout if num_layers &gt; 1 else 0.0,\n        batch_first=batch_first,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.lstm","title":"lstm  <code>instance-attribute</code>","text":"<pre><code>lstm = LSTM(\n    input_size=input_dim,\n    hidden_size=hidden_dim,\n    num_layers=num_layers,\n    bidirectional=bidirectional,\n    dropout=dropout if num_layers &gt; 1 else 0.0,\n    batch_first=batch_first,\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Encode input sequence.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Encode input sequence.\n\n    Args:\n        inputs: Input of shape `(batch_size, seq_len, input_dim)`.\n        mask: Optional mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Encoded sequence of shape `(batch_size, seq_len, output_dim)`.\n\n    \"\"\"\n    if mask is not None:\n        # Pack padded sequence for efficiency\n        lengths = mask.sum(dim=1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n        output, _ = self.lstm(packed)\n        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n    else:\n        output, _ = self.lstm(inputs)\n\n    return output\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LSTMSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._hidden_dim * (2 if self._bidirectional else 1)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.GRUSequenceEncoder","title":"GRUSequenceEncoder","text":"<pre><code>GRUSequenceEncoder(\n    input_dim,\n    hidden_dim,\n    num_layers=1,\n    bidirectional=False,\n    dropout=0.0,\n    batch_first=True,\n)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> <p>GRU-based sequence encoder.</p> PARAMETER DESCRIPTION <code>input_dim</code> <p>Input dimension.</p> <p> TYPE: <code>int</code> </p> <code>hidden_dim</code> <p>Hidden state dimension.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of GRU layers.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>bidirectional</code> <p>Whether to use bidirectional GRU.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>dropout</code> <p>Dropout rate between layers.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>batch_first</code> <p>Whether input is batch-first (default: <code>True</code>).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = GRUSequenceEncoder(\n...     input_dim=128,\n...     hidden_dim=256,\n...     num_layers=2,\n...     bidirectional=True\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    hidden_dim: int,\n    num_layers: int = 1,\n    bidirectional: bool = False,\n    dropout: float = 0.0,\n    batch_first: bool = True,\n) -&gt; None:\n    super().__init__()\n    self._input_dim = input_dim\n    self._hidden_dim = hidden_dim\n    self._num_layers = num_layers\n    self._bidirectional = bidirectional\n\n    self.gru = nn.GRU(\n        input_size=input_dim,\n        hidden_size=hidden_dim,\n        num_layers=num_layers,\n        bidirectional=bidirectional,\n        dropout=dropout if num_layers &gt; 1 else 0.0,\n        batch_first=batch_first,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.gru","title":"gru  <code>instance-attribute</code>","text":"<pre><code>gru = GRU(\n    input_size=input_dim,\n    hidden_size=hidden_dim,\n    num_layers=num_layers,\n    bidirectional=bidirectional,\n    dropout=dropout if num_layers &gt; 1 else 0.0,\n    batch_first=batch_first,\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Encode input sequence.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Encode input sequence.\n\n    Args:\n        inputs: Input of shape `(batch_size, seq_len, input_dim)`.\n        mask: Optional mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Encoded sequence of shape `(batch_size, seq_len, output_dim)`.\n\n    \"\"\"\n    if mask is not None:\n        # Pack padded sequence for efficiency\n        lengths = mask.sum(dim=1).cpu()\n        packed = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n        output, _ = self.gru(packed)\n        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n    else:\n        output, _ = self.gru(inputs)\n\n    return output\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.GRUSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._hidden_dim * (2 if self._bidirectional else 1)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder","title":"ResidualSequenceEncoder","text":"<pre><code>ResidualSequenceEncoder(encoder)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(self, encoder: BaseSequenceEncoder) -&gt; None:\n    assert encoder.get_input_dim() == encoder.get_output_dim()\n\n    super().__init__()\n    self._encoder = encoder\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: torch.Tensor | None = None,\n) -&gt; torch.Tensor:\n    encoded = self._encoder(inputs, mask=mask)\n    return inputs + encoded\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._encoder.get_input_dim()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.ResidualSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._encoder.get_output_dim()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder","title":"FeedForwardSequenceEncoder","text":"<pre><code>FeedForwardSequenceEncoder(feedforward)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(self, feedforward: FeedForward) -&gt; None:\n    super().__init__()\n    self._feedforward = feedforward\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: torch.Tensor | None = None,\n) -&gt; torch.Tensor:\n    del mask\n\n    original_shape = inputs.shape\n    flattened_inputs = inputs.view(-1, original_shape[-1])\n    encoded = self._feedforward(flattened_inputs)\n    return encoded.view(*original_shape[:-1], -1)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._feedforward.get_input_dim()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.FeedForwardSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._feedforward.get_output_dim()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.StackedSequenceEncoder","title":"StackedSequenceEncoder","text":"<pre><code>StackedSequenceEncoder(encoders)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(self, encoders: list[BaseSequenceEncoder]) -&gt; None:\n    super().__init__()\n    self._encoders = torch.nn.ModuleList(encoders)\n    self._input_dim = encoders[0].get_input_dim()\n    self._output_dim = encoders[-1].get_output_dim()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: torch.Tensor | None = None,\n) -&gt; torch.Tensor:\n    x = inputs\n    for encoder in self._encoders:\n        x = encoder(x, mask=mask)\n    return x\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.StackedSequenceEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._output_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BasePositionalEncoder","title":"BasePositionalEncoder","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>ABC</code></p> <p>Abstract base class for positional encoders.</p> <p>Positional encoders add positional information to sequential data.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BasePositionalEncoder.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Add positional encoding to input sequence.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Position-encoded sequence of shape <code>(batch_size, seq_len, output_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Add positional encoding to input sequence.\n\n    Args:\n        inputs: Input sequence of shape `(batch_size, seq_len, input_dim)`.\n        mask: Optional mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Position-encoded sequence of shape `(batch_size, seq_len, output_dim)`.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_input_dim","title":"get_input_dim  <code>abstractmethod</code>","text":"<pre><code>get_input_dim()\n</code></pre> <p>Get the expected input dimension.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef get_input_dim(self) -&gt; int:\n    \"\"\"Get the expected input dimension.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.BasePositionalEncoder.get_output_dim","title":"get_output_dim  <code>abstractmethod</code>","text":"<pre><code>get_output_dim()\n</code></pre> <p>Get the output dimension.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>@abc.abstractmethod\ndef get_output_dim(self) -&gt; int:\n    \"\"\"Get the output dimension.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder","title":"SinusoidalPositionalEncoder","text":"<pre><code>SinusoidalPositionalEncoder(\n    input_dim, max_len=5000, dropout=0.0\n)\n</code></pre> <p>               Bases: <code>BasePositionalEncoder</code></p> <p>Sinusoidal positional encoding.</p> <p>Uses sine and cosine functions of different frequencies to encode position information, as introduced in \"Attention Is All You Need\".</p> PARAMETER DESCRIPTION <code>input_dim</code> <p>Dimension of the embeddings.</p> <p> TYPE: <code>int</code> </p> <code>max_len</code> <p>Maximum sequence length to pre-compute.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5000</code> </p> <code>dropout</code> <p>Dropout rate to apply after adding positional encoding.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = SinusoidalPositionalEncoder(\n...     input_dim=512,\n...     max_len=5000,\n...     dropout=0.1\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    max_len: int = 5000,\n    dropout: float = 0.0,\n) -&gt; None:\n    super().__init__()\n    self._input_dim = input_dim\n    self._max_len = max_len\n\n    # Create positional encoding matrix\n    position = torch.arange(max_len).unsqueeze(1)\n    div_term = torch.exp(torch.arange(0, input_dim, 2) * (-torch.log(torch.tensor(10000.0)) / input_dim))\n\n    pe = torch.zeros(1, max_len, input_dim)\n    pe[0, :, 0::2] = torch.sin(position * div_term)\n    pe[0, :, 1::2] = torch.cos(position * div_term)\n\n    self.register_buffer(\"pe\", pe)\n    self.dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.pe","title":"pe  <code>instance-attribute</code>","text":"<pre><code>pe\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.dropout","title":"dropout  <code>instance-attribute</code>","text":"<pre><code>dropout = Dropout(p=dropout)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Add sinusoidal positional encoding to inputs.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Position-encoded sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Add sinusoidal positional encoding to inputs.\n\n    Args:\n        inputs: Input of shape `(batch_size, seq_len, input_dim)`.\n        mask: Optional mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Position-encoded sequence of shape `(batch_size, seq_len, input_dim)`.\n\n    \"\"\"\n    seq_len = inputs.size(1)\n    if seq_len &gt; self._max_len:\n        raise ValueError(f\"Sequence length {seq_len} exceeds maximum length {self._max_len}\")\n\n    output = inputs + self.pe[:, :seq_len, :]\n    return self.dropout(output)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.SinusoidalPositionalEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder","title":"RotaryPositionalEncoder","text":"<pre><code>RotaryPositionalEncoder(\n    input_dim, max_len=2048, base=10000.0\n)\n</code></pre> <p>               Bases: <code>BasePositionalEncoder</code></p> <p>Rotary positional encoding (RoPE).</p> <p>Applies rotary position embeddings by rotating pairs of dimensions in the feature space, as introduced in \"RoFormer: Enhanced Transformer with Rotary Position Embedding\".</p> PARAMETER DESCRIPTION <code>input_dim</code> <p>Dimension of the embeddings (must be even).</p> <p> TYPE: <code>int</code> </p> <code>max_len</code> <p>Maximum sequence length to pre-compute.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2048</code> </p> <code>base</code> <p>Base for the geometric progression (default: <code>10000</code>).</p> <p> TYPE: <code>float</code> DEFAULT: <code>10000.0</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = RotaryPositionalEncoder(\n...     input_dim=512,\n...     max_len=2048\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    max_len: int = 2048,\n    base: float = 10000.0,\n) -&gt; None:\n    super().__init__()\n    if input_dim % 2 != 0:\n        raise ValueError(f\"input_dim must be even, got {input_dim}\")\n\n    self._input_dim = input_dim\n    self._max_len = max_len\n\n    # Compute inverse frequencies\n    inv_freq = 1.0 / (base ** (torch.arange(0, input_dim, 2).float() / input_dim))\n    self.register_buffer(\"inv_freq\", inv_freq)\n\n    # Pre-compute cos and sin for max_len positions\n    t = torch.arange(max_len).float()\n    freqs = torch.outer(t, inv_freq)\n    emb = torch.cat((freqs, freqs), dim=-1)\n\n    self.register_buffer(\"cos_cached\", emb.cos()[None, :, :])\n    self.register_buffer(\"sin_cached\", emb.sin()[None, :, :])\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.inv_freq","title":"inv_freq  <code>instance-attribute</code>","text":"<pre><code>inv_freq\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.cos_cached","title":"cos_cached  <code>instance-attribute</code>","text":"<pre><code>cos_cached\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.sin_cached","title":"sin_cached  <code>instance-attribute</code>","text":"<pre><code>sin_cached\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Apply rotary positional encoding to inputs.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Position-encoded sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Apply rotary positional encoding to inputs.\n\n    Args:\n        inputs: Input of shape `(batch_size, seq_len, input_dim)`.\n        mask: Optional mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Position-encoded sequence of shape `(batch_size, seq_len, input_dim)`.\n\n    \"\"\"\n    seq_len = inputs.size(1)\n    if seq_len &gt; self._max_len:\n        raise ValueError(f\"Sequence length {seq_len} exceeds maximum length {self._max_len}\")\n\n    cos = self.cos_cached[:, :seq_len, :]\n    sin = self.sin_cached[:, :seq_len, :]\n\n    output = (inputs * cos) + (self._rotate_half(inputs) * sin)\n    return output\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.RotaryPositionalEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder","title":"LearnablePositionalEncoder","text":"<pre><code>LearnablePositionalEncoder(\n    input_dim, max_len=1024, dropout=0.0\n)\n</code></pre> <p>               Bases: <code>BasePositionalEncoder</code></p> <p>Learnable positional embeddings.</p> <p>Uses a learnable embedding table to encode position information, similar to token embeddings.</p> PARAMETER DESCRIPTION <code>input_dim</code> <p>Dimension of the embeddings.</p> <p> TYPE: <code>int</code> </p> <code>max_len</code> <p>Maximum sequence length (vocabulary size for positions).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1024</code> </p> <code>dropout</code> <p>Dropout rate to apply after adding positional encoding.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; encoder = LearnablePositionalEncoder(\n...     input_dim=512,\n...     max_len=1024,\n...     dropout=0.1\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    max_len: int = 1024,\n    dropout: float = 0.0,\n) -&gt; None:\n    super().__init__()\n    self._input_dim = input_dim\n    self._max_len = max_len\n\n    self.position_embeddings = nn.Embedding(max_len, input_dim)\n    self.dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.position_embeddings","title":"position_embeddings  <code>instance-attribute</code>","text":"<pre><code>position_embeddings = Embedding(max_len, input_dim)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.dropout","title":"dropout  <code>instance-attribute</code>","text":"<pre><code>dropout = Dropout(p=dropout)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Add learnable positional encoding to inputs.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input of shape <code>(batch_size, seq_len, input_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Position-encoded sequence of shape <code>(batch_size, seq_len, input_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Add learnable positional encoding to inputs.\n\n    Args:\n        inputs: Input of shape `(batch_size, seq_len, input_dim)`.\n        mask: Optional mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Position-encoded sequence of shape `(batch_size, seq_len, input_dim)`.\n\n    \"\"\"\n    seq_len = inputs.size(1)\n    if seq_len &gt; self._max_len:\n        raise ValueError(f\"Sequence length {seq_len} exceeds maximum length {self._max_len}\")\n\n    position_ids = torch.arange(seq_len, dtype=torch.long, device=inputs.device)\n    position_ids = position_ids.unsqueeze(0).expand(inputs.size(0), -1)\n\n    position_embeddings = self.position_embeddings(position_ids)\n    output = inputs + position_embeddings\n    return self.dropout(output)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.LearnablePositionalEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.TransformerEncoder","title":"TransformerEncoder","text":"<pre><code>TransformerEncoder(\n    input_dim,\n    num_heads,\n    num_layers,\n    feedforward_dim,\n    dropout=0.1,\n    positional_encoder=None,\n    attention_mask=None,\n    activation=\"relu\",\n    layer_norm_eps=1e-05,\n    batch_first=True,\n)\n</code></pre> <p>               Bases: <code>BaseSequenceEncoder</code></p> <p>Transformer-based sequence encoder.</p> <p>Uses stacked TransformerEncoderLayers with positional encoding and configurable attention masking via dependency injection.</p> PARAMETER DESCRIPTION <code>input_dim</code> <p>Dimension of the embeddings (<code>d_model</code>).</p> <p> TYPE: <code>int</code> </p> <code>num_heads</code> <p>Number of attention heads.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>Number of transformer layers.</p> <p> TYPE: <code>int</code> </p> <code>feedforward_dim</code> <p>Dimension of feedforward network.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>Dropout rate.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>positional_encoder</code> <p>Optional positional encoder to add position information.</p> <p> TYPE: <code>Optional[BasePositionalEncoder]</code> DEFAULT: <code>None</code> </p> <code>attention_mask</code> <p>Optional mask generator for self-attention.</p> <p> TYPE: <code>Optional[BaseAttentionMask]</code> DEFAULT: <code>None</code> </p> <code>activation</code> <p>Activation function (default: <code>\"relu\"</code>).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'relu'</code> </p> <code>layer_norm_eps</code> <p>Epsilon for layer normalization.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>batch_first</code> <p>Whether input is batch-first (default: <code>True</code>).</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules.encoders import (\n...     TransformerEncoder,\n...     SinusoidalPositionalEncoder,\n...     CausalMask\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Standard transformer encoder\n&gt;&gt;&gt; encoder = TransformerEncoder(\n...     input_dim=512,\n...     num_heads=8,\n...     num_layers=6,\n...     feedforward_dim=2048,\n...     dropout=0.1,\n...     positional_encoder=SinusoidalPositionalEncoder(input_dim=512)\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Transformer with causal masking (for autoregressive tasks)\n&gt;&gt;&gt; causal_encoder = TransformerEncoder(\n...     input_dim=512,\n...     num_heads=8,\n...     num_layers=6,\n...     feedforward_dim=2048,\n...     dropout=0.1,\n...     positional_encoder=SinusoidalPositionalEncoder(input_dim=512),\n...     attention_mask=CausalMask()\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    num_heads: int,\n    num_layers: int,\n    feedforward_dim: int,\n    dropout: float = 0.1,\n    positional_encoder: Optional[BasePositionalEncoder] = None,\n    attention_mask: Optional[BaseAttentionMask] = None,\n    activation: str = \"relu\",\n    layer_norm_eps: float = 1e-5,\n    batch_first: bool = True,\n) -&gt; None:\n    super().__init__()\n    self._input_dim = input_dim\n    self._positional_encoder = positional_encoder\n    self._attention_mask = attention_mask\n    self._batch_first = batch_first\n\n    # Create transformer encoder layers\n    encoder_layer = nn.TransformerEncoderLayer(\n        d_model=input_dim,\n        nhead=num_heads,\n        dim_feedforward=feedforward_dim,\n        dropout=dropout,\n        activation=activation,\n        layer_norm_eps=layer_norm_eps,\n        batch_first=batch_first,\n        norm_first=False,\n    )\n\n    self.transformer_encoder = nn.TransformerEncoder(\n        encoder_layer=encoder_layer,\n        num_layers=num_layers,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.TransformerEncoder.transformer_encoder","title":"transformer_encoder  <code>instance-attribute</code>","text":"<pre><code>transformer_encoder = TransformerEncoder(\n    encoder_layer=encoder_layer, num_layers=num_layers\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.TransformerEncoder.forward","title":"forward","text":"<pre><code>forward(inputs, mask=None)\n</code></pre> <p>Encode input sequence using transformer.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input of shape <code>(batch_size, seq_len, input_dim)</code> if <code>batch_first=True</code>,    or <code>(seq_len, batch_size, input_dim)</code> if <code>batch_first=False</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional mask of shape <code>(batch_size, seq_len)</code> where 1=valid, 0=padding.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Encoded sequence of same shape as input.</p> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Encode input sequence using transformer.\n\n    Args:\n        inputs: Input of shape `(batch_size, seq_len, input_dim)` if `batch_first=True`,\n               or `(seq_len, batch_size, input_dim)` if `batch_first=False`.\n        mask: Optional mask of shape `(batch_size, seq_len)` where 1=valid, 0=padding.\n\n    Returns:\n        Encoded sequence of same shape as input.\n\n    \"\"\"\n    # Apply positional encoding if provided\n    if self._positional_encoder is not None:\n        inputs = self._positional_encoder(inputs, mask=mask)\n\n    batch_size = inputs.size(0) if self._batch_first else inputs.size(1)\n    seq_len = inputs.size(1) if self._batch_first else inputs.size(0)\n\n    # Generate attention mask if generator is provided\n    # All attention masks return (seq_len, seq_len) or (batch_size, seq_len, seq_len)\n    src_mask = None\n    if self._attention_mask is not None:\n        src_mask = self._attention_mask(\n            seq_len=seq_len,\n            batch_size=batch_size,\n            device=inputs.device,\n            padding_mask=mask,\n        )\n        if src_mask is not None:\n            src_mask = src_mask.to(inputs.device)\n\n    # Generate key padding mask for transformer\n    # This is separate from attention_mask and handles padding from input mask\n    # TransformerEncoder expects True for positions to be masked\n    src_key_padding_mask = None\n    if mask is not None:\n        # Convert mask: 1=valid -&gt; False (not masked), 0=padding -&gt; True (masked)\n        src_key_padding_mask = ~mask.bool()\n\n    # Apply transformer encoder\n    output = self.transformer_encoder(\n        inputs,\n        mask=src_mask,\n        src_key_padding_mask=src_key_padding_mask,\n    )\n\n    return output\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.TransformerEncoder.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.encoders.TransformerEncoder.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/encoders.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.feedforward","title":"formed.integrations.torch.modules.feedforward","text":"<p>Feed-forward neural network modules for PyTorch models.</p> <p>This module provides feed-forward network layers with support for multiple layers, dropout, layer normalization, and residual connections.</p> Key Components <ul> <li>FeedForward: Multi-layer feed-forward network</li> </ul> Features <ul> <li>Configurable activation functions</li> <li>Layer normalization</li> <li>Dropout for regularization</li> <li>Residual connections</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import FeedForward\n&gt;&gt;&gt; import torch.nn as nn\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Simple 3-layer feed-forward network\n&gt;&gt;&gt; ffn = FeedForward(\n...     input_dim=256,\n...     hidden_dims=[512, 512, 256],\n...     dropout=0.1,\n...     activation=nn.GELU()\n... )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.feedforward.FeedForward","title":"FeedForward","text":"<pre><code>FeedForward(\n    input_dim, hidden_dims, dropout=0.0, activation=ReLU()\n)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>A simple feed forward neural network.</p> PARAMETER DESCRIPTION <code>input_dim</code> <p>The dimension of the input.</p> <p> TYPE: <code>int</code> </p> <code>hidden_dims</code> <p>A sequence of integers specifying the dimensions of each layer.</p> <p> TYPE: <code>Sequence[int]</code> </p> <code>dropout</code> <p>The dropout probability. Defaults to <code>0.0</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>activation</code> <p>The activation function. Defaults to <code>torch.nn.ReLU()</code></p> <p> TYPE: <code>Module</code> DEFAULT: <code>ReLU()</code> </p> Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code> <pre><code>def __init__(\n    self,\n    input_dim: int,\n    hidden_dims: Sequence[int],\n    dropout: float = 0.0,\n    activation: torch.nn.Module = torch.nn.ReLU(),\n) -&gt; None:\n    super().__init__()\n    self._input_dim = input_dim\n    self._hidden_dims = hidden_dims\n    self._dropout = dropout\n    self._activation = activation\n\n    layer_dims = [input_dim] + list(hidden_dims)\n    self._layers = torch.nn.ModuleList(\n        [\n            torch.nn.Sequential(\n                torch.nn.Linear(layer_dims[i], layer_dims[i + 1]),\n                torch.nn.Dropout(dropout),\n                activation,\n            )\n            for i in range(len(layer_dims) - 1)\n        ]\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.feedforward.FeedForward.forward","title":"forward","text":"<pre><code>forward(inputs)\n</code></pre> PARAMETER DESCRIPTION <code>inputs</code> <p>A tensor of shape <code>(batch_size, ..., input_dim)</code>.</p> <p> TYPE: <code>FloatTensor</code> </p> RETURNS DESCRIPTION <code>FloatTensor</code> <p>A tensor of shape <code>(batch_size, ..., hidden_dims[-1])</code>.</p> Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code> <pre><code>def forward(self, inputs: torch.FloatTensor) -&gt; torch.FloatTensor:\n    \"\"\"\n    Args:\n        inputs: A tensor of shape `(batch_size, ..., input_dim)`.\n\n    Returns:\n        A tensor of shape `(batch_size, ..., hidden_dims[-1])`.\n    \"\"\"\n    output = inputs\n    for layer in self._layers:\n        output = layer(output)\n    return output\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.feedforward.FeedForward.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code> <pre><code>def get_input_dim(self) -&gt; int:\n    return self._input_dim\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.feedforward.FeedForward.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/feedforward.py</code> <pre><code>def get_output_dim(self) -&gt; int:\n    return self._hidden_dims[-1]\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses","title":"formed.integrations.torch.modules.losses","text":"<p>Loss functions for classification tasks.</p> <p>This module provides loss functions for classification with support for label weighting and different reduction strategies.</p> Key Components <ul> <li><code>BaseClassificationLoss</code>: Abstract base class for classification losses</li> <li><code>CrossEntropyLoss</code>: Standard cross-entropy loss with optional weighting</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import CrossEntropyLoss\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Simple cross-entropy\n&gt;&gt;&gt; loss_fn = CrossEntropyLoss()\n&gt;&gt;&gt; logits = torch.randn(4, 10)  # (batch_size, num_classes)\n&gt;&gt;&gt; labels = torch.randint(0, 10, (4,))  # (batch_size,)\n&gt;&gt;&gt; loss = loss_fn(logits, labels)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With label weighting\n&gt;&gt;&gt; from formed.integrations.torch.modules import StaticLabelWeighter\n&gt;&gt;&gt; weighter = StaticLabelWeighter(weights=torch.ones(10))\n&gt;&gt;&gt; loss_fn = CrossEntropyLoss(weighter=weighter)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.BaseClassificationLoss","title":"BaseClassificationLoss","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for classification loss functions.</p> <p>A ClassificationLoss defines a strategy for computing loss based on model logits and true labels.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during loss computation.</p> <p> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.BaseClassificationLoss.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(logits, labels, params=None)\n</code></pre> <p>Compute the classification loss.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Model output logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>labels</code> <p>True target labels of shape <code>(...)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Optional additional parameters for loss computation.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Computed loss as a scalar tensor.</p> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>@abc.abstractmethod\ndef forward(self, logits: torch.Tensor, labels: torch.Tensor, params: Optional[_ParamsT] = None) -&gt; torch.Tensor:\n    \"\"\"Compute the classification loss.\n\n    Args:\n        logits: Model output logits of shape `(..., num_classes)`.\n        labels: True target labels of shape `(...)`.\n        params: Optional additional parameters for loss computation.\n\n    Returns:\n        Computed loss as a scalar tensor.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.CrossEntropyLoss","title":"CrossEntropyLoss","text":"<pre><code>CrossEntropyLoss(weighter=None, reduce='mean')\n</code></pre> <p>               Bases: <code>BaseClassificationLoss[_ParamsT]</code></p> <p>Cross-entropy loss for classification tasks.</p> PARAMETER DESCRIPTION <code>weighter</code> <p>An optional label weighter to assign weights to each class.</p> <p> TYPE: <code>Optional[BaseLabelWeighter[_ParamsT]]</code> DEFAULT: <code>None</code> </p> <code>reduce</code> <p>Reduction method - <code>\"mean\"</code> or <code>\"sum\"</code>.</p> <p> TYPE: <code>Literal['mean', 'sum']</code> DEFAULT: <code>'mean'</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; loss_fn = CrossEntropyLoss()\n&gt;&gt;&gt; logits = torch.randn(4, 10)\n&gt;&gt;&gt; labels = torch.randint(0, 10, (4,))\n&gt;&gt;&gt; loss = loss_fn(logits, labels)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>def __init__(\n    self,\n    weighter: Optional[BaseLabelWeighter[_ParamsT]] = None,\n    reduce: Literal[\"mean\", \"sum\"] = \"mean\",\n) -&gt; None:\n    super().__init__()\n    self._weighter = weighter\n    self._reduce = reduce\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.CrossEntropyLoss.forward","title":"forward","text":"<pre><code>forward(logits, labels, params=None)\n</code></pre> <p>Compute cross-entropy loss.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>labels</code> <p>Labels of shape <code>(...)</code>.</p> <p> TYPE: <code>TensorCompatible</code> </p> <code>params</code> <p>Optional parameters for the weighter.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Loss scalar.</p> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>def forward(\n    self,\n    logits: torch.Tensor,\n    labels: TensorCompatible,\n    params: Optional[_ParamsT] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Compute cross-entropy loss.\n\n    Args:\n        logits: Logits of shape `(..., num_classes)`.\n        labels: Labels of shape `(...)`.\n        params: Optional parameters for the weighter.\n\n    Returns:\n        Loss scalar.\n\n    \"\"\"\n    labels = ensure_torch_tensor(labels)\n\n    num_classes = logits.shape[-1]\n    one_hot_labels = F.one_hot(labels.long(), num_classes=num_classes).float()\n    log_probs = F.log_softmax(logits, dim=-1)\n\n    if self._weighter is not None:\n        weights = self._weighter(logits, labels, params)\n        loss = -(one_hot_labels * log_probs * weights).sum(dim=-1)\n    else:\n        loss = -(one_hot_labels * log_probs).sum(dim=-1)\n\n    if self._reduce == \"mean\":\n        return loss.mean()\n    elif self._reduce == \"sum\":\n        return loss.sum()\n    else:\n        raise ValueError(f\"Unknown reduce operation: {self._reduce}\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.BCEWithLogitsLoss","title":"BCEWithLogitsLoss","text":"<pre><code>BCEWithLogitsLoss(\n    weighter=None, reduce=\"mean\", pos_weight=None\n)\n</code></pre> <p>               Bases: <code>BaseClassificationLoss[_ParamsT]</code></p> <p>Binary cross-entropy loss with logits for multilabel classification tasks.</p> <p>This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by BCELoss.</p> PARAMETER DESCRIPTION <code>weighter</code> <p>An optional label weighter to assign weights to each class.</p> <p> TYPE: <code>Optional[BaseLabelWeighter[_ParamsT]]</code> DEFAULT: <code>None</code> </p> <code>reduce</code> <p>Reduction method - <code>\"mean\"</code> or <code>\"sum\"</code>.</p> <p> TYPE: <code>Literal['mean', 'sum']</code> DEFAULT: <code>'mean'</code> </p> <code>pos_weight</code> <p>Optional weight for positive examples per class.</p> <p> TYPE: <code>Optional[TensorCompatible]</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; loss_fn = BCEWithLogitsLoss()\n&gt;&gt;&gt; logits = torch.randn(4, 10)  # (batch_size, num_classes)\n&gt;&gt;&gt; labels = torch.randint(0, 2, (4, 10)).float()  # (batch_size, num_classes)\n&gt;&gt;&gt; loss = loss_fn(logits, labels)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>def __init__(\n    self,\n    weighter: Optional[BaseLabelWeighter[_ParamsT]] = None,\n    reduce: Literal[\"mean\", \"sum\"] = \"mean\",\n    pos_weight: Optional[TensorCompatible] = None,\n) -&gt; None:\n    super().__init__()\n    self._weighter = weighter\n    self._reduce = reduce\n    self._pos_weight = ensure_torch_tensor(pos_weight) if pos_weight is not None else None\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.BCEWithLogitsLoss.forward","title":"forward","text":"<pre><code>forward(logits, labels, params=None)\n</code></pre> <p>Compute BCE with logits loss.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>labels</code> <p>Binary labels of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>TensorCompatible</code> </p> <code>params</code> <p>Optional parameters for the weighter.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Loss scalar.</p> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>def forward(\n    self,\n    logits: torch.Tensor,\n    labels: TensorCompatible,\n    params: Optional[_ParamsT] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Compute BCE with logits loss.\n\n    Args:\n        logits: Logits of shape `(..., num_classes)`.\n        labels: Binary labels of shape `(..., num_classes)`.\n        params: Optional parameters for the weighter.\n\n    Returns:\n        Loss scalar.\n\n    \"\"\"\n    labels = ensure_torch_tensor(labels).float()\n\n    loss = F.binary_cross_entropy_with_logits(logits, labels, pos_weight=self._pos_weight, reduction=\"none\")\n\n    if self._weighter is not None:\n        weights = self._weighter(logits, labels, params)\n        loss = loss * weights\n\n    if self._reduce == \"mean\":\n        return loss.mean()\n    elif self._reduce == \"sum\":\n        return loss.sum()\n    else:\n        raise ValueError(f\"Unknown reduce operation: {self._reduce}\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.BaseRegressionLoss","title":"BaseRegressionLoss","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for regression loss functions.</p> <p>A RegressionLoss defines a strategy for computing loss based on model predictions and true labels.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during loss computation.</p> <p> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.BaseRegressionLoss.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(predictions, labels, params=None)\n</code></pre> <p>Compute the regression loss.</p> PARAMETER DESCRIPTION <code>predictions</code> <p>Model output predictions of shape <code>(...)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>labels</code> <p>True target labels of shape <code>(...)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Optional additional parameters for loss computation.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Computed loss as a scalar tensor.</p> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>@abc.abstractmethod\ndef forward(\n    self, predictions: torch.Tensor, labels: torch.Tensor, params: Optional[_ParamsT] = None\n) -&gt; torch.Tensor:\n    \"\"\"Compute the regression loss.\n\n    Args:\n        predictions: Model output predictions of shape `(...)`.\n        labels: True target labels of shape `(...)`.\n        params: Optional additional parameters for loss computation.\n\n    Returns:\n        Computed loss as a scalar tensor.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss","title":"MeanSquaredErrorLoss","text":"<pre><code>MeanSquaredErrorLoss(reduce='mean')\n</code></pre> <p>               Bases: <code>BaseRegressionLoss[_ParamsT]</code></p> <p>Mean Squared Error (MSE) loss for regression tasks.</p> PARAMETER DESCRIPTION <code>reduce</code> <p>Reduction method - <code>\"mean\"</code> or <code>\"sum\"</code>.</p> <p> TYPE: <code>Literal['mean', 'sum']</code> DEFAULT: <code>'mean'</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; loss_fn = MeanSquaredErrorLoss()\n&gt;&gt;&gt; predictions = torch.randn(4)\n&gt;&gt;&gt; labels = torch.randn(4)\n&gt;&gt;&gt; loss = loss_fn(predictions, labels)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>def __init__(\n    self,\n    reduce: Literal[\"mean\", \"sum\"] = \"mean\",\n) -&gt; None:\n    super().__init__()\n    self._reduce = reduce\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.losses.MeanSquaredErrorLoss.forward","title":"forward","text":"<pre><code>forward(predictions, labels, params=None)\n</code></pre> <p>Compute MSE loss.</p> PARAMETER DESCRIPTION <code>predictions</code> <p>Predictions of shape <code>(...)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>labels</code> <p>Labels of shape <code>(...)</code>.</p> <p> TYPE: <code>TensorCompatible</code> </p> <code>params</code> <p>Ignored.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Loss scalar.</p> Source code in <code>src/formed/integrations/torch/modules/losses.py</code> <pre><code>def forward(\n    self,\n    predictions: torch.Tensor,\n    labels: TensorCompatible,\n    params: Optional[_ParamsT] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Compute MSE loss.\n\n    Args:\n        predictions: Predictions of shape `(...)`.\n        labels: Labels of shape `(...)`.\n        params: Ignored.\n\n    Returns:\n        Loss scalar.\n\n    \"\"\"\n    labels = ensure_torch_tensor(labels)\n\n    loss = (predictions - labels).pow(2)\n\n    if self._reduce == \"mean\":\n        return loss.mean()\n    elif self._reduce == \"sum\":\n        return loss.sum()\n    else:\n        raise ValueError(f\"Unknown reduce operation: {self._reduce}\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.masks","title":"formed.integrations.torch.modules.masks","text":"<p>Attention mask generation for transformer models. This module provides reusable attention mask generators for transformer-based models in PyTorch. Attention masks control which positions in a sequence can attend to which other positions, enabling various attention patterns such as causal masking for autoregressive models or sliding window attention for long sequences.</p> Key Components <ul> <li><code>BaseAttentionMask</code>: Abstract base class for attention mask generators</li> <li><code>CausalMask</code>: Generates causal (autoregressive) attention masks</li> <li><code>SlidingWindowAttentionMask</code>: Generates sliding window attention masks</li> <li><code>CombinedMask</code>: Combines multiple attention masks into a single mask</li> </ul> Features <ul> <li>Standardized attention mask format compatible with PyTorch Transformer modules</li> <li>Support for batch-wise and sequence-wise masks</li> <li>Easily extensible via registration system for custom masks</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import CausalMask\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a causal mask generator\n&gt;&gt;&gt; mask_generator = CausalMask()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Generate a causal mask for sequence length 5 and batch size 2\n&gt;&gt;&gt; mask = mask_generator(seq_len=5, batch_size=2, device=torch.device('cpu'))\n&gt;&gt;&gt; # mask shape will be (5, 5) with float values: 0.0 for attendable positions,\n&gt;&gt;&gt; # float('-inf') for masked positions\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.masks.BaseAttentionMask","title":"BaseAttentionMask","text":"<p>               Bases: <code>Registrable</code>, <code>ABC</code></p> <p>Base class for attention mask generation.</p> <p>Attention masks control which positions can attend to which other positions in transformer models.</p> <p>All attention masks must return a mask of shape <code>(seq_len, seq_len)</code> or <code>(batch_size, seq_len, seq_len)</code> using float values where:</p> <ul> <li><code>0.0</code> indicates positions that CAN be attended to</li> <li><code>float('-inf')</code> indicates positions that should NOT be attended to</li> </ul> <p>This standardized format ensures compatibility with PyTorch's <code>TransformerEncoder.mask</code> parameter.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.masks.CausalMask","title":"CausalMask","text":"<p>               Bases: <code>BaseAttentionMask</code></p> <p>Generates causal (autoregressive) attention masks.</p> <p>Causal masks ensure that each position can only attend to itself and previous positions, enabling autoregressive generation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; masks = CausalMask()\n&gt;&gt;&gt; mask = masks(seq_len=4, batch_size=1, device=torch.device('cpu'))\n&gt;&gt;&gt; # mask[i, j] = 0.0 if j &lt;= i else float('-inf')\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask","title":"SlidingWindowAttentionMask","text":"<pre><code>SlidingWindowAttentionMask(window_size)\n</code></pre> <p>               Bases: <code>BaseAttentionMask</code></p> <p>Sliding window attention mask.</p> <p>Restricts attention to a local window around each position, enabling efficient processing of long sequences. Commonly used in models like Longformer and Mistral.</p> PARAMETER DESCRIPTION <code>window_size</code> <p>Size of the attention window on each side.          Total window is <code>(2 * window_size + 1)</code> centered on each position.</p> <p> TYPE: <code>int</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Window size of 1 means each position can attend to itself and\n&gt;&gt;&gt; # one position on each side\n&gt;&gt;&gt; mask_gen = SlidingWindowAttentionMask(window_size=1)\n&gt;&gt;&gt; mask = mask_gen(seq_len=4, batch_size=1, device=torch.device('cpu'))\n&gt;&gt;&gt; # Position 0: can attend to [0, 1]\n&gt;&gt;&gt; # Position 1: can attend to [0, 1, 2]\n&gt;&gt;&gt; # Position 2: can attend to [1, 2, 3]\n&gt;&gt;&gt; # Position 3: can attend to [2, 3]\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/masks.py</code> <pre><code>def __init__(self, window_size: int) -&gt; None:\n    if window_size &lt; 0:\n        raise ValueError(f\"window_size must be non-negative, got {window_size}\")\n    self.window_size = window_size\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.masks.SlidingWindowAttentionMask.window_size","title":"window_size  <code>instance-attribute</code>","text":"<pre><code>window_size = window_size\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.masks.CombinedMask","title":"CombinedMask","text":"<pre><code>CombinedMask(masks)\n</code></pre> <p>               Bases: <code>BaseAttentionMask</code></p> <p>Combines multiple attention masks.</p> <p>Applies multiple masks in sequence and combines their results. A position is masked if ANY mask blocks it (logical OR for <code>-inf</code> values).</p> PARAMETER DESCRIPTION <code>masks</code> <p>List of attention masks to combine.</p> <p> TYPE: <code>Sequence[BaseAttentionMask]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Combine multiple structural masks\n&gt;&gt;&gt; mask1 = CausalMask()\n&gt;&gt;&gt; mask2 = SomeOtherMask()\n&gt;&gt;&gt; combined = CombinedMask(masks=[mask1, mask2])\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/masks.py</code> <pre><code>def __init__(self, masks: Sequence[BaseAttentionMask]) -&gt; None:\n    self.masks = masks\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.masks.CombinedMask.masks","title":"masks  <code>instance-attribute</code>","text":"<pre><code>masks = masks\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers","title":"formed.integrations.torch.modules.samplers","text":"<p>Label samplers for classification tasks.</p> <p>This module provides samplers that convert model logits into discrete labels.</p> Key Components <ul> <li><code>BaseLabelSampler</code>: Abstract base class for label samplers</li> <li><code>ArgmaxLabelSampler</code>: Selects the label with highest logit</li> <li><code>MultinomialLabelSampler</code>: Samples from categorical distribution</li> <li><code>BaseMultilabelSampler</code>: Abstract base class for multilabel samplers</li> <li><code>ThresholdMultilabelSampler</code>: Selects labels above a threshold</li> <li><code>TopKMultilabelSampler</code>: Selects top-k labels</li> <li><code>BernoulliMultilabelSampler</code>: Samples labels from independent Bernoulli distributions</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import ArgmaxLabelSampler, MultinomialLabelSampler\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt;\n&gt;&gt;&gt; logits = torch.randn(4, 10)  # (batch_size, num_classes)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Argmax sampling (deterministic)\n&gt;&gt;&gt; argmax_sampler = ArgmaxLabelSampler()\n&gt;&gt;&gt; labels = argmax_sampler(logits)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Multinomial sampling (stochastic)\n&gt;&gt;&gt; multi_sampler = MultinomialLabelSampler()\n&gt;&gt;&gt; labels = multi_sampler(logits, temperature=0.8)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.BaseLabelSampler","title":"BaseLabelSampler","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for label samplers.</p> <p>A LabelSampler defines a strategy for sampling labels based on model logits.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during sampling.</p> <p> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.BaseLabelSampler.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(logits, params=None)\n</code></pre> <p>Sample labels from logits.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Model output logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Additional parameters for sampling.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Sampled labels of shape <code>(...)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>@abc.abstractmethod\ndef forward(self, logits: torch.Tensor, params: Optional[_ParamsT] = None) -&gt; torch.Tensor:\n    \"\"\"Sample labels from logits.\n\n    Args:\n        logits: Model output logits of shape `(..., num_classes)`.\n        params: Additional parameters for sampling.\n\n    Returns:\n        Sampled labels of shape `(...)`.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler","title":"ArgmaxLabelSampler","text":"<p>               Bases: <code>BaseLabelSampler[None]</code></p> <p>Label sampler that selects the label with the highest logit.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sampler = ArgmaxLabelSampler()\n&gt;&gt;&gt; logits = torch.randn(4, 10)\n&gt;&gt;&gt; labels = sampler(logits)  # Shape: (4,)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.ArgmaxLabelSampler.forward","title":"forward","text":"<pre><code>forward(logits, params=None)\n</code></pre> <p>Select the argmax label.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Ignored.</p> <p> TYPE: <code>None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Labels of shape <code>(...)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>def forward(self, logits: torch.Tensor, params: None = None) -&gt; torch.Tensor:\n    \"\"\"Select the argmax label.\n\n    Args:\n        logits: Logits of shape `(..., num_classes)`.\n        params: Ignored.\n\n    Returns:\n        Labels of shape `(...)`.\n\n    \"\"\"\n    return logits.argmax(dim=-1)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams","title":"MultinomialLabelSamplerParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameters for MultinomialLabelSampler.</p> ATTRIBUTE DESCRIPTION <code>temperature</code> <p>Sampling temperature to control randomness. Higher temperature = more random, lower = more deterministic.</p> <p> TYPE: <code>float</code> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.MultinomialLabelSamplerParams.temperature","title":"temperature  <code>instance-attribute</code>","text":"<pre><code>temperature\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.MultinomialLabelSampler","title":"MultinomialLabelSampler","text":"<p>               Bases: <code>BaseLabelSampler[MultinomialLabelSamplerParams]</code></p> <p>Label sampler that samples labels from a multinomial distribution.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sampler = MultinomialLabelSampler()\n&gt;&gt;&gt; logits = torch.randn(4, 10)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Sample with default temperature\n&gt;&gt;&gt; labels = sampler(logits)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Sample with temperature scaling\n&gt;&gt;&gt; labels = sampler(logits, temperature=0.5)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.MultinomialLabelSampler.forward","title":"forward","text":"<pre><code>forward(logits, params=None)\n</code></pre> <p>Sample labels from categorical distribution.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Optional parameters containing temperature for sampling.</p> <p> TYPE: <code>Optional[MultinomialLabelSamplerParams]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Sampled labels of shape <code>(...)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>def forward(self, logits: torch.Tensor, params: Optional[MultinomialLabelSamplerParams] = None) -&gt; torch.Tensor:\n    \"\"\"Sample labels from categorical distribution.\n\n    Args:\n        logits: Logits of shape `(..., num_classes)`.\n        params: Optional parameters containing temperature for sampling.\n\n    Returns:\n        Sampled labels of shape `(...)`.\n\n    \"\"\"\n    temperature = params.get(\"temperature\", 1.0) if params is not None else 1.0\n    if temperature != 1.0:\n        logits = logits / temperature\n\n    probs = F.softmax(logits, dim=-1)\n    return torch.multinomial(probs.view(-1, probs.shape[-1]), num_samples=1).view(probs.shape[:-1])\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.BaseMultilabelSampler","title":"BaseMultilabelSampler","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for multilabel samplers.</p> <p>A MultilabelSampler defines a strategy for sampling multiple labels based on model logits.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during sampling.</p> <p> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.BaseMultilabelSampler.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(logits, params=None)\n</code></pre> <p>Sample multiple labels from logits.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Model output logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Additional parameters for sampling.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Sampled labels of shape <code>(..., num_labels)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>@abc.abstractmethod\ndef forward(self, logits: torch.Tensor, params: Optional[_ParamsT] = None) -&gt; torch.Tensor:\n    \"\"\"Sample multiple labels from logits.\n\n    Args:\n        logits: Model output logits of shape `(..., num_classes)`.\n        params: Additional parameters for sampling.\n\n    Returns:\n        Sampled labels of shape `(..., num_labels)`.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams","title":"ThresholdMultilabelSamplerParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameters for ThresholdMultilabelSampler.</p> ATTRIBUTE DESCRIPTION <code>threshold</code> <p>Probability threshold for selecting labels.</p> <p> TYPE: <code>float</code> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.ThresholdMultilabelSamplerParams.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler","title":"ThresholdMultilabelSampler","text":"<pre><code>ThresholdMultilabelSampler(threshold=0.5)\n</code></pre> <p>               Bases: <code>BaseMultilabelSampler[ThresholdMultilabelSamplerParams]</code></p> <p>Multilabel sampler that selects labels above a certain threshold.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sampler = ThresholdMultilabelSampler(threshold=0.5)\n&gt;&gt;&gt; logits = torch.randn(4, 10)\n&gt;&gt;&gt; labels = sampler(logits)  # Shape: (4, num_labels)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>def __init__(self, threshold: float = 0.5) -&gt; None:\n    super().__init__()\n    self.threshold = threshold\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.threshold","title":"threshold  <code>instance-attribute</code>","text":"<pre><code>threshold = threshold\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.ThresholdMultilabelSampler.forward","title":"forward","text":"<pre><code>forward(logits, params=None)\n</code></pre> <p>Select labels above the threshold.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Optional parameters containing threshold.</p> <p> TYPE: <code>Optional[ThresholdMultilabelSamplerParams]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Labels of shape <code>(..., num_labels)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>def forward(\n    self,\n    logits: torch.Tensor,\n    params: Optional[ThresholdMultilabelSamplerParams] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Select labels above the threshold.\n\n    Args:\n        logits: Logits of shape `(..., num_classes)`.\n        params: Optional parameters containing threshold.\n\n    Returns:\n        Labels of shape `(..., num_labels)`.\n\n    \"\"\"\n    threshold = (params or {}).get(\"threshold\", self.threshold)\n    probs = torch.sigmoid(logits)\n    return (probs &gt;= threshold).float()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams","title":"TopKMultilabelSamplerParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameters for TopKMultilabelSampler.</p> ATTRIBUTE DESCRIPTION <code>k</code> <p>Number of top labels to select.</p> <p> TYPE: <code>int</code> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.TopKMultilabelSamplerParams.k","title":"k  <code>instance-attribute</code>","text":"<pre><code>k\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.TopKMultilabelSampler","title":"TopKMultilabelSampler","text":"<pre><code>TopKMultilabelSampler(k=1)\n</code></pre> <p>               Bases: <code>BaseMultilabelSampler[TopKMultilabelSamplerParams]</code></p> <p>Multilabel sampler that selects the top-k labels.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sampler = TopKMultilabelSampler(k=3)\n&gt;&gt;&gt; logits = torch.randn(4, 10)\n&gt;&gt;&gt; labels = sampler(logits)  # Shape: (4, num_labels)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>def __init__(self, k: int = 1) -&gt; None:\n    super().__init__()\n    self.k = k\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.k","title":"k  <code>instance-attribute</code>","text":"<pre><code>k = k\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.TopKMultilabelSampler.forward","title":"forward","text":"<pre><code>forward(logits, params=None)\n</code></pre> <p>Select the top-k labels.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Optional parameters containing k for top-k selection.</p> <p> TYPE: <code>Optional[TopKMultilabelSamplerParams]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Labels of shape <code>(..., num_labels)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>def forward(\n    self,\n    logits: torch.Tensor,\n    params: Optional[TopKMultilabelSamplerParams] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Select the top-k labels.\n\n    Args:\n        logits: Logits of shape `(..., num_classes)`.\n        params: Optional parameters containing k for top-k selection.\n\n    Returns:\n        Labels of shape `(..., num_labels)`.\n\n    \"\"\"\n    k = (params or {}).get(\"k\", self.k)\n    topk_indices = logits.topk(k, dim=-1).indices\n    labels = torch.zeros_like(logits).scatter_(-1, topk_indices, 1.0)\n    return labels\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler","title":"BernoulliMultilabelSampler","text":"<p>               Bases: <code>BaseMultilabelSampler[None]</code></p> <p>Multilabel sampler that samples labels from independent Bernoulli distributions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sampler = BernoulliMultilabelSampler()\n&gt;&gt;&gt; logits = torch.randn(4, 10)\n&gt;&gt;&gt; labels = sampler(logits)  # Shape: (4, num_labels)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.samplers.BernoulliMultilabelSampler.forward","title":"forward","text":"<pre><code>forward(logits, params=None)\n</code></pre> <p>Sample labels from Bernoulli distributions.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Ignored.</p> <p> TYPE: <code>None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Sampled labels of shape <code>(..., num_labels)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/samplers.py</code> <pre><code>def forward(self, logits: torch.Tensor, params: None = None) -&gt; torch.Tensor:\n    \"\"\"Sample labels from Bernoulli distributions.\n\n    Args:\n        logits: Logits of shape `(..., num_classes)`.\n        params: Ignored.\n\n    Returns:\n        Sampled labels of shape `(..., num_labels)`.\n\n    \"\"\"\n    probs = torch.sigmoid(logits)\n    return torch.bernoulli(probs)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.scalarmix","title":"formed.integrations.torch.modules.scalarmix","text":""},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.scalarmix.ScalarMix","title":"ScalarMix","text":"<pre><code>ScalarMix(\n    mixture_size,\n    do_layer_norm=False,\n    initial_scalar_parameters=None,\n    trainable=True,\n)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Computes a parameterised scalar mixture of N tensors, <code>mixture = gamma * sum(s_k * tensor_k)</code> where <code>s = softmax(w)</code>, with <code>w</code> and <code>gamma</code> scalar parameters. In addition, if <code>do_layer_norm=True</code> then apply layer normalization to each tensor before weighting.</p> Note <p>This script is based on the AllenNLP implementation of ScalarMix: https://github.com/allenai/allennlp/blob/v2.10.0/allennlp/modules/scalar_mix.py</p> Source code in <code>src/formed/integrations/torch/modules/scalarmix.py</code> <pre><code>def __init__(\n    self,\n    mixture_size: int,\n    do_layer_norm: bool = False,\n    initial_scalar_parameters: Sequence[float] | None = None,\n    trainable: bool = True,\n) -&gt; None:\n    super().__init__()\n    self.mixture_size = mixture_size\n    self.do_layer_norm = do_layer_norm\n\n    if initial_scalar_parameters is None:\n        initial_scalar_parameters = [0.0] * mixture_size\n    elif len(initial_scalar_parameters) != mixture_size:\n        raise ValueError(\n            \"Length of initial_scalar_parameters {} differs from mixture_size {}\".format(\n                initial_scalar_parameters, mixture_size\n            )\n        )\n\n    self.scalar_parameters = torch.nn.ParameterList(\n        [\n            torch.nn.Parameter(torch.FloatTensor([initial_scalar_parameters[i]]), requires_grad=trainable)\n            for i in range(mixture_size)\n        ]\n    )\n    self.gamma = torch.nn.Parameter(torch.FloatTensor([1.0]), requires_grad=trainable)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.scalarmix.ScalarMix.mixture_size","title":"mixture_size  <code>instance-attribute</code>","text":"<pre><code>mixture_size = mixture_size\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.scalarmix.ScalarMix.do_layer_norm","title":"do_layer_norm  <code>instance-attribute</code>","text":"<pre><code>do_layer_norm = do_layer_norm\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.scalarmix.ScalarMix.scalar_parameters","title":"scalar_parameters  <code>instance-attribute</code>","text":"<pre><code>scalar_parameters = ParameterList(\n    [\n        (\n            Parameter(\n                FloatTensor(\n                    [initial_scalar_parameters[i]]\n                ),\n                requires_grad=trainable,\n            )\n        )\n        for i in (range(mixture_size))\n    ]\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.scalarmix.ScalarMix.gamma","title":"gamma  <code>instance-attribute</code>","text":"<pre><code>gamma = Parameter(\n    FloatTensor([1.0]), requires_grad=trainable\n)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.scalarmix.ScalarMix.forward","title":"forward","text":"<pre><code>forward(tensors, mask=None)\n</code></pre> <p>Compute a weighted average of the <code>tensors</code>.  The input tensors an be any shape with at least two dimensions, but must all be the same shape. When <code>do_layer_norm=True</code>, the <code>mask</code> is required input.  If the <code>tensors</code> are dimensioned  <code>(dim_0, ..., dim_{n-1}, dim_n)</code>, then the <code>mask</code> is dimensioned <code>(dim_0, ..., dim_{n-1})</code>, as in the typical case with <code>tensors</code> of shape <code>(batch_size, timesteps, dim)</code> and <code>mask</code> of shape <code>(batch_size, timesteps)</code>. When <code>do_layer_norm=False</code> the <code>mask</code> is ignored.</p> Source code in <code>src/formed/integrations/torch/modules/scalarmix.py</code> <pre><code>def forward(self, tensors: Sequence[torch.Tensor], mask: torch.Tensor | None = None) -&gt; torch.Tensor:\n    \"\"\"\n    Compute a weighted average of the `tensors`.  The input tensors an be any shape\n    with at least two dimensions, but must all be the same shape.\n    When `do_layer_norm=True`, the `mask` is required input.  If the `tensors` are\n    dimensioned  `(dim_0, ..., dim_{n-1}, dim_n)`, then the `mask` is dimensioned\n    `(dim_0, ..., dim_{n-1})`, as in the typical case with `tensors` of shape\n    `(batch_size, timesteps, dim)` and `mask` of shape `(batch_size, timesteps)`.\n    When `do_layer_norm=False` the `mask` is ignored.\n    \"\"\"\n    if len(tensors) != self.mixture_size:\n        raise ValueError(\n            \"{} tensors were passed, but the module was initialized to mix {} tensors.\".format(\n                len(tensors), self.mixture_size\n            )\n        )\n\n    def _do_layer_norm(\n        tensor: torch.Tensor,\n        broadcast_mask: torch.Tensor,\n        num_elements_not_masked: torch.Tensor,\n    ) -&gt; torch.Tensor:\n        tensor_masked = tensor * broadcast_mask\n        mean = torch.sum(tensor_masked) / num_elements_not_masked\n        variance = torch.sum(((tensor_masked - mean) * broadcast_mask) ** 2) / num_elements_not_masked\n        return (tensor - mean) / torch.sqrt(variance + 1e-13)\n\n    normed_weights = torch.split(\n        torch.nn.functional.softmax(torch.cat([parameter for parameter in self.scalar_parameters]), dim=0),\n        split_size_or_sections=1,\n    )\n\n    pieces: list[torch.Tensor]\n    if not self.do_layer_norm:\n        pieces = [weight * tensor for weight, tensor in zip(normed_weights, tensors)]\n        return self.gamma * sum(pieces)\n\n    else:\n        assert mask is not None\n        broadcast_mask = mask.unsqueeze(-1)\n        input_dim = tensors[0].size(-1)\n        num_elements_not_masked = torch.sum(mask) * input_dim\n\n        pieces = [\n            weight * _do_layer_norm(tensor, broadcast_mask, num_elements_not_masked)\n            for weight, tensor in zip(normed_weights, tensors)\n        ]\n        return self.gamma * sum(pieces)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers","title":"formed.integrations.torch.modules.vectorizers","text":"<p>Sequence vectorization modules for PyTorch models.</p> <p>This module provides vectorizers that convert variable-length sequences into fixed-size vectors. Vectorizers apply pooling operations over the sequence dimension to produce single vectors per sequence.</p> Key Components <ul> <li><code>BaseSequenceVectorizer</code>: Abstract base class for vectorizers</li> <li><code>BagOfEmbeddingsSequenceVectorizer</code>: Pools sequence embeddings</li> </ul> Features <ul> <li>Multiple pooling strategies (mean, max, min, sum, first, last, hier)</li> <li>Masked pooling to ignore padding tokens</li> <li>Optional normalization before pooling</li> <li>Hierarchical pooling with sliding windows</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import BagOfEmbeddingsSequenceVectorizer\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Mean pooling over sequence\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(pooling=\"mean\")\n&gt;&gt;&gt; vector = vectorizer(embeddings, mask=mask)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Max pooling with normalization\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(\n...     pooling=\"max\",\n...     normalize=True\n... )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer","title":"BaseSequenceVectorizer","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>ABC</code></p> <p>Abstract base class for sequence vectorizers.</p> <p>Vectorizers convert variable-length sequences into fixed-size vectors by applying pooling operations over the sequence dimension.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(inputs, *, mask=None)\n</code></pre> <p>Vectorize a sequence into a fixed-size vector.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Input embeddings of shape <code>(batch_size, seq_len, embedding_dim)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>Optional attention mask of shape <code>(batch_size, seq_len)</code>.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Vectorized output of shape <code>(batch_size, output_dim)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code> <pre><code>@abc.abstractmethod\ndef forward(\n    self,\n    inputs: torch.Tensor,\n    *,\n    mask: torch.Tensor | None = None,\n) -&gt; torch.Tensor:\n    \"\"\"Vectorize a sequence into a fixed-size vector.\n\n    Args:\n        inputs: Input embeddings of shape `(batch_size, seq_len, embedding_dim)`.\n        mask: Optional attention mask of shape `(batch_size, seq_len)`.\n\n    Returns:\n        Vectorized output of shape `(batch_size, output_dim)`.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_input_dim","title":"get_input_dim  <code>abstractmethod</code>","text":"<pre><code>get_input_dim()\n</code></pre> <p>Get the expected input dimension.</p> RETURNS DESCRIPTION <code>int | None</code> <p>Input dimension or None if dimension-agnostic.</p> Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code> <pre><code>@abc.abstractmethod\ndef get_input_dim(self) -&gt; int | None:\n    \"\"\"Get the expected input dimension.\n\n    Returns:\n        Input dimension or None if dimension-agnostic.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BaseSequenceVectorizer.get_output_dim","title":"get_output_dim  <code>abstractmethod</code>","text":"<pre><code>get_output_dim()\n</code></pre> <p>Get the output dimension.</p> RETURNS DESCRIPTION <code>int | Callable[[int], int]</code> <p>Output feature dimension or a function mapping input dim to output dim.</p> Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code> <pre><code>@abc.abstractmethod\ndef get_output_dim(self) -&gt; int | Callable[[int], int]:\n    \"\"\"Get the output dimension.\n\n    Returns:\n        Output feature dimension or a function mapping input dim to output dim.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer","title":"BagOfEmbeddingsSequenceVectorizer","text":"<pre><code>BagOfEmbeddingsSequenceVectorizer(\n    pooling=\"mean\", normalize=False, window_size=None\n)\n</code></pre> <p>               Bases: <code>BaseSequenceVectorizer</code></p> <p>Bag-of-embeddings vectorizer using pooling operations.</p> <p>This vectorizer applies pooling over the sequence dimension to create fixed-size vectors. Multiple pooling strategies are supported, and padding tokens are properly masked during pooling.</p> PARAMETER DESCRIPTION <code>pooling</code> <p>Pooling strategy to use: - <code>\"mean\"</code>: Average pooling (default) - <code>\"max\"</code>: Max pooling - <code>\"min\"</code>: Min pooling - <code>\"sum\"</code>: Sum pooling - <code>\"first\"</code>: Take first token - <code>\"last\"</code>: Take last non-padding token - <code>\"hier\"</code>: Hierarchical pooling with sliding window</p> <p> TYPE: <code>PoolingMethod | Sequence[PoolingMethod]</code> DEFAULT: <code>'mean'</code> </p> <code>normalize</code> <p>Whether to L2-normalize embeddings before pooling.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>window_size</code> <p>Window size for hierarchical pooling (required if <code>pooling=\"hier\"</code>).</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Mean pooling\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(pooling=\"mean\")\n&gt;&gt;&gt; vector = vectorizer(embeddings, mask=mask)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Max pooling with normalization\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(\n...     pooling=\"max\",\n...     normalize=True\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Multiple pooling methods combined\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(\n...     pooling=[\"mean\", \"max\"]\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Hierarchical pooling\n&gt;&gt;&gt; vectorizer = BagOfEmbeddingsSequenceVectorizer(\n...     pooling=\"hier\",\n...     window_size=3\n... )\n</code></pre> Note <p>This vectorizer is dimension-agnostic - it preserves the embedding dimension from input to output (multiplied by number of pooling methods).</p> Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code> <pre><code>def __init__(\n    self,\n    pooling: PoolingMethod | Sequence[PoolingMethod] = \"mean\",\n    normalize: bool = False,\n    window_size: int | None = None,\n) -&gt; None:\n    super().__init__()\n    self._pooling: PoolingMethod | Sequence[PoolingMethod] = pooling\n    self._normalize = normalize\n    self._window_size = window_size\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.forward","title":"forward","text":"<pre><code>forward(inputs, *, mask=None)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code> <pre><code>def forward(\n    self,\n    inputs: torch.Tensor,\n    *,\n    mask: torch.Tensor | None = None,\n) -&gt; torch.Tensor:\n    return masked_pool(\n        inputs,\n        mask=mask,\n        pooling=self._pooling,\n        normalize=self._normalize,\n        window_size=self._window_size,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_input_dim","title":"get_input_dim","text":"<pre><code>get_input_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code> <pre><code>def get_input_dim(self) -&gt; None:\n    return None\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.vectorizers.BagOfEmbeddingsSequenceVectorizer.get_output_dim","title":"get_output_dim","text":"<pre><code>get_output_dim()\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/vectorizers.py</code> <pre><code>def get_output_dim(self) -&gt; Callable[[int], int]:\n    num_pooling = 1 if isinstance(self._pooling, str) else len(self._pooling)\n    return lambda input_dim: input_dim * num_pooling\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.weighters","title":"formed.integrations.torch.modules.weighters","text":"<p>Label weighters for classification tasks.</p> <p>This module provides weighters that assign weights to class labels, useful for handling imbalanced datasets.</p> Key Components <ul> <li><code>BaseLabelWeighter</code>: Abstract base class for label weighters</li> <li><code>StaticLabelWeighter</code>: Uses fixed weights per class</li> <li><code>BalancedByDistributionLabelWeighter</code>: Balances based on class distribution</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch.modules import StaticLabelWeighter\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Static weights for 3 classes\n&gt;&gt;&gt; weights = torch.tensor([1.0, 2.0, 3.0])  # Weight rare classes more\n&gt;&gt;&gt; weighter = StaticLabelWeighter(weights=weights)\n&gt;&gt;&gt;\n&gt;&gt;&gt; logits = torch.randn(4, 3)\n&gt;&gt;&gt; labels = torch.tensor([0, 1, 2, 0])\n&gt;&gt;&gt; class_weights = weighter(logits, labels)  # Shape: (1, 3)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.weighters.BaseLabelWeighter","title":"BaseLabelWeighter","text":"<p>               Bases: <code>Module</code>, <code>Registrable</code>, <code>Generic[_ParamsT]</code>, <code>ABC</code></p> <p>Abstract base class for label weighters.</p> <p>A LabelWeighter defines a strategy for assigning weights to each label based on model logits and true targets.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>_ParamsT</code> <p>Type of additional parameters used during weighting.</p> <p> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.weighters.BaseLabelWeighter.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(logits, targets, params=None)\n</code></pre> <p>Compute weights for each target label.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Model output logits of shape <code>(..., num_classes)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>targets</code> <p>True target labels of shape <code>(...)</code>.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Optional additional parameters for weighting.</p> <p> TYPE: <code>Optional[_ParamsT]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Weights for each logit of shape <code>(1, num_classes)</code> or broadcastable to logits shape.</p> Source code in <code>src/formed/integrations/torch/modules/weighters.py</code> <pre><code>@abc.abstractmethod\ndef forward(\n    self,\n    logits: torch.Tensor,\n    targets: torch.Tensor,\n    params: Optional[_ParamsT] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Compute weights for each target label.\n\n    Args:\n        logits: Model output logits of shape `(..., num_classes)`.\n        targets: True target labels of shape `(...)`.\n        params: Optional additional parameters for weighting.\n\n    Returns:\n        Weights for each logit of shape `(1, num_classes)` or broadcastable to logits shape.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.weighters.StaticLabelWeighter","title":"StaticLabelWeighter","text":"<pre><code>StaticLabelWeighter(weights)\n</code></pre> <p>               Bases: <code>BaseLabelWeighter[None]</code></p> <p>Label weighter that assigns static weights to each class.</p> PARAMETER DESCRIPTION <code>weights</code> <p>A tensor of shape <code>(num_classes,)</code> containing the weight for each class.</p> <p> TYPE: <code>TensorCompatible</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Weight class 1 twice as much as class 0\n&gt;&gt;&gt; weights = torch.tensor([1.0, 2.0, 1.0])\n&gt;&gt;&gt; weighter = StaticLabelWeighter(weights=weights)\n&gt;&gt;&gt; logits = torch.randn(4, 3)\n&gt;&gt;&gt; labels = torch.tensor([0, 1, 2, 0])\n&gt;&gt;&gt; class_weights = weighter(logits, labels)\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/weighters.py</code> <pre><code>def __init__(self, weights: TensorCompatible) -&gt; None:\n    super().__init__()\n    self.register_buffer(\"_weights\", ensure_torch_tensor(weights, dtype=torch.float))\n    self._weights: torch.Tensor\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.weighters.StaticLabelWeighter.forward","title":"forward","text":"<pre><code>forward(logits, targets, params=None)\n</code></pre> <p>Return static weights.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Ignored.</p> <p> TYPE: <code>Tensor</code> </p> <code>targets</code> <p>Ignored.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Ignored.</p> <p> TYPE: <code>None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Weights of shape <code>(1, num_classes)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/weighters.py</code> <pre><code>def forward(\n    self,\n    logits: torch.Tensor,\n    targets: torch.Tensor,\n    params: None = None,\n) -&gt; torch.Tensor:\n    \"\"\"Return static weights.\n\n    Args:\n        logits: Ignored.\n        targets: Ignored.\n        params: Ignored.\n\n    Returns:\n        Weights of shape `(1, num_classes)`.\n\n    \"\"\"\n    return self._weights.unsqueeze(0)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter","title":"BalancedByDistributionLabelWeighter","text":"<pre><code>BalancedByDistributionLabelWeighter(\n    distribution, eps=1e-08\n)\n</code></pre> <p>               Bases: <code>BaseLabelWeighter[None]</code></p> <p>Label weighter that balances classes based on their distribution.</p> <p>The weight for each class is computed as: <code>1 / (distribution * num_classes + eps)</code></p> PARAMETER DESCRIPTION <code>distribution</code> <p>A tensor of shape <code>(num_classes,)</code> representing the class distribution (should sum to <code>1.0</code>).</p> <p> TYPE: <code>TensorCompatible</code> </p> <code>eps</code> <p>A small epsilon value to avoid division by zero.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Class distribution: 50%, 30%, 20%\n&gt;&gt;&gt; distribution = torch.tensor([0.5, 0.3, 0.2])\n&gt;&gt;&gt; weighter = BalancedByDistributionLabelWeighter(distribution=distribution)\n&gt;&gt;&gt; logits = torch.randn(4, 3)\n&gt;&gt;&gt; labels = torch.tensor([0, 1, 2, 0])\n&gt;&gt;&gt; class_weights = weighter(logits, labels)\n&gt;&gt;&gt; # Rare classes get higher weights\n</code></pre> Source code in <code>src/formed/integrations/torch/modules/weighters.py</code> <pre><code>def __init__(self, distribution: TensorCompatible, eps: float = 1e-8) -&gt; None:\n    super().__init__()\n    self.register_buffer(\"_distribution\", ensure_torch_tensor(distribution, dtype=torch.float))\n    self._distribution: torch.Tensor\n    self._eps = eps\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.modules.weighters.BalancedByDistributionLabelWeighter.forward","title":"forward","text":"<pre><code>forward(logits, targets, params=None)\n</code></pre> <p>Compute balanced weights.</p> PARAMETER DESCRIPTION <code>logits</code> <p>Ignored.</p> <p> TYPE: <code>Tensor</code> </p> <code>targets</code> <p>Ignored.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Ignored.</p> <p> TYPE: <code>None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Weights of shape <code>(1, num_classes)</code>.</p> Source code in <code>src/formed/integrations/torch/modules/weighters.py</code> <pre><code>def forward(\n    self,\n    logits: torch.Tensor,\n    targets: torch.Tensor,\n    params: None = None,\n) -&gt; torch.Tensor:\n    \"\"\"Compute balanced weights.\n\n    Args:\n        logits: Ignored.\n        targets: Ignored.\n        params: Ignored.\n\n    Returns:\n        Weights of shape `(1, num_classes)`.\n\n    \"\"\"\n    num_classes = len(self._distribution)\n    weights = 1.0 / (self._distribution * num_classes + self._eps)\n    return weights.unsqueeze(0)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks","title":"formed.integrations.torch.training.callbacks","text":"<p>Training callbacks for monitoring and controlling PyTorch model training.</p> <p>This module provides a callback system for PyTorch training, allowing custom logic to be executed at various points in the training loop. Callbacks can monitor metrics, save checkpoints, implement early stopping, and integrate with experiment tracking systems.</p> Key Components <ul> <li><code>TorchTrainingCallback</code>: Base class for all callbacks</li> <li><code>EvaluationCallback</code>: Computes metrics using custom evaluators</li> <li><code>EarlyStoppingCallback</code>: Stops training based on metric improvements</li> <li><code>MlflowCallback</code>: Logs metrics to MLflow</li> </ul> Features <ul> <li>Hook points at training/epoch/batch start and end</li> <li>Metric computation and logging</li> <li>Model checkpointing</li> <li>Early stopping with patience</li> <li>MLflow integration</li> <li>Extensible for custom callbacks</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import (\n...     TorchTrainer,\n...     EarlyStoppingCallback,\n...     EvaluationCallback,\n...     MlflowCallback\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; trainer = TorchTrainer(\n...     train_dataloader=train_loader,\n...     val_dataloader=val_loader,\n...     callbacks=[\n...         EvaluationCallback(my_evaluator),\n...         EarlyStoppingCallback(patience=5, metric=\"-loss\"),\n...         MlflowCallback()\n...     ]\n... )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback","title":"TorchTrainingCallback","text":"<p>               Bases: <code>Registrable</code></p> <p>Base class for training callbacks.</p> <p>Callbacks provide hooks to execute custom logic at various points during training. Subclasses can override any hook method to implement custom behavior such as logging, checkpointing, or early stopping.</p> Hook execution order <ol> <li><code>on_training_start</code> - once at the beginning</li> <li><code>on_epoch_start</code> - at the start of each epoch</li> <li><code>on_batch_start</code> - before each training batch</li> <li><code>on_batch_end</code> - after each training batch</li> <li><code>on_eval_start</code> - before evaluation (returns evaluator)</li> <li><code>on_eval_end</code> - after evaluation with computed metrics</li> <li><code>on_log</code> - when metrics are logged</li> <li><code>on_epoch_end</code> - at the end of each epoch</li> <li><code>on_training_end</code> - once at the end (can modify final state)</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @TorchTrainingCallback.register(\"my_callback\")\n... class MyCallback(TorchTrainingCallback):\n...     def on_epoch_end(self, trainer, model, state, epoch):\n...         print(f\"Completed epoch {epoch} at step {state.step}\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    return state\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    class DummyMetric(IEvaluator):\n        def update(self, inputs, output, /) -&gt; None:\n            pass\n\n        def compute(self) -&gt; dict[str, float]:\n            return {}\n\n        def reset(self) -&gt; None:\n            pass\n\n    return DummyMetric()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.TorchTrainingCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback","title":"EvaluationCallback","text":"<pre><code>EvaluationCallback(evaluator)\n</code></pre> <p>               Bases: <code>TorchTrainingCallback</code>, <code>Generic[ModelInputT, ModelOutputT]</code></p> <p>Callback for computing metrics using a custom evaluator.</p> <p>This callback integrates a custom evaluator into the training loop, resetting it before each evaluation phase and returning it for metric accumulation.</p> PARAMETER DESCRIPTION <code>evaluator</code> <p>Evaluator implementing the <code>IEvaluator</code> protocol.</p> <p> TYPE: <code>IEvaluator[ModelInputT, ModelOutputT]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.ml.metrics import MulticlassAccuracy\n&gt;&gt;&gt;\n&gt;&gt;&gt; evaluator = MulticlassAccuracy()\n&gt;&gt;&gt; callback = EvaluationCallback(evaluator)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def __init__(self, evaluator: IEvaluator[ModelInputT, ModelOutputT]) -&gt; None:\n    self._evaluator = evaluator\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_start(  # pyright: ignore[reportIncompatibleMethodOverride]\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    self._evaluator.reset()\n    return self._evaluator\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    return state\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EvaluationCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback","title":"EarlyStoppingCallback","text":"<pre><code>EarlyStoppingCallback(patience=5, metric='-train/loss')\n</code></pre> <p>               Bases: <code>TorchTrainingCallback</code></p> <p>Callback for early stopping based on metric improvements.</p> <p>This callback monitors a specified metric and stops training if it doesn't improve for a given number of evaluations (patience). The best model is automatically saved and restored at the end of training.</p> PARAMETER DESCRIPTION <code>patience</code> <p>Number of evaluations without improvement before stopping.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>metric</code> <p>Metric to monitor. Prefix with <code>-</code> to maximize (e.g., <code>\"-loss\"</code>), or <code>+</code> to minimize (e.g., <code>\"+error\"</code>). Default is <code>\"-loss\"</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'-train/loss'</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Stop if validation loss doesn't improve for 5 evaluations\n&gt;&gt;&gt; callback = EarlyStoppingCallback(patience=5, metric=\"-val/loss\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Stop if accuracy doesn't improve for 3 evaluations\n&gt;&gt;&gt; callback = EarlyStoppingCallback(patience=3, metric=\"+accuracy\")\n</code></pre> Note <p>The best model is saved to the step working directory and automatically restored when training ends early or completes.</p> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def __init__(\n    self,\n    patience: int = 5,\n    metric: str = \"-train/loss\",\n) -&gt; None:\n    self._patience = patience\n    self._metric = metric.lstrip(\"-+\")\n    self._direction = -1 if metric.startswith(\"-\") else 1\n    self._best_metric = -float(\"inf\")\n    self._counter = 0\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    self._best_metric = -float(\"inf\")\n    self._counter = 0\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    import torch\n    import torch.distributed as dist\n\n    logger = use_step_logger(__name__)\n\n    # For DDP: only rank 0 makes the early stopping decision\n    should_stop = False\n\n    if trainer.distributor.is_main_process:\n        if prefix:\n            metrics = {f\"{prefix}{key}\": value for key, value in metrics.items()}\n        try:\n            metric = self._direction * metrics[self._metric]\n        except KeyError:\n            return\n        if metric &gt; self._best_metric:\n            self._best_metric = metric\n            self._counter = 0\n            # Save state_dict for serialization efficiency\n            torch.save(state.state_dict(), self._get_checkpoint_path())\n            logger.info(f\"New best model saved with {self._metric}={self._best_metric:.4f}\")\n        else:\n            self._counter += 1\n            if self._counter &gt;= self._patience:\n                should_stop = True\n\n    # For DDP: broadcast the early stopping decision from rank 0 to all processes\n    if trainer.distributor.world_size &gt; 1 and dist.is_initialized():\n        # Create a tensor for broadcasting\n        # Get device from model's first parameter\n        device = next(state.model.parameters()).device if list(state.model.parameters()) else torch.device(\"cpu\")\n        should_stop_tensor = torch.tensor(1 if should_stop else 0, dtype=torch.int, device=device)\n        dist.broadcast(should_stop_tensor, src=0)\n        should_stop = bool(should_stop_tensor.item())\n\n    # Synchronize all processes before potentially raising StopEarly\n    trainer.distributor.barrier()\n\n    if should_stop:\n        raise StopEarly()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    import torch\n    import torch.distributed as dist\n\n    logger = use_step_logger(__name__)\n\n    # Synchronize before loading best model\n    trainer.distributor.barrier()\n\n    # Load best model if it exists\n    if (checkpoint_path := self._get_checkpoint_path()).exists():\n        if trainer.distributor.is_main_process:\n            logger.info(\"Loading best state from early stopping checkpoint.\")\n            state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n            state.load_state_dict(state_dict)\n\n        # For DDP: broadcast the model state from rank 0 to all other processes\n        if trainer.distributor.world_size &gt; 1 and dist.is_initialized():\n            # Broadcast model parameters\n            for param in state.model.parameters():\n                dist.broadcast(param.data, src=0)\n            # Broadcast optimizer state\n            # Note: optimizer state broadcasting is complex, so we skip it for now\n            # Users can re-initialize optimizer if needed after loading best model\n            if trainer.distributor.is_main_process:\n                logger.info(\"Broadcasted best model to all processes.\")\n\n    # Synchronize after loading so all processes have the best model\n    trainer.distributor.barrier()\n    return state\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    class DummyMetric(IEvaluator):\n        def update(self, inputs, output, /) -&gt; None:\n            pass\n\n        def compute(self) -&gt; dict[str, float]:\n            return {}\n\n        def reset(self) -&gt; None:\n            pass\n\n    return DummyMetric()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.EarlyStoppingCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback","title":"MlflowCallback","text":"<pre><code>MlflowCallback()\n</code></pre> <p>               Bases: <code>TorchTrainingCallback</code></p> <p>Callback for logging metrics to MLflow.</p> <p>This callback automatically logs training and validation metrics to MLflow when used within a workflow step that has MLflow tracking enabled.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import TorchTrainer, MlflowCallback\n&gt;&gt;&gt;\n&gt;&gt;&gt; trainer = TorchTrainer(\n...     train_dataloader=train_loader,\n...     val_dataloader=val_loader,\n...     callbacks=[MlflowCallback()]\n... )\n</code></pre> Note <p>Requires the formed mlflow integration and must be used within a workflow step with MLflow tracking configured.</p> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def __init__(self) -&gt; None:\n    from formed.integrations.mlflow.workflow import MlflowLogger\n\n    self._mlflow_logger: Optional[MlflowLogger] = None\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_start","title":"on_training_start","text":"<pre><code>on_training_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; None:\n    from formed.integrations.mlflow.workflow import use_mlflow_logger\n    from formed.workflow import use_step_logger\n\n    # Only main process logs to MLflow\n    if not trainer.distributor.is_main_process:\n        return\n\n    logger = use_step_logger(__name__)\n\n    self._mlflow_logger = use_mlflow_logger()\n    if self._mlflow_logger is None:\n        logger.warning(\"MlflowLogger not found. Skipping logging.\")\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_log","title":"on_log","text":"<pre><code>on_log(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_log(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    # Only main process logs to MLflow\n    if not trainer.distributor.is_main_process:\n        return\n\n    metrics = {prefix + key: value for key, value in metrics.items()}\n    if self._mlflow_logger is not None:\n        # Log all metrics\n        for key, value in metrics.items():\n            self._mlflow_logger.log_metric(key, value, step=int(state.step))\n\n        # Log learning rate\n        learning_rate = state.get_learning_rate()\n        if learning_rate is not None:\n            self._mlflow_logger.log_metric(\"learning_rate\", learning_rate, step=int(state.step))\n\n        # Log gradient norm\n        gradient_norm = state.get_gradient_norm()\n        if gradient_norm is not None:\n            self._mlflow_logger.log_metric(\"gradient_norm\", gradient_norm, step=int(state.step))\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    # Only main process logs to MLflow\n    if not trainer.distributor.is_main_process:\n        return\n\n    if self._mlflow_logger is not None:\n        self._mlflow_logger.log_metric(\"epoch\", epoch, step=int(state.step))\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_training_end","title":"on_training_end","text":"<pre><code>on_training_end(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_training_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; TrainState:\n    return state\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_epoch_start","title":"on_epoch_start","text":"<pre><code>on_epoch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_epoch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_start","title":"on_batch_start","text":"<pre><code>on_batch_start(trainer, model, state, epoch)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_batch_end","title":"on_batch_end","text":"<pre><code>on_batch_end(trainer, model, state, epoch, output)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_batch_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    epoch: int,\n    output: ModelOutputT,\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_start","title":"on_eval_start","text":"<pre><code>on_eval_start(trainer, model, state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_start(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n) -&gt; IEvaluator[ModelInputT, ModelOutputT]:\n    class DummyMetric(IEvaluator):\n        def update(self, inputs, output, /) -&gt; None:\n            pass\n\n        def compute(self) -&gt; dict[str, float]:\n            return {}\n\n        def reset(self) -&gt; None:\n            pass\n\n    return DummyMetric()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.callbacks.MlflowCallback.on_eval_end","title":"on_eval_end","text":"<pre><code>on_eval_end(trainer, model, state, metrics, prefix='')\n</code></pre> Source code in <code>src/formed/integrations/torch/training/callbacks.py</code> <pre><code>def on_eval_end(\n    self,\n    trainer: \"TorchTrainer[ItemT, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    state: TrainState,\n    metrics: Mapping[str, float],\n    prefix: str = \"\",\n) -&gt; None:\n    pass\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine","title":"formed.integrations.torch.training.engine","text":"<p>Training engine abstractions for PyTorch models.</p> <p>This module provides the training engine abstraction that defines how models are trained and evaluated. Engines handle loss computation, gradient calculation, and parameter updates.</p> Key Components <ul> <li><code>TorchTrainingEngine</code>: Abstract base class for training engines</li> <li><code>DefaultTorchTrainingEngine</code>: Default implementation with automatic differentiation</li> </ul> Features <ul> <li>Customizable loss functions</li> <li>Automatic gradient computation using PyTorch autograd</li> <li>State creation and management</li> <li>Separate train and eval steps</li> <li>Compatible with TorchTrainer and distributors</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import DefaultTorchTrainingEngine\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create engine with custom loss accessor\n&gt;&gt;&gt; engine = DefaultTorchTrainingEngine(loss=\"total_loss\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Or with custom loss function\n&gt;&gt;&gt; def custom_loss(output):\n...     return output.loss + 0.1 * output.regularization\n&gt;&gt;&gt; engine = DefaultTorchTrainingEngine(loss=custom_loss)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.TorchTrainingEngine","title":"TorchTrainingEngine","text":"<p>               Bases: <code>ABC</code>, <code>Registrable</code>, <code>Generic[ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>Abstract base class for PyTorch training engines.</p> <p>A training engine defines how models are trained by implementing state creation, training steps, and evaluation steps. This allows for custom training loops and loss computations.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ModelInputT</code> <p>Type of model input.</p> <p> </p> <code>ModelOutputT</code> <p>Type of model output.</p> <p> </p> <code>ModelParamsT</code> <p>Type of additional parameters.</p> <p> </p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.TorchTrainingEngine.create_state","title":"create_state  <code>abstractmethod</code>","text":"<pre><code>create_state(trainer, model)\n</code></pre> <p>Create initial training state from model and trainer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>Trainer instance.</p> <p> TYPE: <code>TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]</code> </p> <code>model</code> <p>Model to train.</p> <p> TYPE: <code>BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT]</code> </p> RETURNS DESCRIPTION <code>TrainState</code> <p>Initial training state.</p> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>@abc.abstractmethod\ndef create_state(\n    self,\n    trainer: \"TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n) -&gt; TrainState:\n    \"\"\"Create initial training state from model and trainer.\n\n    Args:\n        trainer: Trainer instance.\n        model: Model to train.\n\n    Returns:\n        Initial training state.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.TorchTrainingEngine.train_step","title":"train_step  <code>abstractmethod</code>","text":"<pre><code>train_step(inputs, state, trainer)\n</code></pre> <p>Execute a single training step.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of training inputs.</p> <p> TYPE: <code>ModelInputT</code> </p> <code>state</code> <p>Current training state (model and optimizer are updated in-place).</p> <p> TYPE: <code>TrainState</code> </p> <code>trainer</code> <p>Trainer instance.</p> <p> TYPE: <code>TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]</code> </p> RETURNS DESCRIPTION <code>ModelOutputT</code> <p>Model output.</p> Note <p>This method updates the state in-place for efficiency. The step counter is incremented automatically.</p> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>@abc.abstractmethod\ndef train_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; ModelOutputT:\n    \"\"\"Execute a single training step.\n\n    Args:\n        inputs: Batch of training inputs.\n        state: Current training state (model and optimizer are updated in-place).\n        trainer: Trainer instance.\n\n    Returns:\n        Model output.\n\n    Note:\n        This method updates the state in-place for efficiency.\n        The step counter is incremented automatically.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.TorchTrainingEngine.eval_step","title":"eval_step  <code>abstractmethod</code>","text":"<pre><code>eval_step(inputs, state, trainer)\n</code></pre> <p>Execute a single evaluation step.</p> PARAMETER DESCRIPTION <code>inputs</code> <p>Batch of evaluation inputs.</p> <p> TYPE: <code>ModelInputT</code> </p> <code>state</code> <p>Current training state.</p> <p> TYPE: <code>TrainState</code> </p> <code>trainer</code> <p>Trainer instance.</p> <p> TYPE: <code>TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]</code> </p> RETURNS DESCRIPTION <code>ModelOutputT</code> <p>Model output.</p> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>@abc.abstractmethod\ndef eval_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; ModelOutputT:\n    \"\"\"Execute a single evaluation step.\n\n    Args:\n        inputs: Batch of evaluation inputs.\n        state: Current training state.\n        trainer: Trainer instance.\n\n    Returns:\n        Model output.\n\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine","title":"DefaultTorchTrainingEngine","text":"<pre><code>DefaultTorchTrainingEngine(\n    optimizer=None,\n    lr_scheduler=None,\n    loss=\"loss\",\n    gradient_accumulation_steps=1,\n    max_grad_norm=None,\n    params=None,\n    dtype=None,\n    grad_scaler=None,\n)\n</code></pre> <p>               Bases: <code>TorchTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>Default training engine using automatic differentiation.</p> <p>This engine computes gradients using PyTorch's autograd and updates parameters using the provided optimizer. Loss is extracted from model output either by attribute name or custom function.</p> PARAMETER DESCRIPTION <code>optimizer</code> <p>Optimizer factory or instance. Can be a Lazy object, callable that takes model parameters, or an optimizer instance.</p> <p> TYPE: <code>Optional[OptimizerFactory]</code> DEFAULT: <code>None</code> </p> <code>lr_scheduler</code> <p>Optional learning rate scheduler factory or instance. Can be a Lazy object, callable that takes optimizer, a sequence of schedulers (will be chained), or a scheduler instance.</p> <p> TYPE: <code>Union[LRSchedulerFactory, Sequence[LRSchedulerFactory], None]</code> DEFAULT: <code>None</code> </p> <code>loss</code> <p>Loss accessor - either attribute name (e.g., <code>\"loss\"</code>) or callable that extracts loss from model output.</p> <p> TYPE: <code>Union[str, Callable[[ModelOutputT], Tensor]]</code> DEFAULT: <code>'loss'</code> </p> <code>gradient_accumulation_steps</code> <p>Number of steps to accumulate gradients before performing an optimizer step.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>max_grad_norm</code> <p>Maximum gradient norm for clipping. If <code>None</code>, no clipping is applied.</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> <code>params</code> <p>Optional additional parameters to pass to the model during training.</p> <p> TYPE: <code>ModelParamsT | None</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Data type for mixed precision training (<code>\"float32\"</code>, <code>\"float16\"</code>, <code>\"bfloat16\"</code>).</p> <p> TYPE: <code>Literal['float32', 'float16', 'bfloat16'] | None</code> DEFAULT: <code>None</code> </p> <code>grad_scaler</code> <p>Gradient scaler for mixed precision training.</p> <p> TYPE: <code>Lazy[GradScaler | IGradScaler] | IGradScaler | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with optimizer\n&gt;&gt;&gt; engine = DefaultTorchTrainingEngine(\n...     optimizer=torch.optim.Adam,\n...     loss=\"loss\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With learning rate scheduler and gradient clipping\n&gt;&gt;&gt; engine = DefaultTorchTrainingEngine(\n...     optimizer=Lazy(cls=torch.optim.Adam, config={\"lr\": 1e-3}),\n...     lr_scheduler=Lazy(cls=torch.optim.lr_scheduler.CosineAnnealingLR, config={\"T_max\": 100}),\n...     max_grad_norm=1.0,\n...     loss=lambda output: output.loss + 0.01 * output.regularization\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # With mixed precision training\n&gt;&gt;&gt; engine = DefaultTorchTrainingEngine(\n...     optimizer=torch.optim.AdamW,\n...     dtype=\"bfloat16\",\n...     grad_scaler=Lazy(cls=torch.amp.GradScaler),\n...     max_grad_norm=1.0\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>def __init__(\n    self,\n    optimizer: Optional[OptimizerFactory] = None,\n    lr_scheduler: Union[LRSchedulerFactory, Sequence[LRSchedulerFactory], None] = None,\n    loss: Union[str, Callable[[ModelOutputT], torch.Tensor]] = \"loss\",\n    gradient_accumulation_steps: int = 1,\n    max_grad_norm: Optional[float] = None,\n    params: ModelParamsT | None = None,\n    dtype: Literal[\"float32\", \"float16\", \"bfloat16\"] | None = None,\n    grad_scaler: Lazy[torch.amp.grad_scaler.GradScaler | IGradScaler] | IGradScaler | None = None,\n) -&gt; None:\n    assert dtype in (None, \"float32\", \"float16\", \"bfloat16\"), (\n        \"dtype must be one of None, 'float32', 'float16', or 'bfloat16'\"\n    )\n\n    super().__init__()\n    self._optimizer_factory = optimizer or get_default_optimizer_factory()\n    self._lr_scheduler_factory = lr_scheduler or get_default_lr_scheduler_factory()\n    self._loss = partial(xgetattr, name=loss) if isinstance(loss, str) else loss\n    self._gradient_accumulation_steps = gradient_accumulation_steps\n    self._max_grad_norm = max_grad_norm\n    self._params = params\n    self._dtype = getattr(torch, dtype) if dtype is not None else None\n    self._grad_scaler = grad_scaler\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.create_state","title":"create_state","text":"<pre><code>create_state(trainer, model)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>def create_state(\n    self,\n    trainer: \"TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n) -&gt; TrainState:\n    # Construct optimizer\n    optimizer: IOptimizer\n    if isinstance(self._optimizer_factory, Lazy):\n        optimizer = self._optimizer_factory.construct(params=model.parameters())\n    elif callable(self._optimizer_factory):\n        optimizer = self._optimizer_factory(model.parameters())\n    else:\n        optimizer = self._optimizer_factory\n\n    # Construct lr_scheduler\n    lr_scheduler: ILRScheduler | None = None\n    if self._lr_scheduler_factory is not None:\n\n        def _construct_lr_scheduler(factory: LRSchedulerFactory) -&gt; ILRScheduler:\n            if isinstance(factory, Lazy):\n                return factory.construct(optimizer=optimizer)\n            elif callable(factory):\n                return factory(optimizer)\n            return factory\n\n        if isinstance(self._lr_scheduler_factory, Sequence):\n            lr_scheduler = torch.optim.lr_scheduler.ChainedScheduler(\n                [\n                    cast(torch.optim.lr_scheduler.LRScheduler, _construct_lr_scheduler(scheduler))\n                    for scheduler in self._lr_scheduler_factory\n                ],\n                optimizer=cast(torch.optim.Optimizer, optimizer),\n            )\n        else:\n            lr_scheduler = _construct_lr_scheduler(self._lr_scheduler_factory)\n\n    # Initialize grad_scaler only if requested and on appropriate device\n    grad_scaler: IGradScaler | None = None\n    if isinstance(self._grad_scaler, IGradScaler):\n        grad_scaler = self._grad_scaler\n    elif isinstance(self._grad_scaler, Lazy):\n        if device := get_device():\n            grad_scaler = self._grad_scaler.construct(device=device.type)\n        else:\n            warnings.warn(\"GradScaler requested but device is not set. GradScaler will not be used.\")\n\n    return TrainState(\n        model=model,\n        optimizer=optimizer,\n        lr_scheduler=lr_scheduler,\n        step=0,\n        grad_scaler=grad_scaler,\n    )\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.train_step","title":"train_step","text":"<pre><code>train_step(inputs, state, trainer)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>def train_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; ModelOutputT:\n    del trainer\n\n    # Set model to training mode\n    state.model.train()\n\n    # Zero gradients at the start of accumulation cycle\n    if state.step % self._gradient_accumulation_steps == 0:\n        state.optimizer.zero_grad()\n\n    with ExitStack() as stack:\n        if (device := get_device()) is not None and self._dtype is not None:\n            stack.enter_context(torch.autocast(device_type=device.type, dtype=self._dtype))\n\n        output = state.model(inputs, params=self._params)\n\n        try:\n            loss = self._loss(output)\n        except (KeyError, AttributeError) as e:\n            raise ValueError(\n                f\"Failed to extract loss from model output. \"\n                f\"Error: {e}. \"\n                f\"Output type: {type(output).__name__}. \"\n                \"Please ensure your model's forward() method returns output with a 'loss' attribute or key.\"\n            ) from e\n\n    if loss is None:\n        raise ValueError(\n            \"Model output loss is None. \"\n            \"This typically happens when labels are not provided during training. \"\n            \"Please ensure your training data includes labels.\"\n        )\n\n    # Scale loss for gradient accumulation\n    loss = loss / self._gradient_accumulation_steps\n\n    # Backward pass with or without gradient scaling\n    if state.grad_scaler is not None:\n        state.grad_scaler.scale(loss).backward()\n    else:\n        loss.backward()\n\n    # Update optimizer and scheduler when accumulation is complete\n    if (state.step + 1) % self._gradient_accumulation_steps == 0:\n        # Clip gradients if max_grad_norm is specified\n        if self._max_grad_norm is not None:\n            if state.grad_scaler is not None:\n                if isinstance(state.optimizer, torch.optim.Optimizer):\n                    # Unscale gradients before clipping when using grad_scaler\n                    state.grad_scaler.unscale_(state.optimizer)\n                else:\n                    warnings.warn(\n                        \"Cannot unscale gradients for gradient clipping because \"\n                        \"the optimizer is not a torch.optim.Optimizer instance.\"\n                    )\n            torch.nn.utils.clip_grad_norm_(state.model.parameters(), self._max_grad_norm)\n\n        if state.grad_scaler is not None:\n            # GradScaler.step expects torch.optim.Optimizer\n            state.grad_scaler.step(cast(torch.optim.Optimizer, state.optimizer))\n            state.grad_scaler.update()\n        else:\n            state.optimizer.step()\n        if state.lr_scheduler is not None:\n            state.lr_scheduler.step()\n\n    # Increment step counter (counts micro-batches)\n    state.step += 1\n\n    return output\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.DefaultTorchTrainingEngine.eval_step","title":"eval_step","text":"<pre><code>eval_step(inputs, state, trainer)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>def eval_step(\n    self,\n    inputs: ModelInputT,\n    state: TrainState,\n    trainer: \"TorchTrainer[Any, ModelInputT, ModelOutputT, ModelParamsT]\",\n) -&gt; ModelOutputT:\n    del trainer\n\n    # Set model to eval mode\n    state.model.eval()\n\n    # Standard PyTorch evaluation step\n    with torch.no_grad():\n        output = state.model(inputs)\n\n    return output\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.get_default_optimizer_factory","title":"get_default_optimizer_factory","text":"<pre><code>get_default_optimizer_factory()\n</code></pre> <p>Get a default optimizer factory (Adam with lr=1e-3).</p> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>def get_default_optimizer_factory() -&gt; OptimizerFactory:\n    \"\"\"Get a default optimizer factory (Adam with lr=1e-3).\"\"\"\n    return Lazy(config={\"lr\": 1e-3}, cls=torch.optim.Adam)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.engine.get_default_lr_scheduler_factory","title":"get_default_lr_scheduler_factory","text":"<pre><code>get_default_lr_scheduler_factory()\n</code></pre> <p>Get a default learning rate scheduler factory (None).</p> Source code in <code>src/formed/integrations/torch/training/engine.py</code> <pre><code>def get_default_lr_scheduler_factory() -&gt; Optional[LRSchedulerFactory]:\n    \"\"\"Get a default learning rate scheduler factory (None).\"\"\"\n    return None\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.exceptions","title":"formed.integrations.torch.training.exceptions","text":""},{"location":"reference/integrations/torch/#formed.integrations.torch.training.exceptions.StopEarly","title":"StopEarly","text":"<p>               Bases: <code>Exception</code></p> <p>Raised to stop training early.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state","title":"formed.integrations.torch.training.state","text":"<p>Training state management for PyTorch models.</p> <p>This module provides a training state class that encapsulates model parameters, optimizer state, and training progress for PyTorch models.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState","title":"TrainState","text":"<pre><code>TrainState(\n    model,\n    optimizer,\n    step=0,\n    lr_scheduler=None,\n    grad_scaler=None,\n)\n</code></pre> <p>Training state for PyTorch models.</p> <p>This class encapsulates the training state including model, optimizer, learning rate scheduler, and training progress counters. Unlike the Flax version, this directly holds references to the model and optimizer for efficiency.</p> ATTRIBUTE DESCRIPTION <code>model</code> <p>The PyTorch model being trained.</p> <p> </p> <code>optimizer</code> <p>The optimizer for training.</p> <p> </p> <code>lr_scheduler</code> <p>Optional learning rate scheduler.</p> <p> </p> <code>step</code> <p>Training step counter.</p> <p> </p> <code>grad_scaler</code> <p>Optional gradient scaler for mixed precision training.</p> <p> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create state from model and optimizer\n&gt;&gt;&gt; state = TrainState(\n...     model=model,\n...     optimizer=optimizer,\n...     step=0\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Access model and optimizer directly\n&gt;&gt;&gt; state.model.train()\n&gt;&gt;&gt; state.optimizer.zero_grad()\n</code></pre> Source code in <code>src/formed/integrations/torch/training/state.py</code> <pre><code>def __init__(\n    self,\n    model: torch.nn.Module,\n    optimizer: \"IOptimizer\",\n    step: int = 0,\n    lr_scheduler: Optional[\"ILRScheduler\"] = None,\n    grad_scaler: Optional[\"IGradScaler\"] = None,\n) -&gt; None:\n    self.model = model\n    self.optimizer = optimizer\n    self.lr_scheduler = lr_scheduler\n    self.step = step\n    self.grad_scaler = grad_scaler\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = model\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.optimizer","title":"optimizer  <code>instance-attribute</code>","text":"<pre><code>optimizer = optimizer\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.lr_scheduler","title":"lr_scheduler  <code>instance-attribute</code>","text":"<pre><code>lr_scheduler = lr_scheduler\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.step","title":"step  <code>instance-attribute</code>","text":"<pre><code>step = step\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.grad_scaler","title":"grad_scaler  <code>instance-attribute</code>","text":"<pre><code>grad_scaler = grad_scaler\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.state_dict","title":"state_dict","text":"<pre><code>state_dict()\n</code></pre> <p>Get state dictionary for serialization.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>Dictionary containing model state, <code>optimizer</code> state, <code>lr_scheduler</code> state (if present), <code>grad_scaler</code> state (if present), and <code>step</code>.</p> Source code in <code>src/formed/integrations/torch/training/state.py</code> <pre><code>def state_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Get state dictionary for serialization.\n\n    Returns:\n        Dictionary containing model state, `optimizer` state, `lr_scheduler` state (if present), `grad_scaler` state (if present), and `step`.\n\n    \"\"\"\n    state = {\n        \"model_state\": self.model.state_dict(),\n        \"optimizer_state\": self.optimizer.state_dict(),\n        \"step\": self.step,\n    }\n    if self.lr_scheduler is not None:\n        state[\"lr_scheduler_state\"] = self.lr_scheduler.state_dict()\n    if self.grad_scaler is not None:\n        state[\"grad_scaler_state\"] = self.grad_scaler.state_dict()\n    return state\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.load_state_dict","title":"load_state_dict","text":"<pre><code>load_state_dict(state_dict)\n</code></pre> <p>Load state from dictionary.</p> PARAMETER DESCRIPTION <code>state_dict</code> <p>Dictionary containing model state, optimizer state, lr_scheduler state (optional), grad_scaler state (optional), and step.</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/formed/integrations/torch/training/state.py</code> <pre><code>def load_state_dict(self, state_dict: dict[str, Any]) -&gt; None:\n    \"\"\"Load state from dictionary.\n\n    Args:\n        state_dict: Dictionary containing model state, optimizer state, lr_scheduler state (optional), grad_scaler state (optional), and step.\n\n    \"\"\"\n    self.model.load_state_dict(state_dict[\"model_state\"])\n    self.optimizer.load_state_dict(state_dict[\"optimizer_state\"])\n    self.step = state_dict[\"step\"]\n    if \"lr_scheduler_state\" in state_dict and self.lr_scheduler is not None:\n        self.lr_scheduler.load_state_dict(state_dict[\"lr_scheduler_state\"])\n    if \"grad_scaler_state\" in state_dict and self.grad_scaler is not None:\n        self.grad_scaler.load_state_dict(state_dict[\"grad_scaler_state\"])\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.get_learning_rate","title":"get_learning_rate","text":"<pre><code>get_learning_rate()\n</code></pre> <p>Get current learning rate from optimizer.</p> RETURNS DESCRIPTION <code>Optional[float]</code> <p>Current learning rate from the first parameter group, or <code>None</code> if unavailable.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lr = state.get_learning_rate()\n&gt;&gt;&gt; if lr is not None:\n...     print(f\"Current learning rate: {lr}\")\n</code></pre> Source code in <code>src/formed/integrations/torch/training/state.py</code> <pre><code>def get_learning_rate(self) -&gt; Optional[float]:\n    \"\"\"Get current learning rate from optimizer.\n\n    Returns:\n        Current learning rate from the first parameter group, or `None` if unavailable.\n\n    Examples:\n        &gt;&gt;&gt; lr = state.get_learning_rate()\n        &gt;&gt;&gt; if lr is not None:\n        ...     print(f\"Current learning rate: {lr}\")\n\n    \"\"\"\n    import torch.optim\n\n    if isinstance(self.optimizer, torch.optim.Optimizer):\n        if self.optimizer.param_groups:\n            return self.optimizer.param_groups[0][\"lr\"]\n    return None\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.state.TrainState.get_gradient_norm","title":"get_gradient_norm","text":"<pre><code>get_gradient_norm()\n</code></pre> <p>Compute L2 norm of all gradients.</p> RETURNS DESCRIPTION <code>Optional[float]</code> <p>L2 norm of all parameter gradients, or <code>None</code> if no gradients are available.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; grad_norm = state.get_gradient_norm()\n&gt;&gt;&gt; if grad_norm is not None:\n...     print(f\"Gradient norm: {grad_norm:.4f}\")\n</code></pre> Note <p>This method computes the gradient norm on-demand. It should be called after <code>backward()</code> but before optimizer.step() or <code>zero_grad()</code> to get meaningful results.</p> Source code in <code>src/formed/integrations/torch/training/state.py</code> <pre><code>def get_gradient_norm(self) -&gt; Optional[float]:\n    \"\"\"Compute L2 norm of all gradients.\n\n    Returns:\n        L2 norm of all parameter gradients, or `None` if no gradients are available.\n\n    Examples:\n        &gt;&gt;&gt; grad_norm = state.get_gradient_norm()\n        &gt;&gt;&gt; if grad_norm is not None:\n        ...     print(f\"Gradient norm: {grad_norm:.4f}\")\n\n    Note:\n        This method computes the gradient norm on-demand. It should be called\n        after `backward()` but before optimizer.step() or `zero_grad()` to get\n        meaningful results.\n\n    \"\"\"\n    total_norm = 0.0\n    has_gradients = False\n\n    for param in self.model.parameters():\n        if param.grad is not None:\n            has_gradients = True\n            param_norm = param.grad.data.norm(2)\n            total_norm += param_norm.item() ** 2\n\n    if not has_gradients:\n        return None\n\n    return total_norm**0.5\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.trainer","title":"formed.integrations.torch.training.trainer","text":"<p>High-level trainer for PyTorch models.</p> <p>This module provides the TorchTrainer class, which orchestrates the complete training process for PyTorch models including data loading, optimization, evaluation, callbacks, and distributed training.</p> Key Features <ul> <li>Flexible training loop with epoch and step-based logging/evaluation</li> <li>Support for callbacks at various training stages</li> <li>Distributed training via data parallelism</li> <li>Integration with PyTorch optimizers</li> <li>Rich progress bars with training metrics</li> <li>Early stopping and checkpointing</li> <li>MLflow integration</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import (\n...     TorchTrainer,\n...     EvaluationCallback,\n...     EarlyStoppingCallback\n... )\n&gt;&gt;&gt; from formed.integrations.ml import DataLoader, BasicBatchSampler\n&gt;&gt;&gt; import torch.optim as optim\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Setup data loaders and engine\n&gt;&gt;&gt; train_dataloader = DataLoader(\n...     sampler=BasicBatchSampler(batch_size=32, shuffle=True),\n...     collator=datamodule.batch\n... )\n&gt;&gt;&gt; engine = DefaultTorchTrainingEngine(\n...     optimizer=optim.Adam,\n...     lr_scheduler=optim.lr_scheduler.StepLR\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create trainer\n&gt;&gt;&gt; trainer = TorchTrainer(\n...     train_dataloader=train_dataloader,\n...     val_dataloader=val_dataloader,\n...     engine=engine,\n...     max_epochs=10,\n...     callbacks=[\n...         EvaluationCallback(my_evaluator),\n...         EarlyStoppingCallback(patience=3)\n...     ]\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Train model\n&gt;&gt;&gt; state = trainer.train(model, train_dataset, val_dataset)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.trainer.TorchTrainer","title":"TorchTrainer","text":"<pre><code>TorchTrainer(\n    *,\n    train_dataloader,\n    val_dataloader=None,\n    engine=None,\n    callbacks=(),\n    distributor=None,\n    max_epochs=None,\n    eval_strategy=\"epoch\",\n    eval_interval=1,\n    logging_strategy=\"epoch\",\n    logging_interval=1,\n    logging_first_step=True,\n    train_prefix=\"train/\",\n    val_prefix=\"val/\",\n)\n</code></pre> <p>               Bases: <code>Generic[ItemT, ModelInputT, ModelOutputT, ModelParamsT]</code></p> <p>High-level trainer for PyTorch models.</p> <p>TorchTrainer provides a complete training loop with support for distributed training, callbacks, evaluation, and metric logging. It handles the coordination of data loading, model training, evaluation, and callback execution.</p>                CLASS TYPE PARAMETER              DESCRIPTION <code>ItemT</code> <p>Type of raw dataset items.</p> <p> </p> <code>ModelInputT</code> <p>Type of batched model inputs.</p> <p> </p> <code>ModelOutputT</code> <p>Type of model outputs.</p> <p> </p> <code>ModelParamsT</code> <p>Type of additional model parameters.</p> <p> </p> PARAMETER DESCRIPTION <code>train_dataloader</code> <p>Data loader for training dataset.</p> <p> TYPE: <code>IDataLoader[ItemT, ModelInputT]</code> </p> <code>val_dataloader</code> <p>Optional data loader for validation dataset.</p> <p> TYPE: <code>Optional[IDataLoader[ItemT, ModelInputT]]</code> DEFAULT: <code>None</code> </p> <code>engine</code> <p>Training engine (defaults to <code>DefaultTorchTrainingEngine</code>).</p> <p> TYPE: <code>Optional[TorchTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT]]</code> DEFAULT: <code>None</code> </p> <code>callbacks</code> <p>Sequence of training callbacks.</p> <p> TYPE: <code>Sequence[TorchTrainingCallback]</code> DEFAULT: <code>()</code> </p> <code>distributor</code> <p>Device distributor (defaults to <code>SingleDeviceDistributor</code>).</p> <p> TYPE: <code>Optional[BaseDistributor]</code> DEFAULT: <code>None</code> </p> <code>max_epochs</code> <p>Maximum number of training epochs.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>eval_strategy</code> <p>When to evaluate - <code>\"epoch\"</code> or <code>\"step\"</code>.</p> <p> TYPE: <code>Literal['epoch', 'step']</code> DEFAULT: <code>'epoch'</code> </p> <code>eval_interval</code> <p>Evaluation interval (epochs or steps).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>logging_strategy</code> <p>When to log - <code>\"epoch\"</code> or <code>\"step\"</code>.</p> <p> TYPE: <code>Literal['epoch', 'step']</code> DEFAULT: <code>'epoch'</code> </p> <code>logging_interval</code> <p>Logging interval (epochs or steps).</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>logging_first_step</code> <p>Whether to log after the first training step.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>train_prefix</code> <p>Prefix for training metrics logging. Default is <code>\"train/\"</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'train/'</code> </p> <code>val_prefix</code> <p>Prefix for validation metrics logging. Default is <code>\"val/\"</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'val/'</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; engine = DefaultTorchTrainingEngine(\n...     optimizer=torch.optim.Adam,\n...     lr_scheduler=torch.optim.lr_scheduler.StepLR\n... )\n&gt;&gt;&gt; trainer = TorchTrainer(\n...     train_dataloader=train_loader,\n...     val_dataloader=val_loader,\n...     engine=engine,\n...     max_epochs=10,\n...     eval_strategy=\"epoch\",\n...     logging_strategy=\"step\",\n...     logging_interval=100\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/training/trainer.py</code> <pre><code>def __init__(\n    self,\n    *,\n    train_dataloader: IDataLoader[ItemT, ModelInputT],\n    val_dataloader: Optional[IDataLoader[ItemT, ModelInputT]] = None,\n    engine: Optional[TorchTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT]] = None,\n    callbacks: Sequence[TorchTrainingCallback] = (),\n    distributor: Optional[BaseDistributor] = None,\n    max_epochs: Optional[int] = None,\n    eval_strategy: Literal[\"epoch\", \"step\"] = \"epoch\",\n    eval_interval: int = 1,\n    logging_strategy: Literal[\"epoch\", \"step\"] = \"epoch\",\n    logging_interval: int = 1,\n    logging_first_step: bool = True,\n    train_prefix: str = \"train/\",\n    val_prefix: str = \"val/\",\n) -&gt; None:\n    self._train_dataloader = train_dataloader\n    self._val_dataloader = val_dataloader\n    self._engine = engine or DefaultTorchTrainingEngine[ModelInputT, ModelOutputT, ModelParamsT]()\n    self._distributor = distributor or get_default_distributor()\n    self._max_epochs = max_epochs or get_default_max_epochs()\n    self._eval_strategy = eval_strategy\n    self._eval_interval = eval_interval\n    self._logging_strategy = logging_strategy\n    self._logging_interval = logging_interval\n    self._logging_first_step = logging_first_step\n    self._callbacks = callbacks\n    self._train_prefix = train_prefix\n    self._val_prefix = val_prefix\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.trainer.TorchTrainer.distributor","title":"distributor  <code>property</code>","text":"<pre><code>distributor\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.trainer.TorchTrainer.train","title":"train","text":"<pre><code>train(model, train_dataset, val_dataset=None, state=None)\n</code></pre> <p>Train a model on the provided datasets.</p> PARAMETER DESCRIPTION <code>model</code> <p>Model to train.</p> <p> TYPE: <code>BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT]</code> </p> <code>train_dataset</code> <p>Sequence of training items.</p> <p> TYPE: <code>Sequence[ItemT]</code> </p> <code>val_dataset</code> <p>Optional sequence of validation items.</p> <p> TYPE: <code>Optional[Sequence[ItemT]]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional pre-initialized training state (for resuming).</p> <p> TYPE: <code>Optional[TrainState]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>TrainState</code> <p>Final training state with trained parameters.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If <code>val_dataset</code> is provided but <code>val_dataloader</code> is not.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; state = trainer.train(\n...     model, train_items, val_items\n... )\n&gt;&gt;&gt; # Load trained parameters\n&gt;&gt;&gt; model.load_state_dict(state.model_state)\n</code></pre> Source code in <code>src/formed/integrations/torch/training/trainer.py</code> <pre><code>def train(\n    self,\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    train_dataset: Sequence[ItemT],\n    val_dataset: Optional[Sequence[ItemT]] = None,\n    state: Optional[TrainState] = None,\n) -&gt; TrainState:\n    \"\"\"Train a model on the provided datasets.\n\n    Args:\n        model: Model to train.\n        train_dataset: Sequence of training items.\n        val_dataset: Optional sequence of validation items.\n        state: Optional pre-initialized training state (for resuming).\n\n    Returns:\n        Final training state with trained parameters.\n\n    Raises:\n        ValueError: If `val_dataset` is provided but `val_dataloader` is not.\n\n    Examples:\n        &gt;&gt;&gt; state = trainer.train(\n        ...     model, train_items, val_items\n        ... )\n        &gt;&gt;&gt; # Load trained parameters\n        &gt;&gt;&gt; model.load_state_dict(state.model_state)\n\n    \"\"\"\n    if val_dataset is not None and self._val_dataloader is None:\n        raise ValueError(\"Validation dataloader is not provided.\")\n\n    logger = use_step_logger(__name__)\n\n    # Set device context for ensure_torch_tensor\n    with use_device(self._distributor.device):\n        return self._train_impl(model, train_dataset, val_dataset, state, logger)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.trainer.get_default_max_epochs","title":"get_default_max_epochs","text":"<pre><code>get_default_max_epochs()\n</code></pre> <p>Get a default maximum number of training epochs.</p> Source code in <code>src/formed/integrations/torch/training/trainer.py</code> <pre><code>def get_default_max_epochs() -&gt; int:\n    \"\"\"Get a default maximum number of training epochs.\"\"\"\n    return 10\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.training.trainer.get_default_distributor","title":"get_default_distributor","text":"<pre><code>get_default_distributor()\n</code></pre> <p>Get a default single-device distributor.</p> Source code in <code>src/formed/integrations/torch/training/trainer.py</code> <pre><code>def get_default_distributor() -&gt; BaseDistributor:\n    \"\"\"Get a default single-device distributor.\"\"\"\n    return SingleDeviceDistributor()\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow","title":"formed.integrations.torch.workflow","text":"<p>Workflow integration for PyTorch model training.</p> <p>This module provides workflow steps for training PyTorch models, allowing them to be integrated into the formed workflow system with automatic caching and dependency tracking.</p> Available Steps <ul> <li><code>torch::train</code>: Train a PyTorch model using the provided trainer.</li> <li><code>torch::evaluate</code>: Evaluate a PyTorch model on a dataset.</li> <li><code>torch::predict</code>: Generate predictions on a dataset using a PyTorch model.</li> <li><code>torch::predict_without_caching</code>: Generate predictions without caching (same as <code>torch::predict</code> but uncached).</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.torch import train_torch_model\n&gt;&gt;&gt;\n&gt;&gt;&gt; # In workflow configuration (jsonnet):\n&gt;&gt;&gt; # {\n&gt;&gt;&gt; #   steps: {\n&gt;&gt;&gt; #     train: {\n&gt;&gt;&gt; #       type: \"torch::train\",\n&gt;&gt;&gt; #       model: { type: \"my_model\", ... },\n&gt;&gt;&gt; #       trainer: { type: \"torch_trainer\", ... },\n&gt;&gt;&gt; #       train_dataset: { type: \"ref\", ref: \"preprocess\" },\n&gt;&gt;&gt; #       random_seed: 42\n&gt;&gt;&gt; #     }\n&gt;&gt;&gt; #   }\n&gt;&gt;&gt; # }\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.TorchModelFormat","title":"TorchModelFormat","text":"<p>               Bases: <code>Format[_ModelT]</code></p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.TorchModelFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.TorchModelFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/integrations/torch/workflow.py</code> <pre><code>def write(self, artifact: _ModelT, directory: Path) -&gt; None:\n    if artifact.__model_config__ is not None:\n        config = dict(artifact.__model_config__)\n        config[COLT_TYPEKEY] = f\"{artifact.__class__.__module__}:{artifact.__class__.__name__}\"\n        self._get_config_path(directory).write_text(\n            json.dumps(\n                artifact.__model_config__,\n                indent=2,\n                cls=WorkflowJSONEncoder,\n            )\n        )\n        torch.save(\n            artifact.state_dict(),\n            self._get_state_path(directory),\n        )\n    else:\n        with self._get_pickle_path(directory).open(\"wb\") as f:\n            cloudpickle.dump(artifact, f)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.TorchModelFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/integrations/torch/workflow.py</code> <pre><code>def read(self, directory: Path) -&gt; _ModelT:\n    if (pickle_path := self._get_pickle_path(directory)).exists():\n        with pickle_path.open(\"rb\") as f:\n            model = cloudpickle.load(f)\n        return cast(_ModelT, model)\n\n    config = json.loads(\n        self._get_config_path(directory).read_text(),\n        cls=WorkflowJSONDecoder,\n    )\n    state_dict = torch.load(self._get_state_path(directory), map_location=\"cpu\")\n    model = COLT_BUILDER(config, BaseTorchModel)\n    model.load_state_dict(state_dict)\n    return cast(_ModelT, model)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.TorchModelFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.train_torch_model","title":"train_torch_model","text":"<pre><code>train_torch_model(\n    model,\n    trainer,\n    train_dataset,\n    val_dataset=None,\n    random_seed=0,\n)\n</code></pre> <p>Train a PyTorch model using the provided trainer.</p> <p>This workflow step trains a PyTorch model on the provided datasets, returning the trained model. The training process is cached based on the model architecture, trainer configuration, and dataset fingerprints.</p> PARAMETER DESCRIPTION <code>model</code> <p>PyTorch model to train.</p> <p> TYPE: <code>Lazy[BaseTorchModel]</code> </p> <code>trainer</code> <p>Trainer configuration with dataloaders and callbacks.</p> <p> TYPE: <code>TorchTrainer</code> </p> <code>train_dataset</code> <p>Training dataset items.</p> <p> TYPE: <code>Sequence[ItemT]</code> </p> <code>val_dataset</code> <p>Optional validation dataset items.</p> <p> TYPE: <code>Sequence[ItemT] | None</code> DEFAULT: <code>None</code> </p> <code>random_seed</code> <p>Random seed for reproducibility.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>BaseTorchModel</code> <p>Trained PyTorch model with updated parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Use in Python code\n&gt;&gt;&gt; trained_model = train_torch_model(\n...     model=my_model,\n...     trainer=trainer,\n...     train_dataset=train_data,\n...     val_dataset=val_data,\n...     random_seed=42\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/workflow.py</code> <pre><code>@step(\"torch::train\", format=TorchModelFormat())\ndef train_torch_model(\n    model: Lazy[BaseTorchModel],\n    trainer: TorchTrainer,\n    train_dataset: Sequence[ItemT],\n    val_dataset: Sequence[ItemT] | None = None,\n    random_seed: int = 0,\n) -&gt; BaseTorchModel:\n    \"\"\"Train a PyTorch model using the provided trainer.\n\n    This workflow step trains a PyTorch model on the provided datasets,\n    returning the trained model. The training process is cached based on\n    the model architecture, trainer configuration, and dataset fingerprints.\n\n    Args:\n        model: PyTorch model to train.\n        trainer: Trainer configuration with dataloaders and callbacks.\n        train_dataset: Training dataset items.\n        val_dataset: Optional validation dataset items.\n        random_seed: Random seed for reproducibility.\n\n    Returns:\n        Trained PyTorch model with updated parameters.\n\n    Examples:\n        &gt;&gt;&gt; # Use in Python code\n        &gt;&gt;&gt; trained_model = train_torch_model(\n        ...     model=my_model,\n        ...     trainer=trainer,\n        ...     train_dataset=train_data,\n        ...     val_dataset=val_data,\n        ...     random_seed=42\n        ... )\n\n    \"\"\"\n    # Set random seeds for reproducibility\n    set_random_seed(random_seed)\n\n    # Build model from Lazy\n    model_instance = model.construct()\n\n    # Set config for selialization\n    model_instance.__model_config__ = model.config\n\n    # Train the model\n    state = trainer.train(model_instance, train_dataset, val_dataset)\n\n    # Return the trained model\n    return cast(BaseTorchModel, state.model)\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.evaluate_torch_model","title":"evaluate_torch_model","text":"<pre><code>evaluate_torch_model(\n    model,\n    evaluator,\n    dataset,\n    dataloader,\n    params=None,\n    random_seed=None,\n    device=None,\n)\n</code></pre> <p>Evaluate a PyTorch model on a dataset using the provided evaluator.</p> <p>This workflow step evaluates a PyTorch model on the provided dataset, computing metrics using the evaluator. Evaluation is performed in evaluation mode (no gradient computation).</p> PARAMETER DESCRIPTION <code>model</code> <p>PyTorch model to evaluate.</p> <p> TYPE: <code>BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT]</code> </p> <code>evaluator</code> <p>Evaluator to compute metrics.</p> <p> TYPE: <code>IEvaluator[ModelInputT, ModelOutputT]</code> </p> <code>dataset</code> <p>Dataset items for evaluation.</p> <p> TYPE: <code>Iterable[ItemT]</code> </p> <code>dataloader</code> <p>DataLoader to convert items to model inputs.</p> <p> TYPE: <code>IStreamingDataLoader[ItemT, ModelInputT]</code> </p> <code>params</code> <p>Optional model parameters to use for evaluation.</p> <p> TYPE: <code>ModelParamsT | None</code> DEFAULT: <code>None</code> </p> <code>random_seed</code> <p>Optional random seed for reproducibility.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>device</code> <p>Optional device (e.g., <code>\"cpu\"</code>, <code>\"cuda\"</code>) to run evaluation on.</p> <p> TYPE: <code>str | device | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict[str, float]</code> <p>Dictionary of computed evaluation metrics.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Use in Python code\n&gt;&gt;&gt; metrics = evaluate_torch_model(\n...     model=trained_model,\n...     evaluator=my_evaluator,\n...     dataset=test_data,\n...     dataloader=test_loader\n... )\n</code></pre> Source code in <code>src/formed/integrations/torch/workflow.py</code> <pre><code>@step(\"torch::evaluate\", format=\"json\")\ndef evaluate_torch_model(\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    evaluator: IEvaluator[ModelInputT, ModelOutputT],\n    dataset: Iterable[ItemT],\n    dataloader: IStreamingDataLoader[ItemT, ModelInputT],\n    params: ModelParamsT | None = None,\n    random_seed: int | None = None,\n    device: Annotated[str | torch.device | None, WorkflowStepArgFlag.IGNORE] = None,\n) -&gt; Annotated[dict[str, float], WorkflowStepResultFlag.METRICS]:\n    \"\"\"Evaluate a PyTorch model on a dataset using the provided evaluator.\n\n    This workflow step evaluates a PyTorch model on the provided dataset,\n    computing metrics using the evaluator. Evaluation is performed in\n    evaluation mode (no gradient computation).\n\n    Args:\n        model: PyTorch model to evaluate.\n        evaluator: Evaluator to compute metrics.\n        dataset: Dataset items for evaluation.\n        dataloader: DataLoader to convert items to model inputs.\n        params: Optional model parameters to use for evaluation.\n        random_seed: Optional random seed for reproducibility.\n        device: Optional device (e.g., `\"cpu\"`, `\"cuda\"`) to run evaluation on.\n\n    Returns:\n        Dictionary of computed evaluation metrics.\n\n    Examples:\n        &gt;&gt;&gt; # Use in Python code\n        &gt;&gt;&gt; metrics = evaluate_torch_model(\n        ...     model=trained_model,\n        ...     evaluator=my_evaluator,\n        ...     dataset=test_data,\n        ...     dataloader=test_loader\n        ... )\n\n    \"\"\"\n    logger = use_step_logger(__name__)\n\n    # Set random seed if provided\n    if random_seed is not None:\n        torch.manual_seed(random_seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(random_seed)\n\n    # Evaluate model\n    with torch.inference_mode(), use_device(device) as device:\n        # Move model to device if specified\n        model.to(device)\n\n        # Set model to evaluation mode\n        model.eval()\n\n        # Reset evaluator state\n        evaluator.reset()\n\n        with (\n            closing(dataloader(dataset)) as loader,\n            progress(loader, desc=\"Evaluating model\") as iterator,\n        ):\n            for inputs in iterator:\n                inputs = move_to_device(inputs, device)\n                output = model(inputs, params)\n                evaluator.update(inputs, output)\n\n    metrics = evaluator.compute()\n    logger.info(\"Evaluation metrics: %s\", \", \".join(f\"{k}={v:.4f}\" for k, v in metrics.items()))\n\n    return metrics\n</code></pre>"},{"location":"reference/integrations/torch/#formed.integrations.torch.workflow.predict","title":"predict","text":"<pre><code>predict(\n    dataset,\n    dataloader,\n    model,\n    postprocessor,\n    params=None,\n    device=None,\n    random_seed=None,\n)\n</code></pre> <p>Generate predictions on a dataset using a PyTorch model.</p> <p>This step applies a model to a dataset and postprocesses the outputs to generate final predictions.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>Dataset items for prediction.</p> <p> TYPE: <code>Iterable[ItemT]</code> </p> <code>dataloader</code> <p>DataLoader to convert items to model inputs.</p> <p> TYPE: <code>IStreamingDataLoader[ItemT, ModelInputT]</code> </p> <code>model</code> <p>PyTorch model to use for prediction.</p> <p> TYPE: <code>BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT]</code> </p> <code>postprocessor</code> <p>Function to convert model outputs to final results.</p> <p> TYPE: <code>Callable[[ModelInputT, ModelOutputT], Iterable[_ResultT]]</code> </p> <code>params</code> <p>Optional model parameters to use for prediction.</p> <p> TYPE: <code>ModelParamsT | None</code> DEFAULT: <code>None</code> </p> <code>device</code> <p>Optional device (e.g., <code>\"cpu\"</code>, <code>\"cuda\"</code>) to run prediction on.</p> <p> TYPE: <code>str | device | None</code> DEFAULT: <code>None</code> </p> <code>random_seed</code> <p>Optional random seed for reproducibility.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Iterator[_ResultT]</code> <p>Iterator of prediction results.</p> Source code in <code>src/formed/integrations/torch/workflow.py</code> <pre><code>@step(\"torch::predict\")\n@step(\"torch::predict_without_caching\", cacheable=False)\ndef predict(\n    dataset: Iterable[ItemT],\n    dataloader: IStreamingDataLoader[ItemT, ModelInputT],\n    model: BaseTorchModel[ModelInputT, ModelOutputT, ModelParamsT],\n    postprocessor: Callable[[ModelInputT, ModelOutputT], Iterable[_ResultT]],\n    params: ModelParamsT | None = None,\n    device: Annotated[str | torch.device | None, WorkflowStepArgFlag.IGNORE] = None,\n    random_seed: int | None = None,\n) -&gt; Iterator[_ResultT]:\n    \"\"\"Generate predictions on a dataset using a PyTorch model.\n\n    This step applies a model to a dataset and postprocesses the outputs\n    to generate final predictions.\n\n    Args:\n        dataset: Dataset items for prediction.\n        dataloader: DataLoader to convert items to model inputs.\n        model: PyTorch model to use for prediction.\n        postprocessor: Function to convert model outputs to final results.\n        params: Optional model parameters to use for prediction.\n        device: Optional device (e.g., `\"cpu\"`, `\"cuda\"`) to run prediction on.\n        random_seed: Optional random seed for reproducibility.\n\n    Returns:\n        Iterator of prediction results.\n    \"\"\"\n    # Set random seed if provided\n    if random_seed is not None:\n        torch.manual_seed(random_seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(random_seed)\n\n    with torch.inference_mode(), use_device(device) as device:\n        # Move model to device if specified\n        model.to(device)\n\n        # Set model to evaluation mode\n        model.eval()\n\n        with (\n            closing(dataloader(dataset)) as loader,\n            progress(loader, desc=\"Predicting\") as iterator,\n        ):\n            for inputs in iterator:\n                inputs = move_to_device(inputs, device)\n                output = model(inputs, params)\n                yield from postprocessor(inputs, output)\n</code></pre>"},{"location":"reference/integrations/transformers/","title":"Transformers","text":""},{"location":"reference/integrations/transformers/#formed.integrations.transformers.analyzers","title":"formed.integrations.transformers.analyzers","text":"<p>Text analyzers using pretrained transformers tokenizers.</p> <p>This module provides text analysis tools that leverage pretrained tokenizers from the Hugging Face transformers library to tokenize text into surface forms.</p> Available Classes <ul> <li><code>PretrainedAnalyzer</code>: Analyzer using pretrained transformer tokenizers</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from formed.integrations.transformers.analyzers import PretrainedAnalyzer\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Initialize with model name\n&gt;&gt;&gt; analyzer = PretrainedAnalyzer(\"bert-base-uncased\")\n&gt;&gt;&gt; result = analyzer(\"Hello world!\")\n&gt;&gt;&gt; print(result.surfaces)\n['hello', 'world', '!']\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.analyzers.PretrainedTransformerAnalyzer","title":"PretrainedTransformerAnalyzer  <code>dataclass</code>","text":"<pre><code>PretrainedTransformerAnalyzer(tokenizer)\n</code></pre> <p>Text analyzer using pretrained transformer tokenizers.</p> <p>This analyzer uses tokenizers from the Hugging Face transformers library to split text into tokens (surface forms). It provides a simple interface for text tokenization that's compatible with the formed ML pipeline.</p> PARAMETER DESCRIPTION <code>tokenizer</code> <p>Either a tokenizer name/path string or a <code>PreTrainedTokenizerBase</code> instance. If a string, the tokenizer will be loaded using <code>AutoTokenizer</code>.</p> <p> TYPE: <code>str | PathLike | PreTrainedTokenizerBase</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Initialize with model name\n&gt;&gt;&gt; analyzer = PretrainedAnalyzer(\"bert-base-uncased\")\n&gt;&gt;&gt; result = analyzer(\"Hello, world!\")\n&gt;&gt;&gt; print(result.surfaces)\n['hello', ',', 'world', '!']\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Initialize with tokenizer instance\n&gt;&gt;&gt; from transformers import AutoTokenizer\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n&gt;&gt;&gt; analyzer = PretrainedAnalyzer(tokenizer)\n&gt;&gt;&gt; result = analyzer(\"Machine learning is great!\")\n&gt;&gt;&gt; print(result.surfaces)\n['Machine', '\u0120learning', '\u0120is', '\u0120great', '!']\n</code></pre> Note <p>Tokenizers are cached using LRU cache by the <code>load_pretrained_tokenizer</code> utility. The returned <code>AnalyzedText</code> only contains surface forms; other fields like postags are <code>None</code>.</p>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.analyzers.PretrainedTransformerAnalyzer.tokenizer","title":"tokenizer  <code>instance-attribute</code>","text":"<pre><code>tokenizer\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.training","title":"formed.integrations.transformers.training","text":""},{"location":"reference/integrations/transformers/#formed.integrations.transformers.training.MlflowTrainerCallback","title":"MlflowTrainerCallback","text":"<pre><code>MlflowTrainerCallback()\n</code></pre> <p>               Bases: <code>TrainerCallback</code></p> Source code in <code>src/formed/integrations/transformers/training.py</code> <pre><code>def __init__(self) -&gt; None:\n    from formed.integrations.mlflow.workflow import MlflowLogger\n\n    self._mlflow_logger: MlflowLogger | None = None\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.training.MlflowTrainerCallback.on_train_begin","title":"on_train_begin","text":"<pre><code>on_train_begin(args, state, control, **kwargs)\n</code></pre> Source code in <code>src/formed/integrations/transformers/training.py</code> <pre><code>def on_train_begin(\n    self,\n    args: TrainingArguments,\n    state: TrainerState,\n    control: TrainerControl,\n    **kwargs: Any,\n) -&gt; None:\n    from formed.integrations.mlflow.workflow import use_mlflow_logger\n\n    logger = use_step_logger(__name__)\n    self._mlflow_logger = use_mlflow_logger()\n    if self._mlflow_logger is None:\n        logger.warning(\"MLflow logger is not available. Skipping logging.\")\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.training.MlflowTrainerCallback.on_log","title":"on_log","text":"<pre><code>on_log(args, state, control, logs, model=None, **kwargs)\n</code></pre> Source code in <code>src/formed/integrations/transformers/training.py</code> <pre><code>def on_log(  # type: ignore[override]\n    self,\n    args: TrainingArguments,\n    state: TrainerState,\n    control: TrainerControl,\n    logs: Mapping[str, Any],\n    model: torch.nn.Module | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    if self._mlflow_logger is None:\n        return\n\n    logger = use_step_logger(__name__)\n\n    if not state.is_world_process_zero:\n        return\n\n    for key, value in logs.items():\n        numerical_value: int | float\n        if isinstance(value, (int, float)):\n            numerical_value = value\n        elif isinstance(value, torch.Tensor) and value.numel() == 1:\n            numerical_value = value.item()\n        else:\n            logger.warning(\n                f'Trainer is attempting to log a value of \"{value}\" of type {type(value)} for key \"{key}\" as a metric. '\n                \"MLflow's log_metric() only accepts float and int types so we dropped this attribute.\"\n            )\n            continue\n\n        self._mlflow_logger.log_metric(key, numerical_value, step=state.global_step)\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.utils","title":"formed.integrations.transformers.utils","text":""},{"location":"reference/integrations/transformers/#formed.integrations.transformers.utils.load_pretrained_transformer","title":"load_pretrained_transformer  <code>cached</code>","text":"<pre><code>load_pretrained_transformer(\n    model_name_or_path,\n    auto_class=None,\n    submodule=None,\n    **kwargs,\n)\n</code></pre> Source code in <code>src/formed/integrations/transformers/utils.py</code> <pre><code>@lru_cache(maxsize=8)\ndef load_pretrained_transformer(\n    model_name_or_path: str | PathLike,\n    auto_class: str | type[_BaseAutoModelClass] | None = None,\n    submodule: str | None = None,\n    **kwargs,\n) -&gt; PreTrainedModel:\n    if auto_class is None:\n        auto_class = AutoModel\n    elif isinstance(auto_class, str):\n        assert \":\" in auto_class, \"auto_class string must be in 'module:ClassName' format\"\n        module_name, class_name = auto_class.rsplit(\":\", 1)\n        module = importlib.import_module(module_name)\n        auto_class = getattr(module, class_name)\n\n    assert isinstance(auto_class, type) and issubclass(auto_class, _BaseAutoModelClass), (\n        \"auto_class must be a subclass of transformers._BaseAutoModelClass\"\n    )\n\n    with suppress(FileNotFoundError):\n        model_name_or_path = minato.cached_path(model_name_or_path)\n    model = auto_class.from_pretrained(str(model_name_or_path), **kwargs)\n    if submodule:\n        model = xgetattr(model, submodule)\n    return model\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.utils.load_pretrained_tokenizer","title":"load_pretrained_tokenizer  <code>cached</code>","text":"<pre><code>load_pretrained_tokenizer(model_name_or_path, **kwargs)\n</code></pre> Source code in <code>src/formed/integrations/transformers/utils.py</code> <pre><code>@lru_cache(maxsize=8)\ndef load_pretrained_tokenizer(\n    model_name_or_path: str | PathLike,\n    **kwargs,\n) -&gt; PreTrainedTokenizerBase:\n    with suppress(FileNotFoundError):\n        model_name_or_path = minato.cached_path(model_name_or_path)\n    return AutoTokenizer.from_pretrained(str(model_name_or_path), **kwargs)\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow","title":"formed.integrations.transformers.workflow","text":"<p>Workflow steps for Hugging Face Transformers integration.</p> <p>This module provides workflow steps for loading, tokenizing, training, and converting transformer models using the Hugging Face Transformers library.</p> Available Steps <ul> <li><code>transformers::tokenize</code>: Tokenize a dataset using a pre-trained tokenizer.</li> <li><code>transformers::load_model</code>: Load a pre-trained transformer model.</li> <li><code>transformers::load_tokenizer</code>: Load a pre-trained tokenizer.</li> <li><code>transformers::train_model</code>: Train a transformer model using the Hugging Face Trainer.</li> <li><code>transformers::convert_tokenizer</code>: Convert a transformer tokenizer to a formed Tokenizer (requires ml integration).</li> </ul>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.DataCollator","title":"DataCollator  <code>module-attribute</code>","text":"<pre><code>DataCollator = Callable\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.PretrainedModelT","title":"PretrainedModelT  <code>module-attribute</code>","text":"<pre><code>PretrainedModelT = TypeVar(\n    \"PretrainedModelT\", bound=PreTrainedModel\n)\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.TransformersPretrainedModelFormat","title":"TransformersPretrainedModelFormat","text":"<p>               Bases: <code>Generic[PretrainedModelT]</code>, <code>Format[PretrainedModelT]</code></p>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.TransformersPretrainedModelFormat.identifier","title":"identifier  <code>property</code>","text":"<pre><code>identifier\n</code></pre> <p>Get the unique identifier for this format.</p> RETURNS DESCRIPTION <code>str</code> <p>Format identifier string.</p>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.TransformersPretrainedModelFormat.write","title":"write","text":"<pre><code>write(artifact, directory)\n</code></pre> Source code in <code>src/formed/integrations/transformers/workflow.py</code> <pre><code>def write(self, artifact: PretrainedModelT, directory: Path) -&gt; None:\n    artifact.save_pretrained(str(directory / \"model\"))\n    metadata = {\n        \"module\": artifact.__class__.__module__,\n        \"class\": artifact.__class__.__name__,\n    }\n    metadata_path = directory / \"metadata.json\"\n    metadata_path.write_text(json.dumps(metadata, ensure_ascii=False))\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.TransformersPretrainedModelFormat.read","title":"read","text":"<pre><code>read(directory)\n</code></pre> Source code in <code>src/formed/integrations/transformers/workflow.py</code> <pre><code>def read(self, directory: Path) -&gt; PretrainedModelT:\n    metadata_path = directory / \"metadata.json\"\n    metadata = json.loads(metadata_path.read_text())\n    module_name = metadata[\"module\"]\n    class_name = metadata[\"class\"]\n    module = importlib.import_module(module_name)\n    model_class = getattr(module, class_name)\n    if not issubclass(model_class, PreTrainedModel):\n        raise ValueError(f\"Class {class_name} is not a subclass of PreTrainedModel\")\n    model = model_class.from_pretrained(str(directory / \"model\"))\n    return cast(PretrainedModelT, model)\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.TransformersPretrainedModelFormat.is_default_of","title":"is_default_of  <code>classmethod</code>","text":"<pre><code>is_default_of(obj)\n</code></pre> <p>Check if this format is the default for the given object type.</p> PARAMETER DESCRIPTION <code>obj</code> <p>Object to check.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if this format should be used by default for this type.</p> Source code in <code>src/formed/workflow/format.py</code> <pre><code>@classmethod\ndef is_default_of(cls, obj: Any) -&gt; bool:\n    \"\"\"Check if this format is the default for the given object type.\n\n    Args:\n        obj: Object to check.\n\n    Returns:\n        True if this format should be used by default for this type.\n\n    \"\"\"\n    return False\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.tokenize_dataset","title":"tokenize_dataset","text":"<pre><code>tokenize_dataset(\n    dataset,\n    tokenizer,\n    text_column=\"text\",\n    padding=False,\n    truncation=False,\n    return_special_tokens_mask=False,\n    max_length=None,\n)\n</code></pre> <p>Tokenize a dataset using a pre-trained tokenizer.</p> <p>This step applies tokenization to a text column in the dataset, removing the original text column and adding tokenized features.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>Dataset or DatasetDict to tokenize.</p> <p> TYPE: <code>Dataset | DatasetDict</code> </p> <code>tokenizer</code> <p>Tokenizer identifier, path, or instance.</p> <p> TYPE: <code>str | PathLike | PreTrainedTokenizerBase</code> </p> <code>text_column</code> <p>Name of the text column to tokenize.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'text'</code> </p> <code>padding</code> <p>Padding strategy.</p> <p> TYPE: <code>bool | Literal['max_length', 'longest', 'do_not_pad']</code> DEFAULT: <code>False</code> </p> <code>truncation</code> <p>Truncation strategy.</p> <p> TYPE: <code>bool | Literal['only_first', 'only_second', 'longest_first', 'do_not_truncate']</code> DEFAULT: <code>False</code> </p> <code>return_special_tokens_mask</code> <p>Whether to return special tokens mask.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_length</code> <p>Maximum sequence length.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dataset | DatasetDict</code> <p>Tokenized dataset with the text column removed.</p> Source code in <code>src/formed/integrations/transformers/workflow.py</code> <pre><code>@step(\"transformers::tokenize\", format=DatasetFormat())\ndef tokenize_dataset(\n    dataset: datasets.Dataset | datasets.DatasetDict,\n    tokenizer: str | PathLike | PreTrainedTokenizerBase,\n    text_column: str = \"text\",\n    padding: bool | Literal[\"max_length\", \"longest\", \"do_not_pad\"] = False,\n    truncation: bool | Literal[\"only_first\", \"only_second\", \"longest_first\", \"do_not_truncate\"] = False,\n    return_special_tokens_mask: bool = False,\n    max_length: int | None = None,\n) -&gt; datasets.Dataset | datasets.DatasetDict:\n    \"\"\"Tokenize a dataset using a pre-trained tokenizer.\n\n    This step applies tokenization to a text column in the dataset,\n    removing the original text column and adding tokenized features.\n\n    Args:\n        dataset: Dataset or DatasetDict to tokenize.\n        tokenizer: Tokenizer identifier, path, or instance.\n        text_column: Name of the text column to tokenize.\n        padding: Padding strategy.\n        truncation: Truncation strategy.\n        return_special_tokens_mask: Whether to return special tokens mask.\n        max_length: Maximum sequence length.\n\n    Returns:\n        Tokenized dataset with the text column removed.\n    \"\"\"\n    if not isinstance(tokenizer, PreTrainedTokenizerBase):\n        tokenizer = load_pretrained_tokenizer(tokenizer)\n\n    def tokenize_function(examples: Mapping[str, Any]) -&gt; Any:\n        return tokenizer(\n            examples[text_column],\n            padding=padding,\n            truncation=truncation,\n            max_length=max_length,\n            return_special_tokens_mask=return_special_tokens_mask,\n        )\n\n    return dataset.map(\n        tokenize_function,\n        batched=True,\n        remove_columns=[text_column],\n    )\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.load_pretrained_model","title":"load_pretrained_model","text":"<pre><code>load_pretrained_model(\n    model_name_or_path,\n    auto_class=AutoModel,\n    submodule=None,\n    **kwargs,\n)\n</code></pre> <p>Load a pre-trained transformer model.</p> PARAMETER DESCRIPTION <code>model_name_or_path</code> <p>Model identifier or path to model directory.</p> <p> TYPE: <code>str | PathLike</code> </p> <code>auto_class</code> <p>Auto model class to use for loading (name or class).</p> <p> TYPE: <code>str | type[_BaseAutoModelClass]</code> DEFAULT: <code>AutoModel</code> </p> <code>submodule</code> <p>Optional submodule to extract from the model.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments to pass to the model constructor.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>PreTrainedModel</code> <p>Loaded pre-trained transformer model.</p> Source code in <code>src/formed/integrations/transformers/workflow.py</code> <pre><code>@step(\"transformers::load_model\", cacheable=False)\ndef load_pretrained_model(\n    model_name_or_path: str | PathLike,\n    auto_class: str | type[_BaseAutoModelClass] = transformers.AutoModel,\n    submodule: str | None = None,\n    **kwargs: Any,\n) -&gt; transformers.PreTrainedModel:\n    \"\"\"Load a pre-trained transformer model.\n\n    Args:\n        model_name_or_path: Model identifier or path to model directory.\n        auto_class: Auto model class to use for loading (name or class).\n        submodule: Optional submodule to extract from the model.\n        **kwargs: Additional arguments to pass to the model constructor.\n\n    Returns:\n        Loaded pre-trained transformer model.\n    \"\"\"\n    if isinstance(auto_class, str):\n        auto_class = getattr(transformers, auto_class)\n    assert isinstance(auto_class, type) and issubclass(auto_class, _BaseAutoModelClass)\n    return load_pretrained_transformer.__wrapped__(\n        model_name_or_path=model_name_or_path,\n        auto_class=auto_class,\n        submodule=submodule,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.load_pretrained_tokenizer_step","title":"load_pretrained_tokenizer_step","text":"<pre><code>load_pretrained_tokenizer_step(\n    pretrained_model_name_or_path, **kwargs\n)\n</code></pre> <p>Load a pre-trained tokenizer.</p> PARAMETER DESCRIPTION <code>pretrained_model_name_or_path</code> <p>Model identifier or path to model directory.</p> <p> TYPE: <code>str | PathLike</code> </p> <code>**kwargs</code> <p>Additional arguments to pass to the tokenizer constructor.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>PreTrainedTokenizerBase</code> <p>Loaded pre-trained tokenizer.</p> Source code in <code>src/formed/integrations/transformers/workflow.py</code> <pre><code>@step(\"transformers::load_tokenizer\", cacheable=False)\ndef load_pretrained_tokenizer_step(\n    pretrained_model_name_or_path: str | PathLike,\n    **kwargs: Any,\n) -&gt; PreTrainedTokenizerBase:\n    \"\"\"Load a pre-trained tokenizer.\n\n    Args:\n        pretrained_model_name_or_path: Model identifier or path to model directory.\n        **kwargs: Additional arguments to pass to the tokenizer constructor.\n\n    Returns:\n        Loaded pre-trained tokenizer.\n    \"\"\"\n    return load_pretrained_tokenizer(pretrained_model_name_or_path, **kwargs)\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.train_transformer_model","title":"train_transformer_model","text":"<pre><code>train_transformer_model(\n    model,\n    args,\n    data_collator=None,\n    dataset=None,\n    processing_class=None,\n    model_init=None,\n    compute_loss_func=None,\n    compute_metrics=None,\n    callbacks=None,\n    optimizers=(None, None),\n    optimizer_cls_and_kwargs=None,\n    preprocess_logits_for_metrics=None,\n    train_dataset_key=\"train\",\n    eval_dataset_key=\"validation\",\n)\n</code></pre> <p>Train a transformer model using the Hugging Face Trainer.</p> <p>This step trains a transformer model on the provided datasets using the Hugging Face Trainer API.</p> PARAMETER DESCRIPTION <code>model</code> <p>Pre-trained model to train.</p> <p> TYPE: <code>PreTrainedModel</code> </p> <code>args</code> <p>Training arguments configuration.</p> <p> TYPE: <code>Lazy[TrainingArguments]</code> </p> <code>data_collator</code> <p>Optional data collator for batching.</p> <p> TYPE: <code>DataCollator | None</code> DEFAULT: <code>None</code> </p> <code>dataset</code> <p>Training/validation datasets.</p> <p> TYPE: <code>None | (Dataset | DatasetDict | Mapping[str, Dataset | DatasetDict])</code> DEFAULT: <code>None</code> </p> <code>processing_class</code> <p>Optional processing class (tokenizer, processor, etc.).</p> <p> TYPE: <code>None | (PreTrainedTokenizerBase | BaseImageProcessor | FeatureExtractionMixin | ProcessorMixin)</code> DEFAULT: <code>None</code> </p> <code>model_init</code> <p>Optional model initialization function.</p> <p> TYPE: <code>Callable[[], PreTrainedModel] | None</code> DEFAULT: <code>None</code> </p> <code>compute_loss_func</code> <p>Optional custom loss computation function.</p> <p> TYPE: <code>Callable | None</code> DEFAULT: <code>None</code> </p> <code>compute_metrics</code> <p>Optional metrics computation function.</p> <p> TYPE: <code>Callable[[EvalPrediction], dict] | None</code> DEFAULT: <code>None</code> </p> <code>callbacks</code> <p>Optional training callbacks.</p> <p> TYPE: <code>list[TrainerCallback] | None</code> DEFAULT: <code>None</code> </p> <code>optimizers</code> <p>Optional optimizer and learning rate scheduler.</p> <p> TYPE: <code>tuple[Lazy[Optimizer] | None, Lazy[LambdaLR] | None]</code> DEFAULT: <code>(None, None)</code> </p> <code>optimizer_cls_and_kwargs</code> <p>Optional optimizer class and keyword arguments.</p> <p> TYPE: <code>tuple[type[Optimizer], dict[str, Any]] | None</code> DEFAULT: <code>None</code> </p> <code>preprocess_logits_for_metrics</code> <p>Optional logits preprocessing function.</p> <p> TYPE: <code>Callable[[Tensor, Tensor], Tensor] | None</code> DEFAULT: <code>None</code> </p> <code>train_dataset_key</code> <p>Key for training dataset split.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'train'</code> </p> <code>eval_dataset_key</code> <p>Key for evaluation dataset split.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'validation'</code> </p> RETURNS DESCRIPTION <code>PreTrainedModel</code> <p>Trained transformer model.</p> Source code in <code>src/formed/integrations/transformers/workflow.py</code> <pre><code>@step(\"transformers::train_model\", format=TransformersPretrainedModelFormat())\ndef train_transformer_model(\n    model: PreTrainedModel,\n    args: Lazy[TrainingArguments],\n    data_collator: DataCollator | None = None,  # pyright: ignore[reportInvalidTypeForm]\n    dataset: None\n    | (datasets.Dataset | datasets.DatasetDict | Mapping[str, datasets.Dataset | datasets.DatasetDict]) = None,\n    processing_class: None\n    | (PreTrainedTokenizerBase | BaseImageProcessor | FeatureExtractionMixin | ProcessorMixin) = None,\n    model_init: Callable[[], PreTrainedModel] | None = None,\n    compute_loss_func: Callable | None = None,\n    compute_metrics: Callable[[EvalPrediction], dict] | None = None,\n    callbacks: list[TrainerCallback] | None = None,\n    optimizers: tuple[\n        Lazy[torch.optim.Optimizer] | None,\n        Lazy[torch.optim.lr_scheduler.LambdaLR] | None,\n    ] = (None, None),\n    optimizer_cls_and_kwargs: tuple[type[torch.optim.Optimizer], dict[str, Any]] | None = None,\n    preprocess_logits_for_metrics: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] | None = None,\n    train_dataset_key: str = \"train\",\n    eval_dataset_key: str = \"validation\",\n) -&gt; PreTrainedModel:\n    \"\"\"Train a transformer model using the Hugging Face Trainer.\n\n    This step trains a transformer model on the provided datasets using\n    the Hugging Face Trainer API.\n\n    Args:\n        model: Pre-trained model to train.\n        args: Training arguments configuration.\n        data_collator: Optional data collator for batching.\n        dataset: Training/validation datasets.\n        processing_class: Optional processing class (tokenizer, processor, etc.).\n        model_init: Optional model initialization function.\n        compute_loss_func: Optional custom loss computation function.\n        compute_metrics: Optional metrics computation function.\n        callbacks: Optional training callbacks.\n        optimizers: Optional optimizer and learning rate scheduler.\n        optimizer_cls_and_kwargs: Optional optimizer class and keyword arguments.\n        preprocess_logits_for_metrics: Optional logits preprocessing function.\n        train_dataset_key: Key for training dataset split.\n        eval_dataset_key: Key for evaluation dataset split.\n\n    Returns:\n        Trained transformer model.\n    \"\"\"\n    workdir = use_step_workdir()\n\n    args_ = args.construct(output_dir=str(workdir))\n\n    train_dataset: datasets.Dataset | datasets.DatasetDict | None = None\n    eval_dataset: datasets.Dataset | datasets.DatasetDict | None = None\n    if isinstance(dataset, datasets.Dataset):\n        train_dataset = dataset\n        eval_dataset = None\n    else:\n        train_dataset = dataset.get(train_dataset_key) if dataset and args_.do_train else None\n        eval_dataset = dataset.get(eval_dataset_key) if dataset and args_.do_eval else None\n\n    lazy_optimizer, lazy_lr_scheduler = optimizers\n    optimizer = lazy_optimizer.construct(params=model.parameters()) if lazy_optimizer else None\n    lr_scheduler = lazy_lr_scheduler.construct(optimizer=optimizer) if lazy_lr_scheduler else None\n\n    trainer = transformers.Trainer(\n        model=model,\n        args=args_,\n        data_collator=data_collator,  # pyright: ignore[reportArgumentType]\n        train_dataset=train_dataset,  # pyright: ignore[reportArgumentType]\n        eval_dataset=eval_dataset,  # pyright: ignore[reportArgumentType]\n        processing_class=processing_class,\n        model_init=model_init,\n        compute_loss_func=compute_loss_func,\n        compute_metrics=compute_metrics,\n        callbacks=callbacks,\n        optimizers=optimizer_cls_and_kwargs or (optimizer, lr_scheduler),  # type: ignore[reportArgumentType]\n        preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n    )\n\n    trainer.train()\n\n    return model\n</code></pre>"},{"location":"reference/integrations/transformers/#formed.integrations.transformers.workflow.convert_tokenizer","title":"convert_tokenizer","text":"<pre><code>convert_tokenizer(\n    tokenizer,\n    pad_token=VALUE,\n    unk_token=VALUE,\n    bos_token=VALUE,\n    eos_token=VALUE,\n    freeze=True,\n    accessor=None,\n)\n</code></pre> <p>Convert a transformer tokenizer to a formed Tokenizer.</p> <p>This step converts a Hugging Face tokenizer into a formed Tokenizer with specified special tokens.</p> PARAMETER DESCRIPTION <code>tokenizer</code> <p>Tokenizer identifier, path, or instance.</p> <p> TYPE: <code>str | PathLike | PreTrainedTokenizerBase</code> </p> <code>pad_token</code> <p>Padding token (uses tokenizer default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>unk_token</code> <p>Unknown token (uses tokenizer default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>bos_token</code> <p>Beginning-of-sequence token (uses tokenizer default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>eos_token</code> <p>End-of-sequence token (uses tokenizer default if not specified).</p> <p> TYPE: <code>str | None | NotSpecified</code> DEFAULT: <code>VALUE</code> </p> <code>freeze</code> <p>Whether to freeze the vocabulary.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>accessor</code> <p>Optional accessor for token extraction.</p> <p> TYPE: <code>str | Callable | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tokenizer</code> <p>Converted formed Tokenizer.</p> RAISES DESCRIPTION <code>AssertionError</code> <p>If pad_token is not specified and not available in the tokenizer.</p> Source code in <code>src/formed/integrations/transformers/workflow.py</code> <pre><code>@step(\"transformers::convert_tokenizer\", format=\"json\")\ndef convert_tokenizer(\n    tokenizer: str | PathLike | PreTrainedTokenizerBase,\n    pad_token: str | None | NotSpecified = NotSpecified.VALUE,\n    unk_token: str | None | NotSpecified = NotSpecified.VALUE,\n    bos_token: str | None | NotSpecified = NotSpecified.VALUE,\n    eos_token: str | None | NotSpecified = NotSpecified.VALUE,\n    freeze: bool = True,\n    accessor: str | Callable | None = None,\n) -&gt; Tokenizer:\n    \"\"\"Convert a transformer tokenizer to a formed Tokenizer.\n\n    This step converts a Hugging Face tokenizer into a formed Tokenizer\n    with specified special tokens.\n\n    Args:\n        tokenizer: Tokenizer identifier, path, or instance.\n        pad_token: Padding token (uses tokenizer default if not specified).\n        unk_token: Unknown token (uses tokenizer default if not specified).\n        bos_token: Beginning-of-sequence token (uses tokenizer default if not specified).\n        eos_token: End-of-sequence token (uses tokenizer default if not specified).\n        freeze: Whether to freeze the vocabulary.\n        accessor: Optional accessor for token extraction.\n\n    Returns:\n        Converted formed Tokenizer.\n\n    Raises:\n        AssertionError: If pad_token is not specified and not available in the tokenizer.\n    \"\"\"\n    given_tokenizer = tokenizer\n\n    if isinstance(tokenizer, (str, PathLike)):\n        tokenizer = load_pretrained_tokenizer(tokenizer)\n\n    def get_token(given: str | None | NotSpecified, default: Any) -&gt; str | None:\n        if not isinstance(given, NotSpecified):\n            return given\n        if isinstance(default, str):\n            return default\n        return None\n\n    vocab = tokenizer.get_vocab().copy()\n    pad_token = get_token(pad_token, tokenizer.pad_token)\n    unk_token = get_token(unk_token, tokenizer.unk_token)\n    bos_token = get_token(bos_token, tokenizer.bos_token)\n    eos_token = get_token(eos_token, tokenizer.eos_token)\n\n    assert isinstance(pad_token, str), \"pad_token must be specified or available in the tokenizer\"\n\n    surface_indexer = TokenSequenceIndexer(\n        vocab=vocab,\n        pad_token=pad_token,\n        unk_token=unk_token,\n        bos_token=bos_token,\n        eos_token=eos_token,\n        freeze=freeze,\n    )\n    analyzer = PretrainedTransformerAnalyzer(given_tokenizer)\n    return Tokenizer(\n        surfaces=surface_indexer,\n        analyzer=Param.cast(analyzer),\n        accessor=accessor,\n    )\n</code></pre>"},{"location":"tutorials/","title":"Tutorial","text":"<ul> <li>Text Classification with PyTorch</li> <li>Causal LM Finetuning</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/","title":"Causal Language Modeling with \ud83e\udd17 Transformers","text":"<p>This tutorial shows you how to fine-tune a pre-trained language model using formed's Transformers integration. Unlike custom model development, this tutorial focuses on using formed's built-in workflow steps to orchestrate training with Hugging Face Transformers.</p> <p>What you'll build: A causal language model fine-tuned on question-answer data, using DistilGPT-2 as the base model.</p> <p>What you'll learn:</p> <ul> <li>Loading datasets with the <code>datasets</code> integration</li> <li>Tokenizing text data for language modeling</li> <li>Fine-tuning transformer models with <code>transformers::train_model</code></li> <li>Configuring training arguments and data collators</li> <li>Tracking experiments with MLflow integration</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#prerequisites","title":"Prerequisites","text":"<p>Install formed with required integrations:</p> <pre><code>pip install formed[transformers,datasets,mlflow]\n</code></pre> <p>Note: The transformers integration provides seamless access to Hugging Face's ecosystem, including pre-trained models, tokenizers, and training utilities.</p>"},{"location":"tutorials/causal_lm_finetuning/#what-is-causal-language-modeling","title":"What is Causal Language Modeling?","text":"<p>Causal language modeling (CLM) trains models to predict the next token given previous tokens. This is the training objective used by GPT-style models.</p> <p>Key characteristics:</p> <ul> <li>Models see only left context (previous tokens)</li> <li>Commonly used for text generation tasks</li> <li>Training uses the language modeling head with cross-entropy loss</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#project-setup","title":"Project Setup","text":"<p>Create a new directory:</p> <pre><code>mkdir causallm_tutorial\ncd causallm_tutorial\n</code></pre> <p>We'll create two files:</p> <ul> <li><code>config.jsonnet</code> - Workflow configuration</li> <li><code>formed.yml</code> - Project settings</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#step-1-configure-project-settings","title":"Step 1: Configure Project Settings","text":"<p>Create <code>formed.yml</code>:</p> <pre><code>workflow:\n  organizer:\n    type: mlflow\n    log_execution_metrics: true\n\nrequired_modules:\n  - formed.integrations.mlflow\n  - formed.integrations.datasets\n  - formed.integrations.transformers\n</code></pre> <p>What this does:</p> <ul> <li>MLflow organizer: Automatically tracks all experiments, metrics, and model artifacts</li> <li>Required modules: Imports integrations that provide workflow steps</li> <li><code>datasets</code>: Load data from Hugging Face Hub or local files</li> <li><code>transformers</code>: Tokenization and model training</li> <li><code>mlflow</code>: Experiment tracking</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#step-2-define-the-workflow","title":"Step 2: Define the Workflow","text":"<p>Create <code>config.jsonnet</code>:</p> <pre><code>// Define model and tokenizer configurations at the top for reusability\nlocal base_model = {\n  type: 'transformers:AutoModelForCausalLM.from_pretrained',\n  pretrained_model_name_or_path: 'distilbert/distilgpt2',\n};\n\nlocal tokenizer = {\n  type: 'transformers:AutoTokenizer.from_pretrained',\n  pretrained_model_name_or_path: base_model.pretrained_model_name_or_path,\n  pad_token: '&lt;|endoftext|&gt;',\n};\n\n{\n  steps: {\n    // Step 1: Load dataset from Hugging Face Hub\n    train_dataset: {\n      type: 'datasets::load',\n      path: 'sentence-transformers/eli5',\n      split: 'train[:10000]',\n    },\n\n    // Step 2: Tokenize text data\n    tokenized_dataset: {\n      type: 'transformers::tokenize',\n      dataset: { type: 'ref', ref: 'train_dataset' },\n      tokenizer: tokenizer,\n      text_column: 'answer',\n    },\n\n    // Step 3: Train the model\n    trained_model: {\n      type: 'transformers::train_model',\n      model: base_model,\n      dataset: { type: 'ref', ref: 'tokenized_dataset' },\n\n      // Training arguments (passed to transformers.TrainingArguments)\n      args: {\n        per_device_train_batch_size: 8,\n        per_device_eval_batch_size: 8,\n        learning_rate: 2e-5,\n        warmup_ratio: 0.1,\n        num_train_epochs: 3,\n        fp16: false,\n        bf16: true,  // Use bfloat16 for training (requires compatible hardware)\n        report_to: 'none',  // Don't report to external trackers (we use MLflow)\n        do_train: true,\n        do_eval: false,  // No validation set in this example\n        save_strategy: 'steps',\n        save_steps: 100,\n        save_total_limit: 2,\n        eval_strategy: 'no',\n        logging_strategy: 'steps',\n        logging_first_step: true,\n        logging_steps: 10,\n      },\n\n      // Data collator for language modeling\n      data_collator: {\n        type: 'transformers:DataCollatorForLanguageModeling',\n        tokenizer: tokenizer,\n        mlm: false,  // Use causal LM (not masked LM)\n      },\n\n      // Processing class for tokenization during training\n      processing_class: tokenizer,\n\n      // Callbacks for experiment tracking\n      callbacks: [\n        {\n          type: 'formed.integrations.transformers.training:MlflowTrainerCallback',\n        },\n      ],\n    },\n  },\n}\n</code></pre> <p>Let's break down each component:</p>"},{"location":"tutorials/causal_lm_finetuning/#step-1-loading-data-with-datasetsload","title":"Step 1: Loading Data with <code>datasets::load</code>","text":"<pre><code>train_dataset: {\n  type: 'datasets::load',\n  path: 'sentence-transformers/eli5',\n  split: 'train[:10000]',\n}\n</code></pre> <p>What happens:</p> <ul> <li>Loads the ELI5 (Explain Like I'm 5) dataset from Hugging Face Hub</li> <li>Takes first 10,000 examples from the training split</li> <li>Returns a <code>datasets.Dataset</code> object</li> </ul> <p>Key parameters:</p> <ul> <li><code>path</code>: Dataset name on Hugging Face Hub or path to local dataset</li> <li><code>split</code>: Which split to load (supports slice notation like <code>train[:1000]</code>)</li> <li>Additional kwargs are passed to <code>datasets.load_dataset()</code></li> </ul> <p>Dataset format: The ELI5 dataset contains question-answer pairs. We'll use the <code>answer</code> field for language modeling.</p>"},{"location":"tutorials/causal_lm_finetuning/#step-2-tokenizing-with-transformerstokenize","title":"Step 2: Tokenizing with <code>transformers::tokenize</code>","text":"<pre><code>tokenized_dataset: {\n  type: 'transformers::tokenize',\n  dataset: { type: 'ref', ref: 'train_dataset' },\n  tokenizer: tokenizer,\n  text_column: 'answer',\n}\n</code></pre> <p>What happens:</p> <ul> <li>Applies tokenization to the specified text column</li> <li>Converts text to token IDs compatible with the model</li> <li>Removes the original text column (keeps only token IDs)</li> <li>Returns a tokenized <code>datasets.Dataset</code></li> </ul> <p>Key parameters:</p> <ul> <li><code>dataset</code>: Input dataset (reference to previous step)</li> <li><code>tokenizer</code>: Tokenizer configuration or pre-loaded tokenizer</li> <li><code>text_column</code>: Name of the column containing text to tokenize</li> <li><code>padding</code>: Padding strategy (default: False, padding handled by data collator)</li> <li><code>truncation</code>: Whether to truncate sequences</li> <li><code>max_length</code>: Maximum sequence length</li> </ul> <p>Tokenizer configuration:</p> <pre><code>local tokenizer = {\n  type: 'transformers:AutoTokenizer.from_pretrained',\n  pretrained_model_name_or_path: 'distilbert/distilgpt2',\n  pad_token: '&lt;|endoftext|&gt;',\n};\n</code></pre> <p>This loads DistilGPT-2's tokenizer and sets the padding token (GPT-2 doesn't have one by default).</p>"},{"location":"tutorials/causal_lm_finetuning/#step-3-training-with-transformerstrain_model","title":"Step 3: Training with <code>transformers::train_model</code>","text":"<pre><code>trained_model: {\n  type: 'transformers::train_model',\n  model: base_model,\n  dataset: { type: 'ref', ref: 'tokenized_dataset' },\n  args: { ... },\n  data_collator: { ... },\n  processing_class: tokenizer,\n  callbacks: [ ... ],\n}\n</code></pre> <p>What happens:</p> <ul> <li>Initializes the model from the pre-trained checkpoint</li> <li>Creates a <code>transformers.Trainer</code> with specified arguments</li> <li>Trains the model on the tokenized dataset</li> <li>Saves checkpoints according to <code>save_strategy</code></li> <li>Returns the trained model</li> </ul> <p>Key parameters:</p>"},{"location":"tutorials/causal_lm_finetuning/#model-configuration","title":"Model Configuration","text":"<pre><code>model: {\n  type: 'transformers:AutoModelForCausalLM.from_pretrained',\n  pretrained_model_name_or_path: 'distilbert/distilgpt2',\n}\n</code></pre> <p>Uses <code>AutoModelForCausalLM</code> to load a model with a causal language modeling head.</p>"},{"location":"tutorials/causal_lm_finetuning/#training-arguments","title":"Training Arguments","text":"<p>The <code>args</code> field accepts any parameters from <code>transformers.TrainingArguments</code>:</p> <p>Batch size and epochs:</p> <ul> <li><code>per_device_train_batch_size</code>: Batch size per GPU/CPU</li> <li><code>num_train_epochs</code>: Number of training epochs</li> </ul> <p>Optimization:</p> <ul> <li><code>learning_rate</code>: Learning rate for optimizer (default: 5e-5)</li> <li><code>warmup_ratio</code>: Fraction of steps for learning rate warmup</li> </ul> <p>Mixed precision:</p> <ul> <li><code>fp16</code>: Use float16 (older GPUs)</li> <li><code>bf16</code>: Use bfloat16 (newer GPUs, more stable)</li> </ul> <p>Checkpointing:</p> <ul> <li><code>save_strategy</code>: When to save (\"steps\", \"epoch\", \"no\")</li> <li><code>save_steps</code>: Save checkpoint every N steps</li> <li><code>save_total_limit</code>: Keep only N most recent checkpoints</li> </ul> <p>Logging:</p> <ul> <li><code>logging_strategy</code>: When to log (\"steps\", \"epoch\")</li> <li><code>logging_steps</code>: Log every N steps</li> <li><code>logging_first_step</code>: Whether to log after first step</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#data-collator","title":"Data Collator","text":"<pre><code>data_collator: {\n  type: 'transformers:DataCollatorForLanguageModeling',\n  tokenizer: tokenizer,\n  mlm: false,\n}\n</code></pre> <p>The data collator handles batching and prepares labels:</p> <p><code>DataCollatorForLanguageModeling</code>:</p> <ul> <li><code>mlm: false</code>: Causal language modeling (predict next token)</li> <li><code>mlm: true</code>: Masked language modeling (BERT-style, predict masked tokens)</li> </ul> <p>For causal LM:</p> <ul> <li>Creates labels by shifting <code>input_ids</code> one position to the right</li> <li>Applies padding to create uniform batch size</li> <li>Handles attention masks automatically</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#callbacks","title":"Callbacks","text":"<pre><code>callbacks: [\n  {\n    type: 'formed.integrations.transformers.training:MlflowTrainerCallback',\n  },\n]\n</code></pre> <p><code>MlflowTrainerCallback</code>:</p> <ul> <li>Logs training metrics to MLflow automatically</li> <li>Tracks loss, learning rate, and other training stats</li> <li>Integrates seamlessly with formed's MLflow organizer</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#step-3-run-the-workflow","title":"Step 3: Run the Workflow","text":"<p>Execute the workflow:</p> <pre><code>formed workflow run config.jsonnet --execution-id causallm-distilgpt2\n</code></pre> <p>What happens during execution:</p> <ol> <li>Dataset loading: Downloads and caches the ELI5 dataset</li> <li>Tokenization: Tokenizes all examples and caches results</li> <li>Training: Runs training loop with Hugging Face Trainer</li> <li>Logs metrics every 10 steps</li> <li>Saves checkpoints every 100 steps</li> <li>Uses bfloat16 mixed precision</li> <li>Model saving: Caches the trained model by fingerprint</li> </ol>"},{"location":"tutorials/causal_lm_finetuning/#step-4-view-training-results","title":"Step 4: View Training Results","text":"<p>Launch MLflow UI:</p> <pre><code>mlflow ui\n</code></pre> <p>Open http://localhost:5000 to see:</p> <p>Metrics:</p> <ul> <li>Training loss curve</li> <li>Learning rate schedule</li> <li>Steps per second</li> </ul> <p>Parameters:</p> <ul> <li>All training arguments</li> <li>Model architecture</li> <li>Dataset configuration</li> </ul> <p>Artifacts:</p> <ul> <li>Trained model checkpoints</li> <li>Tokenizer files</li> <li>Training logs</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#understanding-the-components","title":"Understanding the Components","text":""},{"location":"tutorials/causal_lm_finetuning/#the-datasets-integration","title":"The <code>datasets</code> Integration","text":"<p>The <code>datasets</code> integration provides workflow steps for working with Hugging Face datasets:</p> <p>Available steps:</p> <ul> <li><code>datasets::load</code> - Load datasets from Hub or local files</li> <li><code>datasets::compose</code> - Combine multiple datasets into DatasetDict</li> <li><code>datasets::concatenate</code> - Concatenate datasets</li> <li><code>datasets::train_test_split</code> - Split dataset into train/test</li> </ul> <p>Benefits:</p> <ul> <li>Automatic caching of downloaded datasets</li> <li>Memory-efficient processing with Apache Arrow</li> <li>Seamless integration with transformers</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#the-transformers-integration","title":"The <code>transformers</code> Integration","text":"<p>The <code>transformers</code> integration wraps Hugging Face Transformers for workflow use:</p> <p>Key steps:</p> <ul> <li><code>transformers::tokenize</code> - Tokenize text data</li> <li><code>transformers::train_model</code> - Train models with Trainer API</li> <li><code>transformers::load_model</code> - Load pre-trained models</li> <li><code>transformers::load_tokenizer</code> - Load tokenizers</li> <li><code>transformers::convert_tokenizer</code> - Convert to formed's Tokenizer format</li> </ul> <p>Benefits:</p> <ul> <li>Access to thousands of pre-trained models</li> <li>Battle-tested training infrastructure</li> <li>Automatic gradient accumulation, mixed precision, and distributed training</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#data-collators","title":"Data Collators","text":"<p>Data collators prepare batches during training:</p> <p><code>DataCollatorForLanguageModeling</code>:</p> <ul> <li>Handles causal and masked language modeling</li> <li>Creates labels automatically from inputs</li> <li>Applies dynamic padding for efficiency</li> </ul> <p>Other common collators:</p> <ul> <li><code>DataCollatorWithPadding</code> - Simple padding without label generation</li> <li><code>DataCollatorForSeq2Seq</code> - For encoder-decoder models</li> <li><code>DataCollatorForTokenClassification</code> - For NER and similar tasks</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#customization-examples","title":"Customization Examples","text":""},{"location":"tutorials/causal_lm_finetuning/#use-a-different-model","title":"Use a Different Model","text":"<p>Replace DistilGPT-2 with another model:</p> <pre><code>local base_model = {\n  type: 'transformers:AutoModelForCausalLM.from_pretrained',\n  pretrained_model_name_or_path: 'gpt2',  // or 'gpt2-medium', 'EleutherAI/gpt-neo-125M', etc.\n};\n</code></pre>"},{"location":"tutorials/causal_lm_finetuning/#add-validation-set","title":"Add Validation Set","text":"<p>Split the dataset and enable evaluation:</p> <pre><code>{\n  steps: {\n    raw_dataset: {\n      type: 'datasets::load',\n      path: 'sentence-transformers/eli5',\n      split: 'train[:10000]',\n    },\n\n    // Split into train and validation\n    split_dataset: {\n      type: 'datasets::train_test_split',\n      dataset: { type: 'ref', ref: 'raw_dataset' },\n      test_size: 0.1,\n      seed: 42,\n    },\n\n    // Tokenize both splits\n    tokenized_train: {\n      type: 'transformers::tokenize',\n      dataset: { type: 'ref', ref: 'split_dataset.train' },\n      tokenizer: tokenizer,\n      text_column: 'answer',\n    },\n\n    tokenized_val: {\n      type: 'transformers::tokenize',\n      dataset: { type: 'ref', ref: 'split_dataset.test' },\n      tokenizer: tokenizer,\n      text_column: 'answer',\n    },\n\n    // Combine for training\n    dataset: {\n      type: 'datasets::compose',\n      train: { type: 'ref', ref: 'tokenized_train' },\n      validation: { type: 'ref', ref: 'tokenized_val' },\n    },\n\n    trained_model: {\n      type: 'transformers::train_model',\n      // ...\n      dataset: { type: 'ref', ref: 'dataset' },\n      args: {\n        // ...\n        do_eval: true,\n        eval_strategy: 'steps',\n        eval_steps: 100,\n      },\n    },\n  },\n}\n</code></pre>"},{"location":"tutorials/causal_lm_finetuning/#adjust-training-settings","title":"Adjust Training Settings","text":"<p>Longer training with more frequent evaluation:</p> <pre><code>args: {\n  num_train_epochs: 5,\n  eval_strategy: 'steps',\n  eval_steps: 50,\n  logging_steps: 5,\n}\n</code></pre> <p>Larger batch size with gradient accumulation:</p> <pre><code>args: {\n  per_device_train_batch_size: 4,\n  gradient_accumulation_steps: 4,  // Effective batch size: 16\n  learning_rate: 1e-5,\n}\n</code></pre> <p>Different optimizer:</p> <pre><code>trained_model: {\n  type: 'transformers::train_model',\n  // ...\n  args: {\n    // ...\n    optim: 'adamw_torch',  // or 'adafactor', 'adamw_8bit', etc.\n    weight_decay: 0.01,\n  },\n}\n</code></pre>"},{"location":"tutorials/causal_lm_finetuning/#custom-learning-rate-schedule","title":"Custom Learning Rate Schedule","text":"<pre><code>args: {\n  learning_rate: 5e-5,\n  lr_scheduler_type: 'cosine',\n  warmup_steps: 500,\n}\n</code></pre>"},{"location":"tutorials/causal_lm_finetuning/#truncate-long-sequences","title":"Truncate Long Sequences","text":"<pre><code>tokenized_dataset: {\n  type: 'transformers::tokenize',\n  dataset: { type: 'ref', ref: 'train_dataset' },\n  tokenizer: tokenizer,\n  text_column: 'answer',\n  truncation: true,\n  max_length: 512,\n}\n</code></pre>"},{"location":"tutorials/causal_lm_finetuning/#using-the-trained-model","title":"Using the Trained Model","text":"<p>After training, you can load the cached model for inference:</p> <pre><code>from formed.settings import load_formed_settings\nfrom formed.workflow import WorkflowExecutionID\n\n# Load the workflow execution\nsettings = load_formed_settings(\"./formed.yml\")\norganizer = settings.workflow.organizer\n\ncontext = organizer.get(WorkflowExecutionID(\"your-execution-id\"))\n\n# Get the trained model from cache\nmodel_step_id = context.info.graph[\"trained_model\"]\nmodel = context.cache[model_step_id]\n\n# Load tokenizer\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n\n# Generate text\ninputs = tokenizer(\"The meaning of life is\", return_tensors=\"pt\")\noutputs = model.generate(**inputs, max_length=50)\nprint(tokenizer.decode(outputs[0]))\n</code></pre> <p>Or reference the model in a new workflow step:</p> <pre><code>{\n  steps: {\n    // ... training steps ...\n\n    // Generate text using trained model\n    generated_text: {\n      type: 'my_custom::generate',\n      model: { type: 'ref', ref: 'trained_model' },\n      prompts: ['The meaning of life is', 'Once upon a time'],\n      max_length: 100,\n    },\n  },\n}\n</code></pre>"},{"location":"tutorials/causal_lm_finetuning/#key-takeaways","title":"Key Takeaways","text":"<p>Workflow Steps:</p> <ul> <li><code>datasets::load</code> loads datasets from Hugging Face Hub</li> <li><code>transformers::tokenize</code> prepares text for model input</li> <li><code>transformers::train_model</code> orchestrates training with Trainer API</li> <li>All steps are cached by fingerprint for reproducibility</li> </ul> <p>Training Configuration:</p> <ul> <li>TrainingArguments control all aspects of training</li> <li>Data collators handle batch preparation and label creation</li> <li>Callbacks enable custom logging and monitoring</li> </ul> <p>MLflow Integration:</p> <ul> <li>Automatic experiment tracking</li> <li>Metrics, parameters, and artifacts logged transparently</li> <li>Easy comparison across training runs</li> </ul> <p>Workflow Benefits:</p> <ul> <li>No custom Python code needed for standard tasks</li> <li>Configuration-driven experimentation</li> <li>Automatic caching and dependency management</li> <li>Seamless integration with Hugging Face ecosystem</li> </ul>"},{"location":"tutorials/causal_lm_finetuning/#next-steps","title":"Next Steps","text":""},{"location":"tutorials/causal_lm_finetuning/#fine-tune-on-custom-data","title":"Fine-tune on Custom Data","text":"<p>Replace the dataset with your own:</p> <pre><code>train_dataset: {\n  type: 'datasets::load',\n  path: '/path/to/your/dataset.jsonl',\n}\n</code></pre> <p>Your data should be in a format supported by Hugging Face datasets (JSON, CSV, Parquet, etc.).</p>"},{"location":"tutorials/causal_lm_finetuning/#try-masked-language-modeling","title":"Try Masked Language Modeling","text":"<p>For BERT-style models:</p> <pre><code>local base_model = {\n  type: 'transformers:AutoModelForMaskedLM.from_pretrained',\n  pretrained_model_name_or_path: 'bert-base-uncased',\n};\n\n// ...\n\ndata_collator: {\n  type: 'transformers:DataCollatorForLanguageModeling',\n  tokenizer: tokenizer,\n  mlm: true,\n  mlm_probability: 0.15,\n}\n</code></pre>"},{"location":"tutorials/causal_lm_finetuning/#further-reading","title":"Further Reading","text":"<ul> <li>Text Classification Tutorial: Build custom models with PyTorch</li> <li>Transformers Documentation: Complete Hugging Face Transformers guide</li> <li>Workflow Guide: Advanced workflow patterns</li> <li>MLflow Integration: Experiment tracking details</li> </ul> <p>For more examples, see <code>examples/causallm/</code> in the repository.</p>"},{"location":"tutorials/text_classification/","title":"Text Classification with PyTorch","text":"<p>This tutorial guides you through building a text classification system using formed's PyTorch integration. You'll learn how to compose models from reusable components, manage data transformations, and train models within formed's workflow system.</p> <p>What you'll build: A binary text classifier that detects whether a sequence of characters is sorted or not (a toy task for demonstration).</p> <p>What you'll learn: - Defining DataModules for type-safe data transformation - Composing models from pre-built torch modules - Training models with callbacks and evaluation - Integrating everything into a reproducible workflow</p>"},{"location":"tutorials/text_classification/#prerequisites","title":"Prerequisites","text":"<p>Install formed with PyTorch integration:</p> <pre><code>pip install formed[torch,mlflow]\n</code></pre>"},{"location":"tutorials/text_classification/#project-structure","title":"Project Structure","text":"<p>Create a new directory for this tutorial:</p> <pre><code>mkdir text_classification_tutorial\ncd text_classification_tutorial\n</code></pre> <p>We'll create:</p> <ul> <li><code>textclf.py</code> - DataModule, model, and evaluator definitions</li> <li><code>config.jsonnet</code> - Workflow configuration</li> <li><code>formed.yml</code> - Project settings</li> </ul>"},{"location":"tutorials/text_classification/#step-1-define-the-datamodule","title":"Step 1: Define the DataModule","text":"<p>The DataModule handles data transformation from raw examples to model-ready batches. It provides a structured, type-safe way to define how each field should be processed.</p> <p>Create <code>textclf.py</code>:</p> <pre><code>from typing import Any\nfrom collections.abc import Sequence\nimport dataclasses\n\nfrom formed.integrations import ml\nfrom formed.integrations.ml import types as mlt\n\n# Define the raw data structure\n@dataclasses.dataclass\nclass ClassificationExample:\n    id: str\n    text: str | Sequence[str]  # Can be string or tokens\n    label: int | str | None = None\n\n# Define the DataModule for text classification\n@ml.DataModule.register(\"textclf::text_classification\")\nclass TextClassificationDataModule(\n    ml.DataModule[\n        mlt.DataModuleModeT,\n        Any,\n        \"TextClassificationDataModule[mlt.AsInstance]\",\n        \"TextClassificationDataModule[mlt.AsBatch]\",\n    ]\n):\n    \"\"\"DataModule for text classification tasks.\n\n    Fields:\n        id: Example identifier (metadata, not batched)\n        text: Text to classify, processed through tokenization\n        label: Classification label, indexed to integers\n    \"\"\"\n    id: ml.MetadataTransform[Any, str] = ml.MetadataTransform()\n    text: ml.Tokenizer  # Tokenizes and indexes text\n    label: ml.Extra[ml.LabelIndexer] = ml.Extra.default()  # Optional during inference\n</code></pre> <p>Key concepts:</p> <ul> <li>Field transforms: Each field specifies its transformation type</li> <li><code>MetadataTransform</code>: Pass through metadata without batching</li> <li><code>Tokenizer</code>: Tokenize text and build vocabulary</li> <li><code>LabelIndexer</code>: Index labels to integers</li> <li>Extra fields: <code>label</code> is marked with <code>Extra</code> since it's absent during inference</li> <li>Type parameters: Generic parameters track types through transformation stages (AsConverter \u2192 AsInstance \u2192 AsBatch)</li> </ul> <p>How it works:</p> <ol> <li>During training, <code>with datamodule.train():</code> builds vocabularies from data</li> <li><code>datamodule(example)</code> converts raw examples to instances</li> <li><code>datamodule.batch(instances)</code> collates instances into batches</li> <li>The DataModule structure is preserved at each stage</li> </ol>"},{"location":"tutorials/text_classification/#step-2-define-the-model","title":"Step 2: Define the Model","text":"<p>Models in formed are composed from reusable modules. This declarative approach separates architecture from implementation and enables configuration-driven experimentation.</p> <p>Add to <code>textclf.py</code>:</p> <pre><code>import torch\nfrom formed.integrations import torch as ft\nfrom formed.integrations.torch import modules as ftm\n\n@dataclasses.dataclass\nclass ClassifierOutput:\n    \"\"\"Model output structure.\"\"\"\n    probs: torch.Tensor   # Class probabilities\n    label: torch.Tensor   # Predicted labels\n    loss: torch.Tensor | None = None  # Loss (if labels provided)\n\n@ft.BaseTorchModel.register(\"textclf::torch_text_classifier\")\nclass TextClassifier(ft.BaseTorchModel[\n    TextClassificationDataModule[mlt.AsBatch],  # Input type\n    ClassifierOutput,                            # Output type\n]):\n    \"\"\"LSTM-based text classifier.\n\n    Architecture:\n        text \u2192 embedder \u2192 encoder \u2192 vectorizer \u2192 feedforward \u2192 classifier\n\n    Args:\n        num_classes: Number of classification labels\n        embedder: Converts tokens to embeddings\n        encoder: Processes token sequences with context\n        vectorizer: Aggregates sequence to fixed-size vector\n        feedforward: Optional additional transformation\n        dropout: Dropout probability\n        loss: Loss function for training\n    \"\"\"\n\n    def __init__(\n        self,\n        num_classes: int,\n        embedder: ftm.BaseEmbedder,\n        vectorizer: ftm.BaseSequenceVectorizer,\n        encoder: ftm.BaseSequenceEncoder | None = None,\n        feedforward: ftm.FeedForward | None = None,\n        sampler: ftm.BaseLabelSampler | None = None,\n        loss: ftm.BaseClassificationLoss | None = None,\n        dropout: float = 0.1,\n    ) -&gt; None:\n        super().__init__()\n\n        # Use defaults for optional components\n        sampler = sampler or ftm.ArgmaxLabelSampler()\n        loss = loss or ftm.CrossEntropyLoss()\n\n        # Calculate feature dimension through the pipeline\n        # determine_ndim chains output dimensions, handling optional components\n        feature_dim = ft.determine_ndim(\n            embedder.get_output_dim(),\n            encoder.get_output_dim() if encoder is not None else None,\n            vectorizer.get_output_dim(),\n            feedforward.get_output_dim() if feedforward is not None else None,\n        )\n\n        # Store components\n        self._embedder = embedder\n        self._encoder = encoder\n        self._vectorizer = vectorizer\n        self._feedforward = feedforward\n        self._dropout = torch.nn.Dropout(dropout)\n        self._classifier = torch.nn.Linear(feature_dim, num_classes)\n        self._sampler = sampler\n        self._loss = loss\n\n    def forward(\n        self,\n        inputs: TextClassificationDataModule[mlt.AsBatch],\n        params: None = None,\n    ) -&gt; ClassifierOutput:\n        \"\"\"Forward pass through the model.\n\n        Args:\n            inputs: Batched data from DataModule\n            params: Additional parameters (unused)\n\n        Returns:\n            ClassifierOutput with predictions and loss\n        \"\"\"\n        # Embed tokens: (batch, seq_len) \u2192 (batch, seq_len, embed_dim)\n        embeddings, mask = self._embedder(inputs.text)\n\n        # Encode sequence with context (optional)\n        if self._encoder is not None:\n            embeddings = self._encoder(embeddings, mask=mask)\n\n        # Vectorize sequence: (batch, seq_len, dim) \u2192 (batch, dim)\n        vector = self._vectorizer(embeddings, mask=mask)\n\n        # Apply feedforward (optional)\n        if self._feedforward is not None:\n            vector = self._feedforward(vector)\n\n        # Apply dropout and classify\n        vector = self._dropout(vector)\n        logits = self._classifier(vector)\n\n        # Get probabilities and predictions\n        probs = torch.nn.functional.softmax(logits, dim=-1)\n        label = self._sampler(logits)\n\n        # Compute loss if labels provided\n        loss = None\n        if inputs.label is not None:\n            loss = self._loss(logits, inputs.label)\n\n        return ClassifierOutput(probs=probs, label=label, loss=loss)\n</code></pre> <p>Key concepts:</p> <ul> <li>Module composition: Models are built from reusable components</li> <li><code>BaseEmbedder</code>: Token \u2192 embedding</li> <li><code>BaseSequenceEncoder</code>: Contextual sequence processing (LSTM, Transformer, etc.)</li> <li><code>BaseSequenceVectorizer</code>: Sequence \u2192 fixed vector</li> <li><code>FeedForward</code>: Additional transformation layers</li> <li>Structured output: Return dataclass instead of dict for type safety</li> <li>Loss in forward: Including loss in output enables automatic training</li> <li>Optional components: Make encoder/feedforward optional for flexibility</li> </ul>"},{"location":"tutorials/text_classification/#step-3-define-the-evaluator","title":"Step 3: Define the Evaluator","text":"<p>Evaluators compute metrics during training and evaluation. They follow a standard update-compute-reset pattern.</p> <p>Add to <code>textclf.py</code>:</p> <pre><code>class ClassificationEvaluator:\n    \"\"\"Evaluator for classification tasks.\n\n    Tracks loss and configurable classification metrics (accuracy, F-beta, etc.)\n\n    Args:\n        metrics: List of classification metrics to compute\n    \"\"\"\n\n    def __init__(\n        self,\n        metrics: Sequence[ml.MulticlassClassificationMetric],\n    ) -&gt; None:\n        self._loss = ml.Average(\"loss\")\n        self._metrics = metrics\n\n    def update(\n        self,\n        inputs: TextClassificationDataModule[mlt.AsBatch],\n        output: ClassifierOutput,\n    ) -&gt; None:\n        \"\"\"Update metrics with a batch of predictions.\n\n        Args:\n            inputs: Input batch (contains labels)\n            output: Model predictions and loss\n        \"\"\"\n        # Track loss\n        if output.loss is not None:\n            self._loss.update([output.loss.item()])\n\n        # Track classification metrics\n        if inputs.label is not None:\n            predictions = output.label.tolist()\n            targets = inputs.label.tolist()\n            for metric in self._metrics:\n                metric.update(\n                    metric.Input(predictions=predictions, targets=targets)\n                )\n\n    def compute(self) -&gt; dict[str, float]:\n        \"\"\"Compute final metrics.\n\n        Returns:\n            Dictionary of metric names to values\n        \"\"\"\n        metrics = self._loss.compute()\n        for metric in self._metrics:\n            metrics.update(metric.compute())\n        return metrics\n\n    def reset(self) -&gt; None:\n        \"\"\"Reset metrics for next evaluation round.\"\"\"\n        self._loss.reset()\n        for metric in self._metrics:\n            metric.reset()\n</code></pre> <p>Key concepts:</p> <ul> <li>Standard interface: All evaluators implement update/compute/reset</li> <li>Incremental computation: Metrics accumulate over batches</li> <li>Configurable metrics: Accept list of metrics for flexibility</li> </ul>"},{"location":"tutorials/text_classification/#step-4-create-sample-data","title":"Step 4: Create Sample Data","text":"<p>Before defining the workflow, let's create a simple data generation function.</p> <p>Add to <code>textclf.py</code>:</p> <pre><code>import random\nfrom formed import workflow\n\n@workflow.step(\"textclf::generate_sort_detection_dataset\")\ndef generate_sort_detection_dataset(\n    vocab: Sequence[str] = \"abcdefghijklmnopqrstuvwxyz\",\n    num_examples: int = 100,\n    max_tokens: int = 10,\n    random_seed: int = 42,\n) -&gt; list[ClassificationExample]:\n    \"\"\"Generate synthetic dataset for sort detection.\n\n    Creates examples with random character sequences labeled as\n    'sorted' or 'not_sorted' based on alphabetical order.\n\n    Args:\n        vocab: Characters to sample from\n        num_examples: Number of examples to generate\n        max_tokens: Maximum sequence length\n        random_seed: Random seed for reproducibility\n\n    Returns:\n        List of ClassificationExample instances\n    \"\"\"\n    rng = random.Random(random_seed)\n    examples = []\n\n    for _ in range(num_examples):\n        num_tokens = rng.randint(1, max_tokens)\n        label = rng.choice([\"sorted\", \"not_sorted\"])\n        tokens = rng.choices(vocab, k=num_tokens)\n\n        if label == \"sorted\":\n            tokens.sort()\n\n        examples.append(\n            ClassificationExample(\n                id=str(len(examples)),\n                text=tokens,\n                label=label,\n            )\n        )\n\n    return examples\n</code></pre> <p>Key concepts:</p> <ul> <li>Workflow steps: Functions decorated with <code>@workflow.step</code> become cacheable workflow steps</li> <li>Deterministic: Use explicit random seed for reproducibility</li> <li>Typed output: Return structured data that DataModule can process</li> </ul>"},{"location":"tutorials/text_classification/#step-5-configure-the-workflow","title":"Step 5: Configure the Workflow","text":"<p>Now define the complete workflow in Jsonnet. This configuration specifies all steps from data generation to model training.</p> <p>Create <code>config.jsonnet</code>:</p> <pre><code>// Helper for step references\nlocal ref(name) = { type: 'ref', ref: name };\n\n// Define evaluator (reused across steps)\nlocal evaluator = {\n  type: 'textclf:ClassificationEvaluator',\n  metrics: [\n    { type: 'accuracy' },\n    { type: 'fbeta' },  // F1 score by default\n  ],\n};\n\n{\n  steps: {\n    // 1. Generate datasets\n    train_dataset: {\n      type: 'textclf::generate_sort_detection_dataset',\n      num_examples: 1000,\n      random_seed: 1,\n    },\n\n    val_dataset: {\n      type: 'textclf::generate_sort_detection_dataset',\n      num_examples: 100,\n      random_seed: 2,\n    },\n\n    test_dataset: {\n      type: 'textclf::generate_sort_detection_dataset',\n      num_examples: 100,\n      random_seed: 3,\n    },\n\n    // 2. Build DataModule and create instances\n    datamodule: {\n      type: 'ml::train_datamodule',\n      datamodule: {\n        type: 'textclf::text_classification',\n        id: {},  // Use defaults\n        text: {\n          surfaces: {},  // Build vocabulary from training data\n        },\n        label: {},  // Build label set from training data\n      },\n      dataset: ref('train_dataset'),\n    },\n\n    // 3. Train the model\n    model: {\n      type: 'torch::train',\n      model: {\n        type: 'textclf::torch_text_classifier',\n        num_classes: ref('datamodule.label.num_labels'),\n\n        // Embedder: token IDs \u2192 embeddings\n        embedder: {\n          type: 'analyzed_text',  // Handles AnalyzedText from Tokenizer\n          surface: {\n            type: 'token',\n            initializer: {\n              type: 'xavier_uniform',\n              shape: [\n                ref('datamodule.text.surfaces.vocab_size'),\n                32,  // embedding dimension\n              ],\n            },\n            padding_idx: ref('datamodule.text.surfaces.pad_index'),\n          },\n        },\n\n        // Encoder: sequence processing\n        encoder: {\n          type: 'lstm',\n          input_dim: 32,\n          hidden_dim: 32,\n          bidirectional: false,\n        },\n\n        // Vectorizer: sequence \u2192 vector\n        vectorizer: {\n          type: 'boe',  // Bag of embeddings\n          pooling: 'last',  // Use last hidden state\n        },\n\n        dropout: 0.1,\n      },\n\n      // Training configuration\n      trainer: {\n        // Data loaders\n        train_dataloader: {\n          type: 'formed.integrations.ml:DataLoader',\n          sampler: {\n            type: 'basic',\n            batch_size: 32,\n            shuffle: true,\n            drop_last: true,\n          },\n          collator: ref('datamodule.batch'),\n        },\n\n        val_dataloader: {\n          type: 'formed.integrations.ml:DataLoader',\n          sampler: {\n            type: 'basic',\n            batch_size: 32,\n            drop_last: false,\n          },\n          collator: ref('datamodule.batch'),\n        },\n\n        // Training engine\n        engine: {\n          type: 'default',\n          optimizer: {\n            type: 'torch.optim:Adam',\n            lr: 1e-3,\n          },\n        },\n\n        // Callbacks\n        callbacks: [\n          // Log metrics to MLflow\n          { type: 'mlflow' },\n\n          // Compute evaluation metrics\n          {\n            type: 'evaluation',\n            evaluator: evaluator,\n          },\n\n          // Early stopping on validation F-beta\n          {\n            type: 'early_stopping',\n            patience: 3,\n            metric: '+val/fbeta',  // '+' means maximize\n          },\n        ],\n\n        // Training settings\n        max_epochs: 10,\n        logging_strategy: 'step',\n        logging_interval: 5,\n      },\n\n      // Reference datasets\n      train_dataset: ref('train_dataset'),\n      val_dataset: ref('val_dataset'),\n    },\n\n    // 4. Evaluate on test set\n    test_metrics: {\n      type: 'torch::evaluate',\n      model: ref('model'),\n      evaluator: evaluator,\n      dataset: ref('test_dataset'),\n      dataloader: {\n        type: 'formed.integrations.ml:DataLoader',\n        sampler: {\n          type: 'basic',\n          batch_size: 32,\n          shuffle: false,\n          drop_last: false,\n        },\n        collator: ref('datamodule.batch'),\n      },\n      random_seed: 0,\n    },\n  },\n}\n</code></pre> <p>Key concepts:</p> <ul> <li>Step dependencies: Use <code>ref()</code> to reference other steps' outputs</li> <li>Nested references: Access fields with dot notation (e.g., <code>datamodule.label.num_labels</code>)</li> <li>Method references: Reference DataModule methods as collators (<code>datamodule.batch</code>)</li> <li>Metric specifications: Prefix with <code>+</code> to maximize, <code>-</code> to minimize</li> <li>Declarative configuration: Entire architecture specified in configuration</li> </ul>"},{"location":"tutorials/text_classification/#step-6-configure-project-settings","title":"Step 6: Configure Project Settings","text":"<p>Create <code>formed.yml</code> to specify required modules:</p> <pre><code>workflow:\n  organizer:\n    type: mlflow\n    log_execution_metrics: true\n\nrequired_modules:\n  - textclf\n  - formed.integrations.datasets\n  - formed.integrations.ml\n  - formed.integrations.mlflow\n  - formed.integrations.torch\n</code></pre> <p>Key concepts:</p> <ul> <li>MLflow organizer: Automatically logs experiments and artifacts</li> <li>Required modules: Import modules containing step definitions</li> <li>Execution metrics: Track training progress in MLflow</li> </ul>"},{"location":"tutorials/text_classification/#step-7-run-the-workflow","title":"Step 7: Run the Workflow","text":"<p>Execute the workflow:</p> <pre><code>formed workflow run config.jsonnet --execution-id sort-classifier-v1\n</code></pre> <p>What happens:</p> <ol> <li>Data generation: Creates train/val/test datasets</li> <li>DataModule training: Builds vocabulary and label index from training data</li> <li>Model training: Trains with early stopping and metric logging</li> <li>Test evaluation: Computes final metrics on held-out test set</li> <li>Caching: Results are cached by fingerprint for reproducibility</li> </ol> <p>View results:</p> <pre><code>mlflow ui\n</code></pre> <p>Then open http://localhost:5000 to see:</p> <ul> <li>Training curves (loss, accuracy, F-beta)</li> <li>Hyperparameters</li> <li>Model artifacts</li> <li>System metrics</li> </ul> <p>You can access cached results later with the same execution ID:</p> <pre><code>from formed.settings import load_formed_settings\nfrom formed.workflow import WorkflowExecutionID\n\nsettings = load_formed_settings(\"./formed.yml\")\norganizer = settings.workflow.organizer\n\ncontext = organizer.get(WorkflowExecutionID(\"004e597f\"))\nmodel = context.cache[context.info.graph[\"model\"]]\n</code></pre>"},{"location":"tutorials/text_classification/#next-steps","title":"Next Steps","text":""},{"location":"tutorials/text_classification/#experiment-with-configuration","title":"Experiment with Configuration","text":"<p>Try different architectures:</p> <pre><code>// Bidirectional LSTM\nencoder: {\n  type: 'lstm',\n  input_dim: 32,\n  hidden_dim: 64,\n  num_layers: 2,\n  bidirectional: true,\n}\n</code></pre> <p>Add feedforward layers:</p> <pre><code>model: {\n  type: 'textclf::torch_text_classifier',\n  // ...\n  feedforward: {\n    type: 'feedforward',\n    input_dim: 32,\n    hidden_dims: [64, 32],\n    activations: 'relu',\n    dropout: 0.2,\n  },\n}\n</code></pre> <p>Use different optimizers:</p> <pre><code>engine: {\n  type: 'default',\n  optimizer: {\n    type: 'torch.optim:AdamW',\n    lr: 1e-3,\n    weight_decay: 0.01,\n  },\n  lr_scheduler: {\n    type: 'formed.integrations.torch:CosineLRScheduler',\n    t_initial: 100,\n    lr_min: 1e-5,\n  },\n}\n</code></pre>"},{"location":"tutorials/text_classification/#real-world-dataset","title":"Real-World Dataset","text":"<p>Replace synthetic data with actual text classification:</p> <pre><code>train_dataset: {\n  type: 'datasets::load',\n  path: 'dair-ai/emotion',\n  split: 'train',\n}\n</code></pre> <p>Update the DataModule to use pre-trained tokenizer:</p> <pre><code>datamodule: {\n  type: 'textclf::text_classification',\n  text: {\n    type: 'transformers::convert_tokenizer',\n    tokenizer: 'bert-base-uncased',\n  },\n  label: {},\n}\n</code></pre> <p>Use pre-trained models:</p> <pre><code>embedder: {\n  type: 'analyzed_text',\n  surface: {\n    type: 'pretrained_transformer',\n    model: 'bert-base-uncased',\n  },\n}\n</code></pre>"},{"location":"tutorials/text_classification/#key-takeaways","title":"Key Takeaways","text":"<p>DataModule:</p> <ul> <li>Provides type-safe, composable data transformation</li> <li>Structure preserved through transformation pipeline</li> <li>Training mode builds vocabularies automatically</li> </ul> <p>Model Composition:</p> <ul> <li>Build models from reusable, configurable modules</li> <li>Declarative architecture specification</li> <li>Automatic dimension tracking through pipeline</li> </ul> <p>Training:</p> <ul> <li>Integrated callbacks for evaluation and early stopping</li> <li>Automatic metric logging with MLflow</li> <li>Flexible training strategies (epoch/step-based)</li> </ul> <p>Workflow:</p> <ul> <li>Content-based caching ensures reproducibility</li> <li>Automatic dependency tracking</li> <li>Configuration-driven experimentation</li> </ul>"},{"location":"tutorials/text_classification/#further-reading","title":"Further Reading","text":"<ul> <li>ML Integration Guide: Deep dive into DataModule and metrics</li> <li>PyTorch Integration Guide: Complete PyTorch module reference</li> <li>Workflow Guide: Advanced workflow patterns and caching</li> <li>API Reference: Detailed API documentation</li> </ul> <p>For the complete example with more features, see <code>examples/text_classification/</code> in the repository.</p>"}]}